{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xicq53SkeQ6_"
      },
      "source": [
        "STATUS OnnxInputAdjustOpPass::AdjustResize(const CNodePtr &cnode) {\r\n",
        "  MS_ASSERT(cnode != nullptr);\r\n",
        "  auto node = cnode->input(0);\r\n",
        "  MS_ASSERT(value_node != nullptr);\r\n",
        "  auto value_node = node->cast<ValueNodePtr>();\r\n",
        "  if (value_node == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"cnode input0 is not a valuenode.\";\r\n",
        "    return lite::RET_ERROR;\r\n",
        "  }\r\n",
        "  MS_ASSERT(value_node->value() != nullptr);\r\n",
        "  auto primitive_c = value_node->value()->cast<PrimitiveCPtr>();\r\n",
        "  if (primitive_c == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"cnode has no primitive_c.\";\r\n",
        "    return lite::RET_ERROR;\r\n",
        "  }\r\n",
        "  auto primitive = primitive_c->primitiveT();\r\n",
        "  if (primitive == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"cnode has no schema::primitive.\";\r\n",
        "    return lite::RET_ERROR;\r\n",
        "  }\r\n",
        "  if (primitive->value.type != schema::PrimitiveType_Resize) {\r\n",
        "    MS_LOG(DEBUG) << \"cnode is not cast node.\";\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "  auto value = primitive->value.value;\r\n",
        "  if (value == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"value is nullptr.\";\r\n",
        "    return lite::RET_ERROR;\r\n",
        "  }\r\n",
        "  auto attr = reinterpret_cast<schema::ResizeT *>(value);\r\n",
        "  if (cnode->inputs().size() > 3 && attr->coordinateTransformMode == schema::CoordinateTransformMode_TF_CROP_AND_RESIZE) {\r\n",
        "    auto new_resize_inputs = cnode->inputs();\r\n",
        "    new_resize_inputs.erase(new_resize_inputs.begin()+1);\r\n",
        "    cnode->set_inputs(new_resize_inputs);\r\n",
        "  }\r\n",
        "  return lite::RET_OK;\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnCvRtW4eWPg"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "#include \"src/runtime/kernel/arm/fp32/nonzero_fp32.h\"\r\n",
        "#include <vector>\r\n",
        "#include \"schema/model_generated.h\"\r\n",
        "#include \"src/kernel_registry.h\"\r\n",
        "#include \"src/tensor.h\"\r\n",
        "#include \"nnacl/fp32/nonzero_fp32.h\"\r\n",
        "#include \"nnacl/op_base.h\"\r\n",
        "#include \"src/runtime/runtime_api.h\"\r\n",
        "#include \"include/errorcode.h\"\r\n",
        "\r\n",
        "using mindspore::kernel::KERNEL_ARCH::kCPU;\r\n",
        "using mindspore::lite::KernelRegistrar;\r\n",
        "using mindspore::lite::RET_ERROR;\r\n",
        "using mindspore::lite::RET_OK;\r\n",
        "using mindspore::schema::PrimitiveType_NonZero;\r\n",
        "\r\n",
        "namespace mindspore::kernel {\r\n",
        "int NonZeroCPUKernel::Init() {\r\n",
        "  if (!InferShapeDone()) {\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "  return ReSize();\r\n",
        "}\r\n",
        "\r\n",
        "int NonZeroCPUKernel::ReSize() {\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "int NonZeroCPUKernel::Run() {\r\n",
        "  auto in_tensor = in_tensors_.front();\r\n",
        "  auto out_tensor = out_tensors_.front();\r\n",
        "  auto input_data = reinterpret_cast<float *>(in_tensor->MutableData());\r\n",
        "  auto output_data = reinterpret_cast<int *>(out_tensor->MutableData());\r\n",
        "  auto input_dim_size = in_tensor->shape().size();\r\n",
        "  if (out_tensor->shape().size() != 2) {\r\n",
        "    MS_LOG(ERROR) << \"out tensor shape size must be equal to 2!\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto non_zero_nums = out_tensor->shape()[1];\r\n",
        "  int non_zero_count = 0;\r\n",
        "  std::vector coordiate_values(in_tensor->shape().size(), 0);\r\n",
        "  for (size_t i = 0; i < in_tensor->ElementsNum(); i += 1) {\r\n",
        "    if (input_data[i] != 0) {\r\n",
        "      for (size_t j = 0; j < input_dim_size; j++) {\r\n",
        "        output_data[non_zero_count + j * non_zero_nums] = coordiate_values[j];\r\n",
        "      }\r\n",
        "      non_zero_count++;\r\n",
        "    }\r\n",
        "    for (size_t idx = input_dim_size - 1; idx >= 0; --idx) {\r\n",
        "      if (coordiate_values[idx] != in_tensor->shape()[idx] - 1) {\r\n",
        "        coordiate_values[idx]++;\r\n",
        "        break;\r\n",
        "      }\r\n",
        "      coordiate_values[idx] = 0;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "kernel::LiteKernel *CpuNonZeroFp32KernelCreator(const std::vector<lite::Tensor *> &inputs,\r\n",
        "                                                const std::vector<lite::Tensor *> &outputs, OpParameter *opParameter,\r\n",
        "                                                const lite::InnerContext *ctx, const kernel::KernelKey &desc,\r\n",
        "                                                const mindspore::lite::PrimitiveC *primitive) {\r\n",
        "  if (opParameter == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"Input opParameter is nullptr!\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  if (ctx == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"Input context is nullptr!\";\r\n",
        "    free(opParameter);\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  if (ctx->thread_num_ == 0) {\r\n",
        "    MS_LOG(ERROR) << \"context thread num is 0!\";\r\n",
        "    free(opParameter);\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  auto *kernel = new(std::nothrow) NonZeroCPUKernel(opParameter, inputs, outputs, ctx, primitive);\r\n",
        "  if (kernel == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new NonZeroCPUKernel fail!\";\r\n",
        "    free(opParameter);\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  auto ret = kernel->Init();\r\n",
        "  if (ret != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"Init kernel failed, name: \" << opParameter->name_ << \", type: \"\r\n",
        "                  << schema::EnumNamePrimitiveType(static_cast<schema::PrimitiveType>(opParameter->type_));\r\n",
        "    delete kernel;\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  return kernel;\r\n",
        "}\r\n",
        "\r\n",
        "REG_KERNEL(kCPU, kNumberTypeFloat32, PrimitiveType_NonZero, CpuNonZeroFp32KernelCreator)\r\n",
        "REG_KERNEL(kCPU, kNumberTypeBool, PrimitiveType_NonZero, CpuNonZeroFp32KernelCreator)\r\n",
        "}  // namespace mindspore::kernel\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NlqI-pSq77v"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "#ifndef MINDSPORE_LITE_SRC_RUNTIME_KERNEL_ARM_FP32_NONZERO_H_\r\n",
        "#define MINDSPORE_LITE_SRC_RUNTIME_KERNEL_ARM_FP32_NONZERO_H_\r\n",
        "\r\n",
        "#include <vector>\r\n",
        "#include \"src/lite_kernel.h\"\r\n",
        "#include \"nnacl/fp32/nonzero_fp32.h\"\r\n",
        "\r\n",
        "namespace mindspore::kernel {\r\n",
        "class NonZeroCPUKernel : public LiteKernel {\r\n",
        " public:\r\n",
        "  NonZeroCPUKernel(OpParameter *parameter, const std::vector<lite::Tensor *> &inputs,\r\n",
        "                   const std::vector<lite::Tensor *> &outputs, const lite::InnerContext *ctx,\r\n",
        "                   const mindspore::lite::PrimitiveC *primitive)\r\n",
        "      : LiteKernel(parameter, inputs, outputs, ctx, primitive) {}\r\n",
        "\r\n",
        "  ~NonZeroCPUKernel() = default;\r\n",
        "\r\n",
        "  int Init() override;\r\n",
        "  int ReSize() override;\r\n",
        "  int Run() override;\r\n",
        " protected:\r\n",
        "  int thread_count_ = 1;\r\n",
        "};\r\n",
        "}  // namespace mindspore::kernel\r\n",
        "\r\n",
        "#endif  // MINDSPORE_LITE_SRC_RUNTIME_KERNEL_ARM_FP32_NONZERO_H_\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CKturhFMDJE"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2019-2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#include \"src/ops/nonzero.h\"\r\n",
        "#include <algorithm>\r\n",
        "#include \"include/errorcode.h\"\r\n",
        "#include \"src/common/log_adapter.h\"\r\n",
        "#include \"src/tensor.h\"\r\n",
        "#ifndef PRIMITIVE_WRITEABLE\r\n",
        "#include \"src/ops/ops_register.h\"\r\n",
        "#endif\r\n",
        "\r\n",
        "namespace mindspore {\r\n",
        "namespace lite {\r\n",
        "#ifdef PRIMITIVE_WRITEABLE\r\n",
        "int NonZero::UnPackAttr(const Primitive &prim, const std::vector<AnfNodePtr> &inputs) {\r\n",
        "  if (this->primitive_ == nullptr) {\r\n",
        "    this->primitive_ = new (std::nothrow) schema::PrimitiveT;\r\n",
        "    if (this->primitive_ == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"new primitiveT failed\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    this->primitive_->value.type = schema::PrimitiveType_NonZero;\r\n",
        "  }\r\n",
        "  if (this->primitive_->value.type != schema::PrimitiveType_NonZero) {\r\n",
        "    MS_LOG(ERROR) << \"Primitive type is error :\" << this->primitive_->value.type;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  if (this->primitive_->value.value == nullptr) {\r\n",
        "    this->primitive_->value.value = new (std::nothrow) schema::NonZeroT();\r\n",
        "    if (this->primitive_->value.value == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"new primitiveT value failed\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  PopulaterQuantParam(prim, inputs);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "#else\r\n",
        "int NonZero::UnPackToFlatBuilder(const schema::Primitive *primitive, flatbuffers::FlatBufferBuilder *fbb) {\r\n",
        "  MS_ASSERT(nullptr != primitive);\r\n",
        "  MS_ASSERT(nullptr != fbb);\r\n",
        "  auto attr = primitive->value_as_NonZero();\r\n",
        "  if (attr == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"value_as_Merge return nullptr\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto val_offset = schema::CreateNonZero(*fbb);\r\n",
        "  auto prim_offset = schema::CreatePrimitive(*fbb, schema::PrimitiveType_NonZero, val_offset.o);\r\n",
        "  fbb->Finish(prim_offset);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "PrimitiveC *NonZeroCreator(const schema::Primitive *primitive) { return PrimitiveC::NewPrimitiveC<NonZero>(primitive); }\r\n",
        "Registry NonZeroRegistry(schema::PrimitiveType_NonZero, NonZeroCreator);\r\n",
        "#endif\r\n",
        "template<typename T>\r\n",
        "void CalShape(const T *data, const std::vector<Tensor *> &inputs, std::vector<int> *out_shape) {\r\n",
        "  int input_count = inputs[0]->ElementsNum();\r\n",
        "  int input_dim_size = inputs[0]->shape().empty() ? 1 : inputs[0]->shape().size();\r\n",
        "  (*out_shape)[0] = input_dim_size;\r\n",
        "  int nonzero_size = 0;\r\n",
        "  for (int i = 0; i < input_count; i++) {\r\n",
        "    if (static_cast<int>(data[i]) != 0) {\r\n",
        "      nonzero_size++;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  if (nonzero_size == 0) {\r\n",
        "    *out_shape = {};\r\n",
        "  } else {\r\n",
        "    (*out_shape)[1] = nonzero_size / input_dim_size;\r\n",
        "  }\r\n",
        "}\r\n",
        "int NonZero::InferShape(std::vector<Tensor *> inputs_, std::vector<Tensor *> outputs_) {\r\n",
        "  MS_ASSERT(this->primitive_ != nullptr);\r\n",
        "  MS_ASSERT(inputs_.size() == 1);\r\n",
        "  auto input = inputs_.front();\r\n",
        "  MS_ASSERT(input != nullptr);\r\n",
        "  auto output = outputs_.front();\r\n",
        "  MS_ASSERT(output != nullptr);\r\n",
        "  output->set_data_type(input->data_type());\r\n",
        "  output->set_format(input->format());\r\n",
        "  if (!infer_flag()) {\r\n",
        "    return RET_INFER_INVALID;\r\n",
        "  }\r\n",
        "\r\n",
        "  std::vector<int> out_shape;\r\n",
        "  if (inputs_.size() == kSingleNum) {\r\n",
        "    auto input_tensor = inputs_.at(0);\r\n",
        "    if (input_tensor->data_c() == nullptr) {\r\n",
        "      MS_LOG(INFO) << \"Do infer shape in runtime.\";\r\n",
        "      return RET_INFER_INVALID;\r\n",
        "    }\r\n",
        "    size_t shape_size = input_tensor->ElementsNum();\r\n",
        "    switch (input_tensor->data_type()) {\r\n",
        "      case kNumberTypeInt8: {\r\n",
        "        auto data = reinterpret_cast<int8_t *>(input_tensor->MutableData());\r\n",
        "        CalShape<int8_t>(data, inputs_, &out_shape);\r\n",
        "      }\r\n",
        "        break;\r\n",
        "      case kNumberTypeInt32: {\r\n",
        "        auto data = reinterpret_cast<int32_t *>(input_tensor->MutableData());\r\n",
        "        CalShape<int32_t>(data, inputs_, &out_shape);\r\n",
        "      }\r\n",
        "        break;\r\n",
        "      case kNumberTypeInt64: {\r\n",
        "        auto data = reinterpret_cast<int64_t *>(input_tensor->MutableData());\r\n",
        "        CalShape<int64_t>(data, inputs_, &out_shape);\r\n",
        "      }\r\n",
        "        break;\r\n",
        "      case kNumberTypeFloat: {\r\n",
        "        auto data = reinterpret_cast<float *>(input_tensor->MutableData());\r\n",
        "        CalShape<float>(data, inputs_, &out_shape);\r\n",
        "      }\r\n",
        "        break;\r\n",
        "      case kNumberTypeUInt32: {\r\n",
        "        auto data = reinterpret_cast<uint32_t *>(input_tensor->MutableData());\r\n",
        "        CalShape<uint32_t>(data, inputs_, &out_shape);\r\n",
        "      }\r\n",
        "      case kNumberTypeBool: {\r\n",
        "        auto data = reinterpret_cast<uint32_t *>(input_tensor->MutableData());\r\n",
        "        CalShape<uint32_t>(data, inputs_, &out_shape);\r\n",
        "      }\r\n",
        "        break;\r\n",
        "      default: {\r\n",
        "        MS_LOG(ERROR) << \"NonZero weight tensor has unsupported dataType: \" << input_tensor->data_type();\r\n",
        "        return RET_INFER_ERR;\r\n",
        "      }\r\n",
        "    }\r\n",
        "  } else {\r\n",
        "    MS_LOG(ERROR) << \"inputs tensor size invalid.\";\r\n",
        "    return RET_INFER_ERR;\r\n",
        "  }\r\n",
        "  output->set_shape(out_shape);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "}  // namespace lite\r\n",
        "}  // namespace mindspore\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXQvUEPpMGcx"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2019-2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#ifndef MINDSPORE_LITE_SRC_OPS_NONZERO_H_\r\n",
        "#define MINDSPORE_LITE_SRC_OPS_NONZERO_H_\r\n",
        "\r\n",
        "#include <vector>\r\n",
        "#include <set>\r\n",
        "#include <cmath>\r\n",
        "#include <memory>\r\n",
        "\r\n",
        "#include \"src/ops/primitive_c.h\"\r\n",
        "\r\n",
        "namespace mindspore {\r\n",
        "namespace lite {\r\n",
        "class NonZero : public PrimitiveC {\r\n",
        " public:\r\n",
        "  NonZero() = default;\r\n",
        "  ~NonZero() = default;\r\n",
        "#ifdef PRIMITIVE_WRITEABLE\r\n",
        "  MS_DECLARE_PARENT(NonZero, PrimitiveC);\r\n",
        "  explicit NonZero(schema::PrimitiveT *primitive) : PrimitiveC(primitive) {}\r\n",
        "  int UnPackAttr(const Primitive &prim, const std::vector<AnfNodePtr> &inputs) override;\r\n",
        "#else\r\n",
        "  int UnPackToFlatBuilder(const schema::Primitive *primitive, flatbuffers::FlatBufferBuilder *fbb) override;\r\n",
        "#endif\r\n",
        "  int InferShape(std::vector<lite::Tensor *> inputs_, std::vector<lite::Tensor *> outputs_) override;\r\n",
        "};\r\n",
        "}  // namespace lite\r\n",
        "}  // namespace mindspore\r\n",
        "\r\n",
        "#endif  // MINDSPORE_LITE_SRC_OPS_NONZERO_H_\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-et1MoaMMgo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_zAUgY_MO_4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}