{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuppI1BtB91H"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/optimizer/fusion/conv_conv_fusion.h\"\n",
        "#include <memory>\n",
        "#include \"src/ops/primitive_c.h\"\n",
        "#include \"src/ops/conv2d.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"tools/optimizer/common/gllo_utils.h\"\n",
        "\n",
        "namespace mindspore::opt {\n",
        "namespace {\n",
        "constexpr size_t kConvNoBiasLen = 3;\n",
        "constexpr size_t kConvWithBiasLen = 4;\n",
        "constexpr size_t kConvWeightIndex = 2;\n",
        "constexpr size_t kConvBiasIndex = 3;\n",
        "constexpr size_t kNHWC_DIMS = 4;\n",
        "constexpr size_t kNHWC_NDim = 0;\n",
        "constexpr size_t kNHWC_HDim = 1;\n",
        "constexpr size_t kNHWC_WDim = 2;\n",
        "constexpr size_t kNHWC_CDim = 3;\n",
        "\n",
        "bool IsCommonConvNode(const BaseRef &n) {\n",
        "  if (utils::isa<CNodePtr>(n) || utils::isa<ValueNodePtr>(n)) {\n",
        "    auto type = opt::GetCNodeType(n);\n",
        "    return type == schema::PrimitiveType_Conv2D;\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "STATUS GenNewConvBias(const ParameterPtr &down_bias_node,\n",
        "                      const ParameterPtr &down_weight_node,\n",
        "                      const ParameterPtr &up_bias_node,\n",
        "                      const ParameterPtr &new_bias_node) {\n",
        "  float *down_bias_data;\n",
        "  if (down_bias_node != nullptr) {\n",
        "    auto down_bias_param = std::dynamic_pointer_cast<ParamValueLite>(down_bias_node->default_param());\n",
        "    auto down_bias_shape = down_bias_param->tensor_shape();\n",
        "    if (down_bias_shape.size() != 1) {\n",
        "      MS_LOG(ERROR) << \"cur conv_conv fusion only support scalar bias shape\";\n",
        "      return RET_FAILED;\n",
        "    }\n",
        "    down_bias_data = static_cast<float *>(down_bias_param->tensor_addr());\n",
        "  }\n",
        "  auto up_bias_param = std::dynamic_pointer_cast<ParamValueLite>(up_bias_node->default_param());\n",
        "  auto up_bias_shape = up_bias_param->tensor_shape();\n",
        "  if (up_bias_shape.size() != 1) {\n",
        "    MS_LOG(ERROR) << \"cur conv_conv fusion only support scalar bias shape\";\n",
        "    return RET_FAILED;\n",
        "  }\n",
        "  auto down_weight_param = std::dynamic_pointer_cast<ParamValueLite>(down_weight_node->default_param());\n",
        "  auto down_weight_data = static_cast<float *> (down_weight_param->tensor_addr());\n",
        "  auto down_weight_shape = down_weight_param->tensor_shape();\n",
        "  auto up_bias_data = static_cast<float *> (up_bias_param->tensor_addr());\n",
        "  int new_bias_size = down_weight_shape[0];\n",
        "  auto new_bias_data = new(std::nothrow) float[new_bias_size];\n",
        "  if (new_bias_data == nullptr) {\n",
        "    MS_LOG(ERROR) << \"tensor_data is nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  memset(new_bias_data, 0, new_bias_size * sizeof(float));\n",
        "  auto up_bias_size = up_bias_shape[0];\n",
        "  for (int i = 0; i < new_bias_size; i++) {\n",
        "    for (int j = 0; j < up_bias_size; j++) {\n",
        "      new_bias_data[i] += up_bias_data[j] * down_weight_data[i * up_bias_size + j];\n",
        "    }\n",
        "    if (down_bias_node != nullptr) {\n",
        "      new_bias_data[i] += down_bias_data[i];\n",
        "    }\n",
        "  }\n",
        "  ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\n",
        "  MS_ASSERT(param_value != nullptr);\n",
        "  param_value->set_tensor_shape({new_bias_size});\n",
        "  param_value->set_tensor_type(up_bias_param->tensor_type());\n",
        "  param_value->set_format(up_bias_param->format());\n",
        "  param_value->set_tensor_addr(new_bias_data);\n",
        "  param_value->set_tensor_size(sizeof(float) * new_bias_size);\n",
        "  new_bias_node->set_name(down_bias_node->fullname_with_scope());\n",
        "  new_bias_node->set_default_param(param_value);\n",
        "  new_bias_node->set_abstract(down_bias_node->abstract());\n",
        "  return RET_OK;\n",
        "}\n",
        "// up weight shape[cout0,h,w,cin0] down weight shape[cout1,1,1,cout0],new weight shape [cout1,h,w,cin0]\n",
        "STATUS GenNewConvWeight(const ParameterPtr &down_weight_node,\n",
        "                        const ParameterPtr &up_weight_node,\n",
        "                        const ParameterPtr &new_weight_node) {\n",
        "  auto down_weight_param = std::dynamic_pointer_cast<ParamValueLite>(down_weight_node->default_param());\n",
        "  auto down_weight_shape = down_weight_param->tensor_shape();\n",
        "  auto up_weight_param = std::dynamic_pointer_cast<ParamValueLite>(up_weight_node->default_param());\n",
        "  auto up_weight_shape = up_weight_param->tensor_shape();\n",
        "  auto up_weight_data = static_cast<float *> (up_weight_param->tensor_addr());\n",
        "  auto down_weight_data = static_cast<float *> (down_weight_param->tensor_addr());\n",
        "  int cout0 = up_weight_shape[0];\n",
        "  int cin0 = up_weight_shape[kNHWC_CDim];\n",
        "  int cout1 = down_weight_shape[0];\n",
        "  int window_size = up_weight_shape[kNHWC_WDim] * up_weight_shape[kNHWC_HDim];\n",
        "  auto new_weight_shape = up_weight_shape;\n",
        "  new_weight_shape[0] = down_weight_shape[0];\n",
        "  int size = std::accumulate(new_weight_shape.begin(), new_weight_shape.end(), 1, std::multiplies<>());\n",
        "  auto new_weight_data = new(std::nothrow) float[size];\n",
        "  if (new_weight_data == nullptr) {\n",
        "    MS_LOG(ERROR) << \"tensor_data is nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  memset(new_weight_data, 0, size * sizeof(float));\n",
        "\n",
        "  for (int i = 0; i < cout1; i++) {\n",
        "    auto down_weight_base = i * cout0;\n",
        "    auto new_weight_base = i * window_size * cin0;\n",
        "    for (int j = 0; j < cin0; j++) {\n",
        "      for (int k = 0; k < cout0; k++) {\n",
        "        auto up_weight_offset = k * window_size * cin0 + j;\n",
        "        auto down_weight_offset = down_weight_base + k;\n",
        "        auto new_weight_offset = new_weight_base + j;\n",
        "        for (int m = 0; m < window_size; m++) {\n",
        "          new_weight_data[new_weight_offset + cin0 * m] +=\n",
        "              up_weight_data[up_weight_offset + cin0 * m] * down_weight_data[down_weight_offset];\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\n",
        "  MS_ASSERT(param_value != nullptr);\n",
        "  param_value->set_tensor_shape(new_weight_shape);\n",
        "  param_value->set_tensor_type(up_weight_param->tensor_type());\n",
        "  param_value->set_format(up_weight_param->format());\n",
        "  param_value->set_tensor_addr(new_weight_data);\n",
        "  param_value->set_tensor_size(sizeof(float) * size);\n",
        "  new_weight_node->set_name(down_weight_node->fullname_with_scope());\n",
        "  new_weight_node->set_default_param(param_value);\n",
        "  new_weight_node->set_abstract(down_weight_node->abstract());\n",
        "  return RET_OK;\n",
        "}\n",
        "}\n",
        "const BaseRef ConvConvFusion::DefinePattern() const {\n",
        "  auto up_conv_var = std::make_shared<CondVar>(IsCommonConvNode);\n",
        "  auto down_conv_var = std::make_shared<CondVar>(IsCommonConvNode);\n",
        "  auto down_weight_var = std::make_shared<CondVar>(IsParamNode);\n",
        "  auto down_bias_var = std::make_shared<SeqVar>();\n",
        "  return VectorRef({down_conv_var, up_conv_var, down_weight_var, down_bias_var});\n",
        "}\n",
        "\n",
        "// conv->conv1x1 fusion conv (w1x+b)w2+c = (w1*w2)*x+(w2*b+c)\n",
        "const AnfNodePtr ConvConvFusion::Process(const FuncGraphPtr &func_graph, const AnfNodePtr &node,\n",
        "                                         const EquivPtr &) const {\n",
        "  if (CheckIfFuncGraphIsNull(func_graph) != lite::RET_OK || CheckIfAnfNodeIsNull(node) != lite::RET_OK) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto down_conv_cnode = node->cast<CNodePtr>();\n",
        "  if (down_conv_cnode->inputs().size() != kConvWithBiasLen && down_conv_cnode->inputs().size() != kConvNoBiasLen) {\n",
        "    MS_LOG(WARNING) << \"conv node inputs error ,name:\" << down_conv_cnode->fullname_with_scope();\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto down_weight_parameter = down_conv_cnode->input(kConvWeightIndex)->cast<ParameterPtr>();\n",
        "  auto down_weight_value = std::dynamic_pointer_cast<ParamValueLite>(down_weight_parameter->default_param());\n",
        "  auto down_weight_shape = down_weight_value->tensor_shape();\n",
        "  auto down_weight_type = down_weight_value->tensor_type();\n",
        "  // down conv node filter must 1x1,only support float32\n",
        "  if (down_weight_shape.size() != kNHWC_DIMS || down_weight_type != kNumberTypeFloat32\n",
        "      || (down_weight_shape[kNHWC_HDim] != 1 || down_weight_shape[kNHWC_WDim] != 1)) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto up_conv_cnode = down_conv_cnode->input(1)->cast<CNodePtr>();\n",
        "  if (up_conv_cnode->inputs().size() != kConvWithBiasLen && up_conv_cnode->inputs().size() != kConvNoBiasLen) {\n",
        "    MS_LOG(WARNING) << \"conv node inputs error ,name:\" << up_conv_cnode->fullname_with_scope();\n",
        "    return nullptr;\n",
        "  }\n",
        "  // multi output need skip\n",
        "  if (IsMultiOutputTensors(func_graph, up_conv_cnode)) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto primitive = GetValueNode<std::shared_ptr<lite::PrimitiveC>>(up_conv_cnode->input(0));\n",
        "  auto up_conv_primitive = utils::cast<std::shared_ptr<mindspore::lite::Conv2D>>(primitive);\n",
        "  // up conv node must no activation\n",
        "  if (up_conv_primitive == nullptr || up_conv_primitive->GetActivationType() != schema::ActivationType_NO_ACTIVATION) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto up_weight_parameter = up_conv_cnode->input(kConvWeightIndex)->cast<ParameterPtr>();\n",
        "  auto new_weight_paramter = func_graph->add_parameter();\n",
        "  if (GenNewConvWeight(down_weight_parameter, up_weight_parameter, new_weight_paramter) != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"GenNewConvWeight failed.\";\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto manager = func_graph->manager();\n",
        "  manager->Replace(down_weight_parameter, new_weight_paramter);\n",
        "  // up conv node no bias\n",
        "  if (up_conv_cnode->inputs().size() == kConvWithBiasLen) {\n",
        "    ParameterPtr down_bias_parameter;\n",
        "    if (down_conv_cnode->inputs().size() == kConvWithBiasLen) {\n",
        "      down_bias_parameter = down_conv_cnode->input(kConvBiasIndex)->cast<ParameterPtr>();\n",
        "    }\n",
        "    auto up_bias_parameter = up_conv_cnode->input(kConvBiasIndex)->cast<ParameterPtr>();\n",
        "    auto new_bias_paramter = func_graph->add_parameter();\n",
        "    if (GenNewConvBias(down_bias_parameter, down_weight_parameter, up_bias_parameter, new_bias_paramter) != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"GenNewConvBias failed.\";\n",
        "      return nullptr;\n",
        "    }\n",
        "    if (down_conv_cnode->inputs().size() == kConvWithBiasLen) {\n",
        "      manager->Replace(down_bias_parameter, new_bias_paramter);\n",
        "    } else {\n",
        "      down_conv_cnode->add_input(new_bias_paramter);\n",
        "    }\n",
        "  } else {\n",
        "    MS_LOG(INFO) << \"up conv node has no bias,no need replace bias.\";\n",
        "  }\n",
        "  // delete up conv node\n",
        "  manager->Replace(up_conv_cnode, up_conv_cnode->input(1));\n",
        "  return nullptr;\n",
        "}\n",
        "}  // namespace mindspore::opt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oUv5qMcvm8L"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#ifndef MINDSPORE_LITE_SRC_PASS_FUSION_CONV_CONV_FUSION_H_\n",
        "#define MINDSPORE_LITE_SRC_PASS_FUSION_CONV_CONV_FUSION_H_\n",
        "\n",
        "#include <string>\n",
        "#include \"backend/optimizer/common/optimizer.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "class ConvConvFusion : public PatternProcessPass {\n",
        " public:\n",
        "  explicit ConvConvFusion(bool multigraph = true) : PatternProcessPass(\"conv_conv_fusion\", multigraph) {}\n",
        "  ~ConvConvFusion() override = default;\n",
        "  const BaseRef DefinePattern() const override;\n",
        "  const AnfNodePtr Process(const FuncGraphPtr &, const AnfNodePtr &, const EquivPtr &) const override;\n",
        "};\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n",
        "#endif  // MINDSPORE_LITE_SRC_PASS_FUSION_CONV_CONV_FUSION_H_\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}