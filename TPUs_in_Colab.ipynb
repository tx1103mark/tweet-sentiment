{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIWO5XRfhbXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include \"tools/optimizer/fusion/conv_biasadd_fusion.h\"\n",
        "#include <memory>\n",
        "#include \"src/ops/conv2d.h\"\n",
        "#include \"src/ops/depthwise_conv2d.h\"\n",
        "#include \"src/ops/deconv2d.h\"\n",
        "#include \"src/ops/add.h\"\n",
        "#include \"src/ops/primitive_c.h\"\n",
        "#include \"src/param_value_lite.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"utils/utils.h\"\n",
        "#include \"tools/optimizer/common/gllo_utils.h\"\n",
        "#include \"securec/include/securec.h\"\n",
        "\n",
        "namespace mindspore::opt {\n",
        "namespace {\n",
        "constexpr size_t kAddInputsLength = 3;\n",
        "constexpr size_t kAddWEIGHTINDEX = 2;\n",
        "constexpr size_t kConvWeightIndex = 2;\n",
        "constexpr size_t kConvBiasIndex = 3;\n",
        "constexpr size_t kConvNoBiasLen = 3;\n",
        "constexpr size_t kConvWithBiasLen = 4;\n",
        "bool IsConvExtendNode(const BaseRef &n) {\n",
        "  if (utils::isa<CNodePtr>(n) || utils::isa<ValueNodePtr>(n)) {\n",
        "    auto type = opt::GetCNodeType(n);\n",
        "    return type == schema::PrimitiveType_Conv2D || type == schema::PrimitiveType_DepthwiseConv2D ||\n",
        "        type == schema::PrimitiveType_DeConv2D;\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "bool IsAddNode(const BaseRef &n) {\n",
        "  if (utils::isa<CNodePtr>(n) || utils::isa<ValueNodePtr>(n)) {\n",
        "    auto type = opt::GetCNodeType(n);\n",
        "    return type == schema::PrimitiveType_Add || type == schema::PrimitiveType_BiasAdd;\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "\n",
        "int Get_Kenrnel_nums(const CNodePtr &conv_node) {\n",
        "  MS_ASSERT(conv_node != nullptr);\n",
        "  auto value_primitive = conv_node->input(0);\n",
        "  auto value_node = value_primitive->cast<ValueNodePtr>();\n",
        "  MS_ASSERT(value_node != nullptr);\n",
        "  auto value = value_node->value();\n",
        "  MS_ASSERT(value != nullptr);\n",
        "  auto primitive = value->cast<PrimitiveCPtr>();\n",
        "  MS_ASSERT(primitive != nullptr);\n",
        "  auto type = (schema::PrimitiveType) primitive->Type();\n",
        "  if (type == schema::PrimitiveType_Conv2D) {\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::Conv2D>>(primitive));\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::Conv2D>>(primitive);\n",
        "    MS_ASSERT(primc != nullptr);\n",
        "    return primc->GetChannelOut();\n",
        "  } else if (type == schema::PrimitiveType_DepthwiseConv2D) {\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive));\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive);\n",
        "    MS_ASSERT(primc != nullptr);\n",
        "    return primc->GetChannelMultiplier() * primc->GetChannelIn();\n",
        "  } else if (type == schema::PrimitiveType_DeConv2D) {\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DeConv2D>>(primitive));\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::DeConv2D>>(primitive);\n",
        "    MS_ASSERT(primc != nullptr);\n",
        "    return primc->GetChannelOut();\n",
        "  } else {\n",
        "    MS_LOG(ERROR) << \"Unsupported opType, \" << type;\n",
        "    return 0;\n",
        "  }\n",
        "}\n",
        "void GenConvNewBias(const FuncGraphPtr &func_graph, const CNodePtr &conv_node, const CNodePtr &bias_node) {\n",
        "  AnfNodePtr conv_bias_node = nullptr;\n",
        "  AnfNodePtr conv_weight_node = nullptr;\n",
        "  if (conv_node->inputs().size() == kConvNoBiasLen) {\n",
        "    conv_weight_node = conv_node->input(kConvWeightIndex);\n",
        "  } else if (conv_node->inputs().size() == kConvWithBiasLen) {\n",
        "    conv_weight_node = conv_node->input(kConvWeightIndex);\n",
        "    conv_bias_node = conv_node->input(kConvBiasIndex);\n",
        "  } else {\n",
        "    MS_LOG(EXCEPTION) << \"conv node:\" << conv_node->DebugString() << \"inputs size must 3 or 4\";\n",
        "  }\n",
        "  auto kernel_nums = Get_Kenrnel_nums(conv_node);\n",
        "  if (kernel_nums <= 0) {\n",
        "    MS_LOG(EXCEPTION) << \"kernel num less than 0\";\n",
        "  }\n",
        "  auto add_bias_data = new(std::nothrow) float[kernel_nums];\n",
        "  if (add_bias_data == nullptr) {\n",
        "    MS_LOG(ERROR) << \"tensor_data is nullptr\";\n",
        "    return;\n",
        "  }\n",
        "  auto bias_add_weight = bias_node->input(kAddWEIGHTINDEX);\n",
        "  CheckIfNodeIsParam(bias_add_weight);\n",
        "  auto add_weight_param = bias_add_weight->cast<ParameterPtr>()->default_param();\n",
        "  auto add_weight_tensor = std::dynamic_pointer_cast<ParamValueLite>(add_weight_param);\n",
        "  auto add_weight_data = reinterpret_cast<float *>(add_weight_tensor->tensor_addr());\n",
        "  auto add_weight_shape = add_weight_tensor->tensor_shape();\n",
        "  if (add_weight_shape.empty() || (add_weight_shape.size() == 1 && add_weight_shape[0] == 1)) {\n",
        "    for (int i = 0; i < kernel_nums; i++) {\n",
        "      add_bias_data[i] = *add_weight_data;\n",
        "    }\n",
        "  } else {\n",
        "    if (EOK != memcpy_s(add_bias_data, kernel_nums * sizeof(float), add_weight_data, kernel_nums * sizeof(float))) {\n",
        "      MS_LOG(EXCEPTION) << \"memset_s conv_bias_data failed\";\n",
        "    }\n",
        "  }\n",
        "  if (conv_bias_node != nullptr) {\n",
        "    CheckIfNodeIsParam(conv_bias_node);\n",
        "    auto conv_bias_param = conv_bias_node->cast<ParameterPtr>()->default_param();\n",
        "    auto conv_bias_tensor = std::dynamic_pointer_cast<ParamValueLite>(conv_bias_param);\n",
        "    if (conv_bias_tensor->tensor_shape().empty() || conv_bias_tensor->tensor_shape()[0] != kernel_nums) {\n",
        "      MS_LOG(EXCEPTION) << \"conv_bias_node shape error\";\n",
        "    }\n",
        "    auto conv_bias_data = reinterpret_cast<float *>(conv_bias_tensor->tensor_addr());\n",
        "    for (int i = 0; i < kernel_nums; i++) {\n",
        "      conv_bias_data[i] += add_bias_data[i];\n",
        "    }\n",
        "    delete[] add_bias_data;\n",
        "  } else {\n",
        "    auto conv_weight_param = conv_weight_node->cast<ParameterPtr>()->default_param();\n",
        "    auto conv_weight_tensor = std::dynamic_pointer_cast<ParamValueLite>(conv_weight_param);\n",
        "    auto conv_new_bias = AddNewBiasNode(add_bias_data, func_graph, kernel_nums, conv_weight_tensor);\n",
        "    conv_new_bias->set_name(conv_node->fullname_with_scope() + \"_bias\");\n",
        "    conv_node->add_input(conv_new_bias);\n",
        "  }\n",
        "}\n",
        "}  // namespace\n",
        "const BaseRef ConvBiasaddFusion::DefinePattern() const {\n",
        "  auto conv_var = std::make_shared<CondVar>(IsConvExtendNode);\n",
        "  auto add_var = std::make_shared<CondVar>(IsAddNode);\n",
        "  auto weight_var = std::make_shared<CondVar>(IsParamNode);\n",
        "  return VectorRef({add_var, conv_var, weight_var});\n",
        "}\n",
        "\n",
        "const AnfNodePtr ConvBiasaddFusion::Process(const FuncGraphPtr &func_graph, const AnfNodePtr &node,\n",
        "                                            const EquivPtr &) const {\n",
        "  MS_LOG(DEBUG) << \"Enter pass process\";\n",
        "  CheckIfFuncGraphIsNull(func_graph);\n",
        "\n",
        "  CheckIfAnfNodeIsNull(node);\n",
        "  auto add_node = node->cast<CNodePtr>();\n",
        "  CheckIfCNodeIsNull(add_node);\n",
        "  CheckInputSize(add_node, kAddInputsLength);\n",
        "\n",
        "  if (GetCNodeType(add_node) == schema::PrimitiveType_Add) {\n",
        "    auto primitive_c = GetValueNode<std::shared_ptr<lite::PrimitiveC>>(add_node->input(0));\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::Add>>(primitive_c));\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::Add>>(primitive_c);\n",
        "    MS_ASSERT(primc != nullptr);\n",
        "    if (primc->GetActivationType() != schema::ActivationType_NO_ACTIVATION) {\n",
        "      return add_node;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  AnfNodePtr conv_node_anf = add_node->input(1);\n",
        "  CheckIfAnfNodeIsNull(conv_node_anf);\n",
        "  if (IsMultiOutputTensors(func_graph, conv_node_anf)) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto conv_node = conv_node_anf->cast<CNodePtr>();\n",
        "  CheckIfCNodeIsNull(conv_node);\n",
        "  GenConvNewBias(func_graph, conv_node, add_node);\n",
        "  auto primitive_c = GetValueNode<std::shared_ptr<lite::PrimitiveC>>(conv_node->input(0));\n",
        "  MS_ASSERT(primitive_c != nullptr);\n",
        "  auto type = primitive_c->Type();\n",
        "  if (type == schema::PrimitiveType_Conv2D) {\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::Conv2D>>(primitive_c));\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::Conv2D>>(primitive_c);\n",
        "    MS_ASSERT(primc != nullptr);\n",
        "    primc->SetHasBias(true);\n",
        "  } else if (type == schema::PrimitiveType_DepthwiseConv2D) {\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive_c));\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive_c);\n",
        "    MS_ASSERT(primc != nullptr);\n",
        "    primc->SetHasBias(true);\n",
        "  } else if (type == schema::PrimitiveType_DeConv2D) {\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DeConv2D>>(primitive_c));\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::DeConv2D>>(primitive_c);\n",
        "    MS_ASSERT(primc != nullptr);\n",
        "    primc->SetHasBias(true);\n",
        "  } else {\n",
        "    MS_LOG(ERROR) << \"Unsupported opType, \" << type;\n",
        "    return nullptr;\n",
        "  }\n",
        "  return conv_node;\n",
        "}\n",
        "}  // namespace mindspore::opt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVuWr1Zqq_Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2019-2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"src/ops/log.h\"\n",
        "#include <memory>\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "#ifdef PRIMITIVE_WRITEABLE\n",
        "int Log::UnPackAttr(const Primitive &prim, const std::vector<AnfNodePtr> &inputs) {\n",
        "  if (this->primitive_ == nullptr) {\n",
        "    this->primitive_ = new (std::nothrow) schema::PrimitiveT;\n",
        "    if (this->primitive_ == nullptr) {\n",
        "      MS_LOG(ERROR) << \"new primitiveT failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "    this->primitive_->value.type = schema::PrimitiveType_Log;\n",
        "  }\n",
        "  if (this->primitive_->value.type != schema::PrimitiveType_Log) {\n",
        "    MS_LOG(ERROR) << \"Primitive type is error :\" << this->primitive_->value.type;\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  auto attr = std::make_unique<schema::LogT>();\n",
        "  this->primitive_->value.value = attr.release();\n",
        "  if (this->primitive_->value.value == nullptr) {\n",
        "    MS_LOG(ERROR) << \"new primitiveT value failed\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "#else\n",
        "int Log::UnPackToFlatBuilder(const schema::Primitive *primitive, flatbuffers::FlatBufferBuilder *fbb) {\n",
        "  MS_ASSERT(nullptr != primitive);\n",
        "  MS_ASSERT(nullptr != fbb);\n",
        "  auto val_offset = schema::CreateLog(*fbb);\n",
        "  auto prim_offset = schema::CreatePrimitive(*fbb, schema::PrimitiveType_Log, val_offset.o);\n",
        "  fbb->Finish(prim_offset);\n",
        "  return RET_OK;\n",
        "}\n",
        "#endif\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZGU4PDAsNQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2019-2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"src/ops/elu.h\"\n",
        "#include <memory>\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "#ifdef PRIMITIVE_WRITEABLE\n",
        "float Elu::GetAlpha() const { return this->primitive_->value.AsElu()->alpha; }\n",
        "\n",
        "void Elu::SetAlpha(float alpha) { this->primitive_->value.AsElu()->alpha = alpha; }\n",
        "\n",
        "int Elu::UnPackAttr(const Primitive &prim, const std::vector<AnfNodePtr> &inputs) {\n",
        "  if (this->primitive_ == nullptr) {\n",
        "    this->primitive_ = new (std::nothrow) schema::PrimitiveT;\n",
        "    if (this->primitive_ == nullptr) {\n",
        "      MS_LOG(ERROR) << \"new primitiveT failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "    this->primitive_->value.type = schema::PrimitiveType_Elu;\n",
        "  }\n",
        "  if (this->primitive_->value.type != schema::PrimitiveType_Elu) {\n",
        "    MS_LOG(ERROR) << \"Primitive type is error :\" << this->primitive_->value.type;\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  auto attr = std::make_unique<schema::EluT>();\n",
        "  this->primitive_->value.value = attr.release();\n",
        "  if (this->primitive_->value.value == nullptr) {\n",
        "    MS_LOG(ERROR) << \"new primitiveT value failed\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "#else\n",
        "int Elu::UnPackToFlatBuilder(const schema::Primitive *primitive, flatbuffers::FlatBufferBuilder *fbb) {\n",
        "  MS_ASSERT(nullptr != primitive);\n",
        "  MS_ASSERT(nullptr != fbb);\n",
        "  auto attr = primitive->value_as_Elu();\n",
        "  if (attr == nullptr) {\n",
        "    MS_LOG(ERROR) << \"value_as_Elu return nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  auto val_offset = schema::CreateElu(*fbb, attr->alpha());\n",
        "  auto prim_offset = schema::CreatePrimitive(*fbb, schema::PrimitiveType_Elu, val_offset.o);\n",
        "  fbb->Finish(prim_offset);\n",
        "  return RET_OK;\n",
        "}\n",
        "float Elu::GetAlpha() const { return this->primitive_->value_as_Elu()->alpha(); }\n",
        "\n",
        "#endif\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B24P1lcrlmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2019-2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"src/ops/deconv2d.h\"\n",
        "#include <memory>\n",
        "#include <string>\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "#ifdef PRIMITIVE_WRITEABLE\n",
        "int DeConv2D::GetFormat() const { return this->primitive_->value.AsDeConv2D()->format; }\n",
        "int DeConv2D::GetGroup() const { return this->primitive_->value.AsDeConv2D()->group; }\n",
        "int DeConv2D::GetChannelIn() const { return this->primitive_->value.AsDeConv2D()->channelIn; }\n",
        "int DeConv2D::GetChannelOut() const { return this->primitive_->value.AsDeConv2D()->channelOut; }\n",
        "int DeConv2D::GetKernelW() const { return this->primitive_->value.AsDeConv2D()->kernelW; }\n",
        "int DeConv2D::GetKernelH() const { return this->primitive_->value.AsDeConv2D()->kernelH; }\n",
        "int DeConv2D::GetStrideW() const { return this->primitive_->value.AsDeConv2D()->strideW; }\n",
        "int DeConv2D::GetStrideH() const { return this->primitive_->value.AsDeConv2D()->strideH; }\n",
        "int DeConv2D::GetPadMode() const { return this->primitive_->value.AsDeConv2D()->padMode; }\n",
        "int DeConv2D::GetPadUp() const { return this->primitive_->value.AsDeConv2D()->padUp; }\n",
        "int DeConv2D::GetPadDown() const { return this->primitive_->value.AsDeConv2D()->padDown; }\n",
        "int DeConv2D::GetPadLeft() const { return this->primitive_->value.AsDeConv2D()->padLeft; }\n",
        "int DeConv2D::GetPadRight() const { return this->primitive_->value.AsDeConv2D()->padRight; }\n",
        "int DeConv2D::GetDilateW() const { return this->primitive_->value.AsDeConv2D()->dilateW; }\n",
        "int DeConv2D::GetDilateH() const { return this->primitive_->value.AsDeConv2D()->dilateH; }\n",
        "bool DeConv2D::GetHasBias() const { return this->primitive_->value.AsDeConv2D()->hasBias; }\n",
        "int DeConv2D::GetActivationType() const { return this->primitive_->value.AsDeConv2D()->activationType; }\n",
        "\n",
        "void DeConv2D::SetFormat(int format) { this->primitive_->value.AsDeConv2D()->format = (schema::Format)format; }\n",
        "void DeConv2D::SetGroup(int group) { this->primitive_->value.AsDeConv2D()->group = group; }\n",
        "void DeConv2D::SetChannelIn(int channel_in) { this->primitive_->value.AsDeConv2D()->channelIn = channel_in; }\n",
        "void DeConv2D::SetChannelOut(int channel_out) { this->primitive_->value.AsDeConv2D()->channelOut = channel_out; }\n",
        "void DeConv2D::SetKernelW(int kernel_w) { this->primitive_->value.AsDeConv2D()->kernelW = kernel_w; }\n",
        "void DeConv2D::SetKernelH(int kernel_h) { this->primitive_->value.AsDeConv2D()->kernelH = kernel_h; }\n",
        "void DeConv2D::SetStrideW(int stride_w) { this->primitive_->value.AsDeConv2D()->strideW = stride_w; }\n",
        "void DeConv2D::SetStrideH(int stride_h) { this->primitive_->value.AsDeConv2D()->strideH = stride_h; }\n",
        "void DeConv2D::SetPadMode(int pad_mode) { this->primitive_->value.AsDeConv2D()->padMode = (schema::PadMode)pad_mode; }\n",
        "void DeConv2D::SetPadUp(int pad_up) { this->primitive_->value.AsDeConv2D()->padUp = pad_up; }\n",
        "void DeConv2D::SetPadDown(int pad_down) { this->primitive_->value.AsDeConv2D()->padDown = pad_down; }\n",
        "void DeConv2D::SetPadLeft(int pad_left) { this->primitive_->value.AsDeConv2D()->padLeft = pad_left; }\n",
        "void DeConv2D::SetPadRight(int pad_right) { this->primitive_->value.AsDeConv2D()->padRight = pad_right; }\n",
        "void DeConv2D::SetDilateW(int dilate_w) { this->primitive_->value.AsDeConv2D()->dilateW = dilate_w; }\n",
        "void DeConv2D::SetDilateH(int dilate_h) { this->primitive_->value.AsDeConv2D()->dilateH = dilate_h; }\n",
        "void DeConv2D::SetHasBias(bool has_bias) { this->primitive_->value.AsDeConv2D()->hasBias = has_bias; }\n",
        "void DeConv2D::SetActivationType(int activation_type) {\n",
        "  this->primitive_->value.AsDeConv2D()->activationType = (schema::ActivationType)activation_type;\n",
        "}\n",
        "void DeConv2D::PopulaterDeConv2DSingleGroup(const Primitive &prim, schema::PrimitiveT *primitive, const int &group) {\n",
        "  auto attr = std::make_unique<schema::DeConv2DT>();\n",
        "  attr->group = group;\n",
        "  auto format = GetValue<std::string>(prim.GetAttr(\"data_format\"));\n",
        "  if (format == \"NCHW\") {\n",
        "    attr->format = schema::Format_NCHW;\n",
        "  } else if (format == \"NHWC\") {\n",
        "    attr->format = schema::Format_NHWC;\n",
        "  } else {\n",
        "    attr->format = schema::Format_NUM_OF_FORMAT;\n",
        "  }\n",
        "  auto pad_list = GetValue<std::vector<int>>(prim.GetAttr(\"pad_list\"));\n",
        "  attr->padUp = pad_list[0];\n",
        "  attr->padDown = pad_list[1];\n",
        "  attr->padLeft = pad_list[2];\n",
        "  attr->padRight = pad_list[3];\n",
        "\n",
        "  auto dilation = GetValue<std::vector<int>>(prim.GetAttr(\"dilation\"));\n",
        "  attr->dilateH = dilation[0];\n",
        "  attr->dilateW = dilation[1];\n",
        "\n",
        "  auto kernel_size = GetValue<std::vector<int>>(prim.GetAttr(\"kernel_size\"));\n",
        "  attr->kernelH = kernel_size[0];\n",
        "  attr->kernelW = kernel_size[1];\n",
        "\n",
        "  auto stride = GetValue<std::vector<int>>(prim.GetAttr(\"stride\"));\n",
        "  attr->strideH = stride[0];\n",
        "  attr->strideW = stride[1];\n",
        "\n",
        "  attr->channelOut = GetValue<int>(prim.GetAttr(\"out_channel\"));\n",
        "\n",
        "  auto pad_mode = GetValue<std::string>(prim.GetAttr(\"pad_mode\"));\n",
        "  if (pad_mode == \"valid\" || pad_mode == \"VALID\") {\n",
        "    attr->padMode = schema::PadMode_VALID;\n",
        "  } else if (pad_mode == \"same\" || pad_mode == \"SAME\") {\n",
        "    attr->padMode = schema::PadMode_SAME;\n",
        "  } else {\n",
        "    attr->padMode = schema::PadMode_NOTSET;\n",
        "  }\n",
        "\n",
        "  if (prim.GetAttr(\"activation_name\") != nullptr) {\n",
        "    std::string activate_name = GetValue<std::string>(prim.GetAttr(\"activation_name\"));\n",
        "    attr->activationType = kActivationTypeMap[activate_name];\n",
        "  } else {\n",
        "    attr->activationType = schema::ActivationType_NO_ACTIVATION;\n",
        "  }\n",
        "\n",
        "  //  attr->padMode = schema::PadMode_SAME;\n",
        "  //  attr->activationType = schema::ActivationType_RELU;\n",
        "  primitive->value.type = schema::PrimitiveType_DeConv2D;\n",
        "  primitive->value.value = attr.release();\n",
        "}\n",
        "\n",
        "int DeConv2D::UnPackAttr(const Primitive &prim, const std::vector<AnfNodePtr> &inputs) {\n",
        "  if (this->primitive_ == nullptr) {\n",
        "    this->primitive_ = new (std::nothrow) schema::PrimitiveT;\n",
        "    if (this->primitive_ == nullptr) {\n",
        "      MS_LOG(ERROR) << \"new primitiveT failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "    this->primitive_->value.type = schema::PrimitiveType_DeConv2D;\n",
        "  }\n",
        "  if (this->primitive_->value.type != schema::PrimitiveType_DeConv2D) {\n",
        "    MS_LOG(ERROR) << \"primitive_ type is error:\" << this->primitive_->value.type;\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  int group = GetValue<int>(prim.GetAttr(\"group\"));\n",
        "  if (group == 1) {\n",
        "    PopulaterDeConv2DSingleGroup(prim, this->primitive_, group);\n",
        "  }\n",
        "\n",
        "  if (GetQuantType() == schema::QuantType_AwareTraining) {\n",
        "    std::vector<std::vector<schema::QuantParamT>> vecInputQuantParam;\n",
        "    std::vector<std::vector<schema::QuantParamT>> vecOutputQuantParam;\n",
        "    PopulaterQuantParam(prim, &vecInputQuantParam, &vecOutputQuantParam);\n",
        "    SetInputQuantParam(vecInputQuantParam);\n",
        "    SetOutputQuantParam(vecOutputQuantParam);\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "#else\n",
        "int DeConv2D::UnPackToFlatBuilder(const schema::Primitive *primitive, flatbuffers::FlatBufferBuilder *fbb) {\n",
        "  MS_ASSERT(nullptr != primitive);\n",
        "  MS_ASSERT(nullptr != fbb);\n",
        "  auto attr = primitive->value_as_DeConv2D();\n",
        "  if (attr == nullptr) {\n",
        "    MS_LOG(ERROR) << \"value_as_DeConv2D return nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  auto val_offset = schema::CreateDeConv2D(\n",
        "    *fbb, attr->format(), attr->group(), attr->channelIn(), attr->channelOut(), attr->kernelW(), attr->kernelH(),\n",
        "    attr->strideW(), attr->strideH(), attr->padMode(), attr->padUp(), attr->padDown(), attr->padLeft(),\n",
        "    attr->padRight(), attr->dilateW(), attr->dilateH(), attr->hasBias(), attr->activationType());\n",
        "  auto prim_offset = schema::CreatePrimitive(*fbb, schema::PrimitiveType_DeConv2D, val_offset.o);\n",
        "  fbb->Finish(prim_offset);\n",
        "  return RET_OK;\n",
        "}\n",
        "int DeConv2D::GetFormat() const { return this->primitive_->value_as_DeConv2D()->format(); }\n",
        "int DeConv2D::GetGroup() const { return this->primitive_->value_as_DeConv2D()->group(); }\n",
        "int DeConv2D::GetChannelIn() const { return this->primitive_->value_as_DeConv2D()->channelIn(); }\n",
        "int DeConv2D::GetChannelOut() const { return this->primitive_->value_as_DeConv2D()->channelOut(); }\n",
        "int DeConv2D::GetKernelW() const { return this->primitive_->value_as_DeConv2D()->kernelW(); }\n",
        "int DeConv2D::GetKernelH() const { return this->primitive_->value_as_DeConv2D()->kernelH(); }\n",
        "int DeConv2D::GetStrideW() const { return this->primitive_->value_as_DeConv2D()->strideW(); }\n",
        "int DeConv2D::GetStrideH() const { return this->primitive_->value_as_DeConv2D()->strideH(); }\n",
        "int DeConv2D::GetPadMode() const { return this->primitive_->value_as_DeConv2D()->padMode(); }\n",
        "int DeConv2D::GetPadUp() const { return this->primitive_->value_as_DeConv2D()->padUp(); }\n",
        "int DeConv2D::GetPadDown() const { return this->primitive_->value_as_DeConv2D()->padDown(); }\n",
        "int DeConv2D::GetPadLeft() const { return this->primitive_->value_as_DeConv2D()->padLeft(); }\n",
        "int DeConv2D::GetPadRight() const { return this->primitive_->value_as_DeConv2D()->padRight(); }\n",
        "int DeConv2D::GetDilateW() const { return this->primitive_->value_as_DeConv2D()->dilateW(); }\n",
        "int DeConv2D::GetDilateH() const { return this->primitive_->value_as_DeConv2D()->dilateH(); }\n",
        "bool DeConv2D::GetHasBias() const { return this->primitive_->value_as_DeConv2D()->hasBias(); }\n",
        "int DeConv2D::GetActivationType() const { return this->primitive_->value_as_DeConv2D()->activationType(); }\n",
        "\n",
        "#endif\n",
        "int DeConv2D::InferShape(std::vector<lite::tensor::Tensor *> inputs_, std::vector<lite::tensor::Tensor *> outputs_) {\n",
        "  MS_ASSERT(this->primitive_ != nullptr);\n",
        "  auto input = inputs_.front();\n",
        "  MS_ASSERT(input != nullptr);\n",
        "  auto weight = inputs_.at(1);\n",
        "  MS_ASSERT(weight != nullptr);\n",
        "  auto output = outputs_.front();\n",
        "  MS_ASSERT(output != nullptr);\n",
        "  output->SetFormat(input->GetFormat());\n",
        "  output->set_data_type(input->data_type());\n",
        "  if (!GetInferFlag()) {\n",
        "    return RET_OK;\n",
        "  }\n",
        "  int32_t input_h = input->Height();\n",
        "  int32_t input_w = input->Width();\n",
        "\n",
        "  int32_t output_n = input->Batch();\n",
        "  int32_t output_h = 0;\n",
        "  int32_t output_w = 0;\n",
        "  int32_t output_c = weight->Channel();\n",
        "\n",
        "  int kernel_w = GetKernelW();\n",
        "  int kernel_h = GetKernelH();\n",
        "  int stride_w = GetStrideW();\n",
        "  int stride_h = GetStrideH();\n",
        "  int dilate_w = GetDilateW();\n",
        "  int dilate_h = GetDilateH();\n",
        "  pad_l_ = GetPadLeft();\n",
        "  pad_u_ = GetPadUp();\n",
        "  pad_d_ = GetPadDown();\n",
        "  pad_r_ = GetPadRight();\n",
        "  auto pad_mode = (schema::PadMode)GetPadMode();\n",
        "  if (pad_mode == schema::PadMode_CAFFE) {\n",
        "    output_h = (input_h - 1) * stride_h + ((kernel_h - 1) * dilate_h + 1) - pad_u_ - pad_d_;\n",
        "    output_w = (input_w - 1) * stride_w + ((kernel_w - 1) * dilate_w + 1) - pad_l_ - pad_r_;\n",
        "  } else if (pad_mode == schema::PadMode_SAME) {\n",
        "    output_h = input_h * stride_h;\n",
        "    output_w = input_w * stride_w;\n",
        "  } else if (pad_mode == schema::PadMode_VALID) {\n",
        "    output_h = (input_h - 1) * stride_h + kernel_h;\n",
        "    output_w = (input_w - 1) * stride_w + kernel_w;\n",
        "  } else {\n",
        "    MS_LOG(ERROR) << \"unsupported pad mode for deconv\";\n",
        "  }\n",
        "  std::vector<int> out_shape = {output_n, output_h, output_w, output_c};\n",
        "  output->set_shape(out_shape);\n",
        "\n",
        "  if (pad_mode == schema::PadMode_SAME) {\n",
        "    pad_u_ = ((input_h - 1) * stride_h + (kernel_h - 1) * dilate_h + 1 - output_h) / 2;\n",
        "    pad_l_ = ((input_w - 1) * stride_w + (kernel_w - 1) * dilate_w + 1 - output_w) / 2;\n",
        "  } else if (pad_mode == schema::PadMode_VALID) {\n",
        "    pad_u_ = 0;\n",
        "    pad_l_ = 0;\n",
        "  } else if (pad_mode == schema::PadMode_CAFFE) {\n",
        "  } else {\n",
        "    MS_LOG(ERROR) << \"unsupported pad mode for deconv\";\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWGS_5Sfsenj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk",
        "colab_type": "text"
      },
      "source": [
        "#Data process"
      ]
    }
  ]
}