{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuppI1BtB91H"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/optimizer/fusion/custom_multi_fullconnect_fusion.h\"\n",
        "#include <memory>\n",
        "#include \"src/ops/primitive_c.h\"\n",
        "#include \"src/ops/conv2d.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"tools/optimizer/common/gllo_utils.h\"\n",
        "#include \"src/ops/primitive_c.h\"\n",
        "\n",
        "namespace mindspore::opt {\n",
        "namespace {\n",
        "bool IsReshapeNode(const BaseRef &n) {\n",
        "  if (utils::isa<CNodePtr>(n) || utils::isa<ValueNodePtr>(n)) {\n",
        "    auto type = opt::GetCNodeType(n);\n",
        "    return type == schema::PrimitiveType_Reshape || type==schema::PrimitiveType_Add;\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "bool IsConvORAddNode(const BaseRef &n) {\n",
        "  if (utils::isa<CNodePtr>(n) || utils::isa<ValueNodePtr>(n)) {\n",
        "    auto type = opt::GetCNodeType(n);\n",
        "    return type == schema::PrimitiveType_Conv2D || type == schema::PrimitiveType_Add;\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "ValueNodePtr CreateSliceValueNode(std::vector<int> begin, std::vector<int> size, std::vector<int> axes) {\n",
        "  auto slice_primitive = std::make_unique<schema::PrimitiveT>();\n",
        "  slice_primitive->value.type = schema::PrimitiveType_Slice;\n",
        "  auto attr = std::make_unique<schema::SliceT>();\n",
        "  attr->format = schema::Format::Format_NHWC;\n",
        "  attr->begin = std::move(begin);\n",
        "  attr->axes = std::move(axes);\n",
        "  attr->size = std::move(size);\n",
        "  slice_primitive->value.value = attr.release();\n",
        "  auto primitive_value = lite::PrimitiveC::Create(slice_primitive.release());\n",
        "  auto value_node = NewValueNode(std::shared_ptr<lite::PrimitiveC>(primitive_value));\n",
        "  return value_node;\n",
        "}\n",
        "STATUS JointMultiFCWeights(std::vector<ParameterPtr> joint_fc_weights, ParameterPtr jointed_new_paramter) {\n",
        "  auto joint_size = joint_fc_weights.size();\n",
        "  if (joint_size < 2) {\n",
        "    MS_LOG(WARNING) << \"joint fc weight size at least 2\";\n",
        "    return RET_FAILED;\n",
        "  }\n",
        "  auto fc_weight_param = std::dynamic_pointer_cast<ParamValueLite>(joint_fc_weights[0]->default_param());\n",
        "  auto fc_weight_size = fc_weight_param->tensor_size();\n",
        "  auto fc_weight_shape = fc_weight_param->tensor_shape();\n",
        "  auto new_tensor_data = new(std::nothrow) char[joint_size * fc_weight_size];\n",
        "  if (new_tensor_data == nullptr) {\n",
        "    MS_LOG(ERROR) << \"tensor_data is nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  for (size_t i = 0; i < joint_size; i++) {\n",
        "    auto weight_param = std::dynamic_pointer_cast<ParamValueLite>(joint_fc_weights[i]->default_param());\n",
        "    auto tensor_shape = fc_weight_param->tensor_shape();\n",
        "    if (tensor_shape != fc_weight_shape) {\n",
        "      MS_LOG(WARNING) << \"joint fc weight shape must same\";\n",
        "      return RET_FAILED;\n",
        "    }\n",
        "    auto tensor_addr = weight_param->tensor_addr();\n",
        "    if (tensor_addr == nullptr) {\n",
        "      MS_LOG(ERROR) << \"input tensor addr nullptr\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "    if (EOK != memcpy_s(new_tensor_data + i * fc_weight_size, fc_weight_size, tensor_addr, fc_weight_size)) {\n",
        "      MS_LOG(ERROR) << \"memcpy_s data failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "  }\n",
        "  auto type_ptr = TypeIdToType(fc_weight_param->tensor_type());\n",
        "  auto jointed_param_shape = fc_weight_shape;\n",
        "  jointed_param_shape.insert(jointed_param_shape.begin(), joint_size);\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, jointed_param_shape);\n",
        "  jointed_new_paramter->set_abstract(abstract_tensor);\n",
        "  ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\n",
        "  MS_ASSERT(param_value != nullptr);\n",
        "  param_value->set_tensor_shape(jointed_param_shape);\n",
        "  param_value->set_tensor_type(fc_weight_param->tensor_type());\n",
        "  param_value->set_format(fc_weight_param->format());\n",
        "  param_value->set_tensor_addr(new_tensor_data);\n",
        "  param_value->set_tensor_size(joint_size * fc_weight_size);\n",
        "  jointed_new_paramter->set_default_param(param_value);\n",
        "  return RET_OK;\n",
        "}\n",
        "}\n",
        "const BaseRef CustomMultiFCFusion::DefinePattern() const {\n",
        "  auto reshape_var = std::make_shared<CondVar>(IsReshapeNode);\n",
        "  auto fc_var = std::make_shared<CondVar>(IsFullConnectNode);\n",
        "  auto fc_weight = std::make_shared<CondVar>(IsParamNode);\n",
        "  auto fc_bias = std::make_shared<CondVar>(IsParamNode);\n",
        "  return VectorRef({fc_var, reshape_var, fc_weight, fc_bias});\n",
        "}\n",
        "\n",
        "const AnfNodePtr CustomMultiFCFusion::Process(const FuncGraphPtr &func_graph, const AnfNodePtr &node,\n",
        "                                              const EquivPtr &) const {\n",
        "  MS_ASSERT(func_graph != nullptr);\n",
        "  MS_ASSERT(node != nullptr);\n",
        "  auto fc_cnode = node->cast<CNodePtr>();\n",
        "  MS_ASSERT(fc_cnode != nullptr);\n",
        "  auto reshape_node = fc_cnode->input(1);\n",
        "  // reshape cnode all outputs must fullconnect node\n",
        "  auto reshape_output_nodes = GetRealNodeUsedListByOutputIdx(func_graph, reshape_node, 0);\n",
        "  std::vector<ParameterPtr> jointed_fc_weights;\n",
        "  std::vector<schema::QuantParamT> jointed_quant_params;\n",
        "  std::vector<std::vector<schema::QuantParamT>> input_quant_params;\n",
        "  std::vector<std::vector<schema::QuantParamT>> output_quant_params;\n",
        "  for (auto node_pair:*reshape_output_nodes) {\n",
        "    if (!IsFullConnectNode(node_pair.first) || node_pair.first->cast<CNodePtr>() == nullptr) {\n",
        "      MS_LOG(WARNING) << \"reshape all output nodes must be fullconnect node\";\n",
        "      return nullptr;\n",
        "    }\n",
        "    auto fc_weight = node_pair.first->cast<CNodePtr>()->input(2);\n",
        "    if (fc_weight == nullptr || !fc_weight->isa<Parameter>()) {\n",
        "      MS_LOG(WARNING) << \"fullconnect node weight must paramter\";\n",
        "      return nullptr;\n",
        "    }\n",
        "    jointed_fc_weights.push_back(fc_weight->cast<ParameterPtr>());\n",
        "    auto fc_node = node_pair.first->cast<CNodePtr>();\n",
        "    auto fc_prim = GetValueNode<std::shared_ptr<lite::PrimitiveC>>(fc_node->input(0));\n",
        "    auto fc_input_quantParams = fc_prim->GetInputQuantParams();\n",
        "    if (fc_input_quantParams.size() > 1 && !fc_input_quantParams[1].empty()) {\n",
        "      jointed_quant_params.push_back(fc_input_quantParams[1][0]);\n",
        "    }\n",
        "    input_quant_params = fc_input_quantParams;\n",
        "    output_quant_params = fc_prim->GetOutputQuantParams();\n",
        "  }\n",
        "  auto jointed_new_paramter = func_graph->add_parameter();\n",
        "  if (JointMultiFCWeights(jointed_fc_weights, jointed_new_paramter) != RET_OK) {\n",
        "    MS_LOG(WARNING) << \"fullconnect node weight joint new paramter failed\";\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto fc_node = reshape_output_nodes->at(0).first->cast<CNodePtr>();\n",
        "// create batchmatmul node replace multi fullconnect\n",
        "  auto matmul_primitive = std::make_unique<schema::PrimitiveT>();\n",
        "  std::unique_ptr<schema::MatMulT> attr = std::make_unique<schema::MatMulT>();\n",
        "  matmul_primitive->value.type = schema::PrimitiveType_MatMul;\n",
        "  matmul_primitive->value.value = attr.release();\n",
        "  auto matmul_cvalue = lite::PrimitiveC::Create(matmul_primitive.release());\n",
        "  input_quant_params.pop_back();\n",
        "  input_quant_params.pop_back();\n",
        "  input_quant_params.emplace_back(jointed_quant_params);\n",
        "  matmul_cvalue->SetInputQuantParam(input_quant_params);\n",
        "  matmul_cvalue->SetOutputQuantParam(output_quant_params);\n",
        "  auto matmul_value_node = NewValueNode(std::shared_ptr<lite::PrimitiveC>(matmul_cvalue));\n",
        "  std::vector<AnfNodePtr> matmul_inputs = {matmul_value_node, reshape_node, jointed_new_paramter};\n",
        "  auto new_matmul_node = func_graph->NewCNode(matmul_inputs);\n",
        "  new_matmul_node->set_fullname_with_scope(\"matmul_\" + fc_node->fullname_with_scope());\n",
        "\n",
        "  // create same size slice node\n",
        "  std::vector<int> slice_begin = {0, 0, 0};\n",
        "  std::vector<int> slice_size = {1, -1, -1};\n",
        "  std::vector<int> slice_axes = {0, 1, 2};\n",
        "  auto manager = func_graph->manager();\n",
        "  for (size_t i = 0; i < jointed_fc_weights.size(); i++) {\n",
        "    slice_begin[0] = i;\n",
        "    std::vector<AnfNodePtr> op_inputs = {CreateSliceValueNode(slice_begin, slice_size, slice_axes), new_matmul_node};\n",
        "    auto slice_cnode = func_graph->NewCNode(op_inputs);\n",
        "    manager->Replace(reshape_output_nodes->at(i).first, slice_cnode);\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "}  // namespace mindspore::opt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SYOlFaHCfBI"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"src/runtime/kernel/arm/fp32/matmul.h\"\n",
        "#include \"include/errorcode.h\"\n",
        "#include \"nnacl/fp32/matmul.h\"\n",
        "#include \"src/runtime/runtime_api.h\"\n",
        "\n",
        "using mindspore::lite::RET_ERROR;\n",
        "using mindspore::lite::RET_INPUT_TENSOR_ERROR;\n",
        "using mindspore::lite::RET_MEMORY_FAILED;\n",
        "using mindspore::lite::RET_OK;\n",
        "\n",
        "namespace mindspore::kernel {\n",
        "MatmulCPUKernel::~MatmulCPUKernel() { FreeTmpBuffer(); }\n",
        "\n",
        "void MatmulCPUKernel::FreeTmpBuffer() {\n",
        "  if (a_pack_ptr_ != nullptr) {\n",
        "    free(a_pack_ptr_);\n",
        "    a_pack_ptr_ = nullptr;\n",
        "  }\n",
        "  if (b_pack_ptr_ != nullptr) {\n",
        "    free(b_pack_ptr_);\n",
        "    b_pack_ptr_ = nullptr;\n",
        "  }\n",
        "  if (bias_ptr_ != nullptr) {\n",
        "    free(bias_ptr_);\n",
        "    bias_ptr_ = nullptr;\n",
        "  }\n",
        "}\n",
        "\n",
        "int MatmulCPUKernel::MallocMatrixABuffer() {\n",
        "  auto a_shape = in_tensors_[0]->shape();\n",
        "  int batch = 1;\n",
        "  for (size_t i = 0; i < a_shape.size() - 2; ++i) {\n",
        "    batch *= a_shape[i];\n",
        "  }\n",
        "  params_->a_batch = batch;\n",
        "  params_->row_ = params_->a_transpose_ ? a_shape[a_shape.size() - 1] : a_shape[a_shape.size() - 2];\n",
        "#ifdef ENABLE_ARM64\n",
        "  if (params_->row_ == 1) {\n",
        "    is_vector_a_ = true;\n",
        "  }\n",
        "#endif\n",
        "  params_->deep_ = params_->a_transpose_ ? a_shape[a_shape.size() - 2] : a_shape[a_shape.size() - 1];\n",
        "  params_->row_4_ = UP_ROUND(params_->row_, C4NUM);\n",
        "  params_->row_12_ = UP_ROUND(params_->row_, C12NUM);\n",
        "\n",
        "#ifdef ENABLE_ARM32\n",
        "  a_pack_ptr_ = reinterpret_cast<float *>(malloc(params_->a_batch * params_->row_4_ * params_->deep_ * sizeof(float)));\n",
        "  if (a_pack_ptr_ == nullptr) {\n",
        "    FreeTmpBuffer();\n",
        "    return RET_MEMORY_FAILED;\n",
        "  }\n",
        "  memset(a_pack_ptr_, 0, params_->row_4_ * params_->deep_ * sizeof(float));\n",
        "#else\n",
        "  int row_tmp = is_vector_a_ ? 1 : params_->row_12_;\n",
        "  a_pack_ptr_ = reinterpret_cast<float *>(malloc(params_->a_batch * row_tmp * params_->deep_ * sizeof(float)));\n",
        "  if (a_pack_ptr_ == nullptr) {\n",
        "    FreeTmpBuffer();\n",
        "    return RET_MEMORY_FAILED;\n",
        "  }\n",
        "  memset(a_pack_ptr_, 0, params_->a_batch * row_tmp * params_->deep_ * sizeof(float));\n",
        "#endif\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "int MatmulCPUKernel::MallocMatrixBBuffer() {\n",
        "  auto b_shape = in_tensors_[1]->shape();\n",
        "  if (b_shape.empty()) {\n",
        "    return RET_OK;\n",
        "  }\n",
        "  int batch = 1;\n",
        "  for (size_t i = 0; i < b_shape.size() - 2; ++i) {\n",
        "    batch *= b_shape[i];\n",
        "  }\n",
        "  params_->b_batch = batch;\n",
        "  params_->col_ = params_->b_transpose_ ? b_shape[b_shape.size() - 2] : b_shape[b_shape.size() - 1];\n",
        "  params_->col_8_ = UP_ROUND(params_->col_, 8);\n",
        "  params_->deep_ = params_->b_transpose_ ? b_shape[b_shape.size() - 1] : b_shape[b_shape.size() - 2];\n",
        "\n",
        "  int col_tmp = is_vector_a_ ? params_->col_ : params_->col_8_;\n",
        "  b_pack_ptr_ = reinterpret_cast<float *>(malloc(params_->b_batch * col_tmp * params_->deep_ * sizeof(float)));\n",
        "  if (b_pack_ptr_ == nullptr) {\n",
        "    FreeTmpBuffer();\n",
        "    return RET_MEMORY_FAILED;\n",
        "  }\n",
        "  memset(b_pack_ptr_, 0, params_->b_batch * col_tmp * params_->deep_ * sizeof(float));\n",
        "\n",
        "  thread_count_ = MSMIN(thread_count_, UP_DIV(params_->col_8_, 8));\n",
        "  thread_stride_ = UP_DIV(UP_DIV(params_->col_8_, 8), thread_count_);\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "int MatmulCPUKernel::InitBias() {\n",
        "  if (in_tensors_.size() == 3) {\n",
        "    auto c_shape = out_tensors_[0]->shape();\n",
        "    auto bias_shape = in_tensors_[1]->shape();\n",
        "    if (bias_shape[bias_shape.size() - 1] != c_shape[c_shape.size() - 1]) {\n",
        "      MS_LOG(ERROR) << \"The bias'dimension is not equal with colum\";\n",
        "      FreeTmpBuffer();\n",
        "      return RET_INPUT_TENSOR_ERROR;\n",
        "    }\n",
        "    auto col = c_shape[c_shape.size() - 1];\n",
        "    auto col_8 = UP_ROUND(col, 8);\n",
        "    auto col_tmp = is_vector_a_ ? col : col_8;\n",
        "    bias_ptr_ = reinterpret_cast<float *>(malloc(col_tmp * sizeof(float)));\n",
        "    if (bias_ptr_ == nullptr) {\n",
        "      FreeTmpBuffer();\n",
        "      return RET_MEMORY_FAILED;\n",
        "    }\n",
        "    memcpy(bias_ptr_, in_tensors_[2]->data_c(), in_tensors_[2]->ElementsNum() * sizeof(float));\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "int MatmulCPUKernel::ReSize() {\n",
        "  if (params_->a_const_ == false || params_->a_has_shape_ == false) {\n",
        "    if (a_pack_ptr_ != nullptr) {\n",
        "      free(a_pack_ptr_);\n",
        "      a_pack_ptr_ = nullptr;\n",
        "    }\n",
        "    auto ret = MallocMatrixABuffer();\n",
        "    if (ret != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"Matmul fp32 malloc matrix a buffer failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "  }\n",
        "  if (params_->b_const_ == false || params_->b_has_shape_ == false) {\n",
        "    if (b_pack_ptr_ != nullptr) {\n",
        "      free(b_pack_ptr_);\n",
        "      b_pack_ptr_ = nullptr;\n",
        "    }\n",
        "    auto ret = MallocMatrixBBuffer();\n",
        "    if (ret != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"Matmul fp32 malloc matrix b buffer failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "  }\n",
        "  if (bias_ptr_ != nullptr) {\n",
        "    free(bias_ptr_);\n",
        "    bias_ptr_ = nullptr;\n",
        "  }\n",
        "  auto ret = InitBias();\n",
        "  if (ret != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"Matmul fp32 init bias failed\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "void MatmulCPUKernel::InitMatrixA(float *src_ptr, float *dst_ptr) {\n",
        "  if (is_vector_a_) {\n",
        "    memcpy(dst_ptr, src_ptr, params_->a_batch * params_->deep_ * sizeof(float));\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < params_->a_batch; i++) {\n",
        "    float *src = src_ptr + i * params_->deep_ * params_->row_;\n",
        "#ifdef ENABLE_ARM32\n",
        "    float *dst = dst_ptr + i * params_->deep_ * params_->row_4_;\n",
        "    if (params_->a_transpose_) {\n",
        "      RowMajor2Row4Major(src, dst, params_->deep_, params_->row_);\n",
        "    } else {\n",
        "      RowMajor2Col4Major(src, dst, params_->row_, params_->deep_);\n",
        "    }\n",
        "#else\n",
        "    float *dst = dst_ptr + i * params_->deep_ * params_->row_12_;\n",
        "    if (params_->a_transpose_) {\n",
        "      RowMajor2Row12Major(src, dst, params_->deep_, params_->row_);\n",
        "    } else {\n",
        "      RowMajor2Col12Major(src, dst, params_->row_, params_->deep_);\n",
        "    }\n",
        "#endif\n",
        "  }\n",
        "  return;\n",
        "}\n",
        "\n",
        "void MatmulCPUKernel::InitMatrixB(float *src_ptr, float *dst_ptr) {\n",
        "  if (is_vector_a_) {\n",
        "    if (params_->b_transpose_) {\n",
        "      memcpy(dst_ptr, src_ptr, params_->b_batch * params_->col_ * params_->deep_ * sizeof(float));\n",
        "    } else {\n",
        "      for (int i = 0; i < params_->b_batch; i++) {\n",
        "        float *src = src_ptr + i * params_->deep_ * params_->col_;\n",
        "        float *dst = dst_ptr + i * params_->deep_ * params_->col_;\n",
        "        RowMajor2ColMajor(src, dst, params_->deep_, params_->col_);\n",
        "      }\n",
        "    }\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < params_->b_batch; i++) {\n",
        "    float *src = src_ptr + i * params_->deep_ * params_->col_;\n",
        "    float *dst = dst_ptr + i * params_->deep_ * params_->col_8_;\n",
        "    if (params_->b_transpose_) {\n",
        "      RowMajor2Col8Major(src, dst, params_->col_, params_->deep_);\n",
        "    } else {\n",
        "      RowMajor2Row8Major(src, dst, params_->deep_, params_->col_);\n",
        "    }\n",
        "  }\n",
        "  return;\n",
        "}\n",
        "\n",
        "int MatmulCPUKernel::Init() {\n",
        "  auto a_shape = in_tensors_[0]->shape();\n",
        "  auto b_shape = in_tensors_[1]->shape();\n",
        "  params_->a_has_shape_ = (a_shape.size() != 0);\n",
        "  params_->b_has_shape_ = (b_shape.size() != 0);\n",
        "  if (params_->a_has_shape_) {\n",
        "    auto ret = MallocMatrixABuffer();\n",
        "    if (ret != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"Matmul fp32 malloc matrix a buffer failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "  }\n",
        "  if (params_->b_has_shape_) {\n",
        "    auto ret = MallocMatrixBBuffer();\n",
        "    if (ret != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"Matmul fp32 malloc matrix b buffer failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  bool a_broadcast = false;\n",
        "  bool b_broadcast = false;\n",
        "  if (a_shape.size() == 2 && b_shape.size() == 2) {\n",
        "    a_broadcast = false;\n",
        "    b_broadcast = false;\n",
        "  } else if (a_shape.size() == 2 && (b_shape.size() != 2 && b_shape[b_shape.size() - 3] != 1)) {\n",
        "    a_broadcast = true;\n",
        "  } else if ((a_shape.size() != 2 && a_shape[a_shape.size() - 3] != 1) && b_shape.size() == 2) {\n",
        "    b_broadcast = true;\n",
        "  } else if (a_shape[a_shape.size() - 3] == 1 && b_shape.size() > 2 && b_shape[b_shape.size() - 3] != 1) {\n",
        "    a_broadcast = true;\n",
        "  } else if (a_shape[a_shape.size() - 3] != 1 && a_shape.size() > 2 && b_shape[b_shape.size() - 3] == 1) {\n",
        "    b_broadcast = true;\n",
        "  }\n",
        "  params_->a_broadcast_ = a_broadcast;\n",
        "  params_->b_broadcast_ = b_broadcast;\n",
        "\n",
        "  params_->a_const_ = (in_tensors_[0]->data_c() != nullptr);\n",
        "  params_->b_const_ = (in_tensors_[1]->data_c() != nullptr);\n",
        "  if (params_->a_const_) {\n",
        "    InitMatrixA(reinterpret_cast<float *>(in_tensors_[0]->data_c()), a_pack_ptr_);\n",
        "    a_ptr_ = a_pack_ptr_;\n",
        "  }\n",
        "  if (params_->b_const_) {\n",
        "    InitMatrixB(reinterpret_cast<float *>(in_tensors_[1]->data_c()), b_pack_ptr_);\n",
        "    b_ptr_ = b_pack_ptr_;\n",
        "  }\n",
        "  if (!InferShapeDone()) {\n",
        "    return RET_OK;\n",
        "  }\n",
        "  auto ret = InitBias();\n",
        "  if (ret != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"Matmul fp32 init bias failed\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "int MatmulCPUKernel::RunImpl(int task_id) {\n",
        "  int cur_oc = MSMIN(thread_stride_ * C8NUM, params_->col_ - task_id * thread_stride_ * C8NUM);\n",
        "  if (cur_oc <= 0) {\n",
        "    return RET_OK;\n",
        "  }\n",
        "  auto b = cur_b_ptr_ + task_id * thread_stride_ * C8NUM * params_->deep_;\n",
        "  auto c = cur_c_ptr_ + task_id * thread_stride_ * C8NUM;\n",
        "  auto bias = bias_ptr_ ? bias_ptr_ + task_id * thread_stride_ * C8NUM : NULL;\n",
        "  if (is_vector_a_) {\n",
        "    MatVecMul(cur_a_ptr_, b, c, bias, ActType_No, params_->deep_, cur_oc);\n",
        "  } else {\n",
        "    MatMulOpt(cur_a_ptr_, b, c, bias, ActType_No, params_->deep_, params_->row_, cur_oc, params_->col_, OutType_Nhwc);\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "int MatmulFloatRun(void *cdata, int task_id) {\n",
        "  auto op = reinterpret_cast<MatmulCPUKernel *>(cdata);\n",
        "  auto error_code = op->RunImpl(task_id);\n",
        "  if (error_code != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"MatmulFp32Run error task_id[\" << task_id << \"] error_code[\" << error_code << \"]\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "int MatmulCPUKernel::Run() {\n",
        "  auto prepare_ret = Prepare();\n",
        "  if (prepare_ret != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"Prepare fail!ret: \" << prepare_ret;\n",
        "    return prepare_ret;\n",
        "  }\n",
        "  auto a_src = reinterpret_cast<float *>(in_tensors_[0]->data_c());\n",
        "  auto b_src = reinterpret_cast<float *>(in_tensors_[1]->data_c());\n",
        "  auto c_src = reinterpret_cast<float *>(out_tensors_[0]->data_c());\n",
        "\n",
        "  if (params_->a_const_ == false || is_train()) {\n",
        "    if (is_vector_a_) {\n",
        "      a_ptr_ = a_src;\n",
        "    } else {\n",
        "      InitMatrixA(a_src, a_pack_ptr_);\n",
        "      a_ptr_ = a_pack_ptr_;\n",
        "    }\n",
        "  }\n",
        "  if (params_->b_const_ == false || is_train()) {\n",
        "    if (is_vector_a_) {\n",
        "      b_ptr_ = b_src;\n",
        "    } else {\n",
        "      InitMatrixB(b_src, b_pack_ptr_);\n",
        "      b_ptr_ = b_pack_ptr_;\n",
        "    }\n",
        "  }\n",
        "  if (!params_->a_broadcast_ && !params_->b_broadcast_) {\n",
        "    for (int i = 0; i < params_->a_batch; ++i) {\n",
        "      if (is_vector_a_) {\n",
        "        cur_a_ptr_ = a_ptr_ + i * params_->deep_;\n",
        "        cur_b_ptr_ = b_ptr_ + i * params_->deep_ * params_->col_;\n",
        "        cur_c_ptr_ = c_src + i * params_->row_ * params_->col_;\n",
        "      } else {\n",
        "        cur_a_ptr_ = a_ptr_ + i * params_->row_12_ * params_->deep_;\n",
        "        cur_b_ptr_ = b_ptr_ + i * params_->deep_ * params_->col_8_;\n",
        "        cur_c_ptr_ = c_src + i * params_->row_ * params_->col_;\n",
        "      }\n",
        "      ParallelLaunch(this->context_->thread_pool_, MatmulFloatRun, this, thread_count_);\n",
        "    }\n",
        "  } else if (params_->a_broadcast_) {\n",
        "    for (int i = 0; i < params_->a_batch; i++) {\n",
        "      cur_a_ptr_ = a_ptr_ + i * params_->row_12_ * params_->deep_;\n",
        "      for (int j = 0; j < params_->b_batch; j++) {\n",
        "        cur_b_ptr_ = b_ptr_ + j * params_->deep_ * params_->col_8_;\n",
        "        cur_c_ptr_ = c_src + (i * params_->a_batch + j) * params_->row_ * params_->col_;\n",
        "        ParallelLaunch(this->context_->thread_pool_, MatmulFloatRun, this, thread_count_);\n",
        "      }\n",
        "    }\n",
        "    MS_LOG(ERROR) << \"Matmul op input shape error ,cannot broadcast\";\n",
        "  } else if (params_->b_broadcast_) {\n",
        "    for (int i = 0; i < params_->b_batch; i++) {\n",
        "      cur_b_ptr_ = b_ptr_ + i * params_->deep_ * params_->col_8_;\n",
        "      for (int j = 0; j < params_->a_batch; j++) {\n",
        "        cur_a_ptr_ = a_ptr_ + j * params_->row_12_ * params_->deep_;\n",
        "        cur_c_ptr_ = c_src + (i * params_->a_batch + j) * params_->row_ * params_->col_;\n",
        "        ParallelLaunch(this->context_->thread_pool_, MatmulFloatRun, this, thread_count_);\n",
        "      }\n",
        "    }\n",
        "  } else {\n",
        "    MS_LOG(ERROR) << \"Matmul op input shape error ,cannot broadcast\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  return RET_OK;\n",
        "  }\n",
        "\n",
        "  void MatmulCPUKernel::eval() {\n",
        "    // Copy weights after training\n",
        "    LiteKernel::eval();\n",
        "    if (params_->a_const_ == true) {\n",
        "      InitMatrixA(reinterpret_cast<float *>(in_tensors_[0]->MutableData()), a_pack_ptr_);\n",
        "    }\n",
        "    if (params_->b_const_ == true) {\n",
        "      InitMatrixB(reinterpret_cast<float *>(in_tensors_[1]->MutableData()), b_pack_ptr_);\n",
        "    }\n",
        "  }\n",
        "\n",
        "}  // namespace mindspore::kernel\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxrNyOcoKYZ2"
      },
      "source": [
        " if (input_tensor->shape().size() == 3\n",
        "        && input_tensor->GetQuantParams().size() == input_tensor->shape()[0]) { // per batch matmul\n",
        "      auto per_batch_size = input_tensor->shape()[0];\n",
        "      auto quant_param = input_tensor->GetQuantParams();\n",
        "      for (size_t i = 0; i < per_batch_size; i++) {\n",
        "        auto param = quant_param.at(i);\n",
        "        auto scale = param.scale;\n",
        "        auto zero_point = param.zeroPoint;\n",
        "        auto matrix_size = input_tensor->ElementsNum() / per_batch_size;\n",
        "        for (int64_t j = 0; j < matrix_size; j++) {\n",
        "          dequant_datas[i * matrix_size + j] =\n",
        "              static_cast<float>((quant_datas[i * matrix_size + j] - zero_point) * scale);\n",
        "        }\n",
        "      }\n",
        "      return dequant_datas;\n",
        "    } else if (input_tensor->GetQuantParams().size() != kPerTensor) {"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_hh1PrC1-r9"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#ifndef MINDSPORE_LITE_SRC_PASS_FUSION_CUSTOM_MULTI_FULLCONNECT_FUSION_H_\n",
        "#define MINDSPORE_LITE_SRC_PASS_FUSION_CUSTOM_MULTI_FULLCONNECT_FUSION_H_\n",
        "\n",
        "#include <string>\n",
        "#include \"backend/optimizer/common/optimizer.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "class CustomMultiFCFusion : public PatternProcessPass {\n",
        " public:\n",
        "  explicit CustomMultiFCFusion(bool multigraph = true) : PatternProcessPass(\"custom_multiFCFusion\", multigraph) {}\n",
        "  ~CustomMultiFCFusion() override = default;\n",
        "  const BaseRef DefinePattern() const override;\n",
        "  const AnfNodePtr Process(const FuncGraphPtr &, const AnfNodePtr &, const EquivPtr &) const override;\n",
        "};\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n",
        "#endif  // MINDSPORE_LITE_SRC_PASS_FUSION_CUSTOM_MULTI_FULLCONNECT_FUSION_H_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRqLIUpO3C4Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}