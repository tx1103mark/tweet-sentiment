{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnXo0VxCVrXJ"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * distributed under the License is distributed on an AS\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/converter/parser/tf/tf_model_parser.h\"\n",
        "#include <functional>\n",
        "#include <set>\n",
        "#include <regex>\n",
        "#include \"src/common/utils.h\"\n",
        "#include \"src/common/log_adapter.h\"\n",
        "#include \"tools/common/graph_util.h\"\n",
        "#include \"tools/converter/parser/tf/tf_node_parser_registry.h\"\n",
        "#include \"src/param_value_lite.h\"\n",
        "#include \"tools/common/protobuf_utils.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "namespace {\n",
        "int op_idx = 0;\n",
        "std::string GetFlattenNodeName(std::string input_name) {\n",
        "  std::regex re(\"\\\\:+\");\n",
        "  std::vector<std::string>\n",
        "      input_splits\n",
        "      (std::sregex_token_iterator(input_name.begin(), input_name.end(), re, -1), std::sregex_token_iterator());\n",
        "  if (input_splits.size() == 3) {\n",
        "    if (input_splits[2] == \"0\") {\n",
        "      input_name = input_splits[0];\n",
        "    } else {\n",
        "      input_name = input_splits[0] + input_splits[2];  // multi output node\n",
        "    }\n",
        "  }\n",
        "  return input_name;\n",
        "}\n",
        "AnfNodePtr GetAnfNode(const std::string &name,\n",
        "                      const std::unordered_map<std::string, AnfNodePtr> &anf_node_map) {\n",
        "  AnfNodePtr ret = nullptr;\n",
        "  if (anf_node_map.find(name) != anf_node_map.end()) {\n",
        "    ret = anf_node_map.at(name);\n",
        "  } else if (anf_node_map.find(name + \":0\") != anf_node_map.end()) {\n",
        "    ret = anf_node_map.at(name + \":0\");\n",
        "  }\n",
        "  return ret;\n",
        "}\n",
        "\n",
        "std::string GetOriginInputName(const tensorflow::NodeDef &node,\n",
        "                               const std::map<std::string, const tensorflow::NodeDef *> &tf_graph_nodes) {\n",
        "  if (node.op() != \"Identity\" && node.op() != \"StopGradient\") {\n",
        "    return node.name();\n",
        "  }\n",
        "  auto tmp_node = &node;\n",
        "  while (tmp_node->op() == \"Identity\" || tmp_node->op() == \"StopGradient\") {\n",
        "    if (tf_graph_nodes.find(tmp_node->input(0)) == tf_graph_nodes.end()) {\n",
        "      return tmp_node->input(0);\n",
        "    }\n",
        "    tmp_node = tf_graph_nodes.at(tmp_node->input(0));\n",
        "  }\n",
        "  return tmp_node->name();\n",
        "}\n",
        "}  // namespace\n",
        "\n",
        "STATUS TFModelParser::ConvertConstTensor(const tensorflow::AttrValue &attr_value, const TypeId &type,\n",
        "                                         const ParameterPtr &parameter, std::vector<int64_t> *shape_vector) {\n",
        "  MS_ASSERT(parameter != nullptr);\n",
        "  MS_ASSERT(shape_vector != nullptr);\n",
        "  const tensorflow::TensorProto &tensor_proto = attr_value.tensor();\n",
        "  const tensorflow::TensorShapeProto &tensor_shape = tensor_proto.tensor_shape();\n",
        "  int shape_size = 1;\n",
        "  shape_vector->clear();\n",
        "  for (int i = 0; i < tensor_shape.dim_size(); i++) {\n",
        "    shape_vector->push_back(tensor_shape.dim(i).size());\n",
        "    shape_size *= tensor_shape.dim(i).size();\n",
        "  }\n",
        "\n",
        "  int tensor_size;\n",
        "  auto param_value = std::make_shared<ParamValueLite>();\n",
        "  if (param_value == nullptr) {\n",
        "    MS_LOG(ERROR) << \"param_value is nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  if (type == kNumberTypeFloat32 || type == kNumberTypeFloat) {\n",
        "    auto tensor_data = new(std::nothrow) float[shape_size];\n",
        "    if (tensor_proto.float_val_size() == 1) {\n",
        "      float value = tensor_proto.float_val(0);\n",
        "      for (int i = 0; i < shape_size; i++) {\n",
        "        tensor_data[i] = value;\n",
        "      }\n",
        "    }\n",
        "    if (tensor_proto.tensor_content().size() == shape_size * sizeof(float)) {\n",
        "      const auto addr = reinterpret_cast<const float *>(tensor_proto.tensor_content().data());\n",
        "      auto ret = ::memcpy_s(tensor_data, shape_size * sizeof(float), addr, shape_size * sizeof(float));\n",
        "      if (ret != EOK) {\n",
        "        MS_LOG(ERROR) << \"memcpy_s failed\";\n",
        "        delete[] tensor_data;\n",
        "        return RET_ERROR;\n",
        "      }\n",
        "    }\n",
        "    tensor_size = shape_size * sizeof(float);\n",
        "    param_value->SetTensorData(tensor_data, tensor_size);\n",
        "  } else if (type == kNumberTypeInt32) {\n",
        "    auto tensor_data = new(std::nothrow) int[shape_size];\n",
        "    if (tensor_proto.int_val_size() == 1) {\n",
        "      int value = tensor_proto.int_val(0);\n",
        "      for (int i = 0; i < shape_size; i++) {\n",
        "        tensor_data[i] = value;\n",
        "      }\n",
        "    }\n",
        "    if (tensor_proto.tensor_content().size() == shape_size * sizeof(int32_t)) {\n",
        "      const auto addr = reinterpret_cast<const int32_t *>(tensor_proto.tensor_content().data());\n",
        "      auto ret = ::memcpy_s(tensor_data, shape_size * sizeof(int32_t), addr, shape_size * sizeof(int32_t));\n",
        "      if (ret != EOK) {\n",
        "        MS_LOG(ERROR) << \"memcpy_s failed\";\n",
        "        delete[] tensor_data;\n",
        "        return RET_ERROR;\n",
        "      }\n",
        "    }\n",
        "    tensor_size = shape_size * sizeof(int);\n",
        "    param_value->SetTensorData(tensor_data, tensor_size);\n",
        "  } else if (type == kNumberTypeBool) {\n",
        "    auto tensor_data = new(std::nothrow) int[shape_size];\n",
        "    if (tensor_proto.bool_val_size() == 1) {\n",
        "      int value = tensor_proto.bool_val(0);\n",
        "      for (int i = 0; i < shape_size; i++) {\n",
        "        tensor_data[i] = value;\n",
        "      }\n",
        "    }\n",
        "    tensor_size = shape_size * sizeof(int);\n",
        "    param_value->SetTensorData(tensor_data, tensor_size);\n",
        "  } else {\n",
        "    MS_LOG(ERROR) << \"Unsupport dataType: \" << type;\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "\n",
        "  std::vector<int> param_shape(shape_vector->begin(), shape_vector->end());\n",
        "  param_value->set_tensor_shape(param_shape);\n",
        "  param_value->set_tensor_type(type);\n",
        "  param_value->set_format(schema::Format::Format_NHWC);\n",
        "  parameter->set_default_param(param_value);\n",
        "  parameter->set_name(\"const_\" + std::to_string(anf_root_node_map.size()) + \"_parameter\");\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS TFModelParser::ConvertParameter(const tensorflow::NodeDef &node,\n",
        "                                       const ParameterPtr &parameter,\n",
        "                                       std::unordered_map<std::string, AnfNodePtr> *anf_node_map) {\n",
        "  MS_ASSERT(node != nullptr);\n",
        "  MS_ASSERT(parameter != nullptr);\n",
        "\n",
        "  tensorflow::AttrValue attr_value;\n",
        "  TypeId type = kNumberTypeFloat32;\n",
        "  if (TensorFlowUtils::FindAttrValue(node, \"dtype\", &attr_value)) {\n",
        "    type = TensorFlowUtils::GetTFDataType(attr_value.type());\n",
        "  }\n",
        "  auto type_ptr = TypeIdToType(type);\n",
        "\n",
        "  std::vector<int> shape;\n",
        "  if (TensorFlowUtils::FindAttrValue(node, \"shape\", &attr_value)) {\n",
        "    auto &shape_attr = attr_value.shape();\n",
        "    for (int i = 0; i < shape_attr.dim_size(); ++i) {\n",
        "      shape.push_back(shape_attr.dim(i).size());\n",
        "    }\n",
        "  }\n",
        "  std::vector<int64_t> shape_vector(shape.begin(), shape.end());\n",
        "\n",
        "  if (TensorFlowUtils::FindAttrValue(node, \"value\", &attr_value)) {\n",
        "    MS_LOG(INFO) << \"Found value attr, means it has default value\";\n",
        "    auto status = ConvertConstTensor(attr_value, type, parameter, &shape_vector);\n",
        "    if (status != RET_OK) {\n",
        "      return status;\n",
        "    }\n",
        "  } else {\n",
        "    parameter->set_name(\"placeholder_\" + std::to_string(anf_root_node_map.size()));\n",
        "    graph_input_names.emplace_back(parameter->name());  // only root graph need set graph input names\n",
        "  }\n",
        "\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, shape_vector);\n",
        "  if (abstract_tensor == nullptr) {\n",
        "    MS_LOG(ERROR) << \"abstract_tensor is nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  parameter->set_abstract(abstract_tensor);\n",
        "\n",
        "  (*anf_node_map)[node.name()] = parameter;\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS TFModelParser::ConvertGraphInputsAndConsts(const std::map<std::string,\n",
        "                                                                 const tensorflow::NodeDef *> &tf_graph_nodes,\n",
        "                                                  const FuncGraphPtr &anf_graph,\n",
        "                                                  std::unordered_map<std::string, AnfNodePtr> *anf_node_map) {\n",
        "  for (auto &pair : tf_graph_nodes) {\n",
        "    bool have_data_depend = false;\n",
        "    for (int i = 0; i < pair.second->input_size(); ++i) {\n",
        "      auto name = pair.second->input(i);\n",
        "      if (!name.empty() && name[0] != '^') {  // control_depend input start with \"^\"\n",
        "        have_data_depend = true;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "    if (!have_data_depend) {\n",
        "      auto parameter = anf_graph->add_parameter();\n",
        "      if (ConvertParameter(*pair.second, parameter, anf_node_map) != RET_OK) {\n",
        "        MS_LOG(ERROR) << \"convert Parameter Node failed\";\n",
        "        return RET_ERROR;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "FuncGraphPtr paserTfFuction() {\n",
        "  return nullptr;\n",
        "}\n",
        "FuncGraphPtr TFModelParser::Parse(const std::string &modelFile, const std::string &weightFile,\n",
        "                                  const QuantType &quantType) {\n",
        "  auto status = ValidateFileStr(modelFile, \".pb\");\n",
        "  if (status != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"INPUT ILLEGAL: modelFile must be *.pb\";\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\n",
        "    return nullptr;\n",
        "  }\n",
        "  tf_root_graph = std::make_unique<tensorflow::GraphDef>();\n",
        "  if (tf_root_graph == nullptr) {\n",
        "    MS_LOG(ERROR) << \"tf_root_graph is nullptr\";\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(RET_ERROR);\n",
        "    return nullptr;\n",
        "  }\n",
        "  status = ReadProtoFromBinaryFile((const char *) modelFile.c_str(), tf_root_graph.get());\n",
        "  if (status != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"Open modelFile for TF converter failed!\";\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(RET_ERROR);\n",
        "    return nullptr;\n",
        "  }\n",
        "  anf_root_graph = std::make_shared<FuncGraph>();\n",
        "  if (anf_root_graph == nullptr) {\n",
        "    MS_LOG(ERROR) << \"funGraphPtr is nullptr\";\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(RET_ERROR);\n",
        "    return nullptr;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < tf_root_graph->node_size(); i++) {\n",
        "    auto &node_def = tf_root_graph->node(i);\n",
        "    tf_root_graph_nodes[node_def.name()] = &node_def;\n",
        "  }\n",
        "\n",
        "  status = ConvertGraphInputsAndConsts(tf_root_graph_nodes, anf_root_graph, &anf_root_node_map);\n",
        "  if (status != RET_OK) {\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\n",
        "    return nullptr;\n",
        "  }\n",
        "  for (int i = 0; i < tf_root_graph->node_size(); i++) {\n",
        "    auto &node_def = tf_root_graph->node(i);\n",
        "    if (ConvertOps(node_def, tf_root_graph_nodes, anf_root_graph, &anf_root_node_map) != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"Convert ops failed.\";\n",
        "      ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\n",
        "      return nullptr;\n",
        "    }\n",
        "  }\n",
        "  status = ConvertRootGraphOutputs();\n",
        "  if (status != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"Convert graph outputs failed.\";\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\n",
        "    return nullptr;\n",
        "  }\n",
        "\n",
        "  status = ConvertSubgraph();\n",
        "  if (status != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"Convert subgraph failed.\";\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\n",
        "    return nullptr;\n",
        "  }\n",
        "\n",
        "  return anf_root_graph;\n",
        "}\n",
        "STATUS TFModelParser::ConvertSubgraph() {\n",
        "  auto graph_def_liarary = tf_root_graph->library();\n",
        "  auto subgraph_size = graph_def_liarary.function_size();\n",
        "  std::map<CNodePtr, FuncGraphPtr> while_cond_map;\n",
        "  std::map<CNodePtr, FuncGraphPtr> while_body_map;\n",
        "  std::vector<ParameterPtr> sub_graph_inputs;\n",
        "  for (int i = 0; i < subgraph_size; i++) {\n",
        "    auto &tf_sub_fuction = graph_def_liarary.function(i);\n",
        "    auto &tf_sub_signature = tf_sub_fuction.signature();\n",
        "    auto input_arg_size = tf_sub_signature.input_arg_size();\n",
        "\n",
        "    // convert subgraph inputs\n",
        "    std::map<std::string, AnfNodePtr> sub_root_inputs_map;\n",
        "    auto &sub_graph_name = tf_sub_signature.name();\n",
        "    if (!function_while_map.count(sub_graph_name)) {\n",
        "      MS_LOG(ERROR) << \"function map not contains sub graph name.\" << sub_graph_name;\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "    auto while_cnode = function_while_map[sub_graph_name]->cast<CNodePtr>();\n",
        "    if (while_cnode == nullptr || while_cnode->inputs().size() != input_arg_size + 1) {\n",
        "      MS_LOG(ERROR) << \"while cnode  not equal input arg size\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "\n",
        "    FuncGraphPtr sub_func_graph = std::make_shared<FuncGraph>();\n",
        "    std::unordered_map<std::string, AnfNodePtr> anf_sub_node_map;\n",
        "    // convert sub graph inputs\n",
        "    for (int j = 0; j < input_arg_size; j++) {\n",
        "      auto &input_arg = tf_sub_signature.input_arg(j);\n",
        "      auto paramter = sub_func_graph->add_parameter();\n",
        "      paramter->set_name(input_arg.name());\n",
        "      anf_sub_node_map[input_arg.name()] = paramter;\n",
        "      sub_graph_inputs.emplace_back(paramter);\n",
        "    }\n",
        "    std::map<std::string, const tensorflow::NodeDef *> tf_sub_node_map;\n",
        "    for (int j = 0; j < tf_sub_fuction.node_def_size(); j++) {\n",
        "      auto &node_def = tf_sub_fuction.node_def(j);\n",
        "      tf_sub_node_map[node_def.name()] = &node_def;\n",
        "    }\n",
        "    STATUS status = RET_OK;\n",
        "    status = ConvertGraphInputsAndConsts(tf_sub_node_map, sub_func_graph, &anf_sub_node_map);\n",
        "    if (status != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"Convert subgraph consts failed\";\n",
        "      return status;\n",
        "    }\n",
        "    // convert sub graph ops\n",
        "    for (int j = 0; j < tf_sub_fuction.node_def_size(); j++) {\n",
        "      auto &node_def = tf_sub_fuction.node_def(j);\n",
        "      status = ConvertOps(node_def, tf_sub_node_map, sub_func_graph, &anf_sub_node_map);\n",
        "      if (status != RET_OK) {\n",
        "        MS_LOG(ERROR) << \"Convert subgraph ops failed.\";\n",
        "        ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\n",
        "        return RET_ERROR;\n",
        "      }\n",
        "    }\n",
        "\n",
        "    // convert subgraph outputs\n",
        "    std::vector<AnfNodePtr> sub_output_nodes;\n",
        "    auto &subgraph_ret = tf_sub_fuction.ret();\n",
        "    for (auto &t : subgraph_ret) {\n",
        "      MS_LOG(INFO) << \"subret \" << t.first << \" \" << t.second;\n",
        "      auto tf_output_name = GetFlattenNodeName(t.second);\n",
        "      AnfNodePtr anf_node = nullptr;\n",
        "      if (tf_sub_node_map.find(tf_output_name) == tf_sub_node_map.end()) {\n",
        "        anf_node = GetAnfNode(tf_output_name, anf_sub_node_map);\n",
        "      } else {\n",
        "        auto tf_real_name = GetOriginInputName(*tf_sub_node_map[tf_output_name], tf_sub_node_map);\n",
        "        anf_node = GetAnfNode(tf_real_name, anf_sub_node_map);\n",
        "      }\n",
        "      if (anf_node == nullptr) {\n",
        "        MS_LOG(ERROR) << \"can't find anf node,tf node flatten name\" << tf_output_name;\n",
        "        return RET_ERROR;\n",
        "      }\n",
        "      sub_output_nodes.push_back(anf_node);\n",
        "    }\n",
        "    status = MakeAnfGraphOutputs(&sub_output_nodes, sub_func_graph);\n",
        "    if (status != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"cmake anf graph outputs node error\";\n",
        "      return status;\n",
        "    }\n",
        "\n",
        "    // add while cond body function to while node input\n",
        "    if (sub_graph_name.find(\"cond\") != std::string::npos) {\n",
        "      while_cond_map[while_cnode] = sub_func_graph;\n",
        "    } else {\n",
        "      while_body_map[while_cnode] = sub_func_graph;\n",
        "    }\n",
        "    // hardcode subgraph inputs name\n",
        "    for (size_t j = 0; j < sub_graph_inputs.size(); j++) {\n",
        "      sub_graph_inputs[j]->set_name(\"graph_input_\" + std::to_string(j) + \"parameter\");\n",
        "    }\n",
        "    MS_LOG(INFO) << \"parse subgraph end:\" << sub_graph_name;\n",
        "  }\n",
        "  auto status = WhileNodePostProcess(while_cond_map, while_body_map);\n",
        "  if (status != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"while node post process failed\";\n",
        "    return status;\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "STATUS TFModelParser::WhileNodePostProcess(const std::map<CNodePtr, FuncGraphPtr> &while_cond_map,\n",
        "                                           const std::map<CNodePtr, FuncGraphPtr> &while_body_map) {\n",
        "  if (while_cond_map.size() != while_body_map.size()) {\n",
        "    MS_LOG(ERROR) << \"while cond body size error\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  auto root_func_manager = Manage(anf_root_graph, true);\n",
        "  auto anf_root_manager = anf_root_graph->manager();\n",
        "  for (auto &kv : while_cond_map) {\n",
        "    auto while_node = kv.first;\n",
        "    auto &cond_sub_graph = kv.second;\n",
        "    auto &body_sub_graph = while_body_map.at(while_node);\n",
        "    root_func_manager->AddFuncGraph(cond_sub_graph, false);\n",
        "    root_func_manager->AddFuncGraph(body_sub_graph, false);\n",
        "    auto cond_value_node = NewValueNode(cond_sub_graph);\n",
        "    auto body_value_node = NewValueNode(body_sub_graph);\n",
        "    auto new_while_inputs = while_node->cast<CNodePtr>()->inputs();\n",
        "    new_while_inputs[0] = cond_value_node;\n",
        "    new_while_inputs.insert(new_while_inputs.begin() + 1, body_value_node);\n",
        "    auto new_while_node = anf_root_graph->NewCNode(new_while_inputs);\n",
        "    new_while_node->set_abstract(while_node->abstract());\n",
        "    anf_root_manager->Replace(while_node, new_while_node);\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "schema::MetaGraphT *TFModelParser::ParseToFb(const std::string &modelFile, const std::string &weightFile,\n",
        "                                             const QuantType &quantType) {\n",
        "  MS_LOG(ERROR) << \"TF Model Parser not return MetaGraph, use TFModelParser::Parse instead\";\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "STATUS TFModelParser::ConvertInputNodes(const tensorflow::NodeDef &node_def,\n",
        "                                        const std::vector<std::string> &input_names,\n",
        "                                        const std::map<std::string, const tensorflow::NodeDef *> &tf_node_map,\n",
        "                                        const std::unordered_map<std::string, AnfNodePtr> &anf_node_map,\n",
        "                                        std::vector<AnfNodePtr> *inputs) {\n",
        "  // parse inputs\n",
        "  for (size_t j = 0; j < input_names.size(); j++) {\n",
        "    std::string input_name = input_names[j];  // input may be produced by multi-outputs node\n",
        "    // subgraph input name x:output:index,need flatten\n",
        "    auto flatten_input_name = GetFlattenNodeName(input_name);\n",
        "    if (tf_node_map.find(flatten_input_name) != tf_node_map.end()) {\n",
        "      auto input_node = tf_node_map.at(flatten_input_name);\n",
        "      flatten_input_name = GetOriginInputName(*input_node, tf_node_map);\n",
        "    }\n",
        "    auto input = GetAnfNode(flatten_input_name, anf_node_map);\n",
        "    if (input == nullptr) {\n",
        "      MS_LOG(ERROR) << node_def.name() << \" input \" << j << \": \" << input_name << \" can't find parsed in_nodes\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "    inputs->emplace_back(input);\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS TFModelParser::ConvertOutputTensor(const tensorflow::NodeDef &op,\n",
        "                                          const CNodePtr &anf_node,\n",
        "                                          std::unordered_map<std::string, AnfNodePtr> *anf_node_map,\n",
        "                                          const FuncGraphPtr &anf_graph,\n",
        "                                          int output_size) {\n",
        "  if (output_size == 1) {\n",
        "    std::vector<int64_t> shape_vector;\n",
        "    anf_node->set_abstract(std::make_shared<abstract::AbstractTensor>(kFloat32, shape_vector));\n",
        "    anf_node_map->insert(std::pair(op.name(), anf_node));\n",
        "  } else {\n",
        "    AbstractBasePtrList abstractList;\n",
        "    for (int output_idx = 0; output_idx < output_size; output_idx++) {\n",
        "      std::vector<int64_t> shape_vector;\n",
        "      abstractList.emplace_back(std::make_shared<abstract::AbstractTensor>(kFloat32, shape_vector));\n",
        "      auto tupleGetItemPrimPtr = GetTupleGetItemPrim();\n",
        "      if (tupleGetItemPrimPtr == nullptr) {\n",
        "        MS_LOG(ERROR) << \"GetTupleGetItemPrim return nullptr\";\n",
        "        return RET_NULL_PTR;\n",
        "      }\n",
        "      auto tupleGetItemPrim = NewValueNode(tupleGetItemPrimPtr);\n",
        "      auto getItemValue = NewValueNode(MakeValue<int>(output_idx));\n",
        "      std::vector<AnfNodePtr> inputs{tupleGetItemPrim, anf_node, getItemValue};\n",
        "      CNodePtr getItemCNode = anf_graph->NewCNode(inputs);\n",
        "      std::string output_item_name = anf_node->fullname_with_scope() + \"_getitem_\" + std::to_string(output_idx);\n",
        "      getItemCNode->set_fullname_with_scope(output_item_name);\n",
        "      anf_node_map->insert(std::pair(op.name() + \":\" + std::to_string(output_idx), getItemCNode));\n",
        "    }\n",
        "    anf_node->set_abstract(std::make_shared<abstract::AbstractTuple>(abstractList));\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS TFModelParser::ConvertOps(const tensorflow::NodeDef &node_def,\n",
        "                                 const std::map<std::string, const tensorflow::NodeDef *> &tf_node_map,\n",
        "                                 const FuncGraphPtr &func_graph_ptr,\n",
        "                                 std::unordered_map<std::string, AnfNodePtr> *anf_node_map) {\n",
        "  NoSupportOp::GetInstance()->SetFmkType(\"TF\");\n",
        "  STATUS status = RET_OK;\n",
        "  const auto &op_type = node_def.op();\n",
        "  if (op_type == \"Placeholder\" || op_type == \"Const\" || op_type == \"Identity\" || op_type == \"StopGradient\") {\n",
        "    return RET_OK;\n",
        "  }\n",
        "\n",
        "  auto node_parser = TFNodeParserRegistry::GetInstance()->GetNodeParser(op_type);\n",
        "  if (node_parser == nullptr) {\n",
        "    NoSupportOp::GetInstance()->InsertOp(op_type);\n",
        "    MS_LOG(ERROR) << \"cannot find node parser:\" << op_type;\n",
        "    return RET_NOT_FIND_OP;\n",
        "  }\n",
        "  PrimitiveC *primitiveC = nullptr;\n",
        "  int output_size;\n",
        "  std::vector<std::string> input_names;\n",
        "  status = node_parser->Parse(node_def, tf_node_map, &primitiveC, &input_names, &output_size);\n",
        "  if (status != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"node \" << op_type << \" parser failed\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  auto value_node = NewValueNode(std::shared_ptr<PrimitiveC>(primitiveC));\n",
        "  if (value_node == nullptr) {\n",
        "    MS_LOG(ERROR) << \"value_node is nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  std::vector<AnfNodePtr> inputs = {value_node};\n",
        "  status = ConvertInputNodes(node_def, input_names, tf_node_map, *anf_node_map, &inputs);\n",
        "  if (status != RET_OK) {\n",
        "    return status;\n",
        "  }\n",
        "  // control_depends are not processed currently\n",
        "  auto anf_node = func_graph_ptr->NewCNode(inputs);\n",
        "  anf_node->set_fullname_with_scope(op_type + \"-\" + std::to_string(op_idx++));\n",
        "  if (op_type == \"StatelessWhile\" || op_type == \"while\") {\n",
        "    MS_LOG(INFO) << \"find while node:\" << node_def.name();\n",
        "    auto &attr = node_def.attr();\n",
        "    tensorflow::AttrValue attr_value;\n",
        "    if (TensorFlowUtils::FindAttrValue(node_def, \"body\", &attr_value)) {\n",
        "      auto body_name = attr_value.func().name();\n",
        "      function_while_map[body_name] = anf_node;\n",
        "      MS_LOG(DEBUG) << \"parse body name:\" << body_name;\n",
        "    }\n",
        "    if (TensorFlowUtils::FindAttrValue(node_def, \"cond\", &attr_value)) {\n",
        "      auto cond_name = attr_value.func().name();\n",
        "      function_while_map[cond_name] = anf_node;\n",
        "      MS_LOG(DEBUG) << \"parse cond name:\" << cond_name;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  status = ConvertOutputTensor(node_def, anf_node, anf_node_map, func_graph_ptr, output_size);\n",
        "  if (status != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"Convert output tensors for \" << anf_node->fullname_with_scope() << \" failed.\";\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  return status;\n",
        "}\n",
        "\n",
        "STATUS TFModelParser::ConvertRootGraphOutputs() {\n",
        "  // because output of intermediate node in anf graph may also be output tensors, we search output tensors in\n",
        "  // tf_root_graph_nodes but not anf_root_node_map\n",
        "  std::set<std::string> all_node_inputs;\n",
        "  std::vector<AnfNodePtr> output_nodes;\n",
        "  for (auto &pair : tf_root_graph_nodes) {\n",
        "    for (int i = 0; i < pair.second->input_size(); ++i) {\n",
        "      all_node_inputs.insert(pair.second->input(i));\n",
        "    }\n",
        "  }\n",
        "  for (auto &pair : tf_root_graph_nodes) {\n",
        "    auto it = all_node_inputs.find(pair.first);\n",
        "    if (it == all_node_inputs.end() && pair.second->input_size() > 0) {  // output node not constraint to Identity\n",
        "      auto origin_name = GetOriginInputName(*(pair.second), tf_root_graph_nodes);\n",
        "      auto anf_node = GetAnfNode(origin_name, anf_root_node_map);\n",
        "      if (anf_node == nullptr) {\n",
        "        MS_LOG(ERROR) << \"can't find anf node\";\n",
        "        return RET_ERROR;\n",
        "      }\n",
        "      output_nodes.push_back(anf_node);\n",
        "      graph_output_names.push_back(anf_node->fullname_with_scope());\n",
        "    }\n",
        "  }\n",
        "  auto status = MakeAnfGraphOutputs(&output_nodes, anf_root_graph);\n",
        "  if (status != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"make anf graph outputs node error\";\n",
        "    return status;\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "STATUS TFModelParser::MakeAnfGraphOutputs(std::vector<AnfNodePtr> *output_nodes, const FuncGraphPtr &anf_graph) {\n",
        "  if (output_nodes->empty() || anf_graph == nullptr) {\n",
        "    MS_LOG(ERROR) << \"anf output nodes empty or  null anf graph\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  if (output_nodes->size() > 1) {\n",
        "    std::vector<AnfNodePtr> *make_tuple_inputs = output_nodes;\n",
        "    auto make_tuple_prim_ptr = GetMakeTuplePrim();\n",
        "    if (make_tuple_prim_ptr == nullptr) {\n",
        "      MS_LOG(ERROR) << \"GetMakeTuplePrim return nullptr\";\n",
        "      return RET_NULL_PTR;\n",
        "    }\n",
        "    auto make_tuple_prim = NewValueNode(make_tuple_prim_ptr);\n",
        "    make_tuple_inputs->insert(make_tuple_inputs->begin(), make_tuple_prim);\n",
        "    auto make_tuple_cnode = anf_graph->NewCNode(*make_tuple_inputs);\n",
        "    make_tuple_cnode->set_fullname_with_scope(\"return tuple\");\n",
        "\n",
        "    auto return_prim_ptr = GetReturnPrim();\n",
        "    if (return_prim_ptr == nullptr) {\n",
        "      MS_LOG(ERROR) << \"GetReturnPrim return nullptr\";\n",
        "      return RET_NULL_PTR;\n",
        "    }\n",
        "    auto value_node = NewValueNode(return_prim_ptr);\n",
        "    std::vector<AnfNodePtr> op_inputs = {value_node, make_tuple_cnode};\n",
        "    auto cnode = anf_graph->NewCNode(op_inputs);\n",
        "    cnode->set_fullname_with_scope(\"return\");\n",
        "    anf_graph->set_return(cnode);\n",
        "  } else {\n",
        "    auto return_prim_ptr = GetReturnPrim();\n",
        "    if (return_prim_ptr == nullptr) {\n",
        "      MS_LOG(ERROR) << \"GetReturnPrim return nullptr\";\n",
        "      return RET_NULL_PTR;\n",
        "    }\n",
        "    auto value_node = NewValueNode(return_prim_ptr);\n",
        "    std::vector<AnfNodePtr> op_inputs{value_node, output_nodes->front()};\n",
        "    auto return_cnode = anf_graph->NewCNode(op_inputs);\n",
        "    return_cnode->set_fullname_with_scope(\"return\");\n",
        "    anf_graph->set_return(return_cnode);\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Tn3MQMVb2E"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include \"tools/converter/parser/tf/tf_while_parser.h\"\n",
        "#include <string>\n",
        "#include <memory>\n",
        "#include <map>\n",
        "#include <vector>\n",
        "#include \"tools/converter/parser/tf/tf_node_parser_registry.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "STATUS TFWhileParser::Parse(const tensorflow::NodeDef &tf_op,\n",
        "                            const std::map<string, const tensorflow::NodeDef *> &tf_node_map, PrimitiveC **primitiveC,\n",
        "                            std::vector<std::string> *inputs, int *output_size) {\n",
        "  MS_LOG(INFO) << \"TF WhileParser\";\n",
        "  if (primitiveC == nullptr || output_size == nullptr) {\n",
        "    MS_LOG(ERROR) << \"primitiveC is nullptr\";\n",
        "    return RET_NULL_PTR;\n",
        "  }\n",
        "\n",
        "  auto primitive = std::make_unique<schema::PrimitiveT>();\n",
        "  if (primitive == nullptr) {\n",
        "    MS_LOG(ERROR) << \"primitive is nullptr\";\n",
        "    return RET_NULL_PTR;\n",
        "  }\n",
        "  auto attr = std::make_unique<schema::WhileT>();\n",
        "  if (attr == nullptr) {\n",
        "    MS_LOG(ERROR) << \"new op failed\";\n",
        "    return RET_NULL_PTR;\n",
        "  }\n",
        "\n",
        "  primitive->value.type = schema::PrimitiveType_While;\n",
        "  primitive->value.value = attr.release();\n",
        "  *primitiveC = PrimitiveC::Create(primitive.release());\n",
        "  if (*primitiveC == nullptr) {\n",
        "    MS_LOG(ERROR) << \"primitiveC is nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "\n",
        "  *output_size = tf_op.input_size();\n",
        "  for (int i = 0; i < tf_op.input_size(); i++) {\n",
        "    inputs->emplace_back(tf_op.input(i));\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "TFNodeRegistrar g_tfStatelessWhileParser(\"StatelessWhile\", new TFWhileParser());\n",
        "TFNodeRegistrar g_tfWhileParser(\"While\", new TFWhileParser());\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QElZdqNmVkfx"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#ifndef MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_TF_TF_WHILE_PARSER_H_\n",
        "#define MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_TF_TF_WHILE_PARSER_H_\n",
        "\n",
        "#include <string>\n",
        "#include <memory>\n",
        "#include <map>\n",
        "#include <vector>\n",
        "#include \"tools/converter/parser/tf/tf_node_parser.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "class TFWhileParser : public TFNodeParser {\n",
        " public:\n",
        "  TFWhileParser() = default;\n",
        "  ~TFWhileParser() override = default;\n",
        "\n",
        "  STATUS Parse(const tensorflow::NodeDef &tf_op, const std::map<string, const tensorflow::NodeDef *> &tf_node_map,\n",
        "               PrimitiveC **primitiveC, std::vector<std::string> *inputs, int *output_size) override;\n",
        "};\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n",
        "#endif  // MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_TF_TF_MATMUL_PARSER_H_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z87WEpSKV1gC"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#ifndef MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_TF_TF_LOGICAL_PARSER_H_\n",
        "#define MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_TF_TF_LOGICAL_PARSER_H_\n",
        "\n",
        "#include <string>\n",
        "#include <memory>\n",
        "#include <map>\n",
        "#include <vector>\n",
        "#include \"tools/converter/parser/tf/tf_node_parser.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "class TFLogicalParser : public TFNodeParser {\n",
        " public:\n",
        "  TFLogicalParser() = default;\n",
        "  ~TFLogicalParser() override = default;\n",
        "\n",
        "  STATUS Parse(const tensorflow::NodeDef &tf_op, const std::map<string, const tensorflow::NodeDef *> &tf_node_map,\n",
        "               PrimitiveC **primitiveC, std::vector<std::string> *inputs, int *output_size) override;\n",
        "};\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n",
        "#endif  // MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_TF_TF_LOGICAL_PARSER_H_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXAbDhCdW1m2"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include \"tools/converter/parser/tf/tf_logical_parser.h\"\n",
        "#include <string>\n",
        "#include <memory>\n",
        "#include <map>\n",
        "#include <vector>\n",
        "#include \"tools/converter/parser/tf/tf_node_parser_registry.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "STATUS TFLogicalParser::Parse(const tensorflow::NodeDef &tf_op,\n",
        "                              const std::map<string, const tensorflow::NodeDef *> &tf_node_map, PrimitiveC **primitiveC,\n",
        "                              std::vector<std::string> *inputs, int *output_size) {\n",
        "  MS_LOG(INFO) << \"TF LogicalParser\";\n",
        "  if (primitiveC == nullptr || output_size == nullptr) {\n",
        "    MS_LOG(ERROR) << \"primitiveC is nullptr\";\n",
        "    return RET_NULL_PTR;\n",
        "  }\n",
        "\n",
        "  auto primitive = std::make_unique<schema::PrimitiveT>();\n",
        "  if (primitive == nullptr) {\n",
        "    MS_LOG(ERROR) << \"primitive is nullptr\";\n",
        "    return RET_NULL_PTR;\n",
        "  }\n",
        "  if (tf_op.op() == \"LogicalAnd\") {\n",
        "    auto attr = std::make_unique<schema::LogicalAndT>();\n",
        "    if (attr == nullptr) {\n",
        "      MS_LOG(ERROR) << \"new op failed\";\n",
        "      return RET_NULL_PTR;\n",
        "    }\n",
        "    primitive->value.type = schema::PrimitiveType_LogicalAnd;\n",
        "    primitive->value.value = attr.release();\n",
        "    *primitiveC = PrimitiveC::Create(primitive.release());\n",
        "  }\n",
        "  if (*primitiveC == nullptr) {\n",
        "    MS_LOG(ERROR) << \"primitiveC is nullptr\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "\n",
        "  *output_size = 1;\n",
        "  for (int i = 0; i < tf_op.input_size(); i++) {\n",
        "    inputs->emplace_back(tf_op.input(i));\n",
        "  }\n",
        "\n",
        "  return RET_OK;\n",
        "}\n",
        "TFNodeRegistrar g_tfLogicalAndParser(\"LogicalAnd\", new TFLogicalParser());\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}