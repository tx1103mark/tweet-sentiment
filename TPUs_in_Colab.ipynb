{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93a3Yz_tHf4"
      },
      "source": [
        "From cb8484a4126de3624c4df16b48d47364a44e69f0 Mon Sep 17 00:00:00 2001\r\n",
        "From: guohongzilong <guohongzilong@huawei.com>\r\n",
        "Date: Fri, 12 Mar 2021 11:40:35 +0800\r\n",
        "Subject: [PATCH] sync lite code\r\n",
        "\r\n",
        "---\r\n",
        " mindspore/lite/examples/train_lenet/Makefile       |   8 +-\r\n",
        " .../lite/examples/train_lenet/src/lenet_train.cc   | 307 +++++++++++++++++++++\r\n",
        " .../lite/examples/train_lenet/src/lenet_train.h    |  35 +++\r\n",
        " .../lite/examples/train_lenet/src/test_run.cc      |  60 ++++\r\n",
        " .../lite/flclient/src/main/native/CMakeLists.txt   |  10 +-\r\n",
        " .../flclient/src/main/native/include/lenet_train.h |   2 +-\r\n",
        " .../flclient/src/main/native/src/lenet_train.cpp   |  80 +++---\r\n",
        " mindspore/lite/include/train_session.h             |  12 +\r\n",
        " mindspore/lite/schema/ops.fbs                      |  17 +-\r\n",
        " mindspore/lite/src/train/train_session.cc          |  58 ++++\r\n",
        " mindspore/lite/src/train/train_session.h           |   4 +\r\n",
        " 11 files changed, 538 insertions(+), 55 deletions(-)\r\n",
        " create mode 100644 mindspore/lite/examples/train_lenet/src/lenet_train.cc\r\n",
        " create mode 100644 mindspore/lite/examples/train_lenet/src/lenet_train.h\r\n",
        " create mode 100644 mindspore/lite/examples/train_lenet/src/test_run.cc\r\n",
        "\r\n",
        "diff --git a/mindspore/lite/examples/train_lenet/Makefile b/mindspore/lite/examples/train_lenet/Makefile\r\n",
        "index 7e2b69c..5aabd01 100644\r\n",
        "--- a/mindspore/lite/examples/train_lenet/Makefile\r\n",
        "+++ b/mindspore/lite/examples/train_lenet/Makefile\r\n",
        "@@ -5,15 +5,17 @@ LMDLIB:=-lminddata-lite -ljpeg\r\n",
        " LHIAILIB:=-lhiai_ir_build  -lhiai_ir -lhiai\r\n",
        " MSDIR:=$(realpath package-$(TARGET)/lib)\r\n",
        " \r\n",
        "-SRC:=src/net_runner.cc\r\n",
        "+SRC:=src/test_run.cc src/lenet_train.cc\r\n",
        " OBJ:=$(SRC:.cc=.o)\r\n",
        " \r\n",
        " CFLAGS := -Ofast -std=c++17  \\\r\n",
        " \t-I . \\\r\n",
        "+\t   -I ../../ \\\r\n",
        "         -I ./msl \\\r\n",
        "         -I ./msl/minddata \\\r\n",
        "-        -I ./msl/third_party/flatbuffers/include\r\n",
        "-\r\n",
        "+        -I ./msl/third_party/flatbuffers/include \\\r\n",
        "+           -I ./msl/include \\\r\n",
        "+                   -I ../../build \\\r\n",
        " \r\n",
        " ifeq ($(TARGET),arm64)\r\n",
        " CXX :=  ${ANDROID_NDK}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++\r\n",
        "diff --git a/mindspore/lite/examples/train_lenet/src/lenet_train.cc b/mindspore/lite/examples/train_lenet/src/lenet_train.cc\r\n",
        "new file mode 100644\r\n",
        "index 0000000..e6c6a90\r\n",
        "--- /dev/null\r\n",
        "+++ b/mindspore/lite/examples/train_lenet/src/lenet_train.cc\r\n",
        "@@ -0,0 +1,307 @@\r\n",
        "+/**\r\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        "+ *\r\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        "+ * you may not use this file except in compliance with the License.\r\n",
        "+ * You may obtain a copy of the License at\r\n",
        "+ *\r\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        "+ *\r\n",
        "+ * Unless required by applicable law or agreed to in writing, software\r\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        "+ * See the License for the specific language governing permissions and\r\n",
        "+ * limitations under the License.\r\n",
        "+ */\r\n",
        "+#include \"lenet_train.h\"\r\n",
        "+#include <cstring>\r\n",
        "+#include <fstream>\r\n",
        "+#include <iostream>\r\n",
        "+#include \"include/api/lite_context.h\"\r\n",
        "+#include \"include/context.h\"\r\n",
        "+#include \"include/errorcode.h\"\r\n",
        "+#include \"limits.h\"\r\n",
        "+\r\n",
        "+static char *fl_lenet_I0 = 0;\r\n",
        "+static char *fl_lenet_I1 = 0;\r\n",
        "+unsigned int seed_ = time(NULL);\r\n",
        "+\r\n",
        "+std::vector<int> FillInputData(mindspore::session::TrainSession *train_session, int batch_num, bool serially) {\r\n",
        "+  std::vector<int> labels_vec;\r\n",
        "+  auto inputs = train_session->GetInputs();\r\n",
        "+  int batch_size = inputs[0]->shape()[0];\r\n",
        "+  static unsigned int idx = 1;\r\n",
        "+  int data_size = inputs[0]->ElementsNum() / batch_size;\r\n",
        "+  int num_classes = inputs[1]->shape()[1];\r\n",
        "+  float *input_data = reinterpret_cast<float *>(inputs.at(0)->MutableData());\r\n",
        "+  auto labels = reinterpret_cast<float *>(inputs.at(1)->MutableData());\r\n",
        "+  std::fill(labels, labels + inputs.at(1)->ElementsNum(), 0.f);\r\n",
        "+  for (int i = 0; i < batch_size; i++) {\r\n",
        "+    if (serially) {\r\n",
        "+      idx = ++idx % (batch_num*batch_size);\r\n",
        "+    } else {\r\n",
        "+      idx = rand_r(&seed_) % (batch_num*batch_size);\r\n",
        "+    }\r\n",
        "+    std::memcpy(input_data + i * data_size, (float*)fl_lenet_I0 + idx * data_size, data_size*sizeof(float));\r\n",
        "+    int label_idx = *(reinterpret_cast<int *>(fl_lenet_I1) + idx);\r\n",
        "+    labels[i * num_classes + label_idx] = 1.0;  // Model expects labels in onehot representation\r\n",
        "+    labels_vec.push_back(label_idx);\r\n",
        "+  }\r\n",
        "+  return labels_vec;\r\n",
        "+}\r\n",
        "+\r\n",
        "+\r\n",
        "+std::vector<int> FillInputData2(mindspore::session::TrainSession *train_session, int batch_idx, bool serially) {\r\n",
        "+  std::vector<int> labels_vec;\r\n",
        "+  auto inputs = train_session->GetInputs();\r\n",
        "+  int batch_size = inputs[0]->shape()[0];\r\n",
        "+  static unsigned int idx = 1;\r\n",
        "+  int data_size = inputs[0]->ElementsNum() / batch_size;\r\n",
        "+  int num_classes = inputs[1]->shape()[1];\r\n",
        "+  float *input_data = reinterpret_cast<float *>(inputs.at(0)->MutableData());\r\n",
        "+  auto labels = reinterpret_cast<float *>(inputs.at(1)->MutableData());\r\n",
        "+  std::fill(labels, labels + inputs.at(1)->ElementsNum(), 0.f);\r\n",
        "+  for (int i = 0; i < batch_size; i++) {\r\n",
        "+    idx = i;\r\n",
        "+    std::memcpy(input_data + i * data_size, (float*)fl_lenet_I0 +batch_idx* inputs[0]->ElementsNum() + idx * data_size, data_size*sizeof(float));\r\n",
        "+    int label_idx = *(reinterpret_cast<int *>(fl_lenet_I1)+batch_idx *batch_size + idx);\r\n",
        "+    labels[i * num_classes + label_idx] = 1.0;  // Model expects labels in onehot representation\r\n",
        "+    labels_vec.push_back(label_idx);\r\n",
        "+\r\n",
        "+//    std::cout<< \"fill input data:\"<< \",idx:\"<<idx<< \",labels idx:\"<< label_idx <<std::endl;\r\n",
        "+//    float sum_input = 0.0f;\r\n",
        "+//    float sum_fl_input = 0.0f;\r\n",
        "+//    for(int j=0;j<data_size;j++) {\r\n",
        "+//      sum_input+=*(input_data+i*data_size+j);\r\n",
        "+//      sum_fl_input+=*((float*)fl_lenet_I0 + batch_idx* inputs[0]->ElementsNum()+idx * data_size+j);\r\n",
        "+//    }\r\n",
        "+//    std::cout<< \"sum_input:\"<<sum_input<<\",sum_fl_input\"<<sum_fl_input<<std::endl;\r\n",
        "+//    std::cout<<\"------------------\"<<std::endl;\r\n",
        "+  }\r\n",
        "+//    std::cout<< \"-------------next batchsize----------\"<<std::endl;\r\n",
        "+  return labels_vec;\r\n",
        "+}\r\n",
        "+\r\n",
        "+mindspore::tensor::MSTensor *SearchOutputsForSize(mindspore::session::TrainSession *train_session, size_t size) {\r\n",
        "+  auto outputs = train_session->GetOutputs();\r\n",
        "+  for (auto it = outputs.begin(); it != outputs.end(); ++it) {\r\n",
        "+    if (it->second->ElementsNum() == size) return it->second;\r\n",
        "+  }\r\n",
        "+ std::cout << \"Model does not have an output tensor with size \";\r\n",
        "+  return nullptr;\r\n",
        "+}\r\n",
        "+\r\n",
        "+float GetLoss(mindspore::session::TrainSession *train_session) {\r\n",
        "+  auto outputsv = SearchOutputsForSize(train_session, 1);  // Search for Loss which is a single value tensor\r\n",
        "+  if (outputsv == nullptr) {\r\n",
        "+    return 10000;\r\n",
        "+  }\r\n",
        "+  auto loss = reinterpret_cast<float *>(outputsv->MutableData());\r\n",
        "+  return loss[0];\r\n",
        "+}\r\n",
        "+mindspore::session::TrainSession *GetSession(const std::string &ms_file, bool train_mode) {\r\n",
        "+  // create model file\r\n",
        "+  mindspore::lite::Context context;\r\n",
        "+  context.device_list_[0].device_info_.cpu_device_info_.cpu_bind_mode_ = mindspore::lite::NO_BIND;\r\n",
        "+  context.thread_num_ = 1;\r\n",
        "+  return mindspore::session::TrainSession::CreateSession(ms_file, &context, train_mode);\r\n",
        "+}\r\n",
        "+\r\n",
        "+float CalculateAccuracy(mindspore::session::TrainSession *session,int batch_num) {\r\n",
        "+  session->Eval();\r\n",
        "+  auto labels = FillInputData(session, batch_num, false);\r\n",
        "+  session->RunGraph();\r\n",
        "+  auto inputs = session->GetInputs();\r\n",
        "+  auto batch_size = inputs[1]->shape()[0];\r\n",
        "+  auto num_of_class = inputs[1]->shape()[1];\r\n",
        "+  auto outputsv = SearchOutputsForSize(session, batch_size * num_of_class);\r\n",
        "+  auto scores = reinterpret_cast<float *>(outputsv->MutableData());\r\n",
        "+  float accuracy = 0.0;\r\n",
        "+  for (int b = 0; b < batch_size; b++) {\r\n",
        "+    int max_idx = 0;\r\n",
        "+    float max_score = scores[num_of_class * b];\r\n",
        "+    for (int c = 0; c < num_of_class; c++) {\r\n",
        "+      if (scores[num_of_class * b + c] > max_score) {\r\n",
        "+        max_score = scores[num_of_class * b + c];\r\n",
        "+        max_idx = c;\r\n",
        "+      }\r\n",
        "+    }\r\n",
        "+    if (labels[b] == max_idx) accuracy += 1.0;\r\n",
        "+  }\r\n",
        "+  return accuracy/batch_size;\r\n",
        "+}\r\n",
        "+\r\n",
        "+\r\n",
        "+// net training function\r\n",
        "+float fl_lenet_lite_Inference(const std::string &ms_file, int batch_num, int test_nums) {\r\n",
        "+  auto session = GetSession(ms_file, false);\r\n",
        "+  char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\r\n",
        "+  float sum_acc = 0.0f;\r\n",
        "+  for (int j = 0; j < test_nums; ++j) {\r\n",
        "+    auto acc_per_test = CalculateAccuracy(session,batch_num);\r\n",
        "+    sum_acc+=acc_per_test;\r\n",
        "+    std::cout << \"infer:\"<< j <<\"times,acc is \" << acc_per_test << std::endl;\r\n",
        "+  }\r\n",
        "+  fl_lenet_I0 = origin_input[0];\r\n",
        "+  fl_lenet_I1 = origin_input[1];\r\n",
        "+  return sum_acc/test_nums;\r\n",
        "+}\r\n",
        "+\r\n",
        "+\r\n",
        "+// net training function\r\n",
        "+int fl_lenet_lite_Train(const std::string &ms_file, const int batch_num, const int iterations) {\r\n",
        "+  auto session = GetSession(ms_file, true);\r\n",
        "+  if (iterations <= 0) {\r\n",
        "+   std::cout << \"error iterations or epoch!, epoch:\"\r\n",
        "+                  << \", iterations\" << iterations;\r\n",
        "+    return mindspore::lite::RET_ERROR;\r\n",
        "+  }\r\n",
        "+ std::cout << \"total iterations :\" << iterations << \"batch_num:\" << batch_num <<std::endl;\r\n",
        "+  char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\r\n",
        "+  for (int j = 0; j < iterations/batch_num; ++j) {\r\n",
        "+    float sum_loss_per_epoch = 0.0f;\r\n",
        "+    for(int k=0;k<batch_num;++k) {\r\n",
        "+//      FillInputData(session, batch_num, false);\r\n",
        "+      FillInputData2(session,k,false);\r\n",
        "+      session->RunGraph(nullptr, nullptr);\r\n",
        "+      sum_loss_per_epoch+=GetLoss(session);\r\n",
        "+    }\r\n",
        "+    std::cout << \"epoch \" << \"[\" <<j<<\"]\" << \",mean Loss \" << sum_loss_per_epoch/batch_num <<\",train acc \"<< CalculateAccuracy(session,batch_num) <<std::endl;\r\n",
        "+    session->Train();\r\n",
        "+  }\r\n",
        "+  session->SaveToFile(ms_file);\r\n",
        "+  fl_lenet_I0 = origin_input[0];\r\n",
        "+  fl_lenet_I1 = origin_input[1];\r\n",
        "+  return mindspore::lite::RET_OK;\r\n",
        "+}\r\n",
        "+\r\n",
        "+int fl_lenet_lite_UpdateFeatures(const std::string &update_ms_file, TrainFeatureParam *new_features, int size) {\r\n",
        "+  auto train_session = GetSession(update_ms_file, false);\r\n",
        "+  auto status = train_session->UpdateFeatureMaps(update_ms_file, new_features, size);\r\n",
        "+  if (status != mindspore::lite::RET_OK) {\r\n",
        "+   std::cout << \"update model feature map failed\" << update_ms_file;\r\n",
        "+  }\r\n",
        "+  delete train_session;\r\n",
        "+  return status;\r\n",
        "+}\r\n",
        "+\r\n",
        "+int fl_lenet_lite_GetFeatures(const std::string &update_ms_file, mindspore::session::TrainFeatureParam ***feature,\r\n",
        "+                              int *size) {\r\n",
        "+  auto train_session = GetSession(update_ms_file, false);\r\n",
        "+  std::vector<mindspore::session::TrainFeatureParam *> new_features;\r\n",
        "+  auto status = train_session->GetFeatureMaps(&new_features);\r\n",
        "+  if (status != mindspore::lite::RET_OK) {\r\n",
        "+   std::cout << \"get model feature map failed\" << update_ms_file;\r\n",
        "+    delete train_session;\r\n",
        "+    return mindspore::lite::RET_ERROR;\r\n",
        "+  }\r\n",
        "+  *feature = new (std::nothrow) TrainFeatureParam *[new_features.size()];\r\n",
        "+  if (*feature == nullptr) {\r\n",
        "+   std::cout << \"create features failed\";\r\n",
        "+    delete train_session;\r\n",
        "+    return mindspore::lite::RET_ERROR;\r\n",
        "+  }\r\n",
        "+  for (int i = 0; i < new_features.size(); i++) {\r\n",
        "+    (*feature)[i] = new_features[i];\r\n",
        "+  }\r\n",
        "+  *size = new_features.size();\r\n",
        "+  delete train_session;\r\n",
        "+  return mindspore::lite::RET_OK;\r\n",
        "+}\r\n",
        "+\r\n",
        "+std::string RealPath(const char *path) {\r\n",
        "+  if (path == nullptr) {\r\n",
        "+   std::cout << \"path is nullptr\";\r\n",
        "+    return \"\";\r\n",
        "+  }\r\n",
        "+  if ((strlen(path)) >= PATH_MAX) {\r\n",
        "+   std::cout << \"path is too long\";\r\n",
        "+    return \"\";\r\n",
        "+  }\r\n",
        "+  auto resolved_path = std::make_unique<char[]>(PATH_MAX);\r\n",
        "+  if (resolved_path == nullptr) {\r\n",
        "+   std::cout << \"new resolved_path failed\";\r\n",
        "+    return \"\";\r\n",
        "+  }\r\n",
        "+#ifdef _WIN32\r\n",
        "+  char *real_path = _fullpath(resolved_path.get(), path, 1024);\r\n",
        "+#else\r\n",
        "+  char *real_path = realpath(path, resolved_path.get());\r\n",
        "+#endif\r\n",
        "+  if (real_path == nullptr || strlen(real_path) == 0) {\r\n",
        "+   std::cout << \"file path is not valid : \" << path;\r\n",
        "+    return \"\";\r\n",
        "+  }\r\n",
        "+  std::string res = resolved_path.get();\r\n",
        "+  return res;\r\n",
        "+}\r\n",
        "+\r\n",
        "+char *ReadFile(const char *file, size_t *size) {\r\n",
        "+  if (file == nullptr) {\r\n",
        "+   std::cout << \"file is nullptr\";\r\n",
        "+    return nullptr;\r\n",
        "+  }\r\n",
        "+  //  MS_ASSERT(size != nullptr);\r\n",
        "+  std::string real_path = RealPath(file);\r\n",
        "+  std::ifstream ifs(real_path);\r\n",
        "+  if (!ifs.good()) {\r\n",
        "+   std::cout << \"file: \" << real_path << \" is not exist\";\r\n",
        "+    return nullptr;\r\n",
        "+  }\r\n",
        "+\r\n",
        "+  if (!ifs.is_open()) {\r\n",
        "+   std::cout << \"file: \" << real_path << \" open failed\";\r\n",
        "+    return nullptr;\r\n",
        "+  }\r\n",
        "+\r\n",
        "+  ifs.seekg(0, std::ios::end);\r\n",
        "+  *size = ifs.tellg();\r\n",
        "+  std::unique_ptr<char[]> buf(new (std::nothrow) char[*size]);\r\n",
        "+  if (buf == nullptr) {\r\n",
        "+   std::cout << \"malloc buf failed, file: \" << real_path;\r\n",
        "+    ifs.close();\r\n",
        "+    return nullptr;\r\n",
        "+  }\r\n",
        "+  ifs.seekg(0, std::ios::beg);\r\n",
        "+  ifs.read(buf.get(), *size);\r\n",
        "+  ifs.close();\r\n",
        "+\r\n",
        "+  return buf.release();\r\n",
        "+}\r\n",
        "+\r\n",
        "+// Set input tensors.\r\n",
        "+int fl_lenet_lite_SetInputs(const std::string &files, int num) {\r\n",
        "+  std::vector<std::string> res;\r\n",
        "+  if (files.empty()) {\r\n",
        "+   std::cout << \"files empty\";\r\n",
        "+    return -1;\r\n",
        "+  }\r\n",
        "+  std::string pattern = \",\";\r\n",
        "+  std::string strs = files + pattern;\r\n",
        "+  size_t pos = strs.find(pattern);\r\n",
        "+  while (pos != strs.npos) {\r\n",
        "+    std::string temp = strs.substr(0, pos);\r\n",
        "+    res.push_back(temp);\r\n",
        "+    strs = strs.substr(pos + 1, strs.size());\r\n",
        "+    pos = strs.find(pattern);\r\n",
        "+  }\r\n",
        "+  if (res.size() != 2) {\r\n",
        "+   std::cout << \"res size not equal 2\";\r\n",
        "+    return -1;\r\n",
        "+  }\r\n",
        "+  for (int i = 0; i < 2; i++) {\r\n",
        "+    size_t size;\r\n",
        "+    char *bin_buf = ReadFile(res[i].c_str(), &size);\r\n",
        "+    if (bin_buf == nullptr) {\r\n",
        "+     std::cout << \"ReadFile return nullptr\";\r\n",
        "+      return mindspore::lite::RET_ERROR;\r\n",
        "+    }\r\n",
        "+    if (i == 0) {\r\n",
        "+      fl_lenet_I0 = bin_buf;\r\n",
        "+    }\r\n",
        "+    if (i == 1) {\r\n",
        "+      fl_lenet_I1 = bin_buf;\r\n",
        "+    }\r\n",
        "+  }\r\n",
        "+  return 0;\r\n",
        "+}\r\n",
        "diff --git a/mindspore/lite/examples/train_lenet/src/lenet_train.h b/mindspore/lite/examples/train_lenet/src/lenet_train.h\r\n",
        "new file mode 100644\r\n",
        "index 0000000..ad173f5\r\n",
        "--- /dev/null\r\n",
        "+++ b/mindspore/lite/examples/train_lenet/src/lenet_train.h\r\n",
        "@@ -0,0 +1,35 @@\r\n",
        "+/**\r\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        "+ *\r\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        "+ * you may not use this file except in compliance with the License.\r\n",
        "+ * You may obtain a copy of the License at\r\n",
        "+ *\r\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        "+ *\r\n",
        "+ * Unless required by applicable law or agreed to in writing, software\r\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        "+ * See the License for the specific language governing permissions and\r\n",
        "+ * limitations under the License.\r\n",
        "+ */\r\n",
        "+\r\n",
        "+#ifndef MSLITE_FL_LITE_LENET_H\r\n",
        "+#define MSLITE_FL_LITE_LENET_H\r\n",
        "+\r\n",
        "+#include <string>\r\n",
        "+#include \"include/train_session.h\"\r\n",
        "+\r\n",
        "+using mindspore::session::TrainFeatureParam;\r\n",
        "+\r\n",
        "+int fl_lenet_lite_Train(const std::string &ms_file, const int batch_num, const int iterations);\r\n",
        "+\r\n",
        "+float fl_lenet_lite_Inference(const std::string &ms_file, int batch_num, int test_nums);\r\n",
        "+\r\n",
        "+int fl_lenet_lite_GetFeatures(const std::string &update_ms_file, mindspore::session::TrainFeatureParam ***features,\r\n",
        "+                              int *size);\r\n",
        "+int fl_lenet_lite_UpdateFeatures(const std::string &update_ms_file, TrainFeatureParam *new_features, int size);\r\n",
        "+mindspore::session::TrainSession *GetSession(const std::string &ms_file, bool train_mode = false);\r\n",
        "+\r\n",
        "+int fl_lenet_lite_SetInputs(const std::string &files, int num);\r\n",
        "+#endif  // MSLITE_FL_LITE_LENET_H\r\n",
        "diff --git a/mindspore/lite/examples/train_lenet/src/test_run.cc b/mindspore/lite/examples/train_lenet/src/test_run.cc\r\n",
        "new file mode 100644\r\n",
        "index 0000000..ae90a7d\r\n",
        "--- /dev/null\r\n",
        "+++ b/mindspore/lite/examples/train_lenet/src/test_run.cc\r\n",
        "@@ -0,0 +1,60 @@\r\n",
        "+/**\r\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        "+ *\r\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        "+ * you may not use this file except in compliance with the License.\r\n",
        "+ * You may obtain a copy of the License at\r\n",
        "+ *\r\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        "+ *\r\n",
        "+ * Unless required by applicable law or agreed to in writing, software\r\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        "+ * See the License for the specific language governing permissions and\r\n",
        "+ * limitations under the License.\r\n",
        "+ */\r\n",
        "+\r\n",
        "+#include \"src/net_runner.h\"\r\n",
        "+#include <math.h>\r\n",
        "+#include <getopt.h>\r\n",
        "+#include <cstring>\r\n",
        "+#include <iostream>\r\n",
        "+#include <fstream>\r\n",
        "+#include <utility>\r\n",
        "+#include \"include/context.h\"\r\n",
        "+#include \"include/train/loss_monitor.h\"\r\n",
        "+#include \"include/train/ckpt_saver.h\"\r\n",
        "+#include \"include/train/lr_scheduler.h\"\r\n",
        "+#include \"include/train/accuracy_metrics.h\"\r\n",
        "+#include \"include/train/classification_train_accuracy_monitor.h\"\r\n",
        "+#include \"lenet_train.h\"\r\n",
        "+\r\n",
        "+\r\n",
        "+int main(int argc, char **argv) {\r\n",
        "+  std::string train_dataset =\r\n",
        "+    \"/home/meng/zj10/hdc/mindspore/mindspore/lite/flclient/src/main/resources/client_data/f0049_32/\"\r\n",
        "+    \"f0049_32_train_data.bin,/home/meng/zj10/hdc/mindspore/mindspore/lite/flclient/src/main/resources/client_data/\"\r\n",
        "+    \"f0049_32/f0049_32_train_label.bin\";\r\n",
        "+  auto status = fl_lenet_lite_SetInputs(train_dataset, 2);\r\n",
        "+  std::cout << \"set input ok\" << std::endl;\r\n",
        "+  if (status != 0) {\r\n",
        "+    std::cout << \"set inputs error\";\r\n",
        "+  }\r\n",
        "+  std::string ms_file = \"/home/meng/zj10/hdc/fl/mindspore/mindspore/lite/lenet_train.mindir.ms\";\r\n",
        "+  int batches_per_epoch = 11;\r\n",
        "+  fl_lenet_lite_Train(ms_file,batches_per_epoch, 11*2000);\r\n",
        "+\r\n",
        "+  // eval\r\n",
        "+  std::string test_dataset =\r\n",
        "+    \"/home/meng/zj10/hdc/mindspore/mindspore/lite/flclient/src/main/resources/client_data/f0049_32/\"\r\n",
        "+    \"f0049_32_test_data.bin,/home/meng/zj10/hdc/mindspore/mindspore/lite/flclient/src/main/resources/client_data/\"\r\n",
        "+    \"f0049_32/f0049_32_test_label.bin\";\r\n",
        "+  status = fl_lenet_lite_SetInputs(test_dataset, 2);\r\n",
        "+  if (status != 0) {\r\n",
        "+    std::cout << \"set inputs error\";\r\n",
        "+  }\r\n",
        "+  batches_per_epoch = 1;\r\n",
        "+  auto accuracy =fl_lenet_lite_Inference(ms_file,batches_per_epoch, 1);\r\n",
        "+\r\n",
        "+  return 0;\r\n",
        "+}\r\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/CMakeLists.txt b/mindspore/lite/flclient/src/main/native/CMakeLists.txt\r\n",
        "index 81a9ff9..1ee548e 100644\r\n",
        "--- a/mindspore/lite/flclient/src/main/native/CMakeLists.txt\r\n",
        "+++ b/mindspore/lite/flclient/src/main/native/CMakeLists.txt\r\n",
        "@@ -12,12 +12,10 @@ set(LITE_DIR ${TOP_DIR}/mindspore/lite)\r\n",
        " set(MS_VERSION_MAJOR ${MS_VERSION_MAJOR})\r\n",
        " set(MS_VERSION_MINOR ${MS_VERSION_MINOR})\r\n",
        " set(MS_VERSION_REVISION ${MS_VERSION_REVISION})\r\n",
        "-set(CMAKE_C_FLAGS\r\n",
        "-    \"${CMAKE_C_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} \"\r\n",
        "-    \"-DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        "-set(CMAKE_CXX_FLAGS\r\n",
        "-      \"${CMAKE_CXX_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} \"\r\n",
        "-      \"-DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        "+set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} \\\r\n",
        "+  -DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        "+set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} \\\r\n",
        "+  -DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        " set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++17\")\r\n",
        " \r\n",
        " include_directories(${CMAKE_CURRENT_SOURCE_DIR})\r\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/include/lenet_train.h b/mindspore/lite/flclient/src/main/native/include/lenet_train.h\r\n",
        "index 4d448af..ad173f5 100644\r\n",
        "--- a/mindspore/lite/flclient/src/main/native/include/lenet_train.h\r\n",
        "+++ b/mindspore/lite/flclient/src/main/native/include/lenet_train.h\r\n",
        "@@ -24,7 +24,7 @@ using mindspore::session::TrainFeatureParam;\r\n",
        " \r\n",
        " int fl_lenet_lite_Train(const std::string &ms_file, const int batch_num, const int iterations);\r\n",
        " \r\n",
        "-int fl_lenet_lite_Inference(const std::string &ms_file, int batch_num, int test_nums);\r\n",
        "+float fl_lenet_lite_Inference(const std::string &ms_file, int batch_num, int test_nums);\r\n",
        " \r\n",
        " int fl_lenet_lite_GetFeatures(const std::string &update_ms_file, mindspore::session::TrainFeatureParam ***features,\r\n",
        "                               int *size);\r\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/src/lenet_train.cpp b/mindspore/lite/flclient/src/main/native/src/lenet_train.cpp\r\n",
        "index 4455efb..728f0fe 100644\r\n",
        "--- a/mindspore/lite/flclient/src/main/native/src/lenet_train.cpp\r\n",
        "+++ b/mindspore/lite/flclient/src/main/native/src/lenet_train.cpp\r\n",
        "@@ -21,6 +21,7 @@\r\n",
        " #include \"include/context.h\"\r\n",
        " #include \"include/errorcode.h\"\r\n",
        " #include \"src/common/log_adapter.h\"\r\n",
        "+#include \"limits.h\"\r\n",
        " \r\n",
        " static char *fl_lenet_I0 = 0;\r\n",
        " static char *fl_lenet_I1 = 0;\r\n",
        "@@ -33,16 +34,16 @@ std::vector<int> FillInputData(mindspore::session::TrainSession *train_session,\r\n",
        "   static unsigned int idx = 1;\r\n",
        "   int data_size = inputs[0]->ElementsNum() / batch_size;\r\n",
        "   int num_classes = inputs[1]->shape()[1];\r\n",
        "-  char *input_data = reinterpret_cast<char *>(inputs.at(0)->MutableData());\r\n",
        "+  float* input_data = reinterpret_cast<float *>(inputs.at(0)->MutableData());\r\n",
        "   auto labels = reinterpret_cast<float *>(inputs.at(1)->MutableData());\r\n",
        "   std::fill(labels, labels + inputs.at(1)->ElementsNum(), 0.f);\r\n",
        "   for (int i = 0; i < batch_size; i++) {\r\n",
        "     if (serially) {\r\n",
        "-      idx = ++idx % batch_num;\r\n",
        "+      idx = ++idx % (batch_num*batch_size);\r\n",
        "     } else {\r\n",
        "-      idx = rand_r(&seed_) % batch_num;\r\n",
        "+      idx = rand_r(&seed_) % (batch_num*batch_size);\r\n",
        "     }\r\n",
        "-    std::memcpy(input_data + i * data_size, fl_lenet_I0 + idx * data_size, data_size);\r\n",
        "+    std::memcpy(input_data + i * data_size, (float*)fl_lenet_I0 + idx * data_size, data_size*sizeof(float));\r\n",
        "     int label_idx = *(reinterpret_cast<int *>(fl_lenet_I1) + idx);\r\n",
        "     labels[i * num_classes + label_idx] = 1.0;  // Model expects labels in onehot representation\r\n",
        "     labels_vec.push_back(label_idx);\r\n",
        "@@ -75,42 +76,47 @@ mindspore::session::TrainSession *GetSession(const std::string &ms_file, bool tr\r\n",
        "   return mindspore::session::TrainSession::CreateSession(ms_file, &context, train_mode);\r\n",
        " }\r\n",
        " \r\n",
        "-// net training function\r\n",
        "-int fl_lenet_lite_Inference(const std::string &ms_file, int batch_num, int test_nums) {\r\n",
        "-  auto session = GetSession(ms_file, false);\r\n",
        "-  char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\r\n",
        "-  float accuracy = 0.0;\r\n",
        "+float CalculateAccuracy(mindspore::session::TrainSession *session,int batch_num) {\r\n",
        "   session->Eval();\r\n",
        "+  auto labels = FillInputData(session, batch_num, false);\r\n",
        "+  session->RunGraph();\r\n",
        "   auto inputs = session->GetInputs();\r\n",
        "-  if (inputs[1]->shape().size() != 2) {\r\n",
        "-    return mindspore::lite::RET_ERROR;\r\n",
        "-  }\r\n",
        "   auto batch_size = inputs[1]->shape()[0];\r\n",
        "   auto num_of_class = inputs[1]->shape()[1];\r\n",
        "-  for (int j = 0; j < test_nums; ++j) {\r\n",
        "-    auto labels = FillInputData(session, batch_num, true);\r\n",
        "-    session->RunGraph();\r\n",
        "-    auto outputsv = SearchOutputsForSize(session, batch_size * num_of_class);\r\n",
        "-    auto scores = reinterpret_cast<float *>(outputsv->MutableData());\r\n",
        "-    for (int b = 0; b < batch_size; b++) {\r\n",
        "-      int max_idx = 0;\r\n",
        "-      float max_score = scores[num_of_class * b];\r\n",
        "-      for (int c = 0; c < num_of_class; c++) {\r\n",
        "-        if (scores[num_of_class * b + c] > max_score) {\r\n",
        "-          max_score = scores[num_of_class * b + c];\r\n",
        "-          max_idx = c;\r\n",
        "-        }\r\n",
        "+  auto outputsv = SearchOutputsForSize(session, batch_size * num_of_class);\r\n",
        "+  auto scores = reinterpret_cast<float *>(outputsv->MutableData());\r\n",
        "+  float accuracy = 0.0;\r\n",
        "+  for (int b = 0; b < batch_size; b++) {\r\n",
        "+    int max_idx = 0;\r\n",
        "+    float max_score = scores[num_of_class * b];\r\n",
        "+    for (int c = 0; c < num_of_class; c++) {\r\n",
        "+      if (scores[num_of_class * b + c] > max_score) {\r\n",
        "+        max_score = scores[num_of_class * b + c];\r\n",
        "+        max_idx = c;\r\n",
        "       }\r\n",
        "-      if (labels[b] == max_idx) accuracy += 1.0;\r\n",
        "     }\r\n",
        "+    if (labels[b] == max_idx) accuracy += 1.0;\r\n",
        "+  }\r\n",
        "+  return accuracy/batch_size;\r\n",
        "+}\r\n",
        "+\r\n",
        "+\r\n",
        "+// net training function\r\n",
        "+float fl_lenet_lite_Inference(const std::string &ms_file, int batch_num, int test_nums) {\r\n",
        "+  auto session = GetSession(ms_file, false);\r\n",
        "+  char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\r\n",
        "+  float sum_acc = 0.0f;\r\n",
        "+  for (int j = 0; j < test_nums; ++j) {\r\n",
        "+    auto acc_per_test = CalculateAccuracy(session,batch_num);\r\n",
        "+    sum_acc+=acc_per_test;\r\n",
        "+    std::cout << \"infer:\"<< j <<\"times,acc is \" << acc_per_test << std::endl;\r\n",
        "   }\r\n",
        "   fl_lenet_I0 = origin_input[0];\r\n",
        "   fl_lenet_I1 = origin_input[1];\r\n",
        "-  accuracy /= static_cast<float>(batch_size * test_nums);\r\n",
        "-  MS_LOG(INFO) << \"accuracy  is \" << accuracy;\r\n",
        "-  return mindspore::lite::RET_OK;\r\n",
        "+  return sum_acc/test_nums;\r\n",
        " }\r\n",
        " \r\n",
        "+\r\n",
        " // net training function\r\n",
        " int fl_lenet_lite_Train(const std::string &ms_file, const int batch_num, const int iterations) {\r\n",
        "   auto session = GetSession(ms_file, true);\r\n",
        "@@ -121,15 +127,15 @@ int fl_lenet_lite_Train(const std::string &ms_file, const int batch_num, const i\r\n",
        "   }\r\n",
        "   MS_LOG(INFO) << \"total iterations :\" << iterations << \"batch_num:\" << batch_num;\r\n",
        "   char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\r\n",
        "-  float min_loss = 1000.;\r\n",
        "-  for (int j = 0; j < iterations; ++j) {\r\n",
        "-    FillInputData(session, batch_num, false);\r\n",
        "-    session->RunGraph(nullptr, nullptr);\r\n",
        "-    float loss = GetLoss(session);\r\n",
        "-    if (min_loss > loss) min_loss = loss;\r\n",
        "-    if (j % 50 == 0) {\r\n",
        "-      MS_LOG(INFO) << \"iteration:\" << j << \",Loss is\" << loss << \" [min=\" << min_loss << \"]\";\r\n",
        "+  for (int j = 0; j < iterations/batch_num; ++j) {\r\n",
        "+    float sum_loss_per_epoch = 0.0f;\r\n",
        "+    for(int k=0;k<batch_num;++k) {\r\n",
        "+      FillInputData(session, batch_num, false);\r\n",
        "+      session->RunGraph(nullptr, nullptr);\r\n",
        "+      sum_loss_per_epoch+=GetLoss(session);\r\n",
        "     }\r\n",
        "+    std::cout << \"epoch \" << \"[\" <<j<<\"]\" << \",mean Loss \" << sum_loss_per_epoch/batch_num <<\",train acc \"<< CalculateAccuracy(session,batch_num) <<std::endl;\r\n",
        "+    session->Train();\r\n",
        "   }\r\n",
        "   session->SaveToFile(ms_file);\r\n",
        "   fl_lenet_I0 = origin_input[0];\r\n",
        "diff --git a/mindspore/lite/include/train_session.h b/mindspore/lite/include/train_session.h\r\n",
        "index f5d3dfb..08e42a7 100644\r\n",
        "--- a/mindspore/lite/include/train_session.h\r\n",
        "+++ b/mindspore/lite/include/train_session.h\r\n",
        "@@ -23,6 +23,13 @@\r\n",
        " namespace mindspore {\r\n",
        " namespace session {\r\n",
        " \r\n",
        "+struct TrainFeatureParam{\r\n",
        "+  char* name;\r\n",
        "+  void *data;\r\n",
        "+  size_t elenums;\r\n",
        "+  enum TypeId type;\r\n",
        "+};\r\n",
        "+\r\n",
        " /// \\brief TrainSession Defines a class that allows training a MindSpore model\r\n",
        " class TrainSession : public session::LiteSession {\r\n",
        "  public:\r\n",
        "@@ -137,6 +144,11 @@ class TrainSession : public session::LiteSession {\r\n",
        "   /// \\param[in] loss_name Identifucation name for loss kernels\r\n",
        "   void SetLossName(std::string loss_name) { loss_name_ = loss_name; }\r\n",
        " \r\n",
        "+  virtual int GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *>* feature_maps) =0;\r\n",
        "+\r\n",
        "+  virtual int UpdateFeatureMaps(const std::string &update_ms_file,\r\n",
        "+                                TrainFeatureParam* new_features,int size) =0;\r\n",
        "+\r\n",
        "  protected:\r\n",
        "   bool train_mode_ = false;\r\n",
        "   std::string get_loss_name() const { return loss_name_; }\r\n",
        "diff --git a/mindspore/lite/schema/ops.fbs b/mindspore/lite/schema/ops.fbs\r\n",
        "index d07261e..0916185 100644\r\n",
        "--- a/mindspore/lite/schema/ops.fbs\r\n",
        "+++ b/mindspore/lite/schema/ops.fbs\r\n",
        "@@ -953,6 +953,14 @@ table StridedSlice {\r\n",
        "     shrink_axis_mask: long;\r\n",
        " }\r\n",
        " \r\n",
        "+table StridedSliceGrad {\r\n",
        "+    begin_mask: long;\r\n",
        "+    end_mask: long;\r\n",
        "+    ellipsis_mask: long;\r\n",
        "+    new_axis_mask: long;\r\n",
        "+    shrink_axis_mask: long;\r\n",
        "+}\r\n",
        "+\r\n",
        " table SubFusion {\r\n",
        "     activation_type: ActivationType = 0;\r\n",
        " }\r\n",
        "@@ -1056,14 +1064,6 @@ table CropAndResize {\r\n",
        " table Erf {\r\n",
        " }\r\n",
        " \r\n",
        "-table StridedSliceGrad {\r\n",
        "-    begin_mask: long;\r\n",
        "-    end_mask: long;\r\n",
        "-    ellipsis_mask: long;\r\n",
        "-    new_axis_mask: long;\r\n",
        "-    shrink_axis_mask: long;\r\n",
        "-}\r\n",
        "-\r\n",
        " table IsFinite {\r\n",
        " }\r\n",
        " \r\n",
        "@@ -1077,3 +1077,4 @@ table UniformReal {\r\n",
        " \r\n",
        " table AbsGrad {\r\n",
        " }\r\n",
        "+\r\n",
        "diff --git a/mindspore/lite/src/train/train_session.cc b/mindspore/lite/src/train/train_session.cc\r\n",
        "index badd1fd..a3685cb 100644\r\n",
        "--- a/mindspore/lite/src/train/train_session.cc\r\n",
        "+++ b/mindspore/lite/src/train/train_session.cc\r\n",
        "@@ -22,6 +22,7 @@\r\n",
        " #include <iostream>\r\n",
        " #include <fstream>\r\n",
        " #include <memory>\r\n",
        "+#include <cstring>\r\n",
        " #include \"include/errorcode.h\"\r\n",
        " #include \"src/common/utils.h\"\r\n",
        " #include \"src/tensor.h\"\r\n",
        "@@ -480,6 +481,63 @@ bool TrainSession::IsBN(kernel::LiteKernel *kernel) const {\r\n",
        "           (kernel->Type() == schema::PrimitiveType_FusedBatchNorm));\r\n",
        " }\r\n",
        " \r\n",
        "+int lite::TrainSession::GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *> *feature_maps) {\r\n",
        "+  for (auto tensor : this->tensors_) {\r\n",
        "+    if (tensor->IsConst()) {\r\n",
        "+      auto param = new mindspore::session::TrainFeatureParam();\r\n",
        "+      int len = tensor->tensor_name().length();\r\n",
        "+      char* name = nullptr;\r\n",
        "+      if(len>0) {\r\n",
        "+        name = new char[len+1];\r\n",
        "+        memcpy(name, tensor->tensor_name().c_str(), len);\r\n",
        "+        name[len] = 0;\r\n",
        "+      }\r\n",
        "+      param->name =  name;\r\n",
        "+      param->data = new float[tensor->ElementsNum()];\r\n",
        "+      memcpy(param->data, tensor->data_c(), tensor->ElementsNum()*sizeof(float));\r\n",
        "+      param->data = tensor->data_c();\r\n",
        "+      param->elenums = tensor->ElementsNum();\r\n",
        "+      param->type = tensor->data_type();\r\n",
        "+      feature_maps->push_back(param);\r\n",
        "+    }\r\n",
        "+  }\r\n",
        "+  MS_LOG(INFO) << \"get feature map success\";\r\n",
        "+  return RET_OK;\r\n",
        "+}\r\n",
        "+int lite::TrainSession::UpdateFeatureMaps(const std::string &update_ms_file,\r\n",
        "+                                          mindspore::session::TrainFeatureParam* new_features,int size) {\r\n",
        "+  std::vector<mindspore::session::TrainFeatureParam *> old_features;\r\n",
        "+  auto status = GetFeatureMaps(&old_features);\r\n",
        "+  if (status != RET_OK) {\r\n",
        "+    MS_LOG(ERROR) << \"get features map failed:\";\r\n",
        "+  }\r\n",
        "+  for (int i=0;i<size;++i) {\r\n",
        "+    mindspore::session::TrainFeatureParam* new_feature = new_features + i;\r\n",
        "+    bool find = false;\r\n",
        "+    for (auto old_feature : old_features) {\r\n",
        "+      if (strcmp(old_feature->name, new_feature->name) == 0) {\r\n",
        "+        if(old_feature->elenums != new_feature->elenums) {\r\n",
        "+          MS_LOG(ERROR) << \"feature name:\"<<old_feature->name<<\",len diff:\"<<\"old is:\"<<old_feature->elenums<<\"new is:\"<<new_feature->elenums;\r\n",
        "+          return RET_ERROR;\r\n",
        "+        }\r\n",
        "+        find = true;\r\n",
        "+        memcpy(old_feature->data, new_feature->data, new_feature->elenums*sizeof(float));\r\n",
        "+        break;\r\n",
        "+      }\r\n",
        "+    }\r\n",
        "+    if (!find) {\r\n",
        "+      MS_LOG(ERROR) << \"cannot find feature:\" << new_feature->name;\r\n",
        "+      return RET_ERROR;\r\n",
        "+    }\r\n",
        "+  }\r\n",
        "+  SaveToFile(update_ms_file);\r\n",
        "+  for (auto feature : old_features) {\r\n",
        "+    delete feature;\r\n",
        "+  }\r\n",
        "+  MS_LOG(INFO) << \"update model:\" << update_ms_file << \",feature map success\";\r\n",
        "+  return RET_OK;\r\n",
        "+}\r\n",
        "+\r\n",
        " }  // namespace lite\r\n",
        " \r\n",
        " session::TrainSession *session::TrainSession::CreateSession(const char *model_buf, size_t size, lite::Context *context,\r\n",
        "diff --git a/mindspore/lite/src/train/train_session.h b/mindspore/lite/src/train/train_session.h\r\n",
        "index 266baef..c69fa5d 100644\r\n",
        "--- a/mindspore/lite/src/train/train_session.h\r\n",
        "+++ b/mindspore/lite/src/train/train_session.h\r\n",
        "@@ -91,6 +91,10 @@ class TrainSession : virtual public session::TrainSession, virtual public lite::\r\n",
        "     return outputs;\r\n",
        "   }\r\n",
        " \r\n",
        "+  int GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *> *feature_maps) override;\r\n",
        "+  int UpdateFeatureMaps(const std::string &update_ms_file,\r\n",
        "+                        mindspore::session::TrainFeatureParam* new_features,int size) override;\r\n",
        "+\r\n",
        "  protected:\r\n",
        "   void AllocWorkSpace();\r\n",
        "   bool IsLossKernel(const kernel::LiteKernel *kernel) const;\r\n",
        "-- \r\n",
        "2.7.4\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}