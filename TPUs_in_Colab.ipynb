{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93a3Yz_tHf4"
      },
      "source": [
        "From 1625b35d55d1a7f5f69edb1a060f8372913b03e1 Mon Sep 17 00:00:00 2001\r\n",
        "From: guohongzilong <guohongzilong@huawei.com>\r\n",
        "Date: Fri, 12 Mar 2021 11:40:35 +0800\r\n",
        "Subject: [PATCH] sync lite code\r\n",
        "\r\n",
        "---\r\n",
        " .../lite/flclient/src/main/native/CMakeLists.txt   | 10 ++--\r\n",
        " .../flclient/src/main/native/src/lenet_train.cpp   |  3 +-\r\n",
        " mindspore/lite/include/train_session.h             | 12 +++++\r\n",
        " mindspore/lite/schema/ops.fbs                      | 17 ++++---\r\n",
        " mindspore/lite/src/train/train_session.cc          | 58 ++++++++++++++++++++++\r\n",
        " mindspore/lite/src/train/train_session.h           |  4 ++\r\n",
        " 6 files changed, 89 insertions(+), 15 deletions(-)\r\n",
        "\r\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/CMakeLists.txt b/mindspore/lite/flclient/src/main/native/CMakeLists.txt\r\n",
        "index 81a9ff9..1ee548e 100644\r\n",
        "--- a/mindspore/lite/flclient/src/main/native/CMakeLists.txt\r\n",
        "+++ b/mindspore/lite/flclient/src/main/native/CMakeLists.txt\r\n",
        "@@ -12,12 +12,10 @@ set(LITE_DIR ${TOP_DIR}/mindspore/lite)\r\n",
        " set(MS_VERSION_MAJOR ${MS_VERSION_MAJOR})\r\n",
        " set(MS_VERSION_MINOR ${MS_VERSION_MINOR})\r\n",
        " set(MS_VERSION_REVISION ${MS_VERSION_REVISION})\r\n",
        "-set(CMAKE_C_FLAGS\r\n",
        "-    \"${CMAKE_C_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} \"\r\n",
        "-    \"-DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        "-set(CMAKE_CXX_FLAGS\r\n",
        "-      \"${CMAKE_CXX_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} \"\r\n",
        "-      \"-DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        "+set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} \\\r\n",
        "+  -DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        "+set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} \\\r\n",
        "+  -DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        " set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++17\")\r\n",
        " \r\n",
        " include_directories(${CMAKE_CURRENT_SOURCE_DIR})\r\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/src/lenet_train.cpp b/mindspore/lite/flclient/src/main/native/src/lenet_train.cpp\r\n",
        "index 4455efb..86db7f3 100644\r\n",
        "--- a/mindspore/lite/flclient/src/main/native/src/lenet_train.cpp\r\n",
        "+++ b/mindspore/lite/flclient/src/main/native/src/lenet_train.cpp\r\n",
        "@@ -21,6 +21,7 @@\r\n",
        " #include \"include/context.h\"\r\n",
        " #include \"include/errorcode.h\"\r\n",
        " #include \"src/common/log_adapter.h\"\r\n",
        "+#include \"limits.h\"\r\n",
        " \r\n",
        " static char *fl_lenet_I0 = 0;\r\n",
        " static char *fl_lenet_I1 = 0;\r\n",
        "@@ -42,7 +43,7 @@ std::vector<int> FillInputData(mindspore::session::TrainSession *train_session,\r\n",
        "     } else {\r\n",
        "       idx = rand_r(&seed_) % batch_num;\r\n",
        "     }\r\n",
        "-    std::memcpy(input_data + i * data_size, fl_lenet_I0 + idx * data_size, data_size);\r\n",
        "+    std::memcpy(input_data + i * data_size, (float*)fl_lenet_I0 + idx * data_size, data_size*sizeof(float));\r\n",
        "     int label_idx = *(reinterpret_cast<int *>(fl_lenet_I1) + idx);\r\n",
        "     labels[i * num_classes + label_idx] = 1.0;  // Model expects labels in onehot representation\r\n",
        "     labels_vec.push_back(label_idx);\r\n",
        "diff --git a/mindspore/lite/include/train_session.h b/mindspore/lite/include/train_session.h\r\n",
        "index f5d3dfb..08e42a7 100644\r\n",
        "--- a/mindspore/lite/include/train_session.h\r\n",
        "+++ b/mindspore/lite/include/train_session.h\r\n",
        "@@ -23,6 +23,13 @@\r\n",
        " namespace mindspore {\r\n",
        " namespace session {\r\n",
        " \r\n",
        "+struct TrainFeatureParam{\r\n",
        "+  char* name;\r\n",
        "+  void *data;\r\n",
        "+  size_t elenums;\r\n",
        "+  enum TypeId type;\r\n",
        "+};\r\n",
        "+\r\n",
        " /// \\brief TrainSession Defines a class that allows training a MindSpore model\r\n",
        " class TrainSession : public session::LiteSession {\r\n",
        "  public:\r\n",
        "@@ -137,6 +144,11 @@ class TrainSession : public session::LiteSession {\r\n",
        "   /// \\param[in] loss_name Identifucation name for loss kernels\r\n",
        "   void SetLossName(std::string loss_name) { loss_name_ = loss_name; }\r\n",
        " \r\n",
        "+  virtual int GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *>* feature_maps) =0;\r\n",
        "+\r\n",
        "+  virtual int UpdateFeatureMaps(const std::string &update_ms_file,\r\n",
        "+                                TrainFeatureParam* new_features,int size) =0;\r\n",
        "+\r\n",
        "  protected:\r\n",
        "   bool train_mode_ = false;\r\n",
        "   std::string get_loss_name() const { return loss_name_; }\r\n",
        "diff --git a/mindspore/lite/schema/ops.fbs b/mindspore/lite/schema/ops.fbs\r\n",
        "index d07261e..0916185 100644\r\n",
        "--- a/mindspore/lite/schema/ops.fbs\r\n",
        "+++ b/mindspore/lite/schema/ops.fbs\r\n",
        "@@ -953,6 +953,14 @@ table StridedSlice {\r\n",
        "     shrink_axis_mask: long;\r\n",
        " }\r\n",
        " \r\n",
        "+table StridedSliceGrad {\r\n",
        "+    begin_mask: long;\r\n",
        "+    end_mask: long;\r\n",
        "+    ellipsis_mask: long;\r\n",
        "+    new_axis_mask: long;\r\n",
        "+    shrink_axis_mask: long;\r\n",
        "+}\r\n",
        "+\r\n",
        " table SubFusion {\r\n",
        "     activation_type: ActivationType = 0;\r\n",
        " }\r\n",
        "@@ -1056,14 +1064,6 @@ table CropAndResize {\r\n",
        " table Erf {\r\n",
        " }\r\n",
        " \r\n",
        "-table StridedSliceGrad {\r\n",
        "-    begin_mask: long;\r\n",
        "-    end_mask: long;\r\n",
        "-    ellipsis_mask: long;\r\n",
        "-    new_axis_mask: long;\r\n",
        "-    shrink_axis_mask: long;\r\n",
        "-}\r\n",
        "-\r\n",
        " table IsFinite {\r\n",
        " }\r\n",
        " \r\n",
        "@@ -1077,3 +1077,4 @@ table UniformReal {\r\n",
        " \r\n",
        " table AbsGrad {\r\n",
        " }\r\n",
        "+\r\n",
        "diff --git a/mindspore/lite/src/train/train_session.cc b/mindspore/lite/src/train/train_session.cc\r\n",
        "index badd1fd..a3685cb 100644\r\n",
        "--- a/mindspore/lite/src/train/train_session.cc\r\n",
        "+++ b/mindspore/lite/src/train/train_session.cc\r\n",
        "@@ -22,6 +22,7 @@\r\n",
        " #include <iostream>\r\n",
        " #include <fstream>\r\n",
        " #include <memory>\r\n",
        "+#include <cstring>\r\n",
        " #include \"include/errorcode.h\"\r\n",
        " #include \"src/common/utils.h\"\r\n",
        " #include \"src/tensor.h\"\r\n",
        "@@ -480,6 +481,63 @@ bool TrainSession::IsBN(kernel::LiteKernel *kernel) const {\r\n",
        "           (kernel->Type() == schema::PrimitiveType_FusedBatchNorm));\r\n",
        " }\r\n",
        " \r\n",
        "+int lite::TrainSession::GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *> *feature_maps) {\r\n",
        "+  for (auto tensor : this->tensors_) {\r\n",
        "+    if (tensor->IsConst()) {\r\n",
        "+      auto param = new mindspore::session::TrainFeatureParam();\r\n",
        "+      int len = tensor->tensor_name().length();\r\n",
        "+      char* name = nullptr;\r\n",
        "+      if(len>0) {\r\n",
        "+        name = new char[len+1];\r\n",
        "+        memcpy(name, tensor->tensor_name().c_str(), len);\r\n",
        "+        name[len] = 0;\r\n",
        "+      }\r\n",
        "+      param->name =  name;\r\n",
        "+      param->data = new float[tensor->ElementsNum()];\r\n",
        "+      memcpy(param->data, tensor->data_c(), tensor->ElementsNum()*sizeof(float));\r\n",
        "+      param->data = tensor->data_c();\r\n",
        "+      param->elenums = tensor->ElementsNum();\r\n",
        "+      param->type = tensor->data_type();\r\n",
        "+      feature_maps->push_back(param);\r\n",
        "+    }\r\n",
        "+  }\r\n",
        "+  MS_LOG(INFO) << \"get feature map success\";\r\n",
        "+  return RET_OK;\r\n",
        "+}\r\n",
        "+int lite::TrainSession::UpdateFeatureMaps(const std::string &update_ms_file,\r\n",
        "+                                          mindspore::session::TrainFeatureParam* new_features,int size) {\r\n",
        "+  std::vector<mindspore::session::TrainFeatureParam *> old_features;\r\n",
        "+  auto status = GetFeatureMaps(&old_features);\r\n",
        "+  if (status != RET_OK) {\r\n",
        "+    MS_LOG(ERROR) << \"get features map failed:\";\r\n",
        "+  }\r\n",
        "+  for (int i=0;i<size;++i) {\r\n",
        "+    mindspore::session::TrainFeatureParam* new_feature = new_features + i;\r\n",
        "+    bool find = false;\r\n",
        "+    for (auto old_feature : old_features) {\r\n",
        "+      if (strcmp(old_feature->name, new_feature->name) == 0) {\r\n",
        "+        if(old_feature->elenums != new_feature->elenums) {\r\n",
        "+          MS_LOG(ERROR) << \"feature name:\"<<old_feature->name<<\",len diff:\"<<\"old is:\"<<old_feature->elenums<<\"new is:\"<<new_feature->elenums;\r\n",
        "+          return RET_ERROR;\r\n",
        "+        }\r\n",
        "+        find = true;\r\n",
        "+        memcpy(old_feature->data, new_feature->data, new_feature->elenums*sizeof(float));\r\n",
        "+        break;\r\n",
        "+      }\r\n",
        "+    }\r\n",
        "+    if (!find) {\r\n",
        "+      MS_LOG(ERROR) << \"cannot find feature:\" << new_feature->name;\r\n",
        "+      return RET_ERROR;\r\n",
        "+    }\r\n",
        "+  }\r\n",
        "+  SaveToFile(update_ms_file);\r\n",
        "+  for (auto feature : old_features) {\r\n",
        "+    delete feature;\r\n",
        "+  }\r\n",
        "+  MS_LOG(INFO) << \"update model:\" << update_ms_file << \",feature map success\";\r\n",
        "+  return RET_OK;\r\n",
        "+}\r\n",
        "+\r\n",
        " }  // namespace lite\r\n",
        " \r\n",
        " session::TrainSession *session::TrainSession::CreateSession(const char *model_buf, size_t size, lite::Context *context,\r\n",
        "diff --git a/mindspore/lite/src/train/train_session.h b/mindspore/lite/src/train/train_session.h\r\n",
        "index 266baef..c69fa5d 100644\r\n",
        "--- a/mindspore/lite/src/train/train_session.h\r\n",
        "+++ b/mindspore/lite/src/train/train_session.h\r\n",
        "@@ -91,6 +91,10 @@ class TrainSession : virtual public session::TrainSession, virtual public lite::\r\n",
        "     return outputs;\r\n",
        "   }\r\n",
        " \r\n",
        "+  int GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *> *feature_maps) override;\r\n",
        "+  int UpdateFeatureMaps(const std::string &update_ms_file,\r\n",
        "+                        mindspore::session::TrainFeatureParam* new_features,int size) override;\r\n",
        "+\r\n",
        "  protected:\r\n",
        "   void AllocWorkSpace();\r\n",
        "   bool IsLossKernel(const kernel::LiteKernel *kernel) const;\r\n",
        "-- \r\n",
        "2.7.4\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}