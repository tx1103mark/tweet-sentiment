{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnXo0VxCVrXJ"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *conv_activation_fusion.h\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/optimizer/fusion/conv_tuple_activation_fusion.h\"\n",
        "#include <memory>\n",
        "#include \"src/ops/primitive_c.h\"\n",
        "#include \"src/ops/conv2d.h\"\n",
        "#include \"src/ops/depthwise_conv2d.h\"\n",
        "#include \"src/ops/activation.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"tools/optimizer/common/gllo_utils.h\"\n",
        "\n",
        "namespace mindspore::opt {\n",
        "namespace {\n",
        "constexpr size_t kActivationInputsLength = 2;\n",
        "bool IsTupleGetItemNode(const BaseRef &n) {\n",
        "  if (utils::isa<CNodePtr>(n) || utils::isa<ValueNodePtr>(n)) {\n",
        "    auto type = opt::GetCNodeType(n);\n",
        "    return type == schema::PrimitiveType_TupleGetItem;\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "}\n",
        "const BaseRef ConvTupleActivationFusion::DefinePattern() const {\n",
        "  auto conv_var = std::make_shared<CondVar>(IsConvNode);\n",
        "  auto tuple_getitem_var = std::make_shared<CondVar>(IsTupleGetItemNode);\n",
        "  auto tuple_index = std::make_shared<Var>();\n",
        "  VectorRef tuple_get_item = VectorRef({tuple_getitem_var, conv_var, tuple_index});\n",
        "  auto act_var = std::make_shared<CondVar>(IsActivationNode);\n",
        "  return VectorRef({act_var, tuple_get_item});\n",
        "}\n",
        "\n",
        "const AnfNodePtr ConvTupleActivationFusion::Process(const FuncGraphPtr &func_graph, const AnfNodePtr &node,\n",
        "                                                    const EquivPtr &) const {\n",
        "  MS_ASSERT(func_graph != nullptr);\n",
        "  MS_ASSERT(node != nullptr);\n",
        "  if (CheckIfFuncGraphIsNull(func_graph) != lite::RET_OK || CheckIfAnfNodeIsNull(node) != lite::RET_OK) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto act_node = node->cast<CNodePtr>();\n",
        "  if (CheckIfCNodeIsNull(act_node) != lite::RET_OK ||\n",
        "      CheckInputSize(act_node, kActivationInputsLength) != lite::RET_OK) {\n",
        "    return nullptr;\n",
        "  }\n",
        "\n",
        "  auto primitivec = GetValueNode<std::shared_ptr<lite::PrimitiveC>>(act_node->input(0));\n",
        "  MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::Activation>>(primitivec));\n",
        "  auto act_primitivec = utils::cast<std::shared_ptr<mindspore::lite::Activation>>(primitivec);\n",
        "  MS_ASSERT(act_primitivec != nullptr);\n",
        "  if (act_primitivec->GetType() != schema::ActivationType_RELU\n",
        "      || act_primitivec->GetType() != schema::ActivationType_RELU6) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  AnfNodePtr tuple_node = act_node->input(1);\n",
        "  MS_ASSERT(tuple_node != nullptr);\n",
        "  auto tuple_cnode = tuple_node->cast<CNodePtr>();\n",
        "  auto conv_node = tuple_cnode->input(1);\n",
        "  if (CheckIfAnfNodeIsNull(conv_node) != lite::RET_OK) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  if (conv_node != nullptr && conv_node->isa<CNode>()) {\n",
        "    if (IsMultiOutputTensors(func_graph, conv_node)) {\n",
        "      return nullptr;\n",
        "    }\n",
        "    auto conv_cnode = conv_node->cast<CNodePtr>();\n",
        "    auto node_type = GetCNodeType(conv_cnode);\n",
        "    auto primitive_c = GetValueNode<std::shared_ptr<lite::PrimitiveC>>(conv_cnode->input(0));\n",
        "    MS_ASSERT(primitive_c);\n",
        "    if (node_type == schema::PrimitiveType_Conv2D) {\n",
        "      MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::Conv2D>>(primitive_c));\n",
        "      auto primc = utils::cast<std::shared_ptr<mindspore::lite::Conv2D>>(primitive_c);\n",
        "      MS_ASSERT(primc != nullptr);\n",
        "      if (primc->GetActivationType() == schema::ActivationType_NO_ACTIVATION) {\n",
        "        primc->SetActivationType(act_primitivec->GetType());\n",
        "        conv_node->set_abstract(act_node->abstract());\n",
        "        return conv_node;\n",
        "      }\n",
        "    } else if (node_type == schema::PrimitiveType_DepthwiseConv2D) {\n",
        "      MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive_c));\n",
        "      auto primc = utils::cast<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive_c);\n",
        "      MS_ASSERT(primc != nullptr);\n",
        "      if (primc->GetActivationType() == schema::ActivationType_NO_ACTIVATION) {\n",
        "        primc->SetActivationType(act_primitivec->GetType());\n",
        "        conv_node->set_abstract(act_node->abstract());\n",
        "        return conv_node;\n",
        "      }\n",
        "    } else {\n",
        "      MS_LOG(ERROR) << \"conv activation pass match only conv2d or depthwise_conv2d \";\n",
        "    }\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "}  // namespace mindspore::opt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Tn3MQMVb2E"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/optimizer/fusion/conv_activation_fusion.h\"\n",
        "#include <memory>\n",
        "#include \"src/ops/primitive_c.h\"\n",
        "#include \"src/ops/conv2d.h\"\n",
        "#include \"src/ops/depthwise_conv2d.h\"\n",
        "#include \"src/ops/activation.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"tools/optimizer/common/gllo_utils.h\"\n",
        "\n",
        "namespace mindspore::opt {\n",
        "namespace {\n",
        "constexpr size_t kActivationInputsLength = 2;\n",
        "}\n",
        "const BaseRef ConvActivationFusion::DefinePattern() const {\n",
        "  auto conv_var = std::make_shared<CondVar>(IsConvNode);\n",
        "  auto act_var = std::make_shared<CondVar>(IsActivationNode);\n",
        "  return VectorRef({act_var, conv_var});\n",
        "}\n",
        "\n",
        "const AnfNodePtr ConvActivationFusion::Process(const FuncGraphPtr &func_graph, const AnfNodePtr &node,\n",
        "                                               const EquivPtr &) const {\n",
        "  MS_ASSERT(func_graph != nullptr);\n",
        "  MS_ASSERT(node != nullptr);\n",
        "  if (CheckIfFuncGraphIsNull(func_graph) != lite::RET_OK || CheckIfAnfNodeIsNull(node) != lite::RET_OK) {\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_NULL_PTR);\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto act_node = node->cast<CNodePtr>();\n",
        "  if (CheckIfCNodeIsNull(act_node) != lite::RET_OK ||\n",
        "      CheckInputSize(act_node, kActivationInputsLength) != lite::RET_OK) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto primitivec = GetValueNode<std::shared_ptr<lite::PrimitiveC>>(act_node->input(0));\n",
        "  MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::Activation>>(primitivec));\n",
        "  auto act_primitivec = utils::cast<std::shared_ptr<mindspore::lite::Activation>>(primitivec);\n",
        "  MS_ASSERT(act_primitivec != nullptr);\n",
        "  if (act_primitivec->GetType() != schema::ActivationType_RELU\n",
        "      || act_primitivec->GetType() != schema::ActivationType_RELU6) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  AnfNodePtr pre_node = act_node->input(1);\n",
        "  if (CheckIfAnfNodeIsNull(pre_node) != lite::RET_OK) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  if (pre_node != nullptr && pre_node->isa<CNode>()) {\n",
        "    if (IsMultiOutputTensors(func_graph, pre_node)) {\n",
        "      return nullptr;\n",
        "    }\n",
        "    auto conv_node = pre_node->cast<CNodePtr>();\n",
        "    auto node_type = GetCNodeType(conv_node);\n",
        "    auto primitive_c = GetValueNode<std::shared_ptr<lite::PrimitiveC>>(conv_node->input(0));\n",
        "    MS_ASSERT(primitive_c);\n",
        "    if (node_type == schema::PrimitiveType_Conv2D) {\n",
        "      MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::Conv2D>>(primitive_c));\n",
        "      auto primc = utils::cast<std::shared_ptr<mindspore::lite::Conv2D>>(primitive_c);\n",
        "      MS_ASSERT(primc != nullptr);\n",
        "      if (primc->GetActivationType() == schema::ActivationType_NO_ACTIVATION) {\n",
        "        primc->SetActivationType(act_primitivec->GetType());\n",
        "        return pre_node;\n",
        "      }\n",
        "    } else if (node_type == schema::PrimitiveType_DepthwiseConv2D) {\n",
        "      MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive_c));\n",
        "      auto primc = utils::cast<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive_c);\n",
        "      MS_ASSERT(primc != nullptr);\n",
        "      if (primc->GetActivationType() == schema::ActivationType_NO_ACTIVATION) {\n",
        "        primc->SetActivationType(act_primitivec->GetType());\n",
        "        return pre_node;\n",
        "      }\n",
        "    } else {\n",
        "      MS_LOG(ERROR) << \"conv activation pass match only conv2d or depthwise_conv2d \";\n",
        "    }\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "}  // namespace mindspore::opt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QElZdqNmVkfx"
      },
      "source": [
        "/**\n",
        " * Copyright 2019 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/converter/anf_transform.h\"\n",
        "#include <memory>\n",
        "#include <string>\n",
        "#include \"src/common/log_adapter.h\"\n",
        "#include \"tools/optimizer/fusion/conv_biasadd_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/conv_activation_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/conv_tuple_activation_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/conv_scale_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/conv_bn_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/conv_tuplegetitem_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/constant_folding_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/quant_dtype_cast_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/layer_norm_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/batchmatmul_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/sigmoid_mul_fusion.h\"\n",
        "#include \"tools/optimizer/fusion/conv_conv_fusion.h\"\n",
        "#include \"tools/optimizer/graph/identity_remove_pass.h\"\n",
        "#include \"tools/optimizer/graph/weight_format_hardcode_pass.h\"\n",
        "#include \"tools/optimizer/graph/weight_format_transform_pass.h\"\n",
        "#include \"tools/optimizer/graph/clip_convert_activation_pass.h\"\n",
        "#include \"tools/optimizer/graph/unused_cast_node_remove_pass.h\"\n",
        "#include \"tools/optimizer/graph/unused_transpose_node_remove_pass.h\"\n",
        "#include \"tools/optimizer/graph/infershape_pass.h\"\n",
        "#include \"tools/optimizer/graph/slice_prepose_pass.h\"\n",
        "#include \"tools/converter/quantizer/post_training_quantizer.h\"\n",
        "#include \"tools/converter/quantizer/quant_cast.h\"\n",
        "#include \"tools/converter/quantizer/weight_quantizer.h\"\n",
        "\n",
        "using std::string;\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "AnfTransform::AnfTransform() = default;\n",
        "\n",
        "AnfTransform::~AnfTransform() = default;\n",
        "\n",
        "FuncGraphPtr AnfTransform::Transform(const FuncGraphPtr &old_graph, const converter::Flags *config) {\n",
        "  MS_ASSERT(nullptr != old_graph);\n",
        "  if (config == nullptr) {\n",
        "    MS_LOG(ERROR) << \"config shoud be specified\";\n",
        "    return nullptr;\n",
        "  }\n",
        "  // fusion const_fold\n",
        "  auto optimizer = std::make_shared<opt::GraphOptimizer>();\n",
        "  auto fusion_pm = std::make_shared<opt::PassManager>(\"anf fusion pass manager\", false);\n",
        "  auto graph_pm = std::make_shared<opt::PassManager>(\"anf graph pass manager\", true);\n",
        "  auto convert_pm = std::make_shared<opt::PassManager>(\"anf graph convert pass manager\", true);\n",
        "\n",
        "  // for now - trainning is not supporting fuse operations\n",
        "  if (config != nullptr && !config->trainModel) {\n",
        "    // remove quantdtype when awaretraining\n",
        "    fusion_pm->AddPass(std::make_shared<opt::RemoveIdentityOpPass>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::ConvBiasaddFusion>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::ConvBatchNormFusion>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::ConvScaleFusion>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::LayerNormFusion>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::BatchMatMulFusion>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::SigmoidMulFusion>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::ConvActivationFusion>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::ConvTupleGetItemFusion>());\n",
        "    fusion_pm->AddPass(std::make_shared<opt::ConvTupleActivationFusion>());\n",
        "  }\n",
        "  auto weight_format_hardcode_pass = std::make_shared<opt::WeightFormatHardCodePass>();\n",
        "  weight_format_hardcode_pass->SetFmkType(config->fmk);\n",
        "  weight_format_hardcode_pass->SetQuantType(config->quantType);\n",
        "  graph_pm->AddPass(weight_format_hardcode_pass);\n",
        "  auto weight_format_transform_pass = std::make_shared<opt::WeightFormatTransformPass>();\n",
        "  weight_format_transform_pass->SetFmkType(config->fmk);\n",
        "  weight_format_transform_pass->SetQuantType(config->quantType);\n",
        "  graph_pm->AddPass(weight_format_transform_pass);\n",
        "  auto infershape_pass = std::make_shared<opt::InferShapePass>();\n",
        "  infershape_pass->SetFmkType(config->fmk);\n",
        "  graph_pm->AddPass(infershape_pass);\n",
        "  auto slice_prepose_pass = std::make_shared<opt::SlicePreposePass>();\n",
        "  slice_prepose_pass->SetFmkType(config->fmk);\n",
        "  graph_pm->AddPass(slice_prepose_pass);\n",
        "\n",
        "  if (config->fmk == lite::converter::FmkType_MS) {\n",
        "    auto remove_unused_cast_pass = std::make_shared<opt::RemoveUnusedCastOpPass>();\n",
        "    if (remove_unused_cast_pass == nullptr) {\n",
        "      MS_LOG(ERROR) << \"RemoveUnusedCastOpPass shoud be specified\";\n",
        "      return nullptr;\n",
        "    }\n",
        "    remove_unused_cast_pass->SetFmkType(config->fmk);\n",
        "    fusion_pm->AddPass(remove_unused_cast_pass);\n",
        "  }\n",
        "  if (config->fmk == lite::converter::FmkType_ONNX) {\n",
        "    auto remove_unused_transpose_pass = std::make_shared<opt::RemoveUnusedTransposeOpPass>();\n",
        "    if (remove_unused_transpose_pass == nullptr) {\n",
        "      MS_LOG(ERROR) << \"RemoveUnusedTransposeOpPass shoud be specified\";\n",
        "      return nullptr;\n",
        "    }\n",
        "    remove_unused_transpose_pass->SetFmkType(config->fmk);\n",
        "    fusion_pm->AddPass(remove_unused_transpose_pass);\n",
        "  }\n",
        "  auto inne_context_ptr = std::make_shared<lite::InnerContext>();\n",
        "  inne_context_ptr->Init();\n",
        "  fusion_pm->AddPass(std::make_shared<opt::ConstFoldPass>(inne_context_ptr));\n",
        "  fusion_pm->AddPass(std::make_shared<opt::ConvConvFusion>());\n",
        "  convert_pm->AddPass(std::make_shared<opt::ClipConvertActivationPass>());\n",
        "  optimizer->AddPassManager(convert_pm);\n",
        "  optimizer->AddPassManager(fusion_pm);\n",
        "  optimizer->AddPassManager(graph_pm);\n",
        "  auto new_graph = optimizer->Optimize(old_graph);\n",
        "  if (new_graph == nullptr) {\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(RET_NULL_PTR);\n",
        "    return nullptr;\n",
        "  }\n",
        "  // quant\n",
        "  if (config->quantType == schema::QuantType_PostTraining) {\n",
        "    if (!quant::WeightQuantizer::IsPosNum(config->bitNum)) {\n",
        "      MS_LOG(ERROR) << \"bitNum must be valid pos num.\";\n",
        "      ReturnCode::GetSingleReturnCode()->UpdateReturnCode(RET_ERROR);\n",
        "      return nullptr;\n",
        "    }\n",
        "    this->mQuantizer =\n",
        "        std::make_unique<quant::PostTrainingQuantizer>(new_graph, config->configFile, std::stoi(config->bitNum));\n",
        "    if (mQuantizer == nullptr) {\n",
        "      MS_LOG(ERROR) << \"New PostTrainingQuantizer failed\";\n",
        "      ReturnCode::GetSingleReturnCode()->UpdateReturnCode(RET_MEMORY_FAILED);\n",
        "      return nullptr;\n",
        "    }\n",
        "  } else if (config->quantType == schema::QuantType_WeightQuant) {\n",
        "    if (quant::WeightQuantizer::WeightQuantInputCheck(config) != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"weight quant input param error\";\n",
        "      ReturnCode::GetSingleReturnCode()->UpdateReturnCode(RET_ERROR);\n",
        "      return nullptr;\n",
        "    }\n",
        "    this->mQuantizer = std::make_unique<quant::WeightQuantizer>(new_graph, config->quantWeightSize,\n",
        "                                                                config->quantWeightChannel, config->bitNum);\n",
        "    if (mQuantizer == nullptr) {\n",
        "      MS_LOG(ERROR) << \"New WeightQuantizer failed\";\n",
        "      ReturnCode::GetSingleReturnCode()->UpdateReturnCode(RET_MEMORY_FAILED);\n",
        "      return nullptr;\n",
        "    }\n",
        "  }\n",
        "  if (mQuantizer != nullptr) {\n",
        "    mQuantizer->flags = *config;\n",
        "    auto status = mQuantizer->DoQuantize(new_graph);\n",
        "    if (status != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"Quant failed \" << status;\n",
        "      ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\n",
        "      return nullptr;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return new_graph;\n",
        "}\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z87WEpSKV1gC"
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#ifndef MINDSPORE_LITE_SRC_PASS_FUSION_CONSTANT_FOLDING_FUSION_H_\n",
        "#define MINDSPORE_LITE_SRC_PASS_FUSION_CONSTANT_FOLDING_FUSION_H_\n",
        "\n",
        "#include <utility>\n",
        "\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"src/tensor.h\"\n",
        "#include \"src/lite_kernel.h\"\n",
        "#include \"nnacl/op_base.h\"\n",
        "#include \"backend/optimizer/common/optimizer.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "class ConstFoldPass : public PatternProcessPass {\n",
        " public:\n",
        "  explicit ConstFoldPass(std::shared_ptr<lite::InnerContext> context_ptr = nullptr, bool multigraph = true)\n",
        "      : PatternProcessPass(\"constfold_pass\", multigraph), context(std::move(context_ptr)) {}\n",
        "  ~ConstFoldPass() override {}\n",
        "  const AnfNodePtr Process(const FuncGraphPtr &, const AnfNodePtr &, const EquivPtr &) const override;\n",
        " private:\n",
        "  std::shared_ptr<lite::InnerContext> context;\n",
        "};\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n",
        "#endif  // MINDSPORE_LITE_SRC_PASS_FUSION_CONSTANT_FOLDING_FUSION_H_\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}