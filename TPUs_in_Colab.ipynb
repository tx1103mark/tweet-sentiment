{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIWO5XRfhbXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/common/graph_util.h\"\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <utility>\n",
        "#include <set>\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"tools/common/tensor_util.h\"\n",
        "#include \"tools/common/node_util.h\"\n",
        "#include \"utils/log_adapter.h\"\n",
        "#include \"src/common/utils.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace lite {\n",
        "OpDefCopyer GetSimpleOpCopyer() {\n",
        "  return [](CNodeT *inCNode) -> std::unique_ptr<CNodeT> {\n",
        "    std::unique_ptr<CNodeT> newCNode(new CNodeT);\n",
        "\n",
        "    newCNode->name = inCNode->name;\n",
        "    newCNode->quantType = inCNode->quantType;\n",
        "    newCNode->primitive = std::make_unique<schema::PrimitiveT>();\n",
        "    newCNode->primitive->value.type = inCNode->primitive->value.type;\n",
        "    return newCNode;\n",
        "  };\n",
        "}\n",
        "\n",
        "std::vector<size_t> GetInputNodeIdx(const schema::MetaGraphT &graphT, const size_t &nodeIdx, const int inputIndexIdx) {\n",
        "  return GetInputNodeIdx(graphT, *(graphT.nodes.at(nodeIdx).get()), inputIndexIdx);\n",
        "}\n",
        "\n",
        "std::vector<size_t> GetInputNodeIdx(const schema::MetaGraphT &graphT, const CNodeT &node, const int inputIndexIdx) {\n",
        "  std::vector<uint32_t> inputIndexes;\n",
        "  if (inputIndexIdx == -1) {\n",
        "    inputIndexes = node.inputIndex;\n",
        "  } else {\n",
        "    MS_ASSERT(node.inputIndex.size() > inputIndexIdx);\n",
        "    inputIndexes.emplace_back(node.inputIndex.at(inputIndexIdx));\n",
        "  }\n",
        "  std::set<size_t> inputNodeIdx;\n",
        "  for (uint32_t inputIdx : inputIndexes) {\n",
        "    auto linkedPreIdx = GetLinkedPreIdx(graphT, inputIdx);\n",
        "    inputNodeIdx.insert(linkedPreIdx.begin(), linkedPreIdx.end());\n",
        "  }\n",
        "  std::vector<size_t> ret;\n",
        "  ret.insert(ret.end(), inputNodeIdx.begin(), inputNodeIdx.end());\n",
        "  return ret;\n",
        "}\n",
        "\n",
        "std::vector<size_t> GetOutputNodeIdx(const schema::MetaGraphT &graphT, const size_t &nodeIdx,\n",
        "                                     const int outputIndexIdx) {\n",
        "  return GetOutputNodeIdx(graphT, *(graphT.nodes.at(nodeIdx).get()), outputIndexIdx);\n",
        "}\n",
        "\n",
        "std::vector<size_t> GetOutputNodeIdx(const schema::MetaGraphT &graphT, const CNodeT &node, const int outputIndexIdx) {\n",
        "  std::vector<uint32_t> outputIndexes;\n",
        "  if (outputIndexIdx == -1) {\n",
        "    outputIndexes = node.outputIndex;\n",
        "  } else {\n",
        "    MS_ASSERT(node.outputIndex.size() > outputIndexIdx);\n",
        "    outputIndexes.emplace_back(node.outputIndex.at(outputIndexIdx));\n",
        "  }\n",
        "  std::set<size_t> outputNodeIdx;\n",
        "  for (uint32_t outputIdx : outputIndexes) {\n",
        "    auto linkedPostIdx = GetLinkedPostIdx(graphT, outputIdx);\n",
        "    outputNodeIdx.insert(linkedPostIdx.begin(), linkedPostIdx.end());\n",
        "  }\n",
        "  std::vector<size_t> ret;\n",
        "  ret.insert(ret.end(), outputNodeIdx.begin(), outputNodeIdx.end());\n",
        "  return ret;\n",
        "}\n",
        "\n",
        "std::vector<size_t> GetLinkedPreIdx(const schema::MetaGraphT &graphT, const size_t &tensorIdx) {\n",
        "  std::vector<size_t> preNodeIdx;\n",
        "  for (size_t i = 0; i < graphT.nodes.size(); i++) {\n",
        "    auto &oldNode = graphT.nodes.at(i);\n",
        "    if (oldNode == nullptr) {\n",
        "      continue;\n",
        "    }\n",
        "    auto outputIndexes = oldNode->outputIndex;\n",
        "    if (IsContain<uint32_t>(outputIndexes, tensorIdx)) {\n",
        "      preNodeIdx.emplace_back(i);\n",
        "    }\n",
        "  }\n",
        "  return preNodeIdx;\n",
        "}\n",
        "\n",
        "std::vector<size_t> GetLinkedPostIdx(const schema::MetaGraphT &graphT, const size_t &tensorIdx) {\n",
        "  std::vector<size_t> postNodeIdx;\n",
        "  for (size_t i = 0; i < graphT.nodes.size(); i++) {\n",
        "    auto &oldNode = graphT.nodes.at(i);\n",
        "    if (oldNode == nullptr) {\n",
        "      continue;\n",
        "    }\n",
        "    auto inputIndexes = oldNode->inputIndex;\n",
        "    if (IsContain<uint32_t>(inputIndexes, tensorIdx)) {\n",
        "      postNodeIdx.emplace_back(i);\n",
        "    }\n",
        "  }\n",
        "  return postNodeIdx;\n",
        "}\n",
        "\n",
        "STATUS IsolateNode(schema::MetaGraphT *graphT, CNodeT *node) {\n",
        "  MS_ASSERT(graphT != nullptr);\n",
        "  MS_ASSERT(node != nullptr);\n",
        "  size_t nodeIdx = 0;\n",
        "  for (size_t i = 0; i < graphT->nodes.size(); i++) {\n",
        "    auto &inNode = graphT->nodes.at(i);\n",
        "    MS_ASSERT(inNode != nullptr);\n",
        "    if (inNode->name == node->name) {\n",
        "      nodeIdx = i;\n",
        "      break;\n",
        "    }\n",
        "  }\n",
        "  auto inputTensorIdxes = node->inputIndex;\n",
        "  auto outputTensorIdxes = node->outputIndex;\n",
        "  if (inputTensorIdxes.empty()) {\n",
        "    MS_LOG(ERROR) << \"Node \" << node->name.c_str() << \"should has no inputs\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  if (outputTensorIdxes.size() != 1) {\n",
        "    MS_LOG(ERROR) << \"FakeQuantNode \" << node->name.c_str()\n",
        "                  << \"should has 1 output, in fact: \" << outputTensorIdxes.size();\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  auto inDataTensorIdx = inputTensorIdxes.front();\n",
        "  auto outDataTensorIdx = outputTensorIdxes.front();\n",
        "\n",
        "  MS_ASSERT(graphT->allTensors.size() > inDataTensorIdx);\n",
        "  auto &gOutTensorIdx = graphT->outputIndex;\n",
        "  for (auto iter = gOutTensorIdx.begin(); iter != gOutTensorIdx.end(); iter++) {\n",
        "    if (*iter == outDataTensorIdx) {\n",
        "      *iter = inDataTensorIdx;\n",
        "      break;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // find poseNode\n",
        "  auto postNodeIdxes = GetOutputNodeIdx(*graphT, nodeIdx, 0);\n",
        "  for (auto postNodeIdx : postNodeIdxes) {\n",
        "    MS_ASSERT(graphT->nodes.size() > postNodeIdx);\n",
        "    auto &postNode = graphT->nodes.at(postNodeIdx);\n",
        "    MS_ASSERT(postNode != nullptr);\n",
        "    for (auto iter = postNode->inputIndex.begin(); iter != postNode->inputIndex.end(); iter++) {\n",
        "      if (*iter == outDataTensorIdx) {\n",
        "        *iter = inDataTensorIdx;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // whether need to remove weightInputTensores\n",
        "  // remove all node's outputTensors\n",
        "  RemoveTensor(graphT, outputTensorIdxes);\n",
        "  node->inputIndex.clear();\n",
        "  node->outputIndex.clear();\n",
        "\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS IsolateOneWayNode(schema::MetaGraphT *graph, size_t subGraphIdx, size_t nodeIdx, bool removeTensor) {\n",
        "  MS_ASSERT(graph != nullptr);\n",
        "  return IsolateOneWayNode(graph, nodeIdx, removeTensor);\n",
        "}\n",
        "\n",
        "STATUS IsolateOneWayNode(schema::MetaGraphT *graphT, size_t nodeIdx, bool removeTensor) {\n",
        "  MS_ASSERT(graphT != nullptr);\n",
        "  if (graphT->nodes.size() <= nodeIdx) {\n",
        "    MS_LOG(ERROR) << \"nodeIdx out of range: \" << nodeIdx;\n",
        "    return RET_PARAM_INVALID;\n",
        "  }\n",
        "\n",
        "  CNodeT *node = graphT->nodes.at(nodeIdx).get();\n",
        "  auto inputTensorIdxes = node->inputIndex;\n",
        "  auto outputTensorIdxes = node->outputIndex;\n",
        "  auto preNodeIdxes = GetInputNodeIdx(*graphT, nodeIdx);\n",
        "  if (preNodeIdxes.size() > 1 || outputTensorIdxes.size() > 1) {\n",
        "    MS_LOG(ERROR) << \"Only support node who has no more than one input and one output\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  if (inputTensorIdxes.empty()) {\n",
        "    MS_LOG(ERROR) << \"Error, \" << nodeIdx << \"th node has no input tensor\";\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  auto inDataTensorIdx = inputTensorIdxes.front();\n",
        "  if (!outputTensorIdxes.empty()) {\n",
        "    auto outDataTensorIdx = outputTensorIdxes.front();\n",
        "    MS_ASSERT(graphT->allTensors.size() > inDataTensorIdx);\n",
        "    MS_ASSERT(graphT->allTensors.at(inDataTensorIdx) != nullptr);\n",
        "    auto &gOutTensorIdx = graphT->outputIndex;\n",
        "    for (auto iter = gOutTensorIdx.begin(); iter != gOutTensorIdx.end(); iter++) {\n",
        "      if (*iter == outDataTensorIdx) {\n",
        "        *iter = inDataTensorIdx;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "    // find poseNode\n",
        "    auto postNodeIdxes = GetOutputNodeIdx(*graphT, nodeIdx, 0);\n",
        "    for (auto postNodeIdx : postNodeIdxes) {\n",
        "      MS_ASSERT(graphT->nodes.size() > postNodeIdx);\n",
        "      auto &postNode = graphT->nodes.at(postNodeIdx);\n",
        "      MS_ASSERT(postNode != nullptr);\n",
        "      for (auto iter = postNode->inputIndex.begin(); iter != postNode->inputIndex.end(); iter++) {\n",
        "        if (*iter == outDataTensorIdx) {\n",
        "          *iter = inDataTensorIdx;\n",
        "          break;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (removeTensor) {\n",
        "    // now all node's outputTensors are useless\n",
        "    // remove all node's outputTensors\n",
        "    auto status = RemoveTensor(graphT, outputTensorIdxes);\n",
        "    if (status != RET_OK) {\n",
        "      MS_LOG(ERROR) << \"RemoveOutputTensors of node \" << node->name.c_str() << \"failed\";\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "  }\n",
        "  node->inputIndex.clear();\n",
        "  node->outputIndex.clear();\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS IsolateOneWayNode(schema::MetaGraphT *graphT, CNodeT *node, bool removeTensor) {\n",
        "  MS_ASSERT(graphT != nullptr);\n",
        "  MS_ASSERT(node != nullptr);\n",
        "  bool isSubNode = false;\n",
        "  size_t nodeIdx = 0;\n",
        "  for (size_t i = 0; i < graphT->nodes.size(); i++) {\n",
        "    auto &inNode = graphT->nodes.at(i);\n",
        "    if (inNode->name == node->name) {\n",
        "      isSubNode = true;\n",
        "      nodeIdx = i;\n",
        "      break;\n",
        "    }\n",
        "  }\n",
        "  if (!isSubNode) {\n",
        "    MS_LOG(ERROR) << \"Node \" << node->name.c_str() << \"is not in graphT \" << graphT->name.c_str();\n",
        "    return RET_PARAM_INVALID;\n",
        "  } else {\n",
        "    return IsolateOneWayNode(graphT, nodeIdx, removeTensor);\n",
        "  }\n",
        "}\n",
        "\n",
        "STATUS RemoveTensor(schema::MetaGraphT *graphT, std::vector<uint32_t> toDeleteTensorIdxes, bool forceDelete) {\n",
        "  for (auto iter = toDeleteTensorIdxes.begin(); iter != toDeleteTensorIdxes.end();) {\n",
        "    uint32_t deleteIdx = *iter;\n",
        "    if (!forceDelete) {\n",
        "      if (GetRefCount(graphT, deleteIdx) > 1) {\n",
        "        iter++;\n",
        "        continue;\n",
        "      }\n",
        "    }\n",
        "    // update graph input indexes\n",
        "    for (auto gInIdx = graphT->inputIndex.begin(); gInIdx != graphT->inputIndex.end(); gInIdx++) {\n",
        "      if (*gInIdx > deleteIdx) {\n",
        "        (*gInIdx)--;\n",
        "      }\n",
        "    }\n",
        "    // update graph output indexes\n",
        "    for (auto gOutIdx = graphT->outputIndex.begin(); gOutIdx != graphT->outputIndex.end(); gOutIdx++) {\n",
        "      if (*gOutIdx > deleteIdx) {\n",
        "        (*gOutIdx)--;\n",
        "      }\n",
        "    }\n",
        "    // update nodes indexes\n",
        "    for (auto nodeIter = graphT->nodes.begin(); nodeIter != graphT->nodes.end(); nodeIter++) {\n",
        "      // update nodes input indexes\n",
        "      UpdateNodeIndex((*nodeIter).get(), deleteIdx);\n",
        "    }\n",
        "    // update deleteTensorIdx\n",
        "    for (auto selfIt = toDeleteTensorIdxes.begin(); selfIt != toDeleteTensorIdxes.end(); selfIt++) {\n",
        "      if (*selfIt > deleteIdx) {\n",
        "        (*selfIt)--;\n",
        "      }\n",
        "    }\n",
        "    graphT->allTensors.erase(graphT->allTensors.begin() + deleteIdx);\n",
        "    iter = toDeleteTensorIdxes.erase(iter);\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS UpdateNodeIndex(CNodeT *node, uint32_t deleteIdx) {\n",
        "  for (auto inIdxIt = node->inputIndex.begin(); inIdxIt != node->inputIndex.end();) {\n",
        "    if (*inIdxIt == deleteIdx) {\n",
        "      inIdxIt = node->inputIndex.erase(inIdxIt);\n",
        "    } else {\n",
        "      if (*inIdxIt > deleteIdx) {\n",
        "        (*inIdxIt)--;\n",
        "      }\n",
        "      inIdxIt++;\n",
        "    }\n",
        "  }\n",
        "  // update nodes output indexes\n",
        "  for (auto outIdxIt = node->outputIndex.begin(); outIdxIt != node->outputIndex.end();) {\n",
        "    if (*outIdxIt == deleteIdx) {\n",
        "      outIdxIt = node->outputIndex.erase(outIdxIt);\n",
        "    } else {\n",
        "      if (*outIdxIt > deleteIdx) {\n",
        "        (*outIdxIt)--;\n",
        "      }\n",
        "      outIdxIt++;\n",
        "    }\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS AddTensor2Node(schema::MetaGraphT *graphT, uint32_t nodeIdx, std::unique_ptr<TensorT> tensor,\n",
        "                      InsertPlace place) {\n",
        "  if (nodeIdx >= graphT->nodes.size()) {\n",
        "    MS_LOG(ERROR) << \"nodeIdx out of range: \" << nodeIdx;\n",
        "    return RET_PARAM_INVALID;\n",
        "  }\n",
        "  graphT->allTensors.emplace_back(std::move(tensor));\n",
        "  uint32_t newTensorIdx = graphT->allTensors.size() - 1;\n",
        "  auto node = graphT->nodes.at(nodeIdx).get();\n",
        "  if (place == kBefore) {\n",
        "    node->inputIndex.emplace_back(newTensorIdx);\n",
        "  } else {\n",
        "    node->outputIndex.emplace_back(newTensorIdx);\n",
        "  }\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "STATUS ReplaceTensorOfNode(schema::MetaGraphT *graphT, uint32_t nodeIdx, uint32_t inTensorIdx,\n",
        "                           std::unique_ptr<TensorT> tensor) {\n",
        "  if (nodeIdx >= graphT->nodes.size()) {\n",
        "    MS_LOG(ERROR) << \"nodeIdx out of range: \" << nodeIdx;\n",
        "    return RET_PARAM_INVALID;\n",
        "  }\n",
        "  auto node = graphT->nodes.at(nodeIdx).get();\n",
        "  if (inTensorIdx >= graphT->allTensors.size()) {\n",
        "    MS_LOG(ERROR) << \"inTensorIdx out of range: \" << nodeIdx;\n",
        "    return RET_PARAM_INVALID;\n",
        "  }\n",
        "  if (!IsContain(node->inputIndex, inTensorIdx)) {\n",
        "    MS_LOG(ERROR) << \"inTensorIdx(\" << inTensorIdx << \") is not a inputIdx of node(\" << nodeIdx << \")\";\n",
        "    return RET_PARAM_INVALID;\n",
        "  }\n",
        "  graphT->allTensors.at(inTensorIdx).swap(tensor);\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "NodeIter InsertNode(schema::MetaGraphT *graphT, uint32_t existNodeIdx, InsertPlace place, size_t inoutIndex,\n",
        "                    std::unique_ptr<CNodeT> toAddNode, STATUS *errorCode, OpDefCopyer opDefCopyer) {\n",
        "  if (existNodeIdx >= graphT->nodes.size()) {\n",
        "    MS_LOG(ERROR) << \"nodeIdx out of range: \" << existNodeIdx;\n",
        "    return graphT->nodes.end();\n",
        "  }\n",
        "  auto nodeIter = graphT->nodes.begin() + existNodeIdx;\n",
        "  MS_ASSERT(nodeIter != graphT->nodes.begin());\n",
        "  MS_ASSERT((*nodeIter) != nullptr);\n",
        "  return InsertNode(graphT, nodeIter, place, inoutIndex, std::move(toAddNode), errorCode);\n",
        "}\n",
        "\n",
        "NodeIter InsertNode(schema::MetaGraphT *graphT, NodeIter existNodeIter, InsertPlace place, size_t inoutIndexIdx,\n",
        "                    std::unique_ptr<CNodeT> toAddNode, STATUS *errorCode, OpDefCopyer opDefCopyer) {\n",
        "  if (place == kBefore) {\n",
        "    return InsertNodeBefore(graphT, existNodeIter, inoutIndexIdx, std::move(toAddNode), errorCode, opDefCopyer);\n",
        "  } else if (place == kAfter) {\n",
        "    return InsertNodeAfter(graphT, existNodeIter, inoutIndexIdx, std::move(toAddNode), errorCode, opDefCopyer);\n",
        "  } else {\n",
        "    MS_LOG(ERROR) << \"Invalid InsertPlace : \" << place;\n",
        "    return graphT->nodes.end();\n",
        "  }\n",
        "}\n",
        "\n",
        "NodeIter InsertNodeBefore(schema::MetaGraphT *graphT, NodeIter existNodeIter, size_t inputIndexIdx,\n",
        "                          std::unique_ptr<CNodeT> toAddNodeIn, STATUS *errorCode, OpDefCopyer opDefCopyer) {\n",
        "  auto &existNode = *existNodeIter;\n",
        "  MS_ASSERT(existNode != nullptr);\n",
        "  MS_ASSERT(existNode->inputIndex.size() > inputIndexIdx);\n",
        "  MS_ASSERT(toAddNodeIn != nullptr);\n",
        "  auto preTensorIdx = existNode->inputIndex.at(inputIndexIdx);\n",
        "  MS_ASSERT(graphT->allTensors.size() > preTensorIdx);\n",
        "\n",
        "  auto preNodeIdxes = GetInputNodeIdx(*graphT, *(existNode.get()), inputIndexIdx);\n",
        "  if (preNodeIdxes.empty()) {\n",
        "    auto &preTensor = graphT->allTensors.at(preTensorIdx);\n",
        "    MS_ASSERT(preTensor != nullptr);\n",
        "    auto toAddTensor = CopyTensorDefT(preTensor);\n",
        "    if (toAddTensor == nullptr) {\n",
        "      MS_LOG(ERROR) << \"Copy TensorT failed\";\n",
        "      *errorCode = RET_NULL_PTR;\n",
        "      return graphT->nodes.end();\n",
        "    }\n",
        "    preTensor->refCount = 0;\n",
        "    preTensor->data.clear();\n",
        "    if (toAddNodeIn->primitive->value.type == schema::PrimitiveType_QuantDTypeCast) {\n",
        "      preTensor->dataType = toAddNodeIn->primitive->value.AsQuantDTypeCast()->dstT;\n",
        "      toAddTensor->dataType = toAddNodeIn->primitive->value.AsQuantDTypeCast()->srcT;\n",
        "    }\n",
        "    graphT->allTensors.emplace_back(std::move(toAddTensor));\n",
        "    size_t toAddTensorIdx = graphT->allTensors.size() - 1;\n",
        "    auto toAddNode = opDefCopyer(toAddNodeIn.get());\n",
        "    if (toAddNode == nullptr) {\n",
        "      MS_LOG(ERROR) << \"copy toAddNodeIn failed\";\n",
        "      *errorCode = RET_NULL_PTR;\n",
        "      return graphT->nodes.end();\n",
        "    }\n",
        "    toAddNode->inputIndex.clear();\n",
        "    toAddNode->inputIndex.push_back(preTensorIdx);\n",
        "    toAddNode->outputIndex.clear();\n",
        "    toAddNode->outputIndex.push_back(toAddTensorIdx);\n",
        "    for (auto iter = existNode->inputIndex.begin(); iter != existNode->inputIndex.end(); iter++) {\n",
        "      if (*iter == preTensorIdx) {\n",
        "        *iter = toAddTensorIdx;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "    existNodeIter = graphT->nodes.insert(existNodeIter, std::move(toAddNode));\n",
        "    existNodeIter++;\n",
        "  } else {\n",
        "    std::vector<std::unique_ptr<CNodeT>> toAddNodes;\n",
        "    for (size_t i = 0; i < preNodeIdxes.size(); i++) {\n",
        "      MS_ASSERT(graphT->nodes.size() > preNodeIdxes.at(i));\n",
        "      auto &preTensor = graphT->allTensors.at(preTensorIdx);\n",
        "      MS_ASSERT(preTensor != nullptr);\n",
        "      auto toAddTensor = CopyTensorDefT(preTensor);\n",
        "      if (toAddTensor == nullptr) {\n",
        "        *errorCode = RET_NULL_PTR;\n",
        "        MS_LOG(ERROR) << \"Copy TensorT failed\";\n",
        "        return graphT->nodes.end();\n",
        "      }\n",
        "      if (toAddNodeIn->primitive->value.type == schema::PrimitiveType_QuantDTypeCast) {\n",
        "        preTensor->dataType = toAddNodeIn->primitive->value.AsQuantDTypeCast()->srcT;\n",
        "        toAddTensor->dataType = toAddNodeIn->primitive->value.AsQuantDTypeCast()->dstT;\n",
        "      }\n",
        "      graphT->allTensors.emplace_back(std::move(toAddTensor));\n",
        "      size_t toAddTensorIdx = graphT->allTensors.size() - 1;\n",
        "      auto toAddNode = opDefCopyer(toAddNodeIn.get());\n",
        "      if (toAddNode == nullptr) {\n",
        "        MS_LOG(ERROR) << \"copy toAddNodeIn failed\";\n",
        "        *errorCode = RET_NULL_PTR;\n",
        "        return graphT->nodes.end();\n",
        "      }\n",
        "      toAddNode->name = toAddNodeIn->name + \"_\" + std::to_string(i++);\n",
        "      toAddNode->inputIndex.clear();\n",
        "      toAddNode->inputIndex.push_back(preTensorIdx);\n",
        "      toAddNode->outputIndex.clear();\n",
        "      toAddNode->outputIndex.push_back(toAddTensorIdx);\n",
        "      for (auto iter = existNode->inputIndex.begin(); iter != existNode->inputIndex.end(); iter++) {\n",
        "        if (*iter == preTensorIdx) {\n",
        "          *iter = toAddTensorIdx;\n",
        "          break;\n",
        "        }\n",
        "      }\n",
        "      toAddNodes.emplace_back(std::move(toAddNode));\n",
        "    }\n",
        "    for (auto &toAddNode : toAddNodes) {\n",
        "      existNodeIter = graphT->nodes.insert(existNodeIter, std::move(toAddNode));\n",
        "      existNodeIter++;\n",
        "    }\n",
        "  }\n",
        "  *errorCode = RET_OK;\n",
        "  return existNodeIter;\n",
        "}\n",
        "\n",
        "NodeIter InsertNodeAfter(schema::MetaGraphT *graphT, NodeIter existNodeIter, size_t outputIndexIdx,\n",
        "                         std::unique_ptr<schema::CNodeT> toAddNodeIn, STATUS *errorCode, OpDefCopyer opDefCopyer) {\n",
        "  auto &existNode = *existNodeIter;\n",
        "  MS_ASSERT(existNode != nullptr);\n",
        "  MS_ASSERT(existNode->outputIndex.size() > outputIndexIdx);\n",
        "  MS_ASSERT(toAddNodeIn != nullptr);\n",
        "  auto postTensorIdx = existNode->outputIndex.at(outputIndexIdx);\n",
        "  MS_ASSERT(graphT->allTensors.size() > postTensorIdx);\n",
        "\n",
        "  auto postNodeIdxes = GetOutputNodeIdx(*graphT, *(existNode.get()), outputIndexIdx);\n",
        "  if (postNodeIdxes.empty()) {\n",
        "    auto &postTensor = graphT->allTensors.at(postTensorIdx);\n",
        "    MS_ASSERT(postTensor != nullptr);\n",
        "    auto toAddTensor = CopyTensorDefT(postTensor);\n",
        "    if (toAddTensor == nullptr) {\n",
        "      MS_LOG(ERROR) << \"Copy TensorT failed\";\n",
        "      *errorCode = RET_NULL_PTR;\n",
        "      return graphT->nodes.end();\n",
        "    }\n",
        "    if (toAddNodeIn->primitive->value.type == schema::PrimitiveType_QuantDTypeCast) {\n",
        "      postTensor->dataType = toAddNodeIn->primitive->value.AsQuantDTypeCast()->srcT;\n",
        "      toAddTensor->dataType = toAddNodeIn->primitive->value.AsQuantDTypeCast()->dstT;\n",
        "    }\n",
        "    graphT->allTensors.emplace_back(std::move(toAddTensor));\n",
        "    size_t toAddTensorIdx = graphT->allTensors.size() - 1;\n",
        "    auto toAddNode = opDefCopyer(toAddNodeIn.get());\n",
        "    if (toAddNode == nullptr) {\n",
        "      MS_LOG(ERROR) << \"copy toAddNodeIn failed\";\n",
        "      *errorCode = RET_NULL_PTR;\n",
        "      return graphT->nodes.end();\n",
        "    }\n",
        "    toAddNode->inputIndex.clear();\n",
        "    toAddNode->inputIndex.push_back(postTensorIdx);\n",
        "    toAddNode->outputIndex.clear();\n",
        "    toAddNode->outputIndex.push_back(toAddTensorIdx);\n",
        "    for (auto iter = graphT->outputIndex.begin(); iter != graphT->outputIndex.end(); iter++) {\n",
        "      if (*iter == postTensorIdx) {\n",
        "        *iter = toAddTensorIdx;\n",
        "        break;\n",
        "      }\n",
        "    }\n",
        "    existNodeIter = graphT->nodes.insert(existNodeIter, std::move(toAddNode));\n",
        "    existNodeIter++;\n",
        "  } else {\n",
        "    std::vector<std::unique_ptr<schema::CNodeT>> toAddNodes;\n",
        "    int i = 0;\n",
        "    for (size_t postNodeIdx : postNodeIdxes) {\n",
        "      MS_ASSERT(graphT->nodes.size() > postNodeIdx);\n",
        "      auto &postNode = graphT->nodes.at(postNodeIdx);\n",
        "      MS_ASSERT(postNode != nullptr);\n",
        "      auto &postTensor = graphT->allTensors.at(postTensorIdx);\n",
        "      MS_ASSERT(postTensor != nullptr);\n",
        "      auto toAddTensor = CopyTensorDefT(postTensor);\n",
        "      if (toAddTensor == nullptr) {\n",
        "        MS_LOG(ERROR) << \"Copy TensorT failed\";\n",
        "        *errorCode = RET_NULL_PTR;\n",
        "        return graphT->nodes.end();\n",
        "      }\n",
        "      if (toAddNodeIn->primitive->value.type == schema::PrimitiveType_QuantDTypeCast) {\n",
        "        postTensor->dataType = toAddNodeIn->primitive->value.AsQuantDTypeCast()->srcT;\n",
        "        toAddTensor->dataType = toAddNodeIn->primitive->value.AsQuantDTypeCast()->dstT;\n",
        "      }\n",
        "      graphT->allTensors.emplace_back(std::move(toAddTensor));\n",
        "      size_t toAddTensorIdx = graphT->allTensors.size() - 1;\n",
        "      auto toAddNode = opDefCopyer(toAddNodeIn.get());\n",
        "      if (toAddNode == nullptr) {\n",
        "        MS_LOG(ERROR) << \"copy toAddNodeIn failed\";\n",
        "        *errorCode = RET_NULL_PTR;\n",
        "        return graphT->nodes.end();\n",
        "      }\n",
        "      toAddNode->name = toAddNodeIn->name + \"_\" + std::to_string(i++);\n",
        "      toAddNode->inputIndex.clear();\n",
        "      toAddNode->inputIndex.push_back(postTensorIdx);\n",
        "      toAddNode->outputIndex.clear();\n",
        "      toAddNode->outputIndex.push_back(toAddTensorIdx);\n",
        "      MS_ASSERT(IsContain(postNode->inputIndex, postTensorIdx));\n",
        "      for (auto iter = postNode->inputIndex.begin(); iter != postNode->inputIndex.end(); iter++) {\n",
        "        if (*iter == postTensorIdx) {\n",
        "          *iter = toAddTensorIdx;\n",
        "          break;\n",
        "        }\n",
        "      }\n",
        "      toAddNodes.emplace_back(std::move(toAddNode));\n",
        "    }\n",
        "    for (auto &toAddNode : toAddNodes) {\n",
        "      existNodeIter = graphT->nodes.insert(existNodeIter, std::move(toAddNode));\n",
        "      existNodeIter++;\n",
        "    }\n",
        "  }\n",
        "  *errorCode = RET_OK;\n",
        "  return existNodeIter;\n",
        "}\n",
        "\n",
        "STATUS ValidateFileStr(const std::string &modelFile, std::string fileType) {\n",
        "  if (modelFile.size() > fileType.size()) {\n",
        "    if (modelFile.substr(modelFile.size() - fileType.size()) == fileType) {\n",
        "      return RET_OK;\n",
        "    } else {\n",
        "      return RET_ERROR;\n",
        "    }\n",
        "  } else {\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "}\n",
        "\n",
        "std::string GetModelName(const std::string &modelFile) {\n",
        "  std::string modelName = modelFile;\n",
        "  modelName = modelName.substr(modelName.find_last_of('/') + 1);\n",
        "  modelName = modelName.substr(0, modelName.find_last_of('.'));\n",
        "\n",
        "  srand((unsigned)time(NULL));\n",
        "  modelName = modelName + std::to_string(rand());\n",
        "\n",
        "  return modelName;\n",
        "}\n",
        "}  // namespace lite\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVuWr1Zqq_Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include \"backend/optimizer/common/node_pass.h\"\n",
        "\n",
        "#include <unordered_set>\n",
        "#include <deque>\n",
        "#include <algorithm>\n",
        "\n",
        "#include \"ir/anf.h\"\n",
        "#include \"ir/func_graph.h\"\n",
        "#include \"ir/manager.h\"\n",
        "#include \"tools/optimizer/common/gllo_utils.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "bool NodePass::Run(const FuncGraphPtr &func_graph) {\n",
        "  MS_EXCEPTION_IF_NULL(func_graph);\n",
        "  FuncGraphManagerPtr manager = func_graph->manager();\n",
        "  MS_EXCEPTION_IF_NULL(manager);\n",
        "  manager->AddFuncGraph(func_graph);\n",
        "\n",
        "  std::unordered_set<AnfNodePtr> seen_node;\n",
        "  std::deque<AnfNodePtr> to_process{func_graph->output()};\n",
        "  bool changes = false;\n",
        "  while (!to_process.empty()) {\n",
        "    AnfNodePtr node = to_process.front();\n",
        "    to_process.pop_front();\n",
        "    if (seen_node.count(node) > 0 || !manager->all_nodes().contains(node)) {\n",
        "      continue;\n",
        "    }\n",
        "    (void) seen_node.insert(node);\n",
        "    AnfNodePtr new_node = Run(func_graph, node);\n",
        "    bool change = (new_node != nullptr);\n",
        "    if (new_node != nullptr && new_node != node) {\n",
        "      (void) manager->Replace(node, new_node);\n",
        "      (void) seen_node.erase(node);\n",
        "    } else if (new_node == nullptr) {\n",
        "      new_node = node;\n",
        "    }\n",
        "    if (new_node && IsValueNode<FuncGraph>(new_node)) {\n",
        "      auto const_func_graph = GetValueNode<FuncGraphPtr>(new_node);\n",
        "      MS_EXCEPTION_IF_NULL(const_func_graph);\n",
        "      to_process.push_back(const_func_graph->output());\n",
        "    } else if (new_node && new_node->isa<CNode>()) {\n",
        "      if (IsGraphKernel(new_node)) {\n",
        "        to_process.push_back(new_node);\n",
        "      }\n",
        "      auto cnode = new_node->cast<CNodePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(cnode);\n",
        "      auto inputs = cnode->inputs();\n",
        "      (void) to_process.insert(to_process.end(), inputs.begin(), inputs.end());\n",
        "    }\n",
        "    changes = changes || change;\n",
        "    if (changes) {\n",
        "      MS_LOG(DEBUG) << \"pass \" << this->name() << \"changed node:\" << new_node->fullname_with_scope();\n",
        "    }\n",
        "  }\n",
        "  return changes;\n",
        "}\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZGU4PDAsNQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/optimizer/fusion/constant_folding_fusion.h\"\n",
        "#include <memory>\n",
        "#include <set>\n",
        "#include <vector>\n",
        "#include \"tools/optimizer/common/gllo_utils.h\"\n",
        "#include \"tools/anf_exporter/anf_exporter.h\"\n",
        "#include \"src/kernel_registry.h\"\n",
        "#include \"include/context.h\"\n",
        "#include \"src/populate_parameter.h\"\n",
        "#include \"src/ops/primitive_c.h\"\n",
        "\n",
        "using mindspore::lite::KernelRegistry;\n",
        "using mindspore::lite::PrimitiveC;\n",
        "using mindspore::lite::tensor::Tensor;\n",
        "namespace mindspore::opt {\n",
        "namespace {\n",
        "std::vector<Tensor *> GetCNodeInputTensors(const CNodePtr &CNode) {\n",
        "  MS_ASSERT(CNode != nullptr);\n",
        "  auto tmp_meta_graph = std::make_unique<schema::MetaGraphT>();\n",
        "  auto tmp_fb_node = std::make_unique<schema::CNodeT>();\n",
        "  lite::AnfExporter anfExporter;\n",
        "  anfExporter.SetOpInputNode(CNode, tmp_meta_graph, tmp_fb_node.get());\n",
        "  std::vector<Tensor *> input_tensors;\n",
        "  for (auto input_index : tmp_fb_node->inputIndex) {\n",
        "    auto tensorT = tmp_meta_graph->allTensors.at(input_index).get();\n",
        "    auto tensor_shape = tensorT->dims;\n",
        "    auto lite_tensor =\n",
        "        new (std::nothrow) Tensor(TypeId(tensorT->dataType), tensor_shape, tensorT->format, tensorT->nodeType);\n",
        "    if (lite_tensor == nullptr) {\n",
        "      MS_LOG(ERROR) << \"lite tensor is nullptr\";\n",
        "      return input_tensors;\n",
        "    }\n",
        "    auto lite_tensor_size = tensorT->data.size() * sizeof(uint8_t);\n",
        "    // when tensorT as graph input\n",
        "    if (lite_tensor_size <= 0) {\n",
        "      delete lite_tensor;\n",
        "      return input_tensors;\n",
        "    }\n",
        "    auto tensor_data = new (std::nothrow) uint8_t[lite_tensor_size / sizeof(char)];\n",
        "    if (tensor_data == nullptr) {\n",
        "      MS_LOG(ERROR) << \"tensor_data is nullptr\";\n",
        "      delete lite_tensor;\n",
        "      return input_tensors;\n",
        "    }\n",
        "    auto ret = memcpy_s(tensor_data, lite_tensor_size, tensorT->data.data(), lite_tensor_size);\n",
        "    if (ret != EOK) {\n",
        "      delete lite_tensor;\n",
        "      delete[](tensor_data);\n",
        "      MS_LOG(EXCEPTION) << \"memcpy error: \" << ret;\n",
        "    }\n",
        "    lite_tensor->SetData(tensor_data);\n",
        "    input_tensors.emplace_back(lite_tensor);\n",
        "  }\n",
        "  return input_tensors;\n",
        "}\n",
        "\n",
        "ParameterPtr CreateNewParamter(const FuncGraphPtr &func_graph, Tensor *tensor) {\n",
        "  auto parameter = func_graph->add_parameter();\n",
        "  std::vector<int> shape(tensor->shape());\n",
        "  auto type_id = static_cast<TypeId>(tensor->data_type());\n",
        "  auto type_ptr = TypeIdToType(type_id);\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, shape);\n",
        "  parameter->set_abstract(abstract_tensor);\n",
        "\n",
        "  ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\n",
        "  MS_ASSERT(param_value != nullptr);\n",
        "  param_value->set_tensor_shape(shape);\n",
        "  param_value->set_tensor_type(type_id);\n",
        "  param_value->set_format(tensor->GetFormat());\n",
        "  if (tensor->Data() != nullptr) {\n",
        "    auto size = tensor->ElementsNum();\n",
        "    auto tensor_data = new (std::nothrow) float[size];\n",
        "    if (tensor_data == nullptr) {\n",
        "      MS_LOG(ERROR) << \"tensor_data is nullptr\";\n",
        "      return nullptr;\n",
        "    }\n",
        "    auto ret = memcpy_s(tensor_data, size * sizeof(float), tensor->Data(), size * sizeof(float));\n",
        "    if (ret != EOK) {\n",
        "      delete[] tensor_data;\n",
        "      MS_LOG(ERROR) << \"memcpy error: \" << ret;\n",
        "      return nullptr;\n",
        "    }\n",
        "    param_value->set_tensor_addr(tensor_data);\n",
        "    param_value->set_tensor_size(size * sizeof(float) / sizeof(uint8_t));\n",
        "  }\n",
        "  parameter->set_default_param(param_value);\n",
        "  return parameter;\n",
        "}\n",
        "kernel::LiteKernel *GetLiteKernel(std::vector<Tensor *> inputs, std::vector<Tensor *> outputs, OpParameter *parameter,\n",
        "                                  mindspore::lite::PrimitiveC *primitive) {\n",
        "  MS_ASSERT(nullptr != lite_primitive);\n",
        "  auto data_type = inputs.front()->data_type();\n",
        "  kernel::KernelKey desc{kernel::KERNEL_ARCH::kCPU, data_type, (schema::PrimitiveType) primitive->Type()};\n",
        "  lite::Context context;\n",
        "  auto creator = lite::KernelRegistry::GetInstance()->GetCreator(desc);\n",
        "  if (creator != nullptr) {\n",
        "    auto lite_kernel = creator(inputs, outputs, parameter, &context, desc, primitive);\n",
        "    return lite_kernel;\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "lite::STATUS ReplaceCNode(const FuncGraphPtr &func_graph, const CNodePtr &any_node, const AnfNodePtr &input_node,\n",
        "                          std::vector<Tensor *> output_tensors, size_t replace_index) {\n",
        "  MS_ASSERT(func_graph != nullptr);\n",
        "  auto manager = func_graph->manager();\n",
        "  MS_ASSERT(manager != nullptr);\n",
        "  if (output_tensors.size() != 1) {\n",
        "    for (size_t k = 0; k < output_tensors.size(); k++) {\n",
        "      auto used_node_list = GetRealNodeUsedListByOutputIdx(func_graph, input_node, k);\n",
        "      if (used_node_list->size() != 1) {\n",
        "        MS_LOG(ERROR) << \" output must tuple_getitem\";\n",
        "        return lite::RET_ERROR;\n",
        "      }\n",
        "      auto tuple_node = used_node_list->at(0).first;\n",
        "      if (GetCNodeType(tuple_node) == schema::PrimitiveType_TupleGetItem) {\n",
        "        auto new_parameter = CreateNewParamter(func_graph, output_tensors.at(k));\n",
        "        if (new_parameter == nullptr) {\n",
        "          MS_LOG(ERROR) << \"CreateNewParamter failed, name: \" << input_node->fullname_with_scope();\n",
        "          return lite::RET_ERROR;\n",
        "        }\n",
        "        new_parameter->set_name(input_node->fullname_with_scope() + \"_const_\" + std::to_string(k));\n",
        "        manager->Replace(tuple_node, new_parameter);\n",
        "      } else {\n",
        "        MS_LOG(ERROR) << \" multi out tensor must connect tuple-getitem: \" << input_node->fullname_with_scope();\n",
        "        return lite::RET_ERROR;\n",
        "      }\n",
        "    }\n",
        "  } else {\n",
        "    auto new_parameter = CreateNewParamter(func_graph, output_tensors.front());\n",
        "    if (new_parameter == nullptr) {\n",
        "      MS_LOG(ERROR) << \"CreateNewParamter failed, name: \" << input_node->fullname_with_scope();\n",
        "      return lite::RET_ERROR;\n",
        "    }\n",
        "    new_parameter->set_name(input_node->fullname_with_scope());\n",
        "    any_node->set_input(replace_index, new_parameter);\n",
        "  }\n",
        "  return lite::RET_OK;\n",
        "}\n",
        "}  //  namespace\n",
        "void FreeTensors(std::vector<Tensor *> *input_tensor, std::vector<Tensor *> *output_tensor) {\n",
        "  if (input_tensor != nullptr) {\n",
        "    for (size_t i = 0; i < input_tensor->size(); i++) {\n",
        "      delete (*input_tensor)[i];\n",
        "      (*input_tensor)[i] = nullptr;\n",
        "    }\n",
        "  }\n",
        "  if (output_tensor != nullptr) {\n",
        "    for (size_t i = 0; i < output_tensor->size(); i++) {\n",
        "      delete (*output_tensor)[i];\n",
        "      (*output_tensor)[i] = nullptr;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "const AnfNodePtr ConstFoldPass::Process(const FuncGraphPtr &func_graph, const AnfNodePtr &node,\n",
        "                                        const EquivPtr &) const {\n",
        "  CheckIfFuncGraphIsNull(func_graph);\n",
        "  CheckIfAnfNodeIsNull(node);\n",
        "  if (!node->isa<CNode>()) {\n",
        "    return nullptr;\n",
        "  }\n",
        "  auto any_node = node->cast<CNodePtr>();\n",
        "  CheckIfCNodeIsNull(any_node);\n",
        "  bool changed = false;\n",
        "  for (size_t i = 1; i < any_node->inputs().size(); i++) {\n",
        "    auto input_node = any_node->input(i);\n",
        "    if (!input_node->isa<CNode>() || !CheckIsAllInputsParam(input_node)) {\n",
        "      continue;\n",
        "    }\n",
        "    auto input_cnode = input_node->cast<CNodePtr>();\n",
        "    auto input_tensors = GetCNodeInputTensors(input_cnode);\n",
        "    if (input_tensors.empty() || input_tensors.size() != input_cnode->inputs().size() - 1) {\n",
        "      FreeTensors(&input_tensors, nullptr);\n",
        "      continue;\n",
        "    }\n",
        "    changed = true;\n",
        "    auto output_nums = GetOutputTensorNum(input_cnode);\n",
        "    std::vector<Tensor *> output_tensors{output_nums, new Tensor()};\n",
        "    auto lite_primitive = GetValueNode<std::shared_ptr<PrimitiveC>>(input_cnode->input(0));\n",
        "    if (lite_primitive == nullptr) {\n",
        "      MS_LOG(ERROR) << \"lite_primitive is nullptr\";\n",
        "      FreeTensors(&input_tensors, &output_tensors);\n",
        "      return nullptr;\n",
        "    }\n",
        "    auto inputQuantParams = lite_primitive->GetInputQuantParams();\n",
        "    for (size_t m = 0; m < inputQuantParams.size(); m++) {\n",
        "      for (auto inputQuantParam : inputQuantParams[m]) {\n",
        "        lite::tensor::QuantArg quant_arg{};\n",
        "        quant_arg.scale = inputQuantParam.scale;\n",
        "        quant_arg.zeroPoint = inputQuantParam.zeroPoint;\n",
        "        input_tensors[m]->AddQuantParam(quant_arg);\n",
        "      }\n",
        "    }\n",
        "    auto outputQuantParams = lite_primitive->GetOutputQuantParams();\n",
        "    for (size_t m = 0; m < outputQuantParams.size(); m++) {\n",
        "      for (auto outputQuantParam : outputQuantParams[m]) {\n",
        "        lite::tensor::QuantArg quant_arg{};\n",
        "        quant_arg.scale = outputQuantParam.scale;\n",
        "        quant_arg.zeroPoint = outputQuantParam.zeroPoint;\n",
        "        output_tensors[m]->AddQuantParam(quant_arg);\n",
        "      }\n",
        "    }\n",
        "    // here, input_tensor's format need to be transposed nhwc according to fmkType,\n",
        "    // but for the time being, we only transpose the tensor with 0/1/2/3D.\n",
        "    // Others should be added in future.\n",
        "    for (size_t j = 0; j < input_tensors.size(); ++j) {\n",
        "      input_tensors[j]->SetFormat(schema::Format_NHWC);\n",
        "      if (input_tensors[j]->shape().size() == 4) {\n",
        "        MS_LOG(INFO) << \"init input_tensor format to nhwc\";\n",
        "      }\n",
        "    }\n",
        "    lite_primitive->InferShape(input_tensors, output_tensors);\n",
        "    auto parameter = kernel::PopulateParameter(lite_primitive.get());\n",
        "    if (parameter == nullptr) {\n",
        "      MS_LOG(ERROR) << \"PopulateParameter return nullptr, type: \"\n",
        "                    << schema::EnumNamePrimitiveType((schema::PrimitiveType) (lite_primitive->Type()));\n",
        "      return nullptr;\n",
        "    }\n",
        "    auto lite_kernel = GetLiteKernel(input_tensors, output_tensors, parameter, lite_primitive.get());\n",
        "    if (lite_kernel == nullptr) {\n",
        "      MS_LOG(ERROR) << \"constant_folding schedule node lite kernel nullptr\";\n",
        "      FreeTensors(&input_tensors, &output_tensors);\n",
        "      return nullptr;\n",
        "    }\n",
        "    auto ret = lite_kernel->Run();\n",
        "    if (0 != ret) {\n",
        "      FreeTensors(&input_tensors, &output_tensors);\n",
        "      MS_LOG(ERROR) << \"run kernel failed, name: \" << lite_kernel->name();\n",
        "      return nullptr;\n",
        "    }\n",
        "    // replace cnode by new param\n",
        "    if (ReplaceCNode(func_graph, any_node, input_node, output_tensors, i) != lite::RET_OK) {\n",
        "      FreeTensors(&input_tensors, &output_tensors);\n",
        "      delete (lite_kernel);\n",
        "      MS_LOG(ERROR) << \"constant_folding replace cnode failed\";\n",
        "      return nullptr;\n",
        "    }\n",
        "    MS_LOG(DEBUG) << \"fold node:\" << input_node->fullname_with_scope() << \" success \";\n",
        "    FreeTensors(&input_tensors, &output_tensors);\n",
        "    delete (lite_kernel);\n",
        "  }\n",
        "  return changed ? any_node : nullptr;\n",
        "}\n",
        "}  // namespace mindspore::opt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B24P1lcrlmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWGS_5Sfsenj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk",
        "colab_type": "text"
      },
      "source": [
        "#Data process"
      ]
    }
  ]
}