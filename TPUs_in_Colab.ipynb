{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o52NToMnM1mL"
      },
      "source": [
        "From ee750131058e9469e14f8d37a7f2d70afd7cd63a Mon Sep 17 00:00:00 2001\n",
        "From: guohongzilong <guohongzilong@huawei.com>\n",
        "Date: Sat, 10 Apr 2021 15:11:00 +0800\n",
        "Subject: [PATCH] add android train api\n",
        "\n",
        "---\n",
        " .../main/java/com/huawei/flclient/AsyncFLJob.java  |  77 ++++++++-\n",
        " .../main/java/com/huawei/flclient/LiteTrain.java   |   8 +\n",
        " .../main/java/com/huawei/flclient/NativeTrain.java |   4 +\n",
        " .../lite/flclient/src/main/native/bert_train.cpp   | 173 ++++++++++++++++-----\n",
        " .../lite/flclient/src/main/native/bert_train.h     |   9 +-\n",
        " .../src/main/native/dataset/CustomizedTokenizer.cc |  23 +--\n",
        " .../src/main/native/dataset/CustomizedTokenizer.h  |   4 +-\n",
        " .../flclient/src/main/native/lite_train_jni.cpp    | 156 +++++++++++++------\n",
        " .../lite/flclient/src/main/native/test_train.cc    |  92 +++++------\n",
        " mindspore/lite/flclient/src/main/native/util.cpp   |   8 +-\n",
        " 10 files changed, 394 insertions(+), 160 deletions(-)\n",
        "\n",
        "diff --git a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/AsyncFLJob.java b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/AsyncFLJob.java\n",
        "index d6850f1..d373a7f 100644\n",
        "--- a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/AsyncFLJob.java\n",
        "+++ b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/AsyncFLJob.java\n",
        "@@ -1,8 +1,13 @@\n",
        " package com.huawei.flclient;\n",
        " \n",
        "-import java.io.FileInputStream;\n",
        "-import java.io.InputStream;\n",
        "+import java.io.*;\n",
        " import java.nio.ByteBuffer;\n",
        "+import java.nio.channels.FileChannel;\n",
        "+import java.nio.charset.StandardCharsets;\n",
        "+import java.nio.file.Files;\n",
        "+import java.nio.file.Path;\n",
        "+import java.nio.file.Paths;\n",
        "+import java.util.List;\n",
        " \n",
        " public class AsyncFLJob {\n",
        "     public AsyncFLJob() {}\n",
        "@@ -130,6 +135,33 @@ public class AsyncFLJob {\n",
        "         }\n",
        "     }\n",
        " \n",
        "+    public int modeTrainFromBuffer(String trainFile,String vocabFile,String modelPath,int batchSize,int epoches,EarlyStopMod earlyStopMod,int numThreads) {\n",
        "+        LiteTrain train = LiteTrain.getInstance();\n",
        "+        System.out.println(\"==========initial model===========\");\n",
        "+        ByteBuffer modelBuffer = loadModelFile(modelPath);\n",
        "+        train.initFromBuffer(modelBuffer, numThreads);\n",
        "+        System.out.println(\"trainFilePath: \" + trainFile);\n",
        "+        System.out.println(\"===========model train=============\");\n",
        "+        try {\n",
        "+            Path path = Paths.get(vocabFile);\n",
        "+            List<String> allLines = Files.readAllLines(path, StandardCharsets.UTF_8);\n",
        "+            String vocal[] = new String[allLines.size()];\n",
        "+            for(int i=0;i<allLines.size();i++) {\n",
        "+                vocal[i] = allLines.get(i);\n",
        "+            }\n",
        "+            int trainSize = train.setAlbertInput(trainFile,vocal);\n",
        "+            int status = train.trainAlbert(batchSize, epoches,earlyStopMod.ordinal());\n",
        "+            // update modelBuffer to msfile\n",
        "+            updateModelFile(modelPath,modelBuffer);\n",
        "+            train.free();\n",
        "+            System.out.println(\"train finish\");\n",
        "+            return status;\n",
        "+        } catch (Exception e) {\n",
        "+            e.printStackTrace();\n",
        "+            System.out.println(\"train failed\");\n",
        "+            throw new RuntimeException();\n",
        "+        }\n",
        "+    }\n",
        "     public int modelInferenceSingleDataFromBuffer(String data, ByteBuffer modelPath, String[] vocal_file, int numThreads) {\n",
        "         LiteTrain train = LiteTrain.getInstance();\n",
        "         System.out.println(\"==========initial model===========\");\n",
        "@@ -149,7 +181,7 @@ public class AsyncFLJob {\n",
        "         }\n",
        "     }\n",
        " \n",
        "-    public ByteBuffer loadModelFile(String modelPath) {\n",
        "+    public static ByteBuffer loadModelFile(String modelPath) {\n",
        "         InputStream input = null;\n",
        "         try {\n",
        "             input = new FileInputStream(modelPath);\n",
        "@@ -163,7 +195,15 @@ public class AsyncFLJob {\n",
        "         return null;\n",
        "     }\n",
        " \n",
        "-    public static void main(String[] args) {\n",
        "+    public static void updateModelFile(String modelPath,ByteBuffer modelBuffer) throws IOException {\n",
        "+        File file = new File(modelPath);\n",
        "+        FileChannel wChannel = new FileOutputStream(file, false).getChannel();\n",
        "+        modelBuffer.flip();\n",
        "+        wChannel.write(modelBuffer);\n",
        "+        wChannel.close();\n",
        "+    }\n",
        "+\n",
        "+    public static void main(String[] args) throws IOException {\n",
        "         String url = args[0];\n",
        "         String flName = args[1];\n",
        "         String modelPath = args[2];\n",
        "@@ -177,6 +217,20 @@ public class AsyncFLJob {\n",
        "         String task = args[10];\n",
        "         boolean ifInteract = Boolean.parseBoolean(args[11]);\n",
        " \n",
        "+//        String url = \"null\";\n",
        "+//        String flName = \"/home/meng/zj10/fl/mindspore/mindspore/lite/albert.ms\";\n",
        "+//        String modelPath = \"/home/meng/zj10/fl/mindspore/mindspore/lite/albert.ms\";\n",
        "+//        String flID = \"32\";\n",
        "+//        int batchSize = 16;\n",
        "+//        int epochs = 1;\n",
        "+//        int iterations = 2;\n",
        "+//        String trainDataset =  \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/main/native/dataset/0.tsv\";\n",
        "+//        String testDataset =  \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/main/native/dataset/0.tsv\";\n",
        "+//        EarlyStopMod earlyStopMod = EarlyStopMod.NotEarlyStop;\n",
        "+//        String task = \"train\";\n",
        "+//        boolean ifInteract = false;\n",
        "+        String vocabFile =  \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/main/native/dataset/vocab.txt\";\n",
        "+\n",
        "         // todo test\n",
        "         System.out.println(\"[args] url: \" + url);\n",
        "         System.out.println(\"[args] flName: \" + flName);\n",
        "@@ -191,14 +245,21 @@ public class AsyncFLJob {\n",
        "         System.out.println(\"[args] task: \" + task);\n",
        "         System.out.println(\"[args] ifInteract: \" + ifInteract);\n",
        "         AsyncFLJob asyncFLJob = new AsyncFLJob();\n",
        "+\n",
        "         if (task.equals(\"train\")) {\n",
        "-            asyncFLJob.asyncFLJobRun(url, flName, modelPath, flID, batchSize, epochs, iterations, trainDataset, testDataset, earlyStopMod, ifInteract);\n",
        "+//            asyncFLJob.asyncFLJobRun(url, flName, modelPath, flID, batchSize, epochs, iterations, trainDataset, testDataset, earlyStopMod, ifInteract);\n",
        "+            asyncFLJob.modeTrainFromBuffer(trainDataset,vocabFile,modelPath,batchSize,epochs,EarlyStopMod.NotEarlyStop,1);\n",
        "         } else if (task.equals(\"inference\")) {\n",
        "             asyncFLJob.modelInference(trainDataset, modelPath);\n",
        "         } else {\n",
        "-            String[] vocal = {\"hello1\", \"hello2\"};\n",
        "-            ByteBuffer modelPathBuf = asyncFLJob.loadModelFile(modelPath);\n",
        "-            asyncFLJob.modelInferenceSingleDataFromBuffer(\"hello\", modelPathBuf, vocal, 1);\n",
        "+            Path path = Paths.get(vocabFile);\n",
        "+            List<String> allLines = Files.readAllLines(path, StandardCharsets.UTF_8);\n",
        "+            String[] vocal = new String[allLines.size()];\n",
        "+            for(int i=0;i<allLines.size();i++) {\n",
        "+                vocal[i] = allLines.get(i);\n",
        "+            }\n",
        "+            ByteBuffer modelPathBuf = loadModelFile(modelPath);\n",
        "+            asyncFLJob.modelInferenceSingleDataFromBuffer(\"\", modelPathBuf, vocal, 1);\n",
        "         }\n",
        "       \n",
        " \n",
        "diff --git a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "index 759dd05..73edd36 100644\n",
        "--- a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "+++ b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "@@ -41,10 +41,18 @@ public class LiteTrain {\n",
        "         return NativeTrain.setInput(fileSet);\n",
        "     }\n",
        " \n",
        "+    public int  setAlbertInput(String trainFile,String[] vocabArray) {\n",
        "+        return NativeTrain.setBertInputFromArr(trainFile,vocabArray);\n",
        "+    }\n",
        "+\n",
        "     public int train(int batchSize,int epoches, int earlyStopMod) {\n",
        "         return NativeTrain.train(sessionPtr, batchSize,epoches, earlyStopMod);\n",
        "     }\n",
        " \n",
        "+    public int trainAlbert(int batchSize, int epoches, int earlyStopMod) {\n",
        "+        return NativeTrain.trainFromBuffer(sessionPtr, batchSize,epoches, earlyStopMod);\n",
        "+    }\n",
        "+\n",
        "     public float infer() {\n",
        "         return NativeTrain.infer(sessionPtr);\n",
        "     }\n",
        "diff --git a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/NativeTrain.java b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/NativeTrain.java\n",
        "index 725aebd..f4bde20 100644\n",
        "--- a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/NativeTrain.java\n",
        "+++ b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/NativeTrain.java\n",
        "@@ -30,6 +30,8 @@ public  class NativeTrain {\n",
        " \n",
        "     static native int setInput(String fileSet);\n",
        " \n",
        "+    static native int setBertInputFromArr(String trainFile,String[] vocabArray);\n",
        "+\n",
        "     static native long createSessionFromBuffer(ByteBuffer modelBuffer,int numThread);\n",
        " \n",
        "     static native long createSession(String modelPath,long msConfigPtr);\n",
        "@@ -44,6 +46,8 @@ public  class NativeTrain {\n",
        " \n",
        "     static native int train(long sessionPtr,int batch_size,int epoches,int earlyStopMod);\n",
        " \n",
        "+    static native int trainFromBuffer(long sessionPtr,int batch_size,int epoches,int earlyStopMod);\n",
        "+\n",
        "    static native int[] getSeralizeFeaturesMap(long sessionPtr, FlatBufferBuilder builder);\n",
        " \n",
        "    static native Map<String,float[]> getFeaturesMap(long sessionPtr);\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/bert_train.cpp b/mindspore/lite/flclient/src/main/native/bert_train.cpp\n",
        "index 1996a11..0be3b3b 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/bert_train.cpp\n",
        "+++ b/mindspore/lite/flclient/src/main/native/bert_train.cpp\n",
        "@@ -14,15 +14,16 @@\n",
        "  * limitations under the License.\n",
        "  */\n",
        " #include \"bert_train.h\"\n",
        "-#include <climits>\n",
        "+#include \"util.h\"\n",
        "+#include \"dataset/labels.h\"\n",
        " #include <cstring>\n",
        " #include <fstream>\n",
        " #include <iostream>\n",
        "-#include \"dataset/CustomizedTokenizer.h\"\n",
        " #include \"include/context.h\"\n",
        " #include \"include/errorcode.h\"\n",
        " #include \"src/common/log_adapter.h\"\n",
        "-#include \"util.h\"\n",
        "+#include \"dataset/CustomizedTokenizer.h\"\n",
        "+#include <climits>\n",
        " \n",
        " static int *lable_ids = 0;\n",
        " static int *input_ids = 0;\n",
        "@@ -60,21 +61,21 @@ std::vector<int> FillBertInput(mindspore::session::TrainSession *train_session,\n",
        "       labels_vec[i] = lable_ids[batch_idx * batch_size + i];\n",
        "     }\n",
        "   }\n",
        "-  //  std::ofstream ofs(\"model_input_mask.bin\", std::ios::binary | std::ios::out);\n",
        "-  //  ofs.write((const char *)model_input_mask, sizeof(int) * inputs[0]->ElementsNum());\n",
        "-  //  ofs.close();\n",
        "-  //\n",
        "-  //  std::ofstream ofs1(\"model_input_ids.bin\", std::ios::binary | std::ios::out);\n",
        "-  //  ofs1.write((const char *)model_input_ids, sizeof(int) * inputs[1]->ElementsNum());\n",
        "-  //  ofs1.close();\n",
        "-  //\n",
        "-  //  std::ofstream ofs3(\"model_label_ids.bin\", std::ios::binary | std::ios::out);\n",
        "-  //  ofs3.write((const char *)model_label_ids, sizeof(int) * inputs[3]->ElementsNum());\n",
        "-  //  ofs3.close();\n",
        "-  //\n",
        "-  //  std::ofstream ofs2(\"model_token_id.bin\", std::ios::binary | std::ios::out);\n",
        "-  //  ofs2.write((const char *)model_token_id, sizeof(int) * inputs[2]->ElementsNum());\n",
        "-  //  ofs2.close();\n",
        "+    std::ofstream ofs(\"model_input_mask.bin\", std::ios::binary | std::ios::out);\n",
        "+    ofs.write((const char *)model_input_mask, sizeof(int) * inputs[0]->ElementsNum());\n",
        "+    ofs.close();\n",
        "+\n",
        "+    std::ofstream ofs1(\"model_input_ids.bin\", std::ios::binary | std::ios::out);\n",
        "+    ofs1.write((const char *)model_input_ids, sizeof(int) * inputs[1]->ElementsNum());\n",
        "+    ofs1.close();\n",
        "+\n",
        "+    std::ofstream ofs3(\"model_label_ids.bin\", std::ios::binary | std::ios::out);\n",
        "+    ofs3.write((const char *)model_label_ids, sizeof(int) * inputs[3]->ElementsNum());\n",
        "+    ofs3.close();\n",
        "+\n",
        "+    std::ofstream ofs2(\"model_token_id.bin\", std::ios::binary | std::ios::out);\n",
        "+    ofs2.write((const char *)model_token_id, sizeof(int) * inputs[2]->ElementsNum());\n",
        "+    ofs2.close();\n",
        "   return labels_vec;\n",
        " }\n",
        " \n",
        "@@ -101,23 +102,23 @@ int InferFromVocabFile(TrainSession *session, const std::string &input_str, cons\n",
        "   int s_token_type_ids[MAX_SEQ_LENGTH];\n",
        "   int len = 0;\n",
        "   customized_tokenizer.tokenize(input_str, s_input_ids, s_attention_mask, s_token_type_ids, len);\n",
        "+  session->Eval();\n",
        "   // not support one input,need pad to one batch\n",
        "   auto ms_inputs = session->GetInputs();\n",
        "   auto model_input_mask = reinterpret_cast<int *>(ms_inputs.at(0)->MutableData());\n",
        "   auto model_input_ids = reinterpret_cast<int *>(ms_inputs.at(1)->MutableData());\n",
        "   auto model_token_id = reinterpret_cast<int *>(ms_inputs.at(2)->MutableData());\n",
        "   auto model_label_ids = reinterpret_cast<int *>(ms_inputs.at(3)->MutableData());\n",
        "-  for (int i = 0; i < BATCH_SIZE; i++) {\n",
        "-    std::memcpy(model_input_mask + i * MAX_SEQ_LENGTH, s_attention_mask, MAX_SEQ_LENGTH * sizeof(int));\n",
        "-    std::memcpy(model_input_ids + i * MAX_SEQ_LENGTH, s_input_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "-    std::memcpy(model_token_id + i * MAX_SEQ_LENGTH, s_token_type_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+  for(int i=0;i<BATCH_SIZE;i++) {\n",
        "+  std::memcpy(model_input_mask+i*MAX_SEQ_LENGTH, s_attention_mask, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+  std::memcpy(model_input_ids+i*MAX_SEQ_LENGTH, s_input_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+  std::memcpy(model_token_id+i*MAX_SEQ_LENGTH, s_token_type_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "   }\n",
        "   std::fill(model_label_ids, model_label_ids + ms_inputs.at(3)->ElementsNum(), 0.f);\n",
        " \n",
        "-  session->Eval();\n",
        "   session->RunGraph();\n",
        "   auto inputs = session->GetInputs();\n",
        "-  auto outputsv = SearchOutputsForSize(session, BATCH_SIZE * LABEL_CLASS);\n",
        "+  auto outputsv = SearchOutputsForSize(session,  BATCH_SIZE* LABEL_CLASS);\n",
        "   std::cout << \"ouput tensor name:\" << outputsv->tensor_name() << std::endl;\n",
        "   auto scores = reinterpret_cast<float *>(outputsv->MutableData());\n",
        " \n",
        "@@ -132,32 +133,35 @@ int InferFromVocabFile(TrainSession *session, const std::string &input_str, cons\n",
        "   return max_idx;\n",
        " }\n",
        " \n",
        "-int InferFromVocabArr(TrainSession *session, const std::string &input_str, std::string vocab_array[]) {\n",
        "+int InferFromVocabArr(TrainSession *session, const std::string &input_str, std::string vocab_array[],int vocab_size) {\n",
        "+  if(input_str.empty()) {\n",
        "+    return -1;\n",
        "+  }\n",
        "   CustomizedTokenizer customized_tokenizer;\n",
        "   bool do_lower_case = true;\n",
        "-  customized_tokenizer.initFromVocab(vocab_array, do_lower_case);\n",
        "+  customized_tokenizer.initFromVocab(vocab_array,vocab_size, do_lower_case);\n",
        "   int s_input_ids[MAX_SEQ_LENGTH];\n",
        "   int s_attention_mask[MAX_SEQ_LENGTH];\n",
        "   int s_token_type_ids[MAX_SEQ_LENGTH];\n",
        "   int len = 0;\n",
        "   customized_tokenizer.tokenize(input_str, s_input_ids, s_attention_mask, s_token_type_ids, len);\n",
        "+  session->Eval();\n",
        "   // not support one input,need pad to one batch\n",
        "   auto ms_inputs = session->GetInputs();\n",
        "   auto model_input_mask = reinterpret_cast<int *>(ms_inputs.at(0)->MutableData());\n",
        "   auto model_input_ids = reinterpret_cast<int *>(ms_inputs.at(1)->MutableData());\n",
        "   auto model_token_id = reinterpret_cast<int *>(ms_inputs.at(2)->MutableData());\n",
        "   auto model_label_ids = reinterpret_cast<int *>(ms_inputs.at(3)->MutableData());\n",
        "-  for (int i = 0; i < BATCH_SIZE; i++) {\n",
        "-    std::memcpy(model_input_mask + i * MAX_SEQ_LENGTH, s_attention_mask, MAX_SEQ_LENGTH * sizeof(int));\n",
        "-    std::memcpy(model_input_ids + i * MAX_SEQ_LENGTH, s_input_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "-    std::memcpy(model_token_id + i * MAX_SEQ_LENGTH, s_token_type_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+  for(int i=0;i<BATCH_SIZE;i++) {\n",
        "+    std::memcpy(model_input_mask+i*MAX_SEQ_LENGTH, s_attention_mask, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+    std::memcpy(model_input_ids+i*MAX_SEQ_LENGTH, s_input_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+    std::memcpy(model_token_id+i*MAX_SEQ_LENGTH, s_token_type_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "   }\n",
        "   std::fill(model_label_ids, model_label_ids + ms_inputs.at(3)->ElementsNum(), 0.f);\n",
        " \n",
        "-  session->Eval();\n",
        "   session->RunGraph();\n",
        "   auto inputs = session->GetInputs();\n",
        "-  auto outputsv = SearchOutputsForSize(session, BATCH_SIZE * LABEL_CLASS);\n",
        "+  auto outputsv = SearchOutputsForSize(session,  BATCH_SIZE* LABEL_CLASS);\n",
        "   std::cout << \"ouput tensor name:\" << outputsv->tensor_name() << std::endl;\n",
        "   auto scores = reinterpret_cast<float *>(outputsv->MutableData());\n",
        " \n",
        "@@ -172,6 +176,7 @@ int InferFromVocabArr(TrainSession *session, const std::string &input_str, std::\n",
        "   return max_idx;\n",
        " }\n",
        " \n",
        "+\n",
        " // net training function\n",
        " int TrainBert(TrainSession *session, const std::string &ms_file, int batch_size, int epoches) {\n",
        "   if (epoches <= 0) {\n",
        "@@ -190,7 +195,7 @@ int TrainBert(TrainSession *session, const std::string &ms_file, int batch_size,\n",
        "       session->RunGraph(nullptr, nullptr);\n",
        "       auto loss = GetLoss(session);\n",
        "       sum_loss_per_epoch += loss;\n",
        "-      //      std::cout << \"batch:\" << k << \",loss:\" << loss << std::endl;\n",
        "+            std::cout << \"batch:\" << k << \",loss:\" << loss << std::endl;\n",
        "       sum_acc_per_epoch += CalculateAccuracy(session, lables, LABEL_CLASS);\n",
        "     }\n",
        "     std::cout << \"epoch \"\n",
        "@@ -202,6 +207,36 @@ int TrainBert(TrainSession *session, const std::string &ms_file, int batch_size,\n",
        "   return mindspore::lite::RET_OK;\n",
        " }\n",
        " \n",
        "+// net training function\n",
        "+int TrainBertFromBuffer(TrainSession *session, int batch_size, int epoches,char* model_buffer,size_t* model_len) {\n",
        "+  if (epoches <= 0) {\n",
        "+    std::cout << \"error iterations or epoch!, epoch:\"\n",
        "+              << \", iterations\" << epoches;\n",
        "+    return mindspore::lite::RET_ERROR;\n",
        "+  }\n",
        "+  batch_num = total_size / batch_size;\n",
        "+  std::cout << \"total epoches :\" << epoches << \",batch_num:\" << batch_num << std::endl;\n",
        "+  for (int j = 0; j < epoches; ++j) {\n",
        "+    float sum_loss_per_epoch = 0.0f;\n",
        "+    float sum_acc_per_epoch = 0.0f;\n",
        "+    for (int k = 0; k < batch_num; ++k) {\n",
        "+      session->Train();\n",
        "+      auto lables = FillBertInput(session, k);\n",
        "+      session->RunGraph(nullptr, nullptr);\n",
        "+      auto loss = GetLoss(session);\n",
        "+      sum_loss_per_epoch += loss;\n",
        "+//            std::cout << \"batch:\" << k << \",loss:\" << loss << std::endl;\n",
        "+      sum_acc_per_epoch += CalculateAccuracy(session, lables, LABEL_CLASS);\n",
        "+    }\n",
        "+    std::cout << \"epoch \"\n",
        "+              << \"[\" << j << \"]\"\n",
        "+              << \",mean Loss \" << sum_loss_per_epoch / batch_num << \",train acc \" << sum_acc_per_epoch / batch_num\n",
        "+              << std::endl;\n",
        "+  }\n",
        "+  session->ExportToBuf(model_buffer,model_len);\n",
        "+  return mindspore::lite::RET_OK;\n",
        "+}\n",
        "+\n",
        " void ReadTxt(const std::string &file, std::vector<std::string> *train_data) {\n",
        "   std::fstream fin;\n",
        "   fin.open(file, std::ios::in);\n",
        "@@ -222,17 +257,79 @@ void ReadTxt(const std::string &file, std::vector<std::string> *train_data) {\n",
        " }\n",
        " \n",
        " // Set input tensors.\n",
        "-int SetBertInputs(const std::string &train_file, const std::string &vocab_file, const std::string &labels_file) {\n",
        "+int SetBertInputsFromArray(const std::string &train_file, std::string vocab_file[],int vocab_size) {\n",
        "+  if (train_file.empty()) {\n",
        "+    std::cout << \"files empty\";\n",
        "+    return -1;\n",
        "+  }\n",
        "+  std::vector<std::string> train_data;\n",
        "+  ReadTxt(train_file, &train_data);\n",
        "+  std::map<std::string, int> labels_map;\n",
        "+  for (int i = 0; i < LABEL_CLASS; i++) {\n",
        "+    labels_map[labels[i]] = i;\n",
        "+  }\n",
        "+  int train_size = train_data.size();\n",
        "+  int total_batch_num = train_size / BATCH_SIZE;\n",
        "+  int remain_size = train_size % BATCH_SIZE;\n",
        "+  int pad_size = BATCH_SIZE - remain_size;\n",
        "+  if (total_batch_num == 0) {\n",
        "+    std::cout << \"train data size less than one batch,need random padding\" << std::endl;\n",
        "+  }\n",
        "+  total_size = train_size + pad_size;\n",
        "+  input_ids = new (std::nothrow) int[total_size * MAX_SEQ_LENGTH];\n",
        "+  input_mask = new (std::nothrow) int[total_size * MAX_SEQ_LENGTH];\n",
        "+  token_type_ids = new (std::nothrow) int[total_size * MAX_SEQ_LENGTH];\n",
        "+  lable_ids = new (std::nothrow) int[total_size];\n",
        "+\n",
        "+  CustomizedTokenizer customized_tokenizer;\n",
        "+  bool do_lower_case = true;\n",
        "+  customized_tokenizer.initFromVocab(vocab_file, vocab_size,do_lower_case);\n",
        "+\n",
        "+  int s_input_ids[MAX_SEQ_LENGTH];\n",
        "+  int s_attention_mask[MAX_SEQ_LENGTH];\n",
        "+  int s_token_type_ids[MAX_SEQ_LENGTH];\n",
        "+  int seq_length;\n",
        "+\n",
        "+  for (int i = 0; i < total_size; i++) {\n",
        "+    std::vector<std::string> dataset_tuple(2);\n",
        "+    dataset_tuple.clear();\n",
        "+    int idx = i;\n",
        "+    // less than one batch would  pad random\n",
        "+    if (i >= train_size) {\n",
        "+      idx = rand_r(&seed_) % train_size;\n",
        "+    }\n",
        "+    size_t pos = train_data[idx].find(\"\\t\", 0);\n",
        "+    if (pos != std::string::npos) {\n",
        "+      dataset_tuple.push_back(train_data[idx].substr(0, pos));\n",
        "+      dataset_tuple.push_back(train_data[idx].substr(pos + 1, train_data[idx].size()));\n",
        "+    }\n",
        "+    if (dataset_tuple.size() != 2) {\n",
        "+      std::cout << \"train data error,must 2 word.idx::\" << idx << std::endl;\n",
        "+      return -1;\n",
        "+    }\n",
        "+    customized_tokenizer.tokenize(dataset_tuple[1], s_input_ids, s_attention_mask, s_token_type_ids, seq_length);\n",
        "+    memcpy(input_ids + i * MAX_SEQ_LENGTH, s_input_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+    memcpy(input_mask + i * MAX_SEQ_LENGTH, s_attention_mask, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+    memcpy(token_type_ids + i * MAX_SEQ_LENGTH, s_token_type_ids, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+    std::string key = dataset_tuple[0];\n",
        "+    lable_ids[i] = labels_map[key];\n",
        "+  }\n",
        "+  std::cout << \"total train size :\" << total_size << std::endl << std::endl;\n",
        "+  return total_size;\n",
        "+}\n",
        "+\n",
        "+// Set input tensors.\n",
        "+int SetBertInputs(const std::string &train_file, const std::string &vocab_file) {\n",
        "   if (train_file.empty()) {\n",
        "     std::cout << \"files empty\";\n",
        "     return -1;\n",
        "   }\n",
        "   std::vector<std::string> train_data;\n",
        "   ReadTxt(train_file, &train_data);\n",
        "-  std::vector<std::string> labels;\n",
        "-  ReadTxt(labels_file, &labels);\n",
        "+//  std::vector<std::string> labels;\n",
        "+//  ReadTxt(labels_file, &labels);\n",
        "   std::map<std::string, int> labels_map;\n",
        "-  for (int i = 0; i < labels.size(); i++) {\n",
        "+  for (int i = 0; i < LABEL_CLASS; i++) {\n",
        "     labels_map[labels[i]] = i;\n",
        "   }\n",
        "   int train_size = train_data.size();\n",
        "@@ -281,7 +378,7 @@ int SetBertInputs(const std::string &train_file, const std::string &vocab_file,\n",
        "     std::string key = dataset_tuple[0];\n",
        "     lable_ids[i] = labels_map[key];\n",
        "   }\n",
        "-  std::cout << \"total train size :\" << std::endl << std::endl;\n",
        "+  std::cout << \"total train size :\" << total_size << std::endl << std::endl;\n",
        "   return total_size;\n",
        " }\n",
        " \n",
        "diff --git a/mindspore/lite/flclient/src/main/native/bert_train.h b/mindspore/lite/flclient/src/main/native/bert_train.h\n",
        "index 240e6e9..edd57db 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/bert_train.h\n",
        "+++ b/mindspore/lite/flclient/src/main/native/bert_train.h\n",
        "@@ -20,11 +20,14 @@\n",
        " #include \"include/train/train_session.h\"\n",
        " #include <string>\n",
        " using mindspore::session::TrainSession;\n",
        "-int SetBertInputs(const std::string &train_file,const std::string &vocab_file,const std::string &labels_file);\n",
        "+int SetBertInputs(const std::string &train_file, const std::string &vocab_file);\n",
        "+int SetBertInputsFromArray(const std::string &train_file, std::string vocab_file[],int vocab_size);\n",
        " void FreeBertInput();\n",
        " std::vector<int> GetBertInferRes(TrainSession *session);\n",
        "-int TrainBert( TrainSession*session,const std::string &ms_file,int batch_size ,int epoches);\n",
        "+int InferFromVocabArr(TrainSession *session, const std::string &input_str, std::string vocab_array[],int vocab_size);\n",
        "+int TrainBert(TrainSession *session, const std::string &ms_file, int batch_size, int epoches);\n",
        "+int TrainBertFromBuffer(TrainSession *session, int batch_size, int epoches,\n",
        "+                        char *model_buffer, size_t *model_len);\n",
        " float InferBert(TrainSession *session);\n",
        " int InferFromVocabFile(TrainSession *session, const std::string &input_str, const std::string &vocab_file);\n",
        "-int InferFromVocabArr(TrainSession *session, const std::string &input_str, std::string vocab_array[]);\n",
        " #endif  // MSLITE_FL_BERT_TRAIN_H\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/dataset/CustomizedTokenizer.cc b/mindspore/lite/flclient/src/main/native/dataset/CustomizedTokenizer.cc\n",
        "index 910f4fd..4d2c2c5 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/dataset/CustomizedTokenizer.cc\n",
        "+++ b/mindspore/lite/flclient/src/main/native/dataset/CustomizedTokenizer.cc\n",
        "@@ -5,6 +5,7 @@\n",
        " \n",
        " CustomizedTokenizer::CustomizedTokenizer() = default;\n",
        " \n",
        "+\n",
        " CustomizedTokenizer::~CustomizedTokenizer() {\n",
        "   _vocab.clear();\n",
        " }\n",
        "@@ -14,6 +15,11 @@ void CustomizedTokenizer::init(const string &vocab_file, bool do_lower_case) {\n",
        "   _load_vocab(vocab_file);\n",
        " }\n",
        " \n",
        "+void CustomizedTokenizer::initFromVocab(string vocab_array[], int vocab_size,bool do_lower_case) {\n",
        "+  _do_lower_case = do_lower_case;\n",
        "+  _load_vocabFromVocab(vocab_array,vocab_size);\n",
        "+}\n",
        "+\n",
        " void CustomizedTokenizer::tokenize(const string &text, string output_tokens[MAX_SEQ_LENGTH], int &seq_length) {\n",
        " //  clock_t startTime;\n",
        " //  double time_cost = 0.0;\n",
        "@@ -254,6 +260,12 @@ void CustomizedTokenizer::_clean_text() {\n",
        "   }\n",
        " }\n",
        " \n",
        "+void CustomizedTokenizer::_load_vocabFromVocab(string vocab_file[],int vocab_size) {\n",
        "+  for(int i=0;i<vocab_size;i++) {\n",
        "+    _vocab[vocab_file[i]] = i;\n",
        "+  }\n",
        "+}\n",
        "+\n",
        " void CustomizedTokenizer::_load_vocab(const string &vocab_file) {\n",
        "   int index = 0;\n",
        "   fstream fin;\n",
        "@@ -315,17 +327,6 @@ void CustomizedTokenizer::_fixed_matching(int &pos, string &token) {\n",
        "   pos++;\n",
        " }\n",
        " \n",
        "-void CustomizedTokenizer::initFromVocab(string vocab_array[], bool do_lower_case) {\n",
        "-  _do_lower_case = do_lower_case;\n",
        "-  _load_vocabFromVocab(vocab_array);\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::_load_vocabFromVocab(string vocab_file[]) {\n",
        "-  for(int i=0;i<vocab_file->length();i++) {\n",
        "-    _vocab[vocab_file[i]] = i;\n",
        "-  }\n",
        "-}\n",
        "-\n",
        " void CustomizedTokenizer::_split_text() {\n",
        "   // Performs invalid character removal and whitespace cleanup on text.\n",
        "   _clean_text();\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/dataset/CustomizedTokenizer.h b/mindspore/lite/flclient/src/main/native/dataset/CustomizedTokenizer.h\n",
        "index 9566d08..f8ee67a 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/dataset/CustomizedTokenizer.h\n",
        "+++ b/mindspore/lite/flclient/src/main/native/dataset/CustomizedTokenizer.h\n",
        "@@ -23,10 +23,10 @@ class CustomizedTokenizer\n",
        "   ~CustomizedTokenizer();\n",
        " \n",
        "   void init(const std::string &vocab_file, bool do_lower_case);\n",
        "+  void initFromVocab(string vocab_array[], int vocab_size,bool do_lower_case);\n",
        "   void tokenize(const string &text, string output_tokens[MAX_SEQ_LENGTH], int &seq_length);\n",
        "   void tokenize(const string &text, int input_ids[MAX_SEQ_LENGTH],\n",
        "                 int attention_mask[MAX_SEQ_LENGTH], int token_type_ids[MAX_SEQ_LENGTH], int &seq_length);\n",
        "-                void initFromVocab(string vocab_array[], bool do_lower_case);\n",
        " \n",
        " //private:\n",
        "   string _text;\n",
        "@@ -42,8 +42,8 @@ class CustomizedTokenizer\n",
        "   void _split_text();\n",
        "   void _clean_text();\n",
        "   void _fixed_matching(int &pos, string &token);\n",
        "+  void _load_vocabFromVocab(string vocab_file[],int vocab_size);\n",
        "   void _load_vocab(const string &vocab_file);\n",
        "-  void _load_vocabFromVocab(string vocab_file[]);\n",
        " };\n",
        " \n",
        " \n",
        "diff --git a/mindspore/lite/flclient/src/main/native/lite_train_jni.cpp b/mindspore/lite/flclient/src/main/native/lite_train_jni.cpp\n",
        "index b74b40d..ce0f34e 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/lite_train_jni.cpp\n",
        "+++ b/mindspore/lite/flclient/src/main/native/lite_train_jni.cpp\n",
        "@@ -29,6 +29,7 @@ static jobject fbb;\n",
        " static jmethodID create_string_char;\n",
        " static jobject jmap;\n",
        " static jstring model_path;\n",
        "+static jobject jmodel_buffer;\n",
        " \n",
        " char *JstringToChar(JNIEnv *env, jstring jstr) {\n",
        "   char *rtn = nullptr;\n",
        "@@ -47,6 +48,30 @@ char *JstringToChar(JNIEnv *env, jstring jstr) {\n",
        "   return rtn;\n",
        " }\n",
        " \n",
        "+void CastJstringArrayToC(JNIEnv *env,jobjectArray vocab_array,std::string c_array[],int size) {\n",
        "+  for (int i = 0; i < size; i++) {\n",
        "+    jstring jstr = (jstring)env->GetObjectArrayElement(vocab_array, i);\n",
        "+    const jsize strLen = env->GetStringUTFLength(jstr);\n",
        "+    const char *charBuffer = env->GetStringUTFChars(jstr, 0);\n",
        "+    c_array[i] = std::string(charBuffer, strLen);\n",
        "+    env->ReleaseStringUTFChars(jstr, charBuffer);\n",
        "+    env->DeleteLocalRef(jstr);\n",
        "+  }\n",
        "+}\n",
        "+\n",
        "+char *CreateLocalModelBuffer(JNIEnv *env, jobject modelBuffer) {\n",
        "+  jbyte *modelAddr = static_cast<jbyte *>(env->GetDirectBufferAddress(modelBuffer));\n",
        "+  int modelLen = static_cast<int>(env->GetDirectBufferCapacity(modelBuffer));\n",
        "+  char *buffer(new char[modelLen]);\n",
        "+  memcpy(buffer, modelAddr, modelLen);\n",
        "+  return buffer;\n",
        "+}\n",
        "+\n",
        "+void UpdateModelBuffer(JNIEnv *env,char* updated_buffer,int size) {\n",
        "+  jbyte *modelAddr = static_cast<jbyte *>(env->GetDirectBufferAddress(jmodel_buffer));\n",
        "+  memcpy(modelAddr, updated_buffer ,size);\n",
        "+}\n",
        "+\n",
        " extern \"C\" jint CreateFeatureMap(JNIEnv *env, const char *name, float *data, size_t size) {\n",
        "   jstring name1 = env->NewStringUTF(name);\n",
        "   jint name_offset = env->CallIntMethod(fbb, create_string_char, name1);\n",
        "@@ -66,17 +91,34 @@ extern \"C\" jint CreateFeatureMap(JNIEnv *env, const char *name, float *data, siz\n",
        " }\n",
        " \n",
        " extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_train(JNIEnv *env, jobject thiz,\n",
        "-                                                                             jlong session_ptr,\n",
        "-                                                                             jint batch_size, jint epoches,\n",
        "-                                                                             jint early_stop_type) {\n",
        "+                                                                             jlong session_ptr, jint batch_size,\n",
        "+                                                                             jint epoches, jint early_stop_type) {\n",
        "   std::string model_name = JstringToChar(env, model_path);\n",
        "-  if(model_name.find(\"lenet\") != std::string::npos){\n",
        "+  if (model_name.find(\"lenet\") != std::string::npos) {\n",
        "     return TrainLenet(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr), JstringToChar(env, model_path),\n",
        "                       batch_size, epoches);\n",
        "+  } else {\n",
        "+    return TrainBert(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr), JstringToChar(env, model_path),\n",
        "+                     batch_size, epoches);\n",
        "   }\n",
        "-  return TrainBert(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr), JstringToChar(env, model_path),\n",
        "-                   batch_size, epoches);\n",
        "+}\n",
        "+\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_trainFromBuffer(JNIEnv *env, jobject thiz,\n",
        "+                                                                             jlong session_ptr, jint batch_size,\n",
        "+                                                                             jint epoches, jint early_stop_type) {\n",
        " \n",
        "+  int model_len = static_cast<int>(env->GetDirectBufferCapacity(jmodel_buffer));\n",
        "+  std::cout<< \"model len:\"<< model_len<<std::endl;\n",
        "+  char* temp_buffer = new char[model_len];\n",
        "+  size_t model_size = model_len;\n",
        "+  auto status = TrainBertFromBuffer(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr),batch_size, epoches,temp_buffer,&model_size);\n",
        "+  if(model_size != model_len) {\n",
        "+    std::cout<< \"java local bytebuffer size not equal model size\"<<std::endl;\n",
        "+    return -1;\n",
        "+  }\n",
        "+  UpdateModelBuffer(env,temp_buffer,model_size);\n",
        "+  delete[] temp_buffer;\n",
        "+  return status;\n",
        " }\n",
        " \n",
        " extern \"C\" jlong JNICALL Java_com_huawei_flclient_NativeTrain_createSession(JNIEnv *env, jclass, jstring ms_file,\n",
        "@@ -84,32 +126,27 @@ extern \"C\" jlong JNICALL Java_com_huawei_flclient_NativeTrain_createSession(JNIE\n",
        "   model_path = (jstring)env->NewGlobalRef(ms_file);\n",
        "   return reinterpret_cast<jlong>(CreateSession(JstringToChar(env, ms_file)));\n",
        " }\n",
        "-char *CreateLocalModelBuffer(JNIEnv *env, jobject modelBuffer) {\n",
        "-  jbyte *modelAddr = static_cast<jbyte *>(env->GetDirectBufferAddress(modelBuffer));\n",
        "-  int modelLen = static_cast<int>(env->GetDirectBufferCapacity(modelBuffer));\n",
        "-  char *buffer(new char[modelLen]);\n",
        "-  memcpy(buffer, modelAddr, modelLen);\n",
        "-  return buffer;\n",
        "-}\n",
        " \n",
        "-extern \"C\" jlong JNICALL Java_com_huawei_flclient_NativeTrain_createSessionFromBuffer(JNIEnv *env, jclass,jobject model_buffer,jint num_thread) {\n",
        " \n",
        "+extern \"C\" jlong JNICALL Java_com_huawei_flclient_NativeTrain_createSessionFromBuffer(JNIEnv *env, jclass,\n",
        "+                                                                                      jobject model_buffer,\n",
        "+                                                                                      jint num_thread) {\n",
        "   if (nullptr == model_buffer) {\n",
        "-//    MS_PRINT(\"error, buffer is nullptr!\");\n",
        "+    //    MS_PRINT(\"error, buffer is nullptr!\");\n",
        "     return (jlong) nullptr;\n",
        "   }\n",
        "   jlong bufferLen = env->GetDirectBufferCapacity(model_buffer);\n",
        "   if (0 == bufferLen) {\n",
        "-//    MS_PRINT(\"error, bufferLen is 0!\");\n",
        "+    //    MS_PRINT(\"error, bufferLen is 0!\");\n",
        "     return (jlong) nullptr;\n",
        "   }\n",
        "-\n",
        "+  jmodel_buffer = env->NewGlobalRef(model_buffer);\n",
        "   char *modelBuffer = CreateLocalModelBuffer(env, model_buffer);\n",
        "   if (modelBuffer == nullptr) {\n",
        "-//    MS_PRINT(\"modelBuffer create failed!\");\n",
        "+    //    MS_PRINT(\"modelBuffer create failed!\");\n",
        "     return (jlong) nullptr;\n",
        "   }\n",
        "-  return reinterpret_cast<jlong>(CreateSession(modelBuffer,bufferLen));\n",
        "+  return reinterpret_cast<jlong>(CreateSession(modelBuffer, bufferLen));\n",
        " }\n",
        " \n",
        " extern \"C\" JNIEXPORT jobject JNICALL Java_com_huawei_flclient_NativeTrain_getFeaturesMap(JNIEnv *env, jclass,\n",
        "@@ -251,11 +288,12 @@ extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_updateFea\n",
        "     param->type = mindspore::kNumberTypeFloat32;\n",
        "     MS_LOG(INFO) << \"get feature:\" << param->name << \",elenums:\" << param->elenums;\n",
        "   }\n",
        "-  return UpdateFeatures(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr), JstringToChar(env, model_path),\n",
        "-                        features_param, size);\n",
        "+  return UpdateFeatures(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr),\n",
        "+                        JstringToChar(env, model_path), features_param, size);\n",
        " }\n",
        " \n",
        "-extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_setInput(JNIEnv *env, jobject, jstring files) {\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_setInput(JNIEnv *env, jobject,\n",
        "+                                                                                     jstring files) {\n",
        "   std::string input_files = JstringToChar(env, files);\n",
        "   std::string pattern = \",\";\n",
        "   std::string strs = input_files + pattern;\n",
        "@@ -267,59 +305,73 @@ extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_setInput(\n",
        "     strs = strs.substr(pos + 1, strs.size());\n",
        "     pos = strs.find(pattern);\n",
        "   }\n",
        "-  if (res.size() == 2) {\n",
        "+  if (res[0].find(\"bin\") != std::string::npos) {\n",
        "     return SetLenetInputs(res[0], res[1]);\n",
        "-  } else if (res.size() == 3) {\n",
        "-    return SetBertInputs(res[0], res[1], res[2]);\n",
        "+  } else {\n",
        "+    return SetBertInputs(res[0], res[1]);\n",
        "   }\n",
        "-  std::cout << \"input files error\" << std::endl;\n",
        "-  return -1;\n",
        " }\n",
        " \n",
        "-extern \"C\" JNIEXPORT jfloat JNICALL Java_com_huawei_flclient_NativeTrain_infer(JNIEnv *env, jclass, jlong session_ptr) {\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_setBertInputFromArr(JNIEnv *env, jobject,\n",
        "+                                                                                           jstring train_file,\n",
        "+                                                                                           jobjectArray vocab_array) {\n",
        "+  jsize size = env->GetArrayLength(vocab_array);\n",
        "+  std::string c_vocab_array[size];\n",
        "+  CastJstringArrayToC(env,vocab_array,c_vocab_array,size);\n",
        "+  return SetBertInputsFromArray(JstringToChar(env, train_file), c_vocab_array,size);\n",
        "+}\n",
        " \n",
        "+extern \"C\" JNIEXPORT jfloat JNICALL Java_com_huawei_flclient_NativeTrain_infer(JNIEnv *env, jclass, jlong session_ptr) {\n",
        "   std::string model_name = JstringToChar(env, model_path);\n",
        "-  if(model_name.find(\"lenet\") != std::string::npos){\n",
        "+  if (model_name.find(\"lenet\") != std::string::npos) {\n",
        "     return InferLenet(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr));\n",
        "   }\n",
        "   return InferBert(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr));\n",
        " }\n",
        " \n",
        "-extern \"C\" JNIEXPORT jintArray JNICALL Java_com_huawei_flclient_NativeTrain_getInferLabels(JNIEnv *env, jclass, jlong session_ptr) {\n",
        "-\n",
        "+extern \"C\" JNIEXPORT jintArray JNICALL Java_com_huawei_flclient_NativeTrain_getInferLabels(JNIEnv *env, jclass,\n",
        "+                                                                                           jlong session_ptr) {\n",
        "   std::string model_name = JstringToChar(env, model_path);\n",
        "   std::vector<int> infer_result;\n",
        "-  if(model_name.find(\"lenet\") != std::string::npos){\n",
        "-   infer_result = GetLenetInferRes(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr));\n",
        "+  if (model_name.find(\"lenet\") != std::string::npos) {\n",
        "+    infer_result = GetLenetInferRes(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr));\n",
        "   } else {\n",
        "     infer_result = GetBertInferRes(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr));\n",
        "   }\n",
        "   jintArray jArray = env->NewIntArray(infer_result.size());\n",
        "   jint *jnum = new jint[infer_result.size()];\n",
        "-  for(int i=0;i<infer_result.size();i++) {\n",
        "-    *(jnum+i) = infer_result[i];\n",
        "+  for (int i = 0; i < infer_result.size(); i++) {\n",
        "+    *(jnum + i) = infer_result[i];\n",
        "   }\n",
        "   env->SetIntArrayRegion(jArray, 0, infer_result.size(), jnum);\n",
        "   return jArray;\n",
        " }\n",
        " \n",
        "-extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_getInferLabel(JNIEnv *env, jclass, jlong session_ptr,jstring input_str ,jstring vocab_file) {\n",
        "-  return InferFromVocabFile(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr),JstringToChar(env, input_str),JstringToChar(env, vocab_file));\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_getInferLabel(JNIEnv *env, jclass,\n",
        "+                                                                                     jlong session_ptr,\n",
        "+                                                                                     jstring input_str,\n",
        "+                                                                                     jstring vocab_file) {\n",
        "+  return InferFromVocabFile(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr),\n",
        "+                            JstringToChar(env, input_str), JstringToChar(env, vocab_file));\n",
        " }\n",
        " \n",
        "-extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_getInferLabelFromVocab(JNIEnv *env, jclass, jlong session_ptr,jstring input_str ,jobjectArray vocab_array) {\n",
        " \n",
        "+\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_getInferLabelFromVocab(\n",
        "+  JNIEnv *env, jclass, jlong session_ptr, jstring input_str, jobjectArray vocab_array) {\n",
        "+  if(input_str == NULL) {\n",
        "+    std::cout<< \"input cannot empty\" << std::endl;\n",
        "+    return -1;\n",
        "+  }\n",
        "+  auto c_input = JstringToChar(env, input_str);\n",
        "+  if(c_input == nullptr) {\n",
        "+    std::cout<< \"input cannot empty\" << std::endl;\n",
        "+    return -1;\n",
        "+  }\n",
        "   jsize size = env->GetArrayLength(vocab_array);\n",
        "   std::string c_vocab_array[size];\n",
        "-  for(int i=0;i<size;i++) {\n",
        "-    jstring jstr = (jstring)env->GetObjectArrayElement(vocab_array, i);\n",
        "-    const jsize strLen = env->GetStringUTFLength(jstr);\n",
        "-    const char *charBuffer = env->GetStringUTFChars(jstr, 0);\n",
        "-    c_vocab_array[i] = std::string (charBuffer, strLen);\n",
        "-    env->ReleaseStringUTFChars(jstr, charBuffer);\n",
        "-    env->DeleteLocalRef(jstr);\n",
        "-  }\n",
        "-  return InferFromVocabArr(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr),JstringToChar(env, input_str),c_vocab_array);\n",
        "+  CastJstringArrayToC(env,vocab_array,c_vocab_array,size);\n",
        "+  return InferFromVocabArr(reinterpret_cast<mindspore::session::TrainSession *>(session_ptr),c_input, c_vocab_array,size);\n",
        " }\n",
        " \n",
        " extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_free(JNIEnv *env, jclass, jlong session_ptr) {\n",
        "@@ -328,9 +380,13 @@ extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_NativeTrain_free(JNIE\n",
        "   if (0 != session_ptr) {\n",
        "     delete (reinterpret_cast<mindspore::session::TrainSession *>(session_ptr));\n",
        "   }\n",
        "-  std::string model_name = JstringToChar(env, model_path);\n",
        "-  if(model_name.find(\"lenet\") != std::string::npos){\n",
        "-    FreeLenetInput();\n",
        "+  if (model_path != NULL) {\n",
        "+    std::string model_name = JstringToChar(env, model_path);\n",
        "+    if (model_name.find(\"lenet\") != std::string::npos) {\n",
        "+      FreeLenetInput();\n",
        "+    } else {\n",
        "+      FreeBertInput();\n",
        "+    }\n",
        "   } else {\n",
        "     FreeBertInput();\n",
        "   }\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/test_train.cc b/mindspore/lite/flclient/src/main/native/test_train.cc\n",
        "index 94f7584..89d9121 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/test_train.cc\n",
        "+++ b/mindspore/lite/flclient/src/main/native/test_train.cc\n",
        "@@ -6,49 +6,49 @@\n",
        " #include \"lenet_train.h\"\n",
        " #include \"util.h\"\n",
        " int main() {\n",
        "-  std::cout << \"----------begin train lenet-------\" << std::endl;\n",
        "-  std::string lenet_ms_file = \"/home/meng/zj10/fl/mindspore/mindspore/lite/lenet_train.mindir.ms\";\n",
        "-  std::string lenet_data_input =\n",
        "-    \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/test/resources/data_bin_new/f0049_32/\"\n",
        "-    \"f0049_32_bn_11_train_data.bin\";\n",
        "-  std::string lenet_label_input =\n",
        "-    \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/test/resources/data_bin_new/f0049_32/\"\n",
        "-    \"f0049_32_bn_11_train_label.bin\";\n",
        "-\n",
        "-  auto lenet_input_size = SetLenetInputs(lenet_data_input,lenet_label_input);\n",
        "-  std::cout<< \"total train size:\"<< lenet_input_size<<std::endl;\n",
        "-  auto session = CreateSession(lenet_ms_file);\n",
        "-  auto status = TrainLenet(session, lenet_ms_file, 32, 2);\n",
        "-  if (status != 0) {\n",
        "-    std::cout << \"train failed\" << std::endl;\n",
        "-  }\n",
        "-  mindspore::session::TrainFeatureParam **feature;\n",
        "-  int size = 0;\n",
        "-  status = GetFeatures(session, &feature, &size);\n",
        "-  if(status != 0) {\n",
        "-    std::cout<< \"get feature failed\"<<std::endl;\n",
        "-  }\n",
        "-  std::cout << \"get total features:\" << size << std::endl;\n",
        "-  for (int i = 0; i < size; i++) {\n",
        "-    std::cout << \"name:\" << feature[i]->name << std::endl;\n",
        "-  }\n",
        "-  std::string lenet_test_data = \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/test/resources/data_bin_new/f0049_32/f0049_32_bn_1_test_data.bin\";\n",
        "-  std::string lenet_test_label = \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/test/resources/data_bin_new/f0049_32/f0049_32_bn_1_test_label.bin\";\n",
        "-\n",
        "-  (void)SetLenetInputs(lenet_test_data,lenet_test_label);\n",
        "-  std::cout<< \"cal acc:\"<< InferLenet(session) << std::endl;\n",
        "-  auto infer_result = GetLenetInferRes(session);\n",
        "-  for(auto infer_label:infer_result) {\n",
        "-    std::cout<< \"infer_label:\"<< infer_label<<std::endl;\n",
        "-  }\n",
        "-  delete session;\n",
        "+//  std::cout << \"----------begin train lenet-------\" << std::endl;\n",
        "+//  std::string lenet_ms_file = \"/home/meng/zj10/fl/mindspore/mindspore/lite/lenet_train.mindir.ms\";\n",
        "+//  std::string lenet_data_input =\n",
        "+//    \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/test/resources/data_bin_new/f0049_32/\"\n",
        "+//    \"f0049_32_bn_11_train_data.bin\";\n",
        "+//  std::string lenet_label_input =\n",
        "+//    \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/test/resources/data_bin_new/f0049_32/\"\n",
        "+//    \"f0049_32_bn_11_train_label.bin\";\n",
        "+//\n",
        "+//  auto lenet_input_size = SetLenetInputs(lenet_data_input,lenet_label_input);\n",
        "+//  std::cout<< \"total train size:\"<< lenet_input_size<<std::endl;\n",
        "+//  auto session = CreateSession(lenet_ms_file);\n",
        "+//  auto status = TrainLenet(session, lenet_ms_file, 32, 2);\n",
        "+//  if (status != 0) {\n",
        "+//    std::cout << \"train failed\" << std::endl;\n",
        "+//  }\n",
        "+//  mindspore::session::TrainFeatureParam **feature;\n",
        "+//  int size = 0;\n",
        "+//  status = GetFeatures(session, &feature, &size);\n",
        "+//  if(status != 0) {\n",
        "+//    std::cout<< \"get feature failed\"<<std::endl;\n",
        "+//  }\n",
        "+//  std::cout << \"get total features:\" << size << std::endl;\n",
        "+//  for (int i = 0; i < size; i++) {\n",
        "+//    std::cout << \"name:\" << feature[i]->name << std::endl;\n",
        "+//  }\n",
        "+//  std::string lenet_test_data = \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/test/resources/data_bin_new/f0049_32/f0049_32_bn_1_test_data.bin\";\n",
        "+//  std::string lenet_test_label = \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/test/resources/data_bin_new/f0049_32/f0049_32_bn_1_test_label.bin\";\n",
        "+//\n",
        "+//  (void)SetLenetInputs(lenet_test_data,lenet_test_label);\n",
        "+//  std::cout<< \"cal acc:\"<< InferLenet(session) << std::endl;\n",
        "+//  auto infer_result = GetLenetInferRes(session);\n",
        "+//  for(auto infer_label:infer_result) {\n",
        "+//    std::cout<< \"infer_label:\"<< infer_label<<std::endl;\n",
        "+//  }\n",
        "+//  delete session;\n",
        " \n",
        " \n",
        "   std::cout << \"----------begin train bert-------\" << std::endl;\n",
        "   std::string vocab_file = \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/main/native/dataset/vocab.txt\";\n",
        "   std::string train_file = \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/main/native/dataset/0.tsv\";\n",
        "   std::string labels_file = \"/home/meng/zj10/fl/mindspore/mindspore/lite/flclient/src/main/native/dataset/label.tsv\";\n",
        "-  auto train_data_size = SetBertInputs(train_file, vocab_file, labels_file);\n",
        "+  auto train_data_size = SetBertInputs(train_file, vocab_file);\n",
        "   std::cout << \"total train data size:\" << train_data_size << std::endl;\n",
        "   if(train_data_size == -1) {\n",
        "     std::cout<< \"set bert inputs failed\" << std::endl;\n",
        "@@ -57,16 +57,18 @@ int main() {\n",
        "   std::string ms_file = \"/home/meng/zj10/fl/mindspore/mindspore/lite/albert.ms\";\n",
        "   int epoches = 2;\n",
        "   int batch_size = 16;\n",
        "-  session = CreateSession(ms_file);\n",
        "-  status = TrainBert(session, ms_file, 16, epoches);\n",
        "+  auto session = CreateSession(ms_file);\n",
        "+  auto status = TrainBert(session, ms_file, batch_size, epoches);\n",
        "   if (status != 0) {\n",
        "     std::cout << \"train failed\" << std::endl;\n",
        "   }\n",
        "-  size = 0;\n",
        "-  status = GetFeatures(session, &feature, &size);\n",
        "-  std::cout << \"get total features:\" << size << std::endl;\n",
        "-  for (int i = 0; i < size; i++) {\n",
        "-    std::cout << \"name:\" << feature[i]->name << std::endl;\n",
        "-  }\n",
        "+//  auto size = 0;\n",
        "+//  status = GetFeatures(session, &feature, &size);\n",
        "+//  std::cout << \"get total features:\" << size << std::endl;\n",
        "+//  for (int i = 0; i < size; i++) {\n",
        "+//    std::cout << \"name:\" << feature[i]->name << std::endl;\n",
        "+//  }\n",
        "+  std::string input = \"DIéŽºÑƒåŸ—MEæ¶“â‚¬é©å­˜æ§¸éšå‹­ç²æµ å‰æ®‘éå›¨æ½ŒéŸ?;\n",
        "+  std::cout<<\"infer result:\"<< InferFromVocabFile(session,input,vocab_file) <<std::endl;\n",
        "   delete session;\n",
        " }\n",
        "\\ No newline at end of file\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/util.cpp b/mindspore/lite/flclient/src/main/native/util.cpp\n",
        "index 462f965..8a2a2d0 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/util.cpp\n",
        "+++ b/mindspore/lite/flclient/src/main/native/util.cpp\n",
        "@@ -37,13 +37,15 @@ float GetLoss(mindspore::session::TrainSession *train_session) {\n",
        "   auto loss = reinterpret_cast<float *>(outputsv->MutableData());\n",
        "   return loss[0];\n",
        " }\n",
        "-mindspore::session::TrainSession *CreateSession(const std::string &ms_file) {\n",
        "+TrainSession *CreateSession(const std::string &ms_file) {\n",
        "   // create model file\n",
        "   mindspore::lite::Context context;\n",
        "   context.device_list_[0].device_info_.cpu_device_info_.cpu_bind_mode_ = mindspore::lite::NO_BIND;\n",
        "   context.thread_num_ = 1;\n",
        "   bool train_mode = false;\n",
        "-  return mindspore::session::TrainSession::CreateSession(ms_file, &context, train_mode);\n",
        "+  size_t size=0;\n",
        "+//  auto *model = mindspore::lite::Model::Import(ms_file.c_str(),size);\n",
        "+  return mindspore::session::TrainSession::CreateSession(ms_file,&context, train_mode);\n",
        " }\n",
        " \n",
        " TrainSession *CreateSession(char* model_buffer,size_t buffen_len) {\n",
        "@@ -64,7 +66,7 @@ std::vector<int> GetInferResult(TrainSession *session,int num_of_class) {\n",
        "   auto inputs = session->GetInputs();\n",
        "   auto batch_size = inputs[1]->shape()[0];\n",
        "   auto outputsv = SearchOutputsForSize(session, batch_size * num_of_class);\n",
        "-  std::cout<< \"ouput tensor name:\"<< outputsv->tensor_name()<<std::endl;\n",
        "+//  std::cout<< \"ouput tensor name:\"<< outputsv->tensor_name()<<std::endl;\n",
        "   auto scores = reinterpret_cast<float *>(outputsv->MutableData());\n",
        "   std::vector<int> infer_result(batch_size);\n",
        "   for (int b = 0; b < batch_size; b++) {\n",
        "-- \n",
        "2.7.4\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}