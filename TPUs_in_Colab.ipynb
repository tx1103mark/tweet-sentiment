{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Hkdaly_s6h"
      },
      "source": [
        "diff --git a/mindspore/lite/examples/train_lenet/src/net_runner.cc b/mindspore/lite/examples/train_lenet/src/net_runner.cc\n",
        "index a44551a..78ecb34 100644\n",
        "--- a/mindspore/lite/examples/train_lenet/src/net_runner.cc\n",
        "+++ b/mindspore/lite/examples/train_lenet/src/net_runner.cc\n",
        "@@ -15,9 +15,9 @@\n",
        "  */\n",
        " \n",
        " #include \"src/net_runner.h\"\n",
        "-#include <math.h>\n",
        "+#include <cmath>\n",
        " #include <getopt.h>\n",
        "-#include <stdio.h>\n",
        "+#include <cstdio>\n",
        " #include <cstring>\n",
        " #include <iostream>\n",
        " #include <fstream>\n",
        "@@ -43,10 +43,20 @@ using mindspore::lite::AccuracyMetrics;\n",
        " using mindspore::session::TrainLoopCallBack;\n",
        " using mindspore::session::TrainLoopCallBackData;\n",
        " \n",
        "+constexpr int kPrintNum = 10;\n",
        "+constexpr float kScalePoint = 255.0f;\n",
        "+constexpr int kBatchSize = 2;\n",
        "+constexpr int kNCHWDims = 4;\n",
        "+constexpr int kNCHWCDim = 2;\n",
        "+constexpr int kPrintTimes = 100;\n",
        "+constexpr int kSaveSteps = 1000;\n",
        "+constexpr float kLearningRate = 0.7f;\n",
        " class Rescaler : public mindspore::session::TrainLoopCallBack {\n",
        "  public:\n",
        "   explicit Rescaler(float scale) : scale_(scale) {\n",
        "-    if (scale_ == 0) scale_ = 1.0;\n",
        "+    if (scale_ == 0) {\n",
        "+      scale_ = 1.0;\n",
        "+    }\n",
        "   }\n",
        "   ~Rescaler() override = default;\n",
        "   void StepBegin(const mindspore::session::TrainLoopCallBackData &cb_data) override {\n",
        "@@ -67,7 +77,7 @@ bool after_callback(const std::vector<mindspore::tensor::MSTensor *> &after_inpu\n",
        "   for (size_t i = 0; i < after_inputs.size(); i++) {\n",
        "     int num2p = (after_inputs.at(i)->ElementsNum());\n",
        "     printf(\"in%zu(%d): \", i, num2p);\n",
        "-    if (num2p > 10) num2p = 10;\n",
        "+    if (num2p > kPrintNum) num2p = kPrintNum;\n",
        "     if (after_inputs.at(i)->data_type() == mindspore::kNumberTypeInt32) {\n",
        "       auto d = reinterpret_cast<int *>(after_inputs.at(i)->MutableData());\n",
        "       for (int j = 0; j < num2p; j++) printf(\"%d, \", d[j]);\n",
        "@@ -100,7 +110,7 @@ void NetRunner::InitAndFigureInputs() {\n",
        "   context.thread_num_ = 2;\n",
        " \n",
        "   session_ = mindspore::session::TrainSession::CreateSession(ms_file_, &context);\n",
        "-  MS_ASSERT(nullptr != session_);\n",
        "+  MS_ASSERT(session_ != nullptr);\n",
        "   loop_ = mindspore::session::TrainLoop::CreateTrainLoop(session_);\n",
        " \n",
        "   acc_metrics_ = std::shared_ptr<AccuracyMetrics>(new AccuracyMetrics);\n",
        "@@ -110,10 +120,10 @@ void NetRunner::InitAndFigureInputs() {\n",
        "   auto inputs = session_->GetInputs();\n",
        "   MS_ASSERT(inputs.size() > 1);\n",
        "   auto nhwc_input_dims = inputs.at(0)->shape();\n",
        "-  MS_ASSERT(nhwc_input_dims.size() == 4);\n",
        "+  MS_ASSERT(nhwc_input_dims.size() == kNCHWDims);\n",
        "   batch_size_ = nhwc_input_dims.at(0);\n",
        "   h_ = nhwc_input_dims.at(1);\n",
        "-  w_ = nhwc_input_dims.at(2);\n",
        "+  w_ = nhwc_input_dims.at(kNCHWCDim);\n",
        " }\n",
        " \n",
        " float NetRunner::CalculateAccuracy(int max_tests) {\n",
        "@@ -126,7 +136,7 @@ float NetRunner::CalculateAccuracy(int max_tests) {\n",
        "   test_ds_ = test_ds_->Map({&typecast}, {\"label\"});\n",
        "   test_ds_ = test_ds_->Batch(batch_size_, true);\n",
        " \n",
        "-  Rescaler rescale(255.0);\n",
        "+  Rescaler rescale(kScalePoint);\n",
        " \n",
        "   loop_->Eval(test_ds_.get(), std::vector<TrainLoopCallBack *>{&rescale});\n",
        "   std::cout << \"Eval Accuracy is \" << acc_metrics_->Eval() << std::endl;\n",
        "@@ -144,7 +154,7 @@ int NetRunner::InitDB() {\n",
        "   TypeCast typecast(\"int32\");\n",
        "   train_ds_ = train_ds_->Map({&typecast}, {\"label\"});\n",
        " \n",
        "-  train_ds_ = train_ds_->Shuffle(2);\n",
        "+  train_ds_ = train_ds_->Shuffle(kBatchSize);\n",
        "   train_ds_ = train_ds_->Batch(batch_size_, true);\n",
        " \n",
        "   if (verbose_) {\n",
        "@@ -159,13 +169,13 @@ int NetRunner::InitDB() {\n",
        " }\n",
        " \n",
        " int NetRunner::TrainLoop() {\n",
        "-  struct mindspore::lite::StepLRLambda step_lr_lambda(1, 0.7);\n",
        "+  struct mindspore::lite::StepLRLambda step_lr_lambda(1, kLearningRate);\n",
        "   mindspore::lite::LRScheduler step_lr_sched(mindspore::lite::StepLRLambda, static_cast<void *>(&step_lr_lambda), 1);\n",
        " \n",
        "-  mindspore::lite::LossMonitor lm(100);\n",
        "+  mindspore::lite::LossMonitor lm(kPrintTimes);\n",
        "   mindspore::lite::ClassificationTrainAccuracyMonitor am(1);\n",
        "-  mindspore::lite::CkptSaver cs(1000, std::string(\"lenet\"));\n",
        "-  Rescaler rescale(255.0);\n",
        "+  mindspore::lite::CkptSaver cs(kSaveSteps, std::string(\"lenet\"));\n",
        "+  Rescaler rescale(kScalePoint);\n",
        " \n",
        "   loop_->Train(epochs_, train_ds_.get(), std::vector<TrainLoopCallBack *>{&rescale, &lm, &cs, &am, &step_lr_sched});\n",
        "   return 0;\n",
        "diff --git a/mindspore/lite/examples/transfer_learning/src/dataset.cc b/mindspore/lite/examples/transfer_learning/src/dataset.cc\n",
        "index 7a0669b..2f8d3c2 100644\n",
        "--- a/mindspore/lite/examples/transfer_learning/src/dataset.cc\n",
        "+++ b/mindspore/lite/examples/transfer_learning/src/dataset.cc\n",
        "@@ -50,6 +50,10 @@ float CH_MEAN[3] = {0.485, 0.456, 0.406};\n",
        " float CH_STD[3] = {0.229, 0.224, 0.225};\n",
        " \n",
        " using LabelId = std::map<std::string, int>;\n",
        "+constexpr int kClassNum = 10;\n",
        "+constexpr int kBGRDim = 2;\n",
        "+constexpr float kRGBMAX = 255.0f;\n",
        "+constexpr int kRGBDims = 3;\n",
        " \n",
        " static char *ReadBitmapFile(const std::string &filename, size_t *size) {\n",
        "   MS_ASSERT(size != nullptr);\n",
        "@@ -78,7 +82,7 @@ static char *ReadBitmapFile(const std::string &filename, size_t *size) {\n",
        " \n",
        "   ifs.read(reinterpret_cast<char *>(bmp_image), bitmap_header.image_size_bytes);\n",
        " \n",
        "-  size_t buffer_size = bitmap_header.width * bitmap_header.height * 3;\n",
        "+  size_t buffer_size = bitmap_header.width * bitmap_header.height * kRGBDims;\n",
        "   float *hwc_bin_image = new (std::nothrow) float[buffer_size];\n",
        "   if (hwc_bin_image == nullptr) {\n",
        "     free(bmp_image);\n",
        "@@ -95,14 +99,16 @@ static char *ReadBitmapFile(const std::string &filename, size_t *size) {\n",
        "   for (int h = 0; h < bitmap_header.height; h++) {\n",
        "     for (int w = 0; w < bitmap_header.width; w++) {\n",
        "       hwc_bin_image[h * hStride + w * channels + 0] =\n",
        "-        (((static_cast<float>(bmp_image[(height - h - 1) * hStride + w * channels + 2])) / 255.0) - CH_MEAN[0]) /\n",
        "+        (((static_cast<float>(bmp_image[(height - h - 1) * hStride + w * channels + kBGRDim])) / kRGBMAX) -\n",
        "+         CH_MEAN[0]) /\n",
        "         CH_STD[0];\n",
        "       hwc_bin_image[h * hStride + w * channels + 1] =\n",
        "-        (((static_cast<float>(bmp_image[(height - h - 1) * hStride + w * channels + 1])) / 255.0) - CH_MEAN[1]) /\n",
        "+        (((static_cast<float>(bmp_image[(height - h - 1) * hStride + w * channels + 1])) / kRGBMAX) - CH_MEAN[1]) /\n",
        "         CH_STD[1];\n",
        "-      hwc_bin_image[h * hStride + w * channels + 2] =\n",
        "-        (((static_cast<float>(bmp_image[(height - h - 1) * hStride + w * channels + 0])) / 255.0) - CH_MEAN[2]) /\n",
        "-        CH_STD[2];\n",
        "+      hwc_bin_image[h * hStride + w * channels + kBGRDim] =\n",
        "+        (((static_cast<float>(bmp_image[(height - h - 1) * hStride + w * channels + 0])) / kRGBMAX) -\n",
        "+         CH_MEAN[kBGRDim]) /\n",
        "+        CH_STD[kBGRDim];\n",
        "     }\n",
        "   }\n",
        " \n",
        "@@ -190,7 +196,7 @@ void DataSet::InitializeBMPFoldersDatabase(std::string dpath) {\n",
        " std::vector<FileTuple> DataSet::ReadDir(const std::string dpath) {\n",
        "   std::vector<FileTuple> vec;\n",
        "   struct dirent *entry = nullptr;\n",
        "-  num_of_classes_ = 10;\n",
        "+  num_of_classes_ = kClassNum;\n",
        "   for (int class_id = 0; class_id < num_of_classes_; class_id++) {\n",
        "     std::string dirname = dpath + \"/\" + std::to_string(class_id);\n",
        "     DIR *dp = opendir(dirname.c_str());\n",
        "diff --git a/mindspore/lite/examples/transfer_learning/src/net_runner.cc b/mindspore/lite/examples/transfer_learning/src/net_runner.cc\n",
        "index cc0db4a..56fa14b 100644\n",
        "--- a/mindspore/lite/examples/transfer_learning/src/net_runner.cc\n",
        "+++ b/mindspore/lite/examples/transfer_learning/src/net_runner.cc\n",
        "@@ -15,7 +15,7 @@\n",
        "  */\n",
        " \n",
        " #include \"src/net_runner.h\"\n",
        "-#include <math.h>\n",
        "+#include <cmath>\n",
        " #include <getopt.h>\n",
        " #include <algorithm>\n",
        " #include <cstring>\n",
        "@@ -25,6 +25,9 @@\n",
        " #include \"src/utils.h\"\n",
        " \n",
        " static unsigned int seed = time(NULL);\n",
        "+constexpr int kBatchNum = 20;\n",
        "+constexpr int kPrintNum = 10;\n",
        "+constexpr float kThreshold = 0.9f;\n",
        " \n",
        " // Definition of callback function after forwarding operator.\n",
        " bool after_callback(const std::vector<mindspore::tensor::MSTensor *> &after_inputs,\n",
        "@@ -34,7 +37,7 @@ bool after_callback(const std::vector<mindspore::tensor::MSTensor *> &after_inpu\n",
        "   for (size_t i = 0; i < after_inputs.size(); i++) {\n",
        "     int num2p = (after_inputs.at(i)->ElementsNum());\n",
        "     std::cout << \"in\" << i << \"(\" << num2p << \"): \";\n",
        "-    if (num2p > 10) num2p = 10;\n",
        "+    if (num2p > kPrintNum) num2p = kPrintNum;\n",
        "     if (after_inputs.at(i)->data_type() == mindspore::kNumberTypeInt32) {\n",
        "       auto d = reinterpret_cast<int *>(after_inputs.at(i)->MutableData());\n",
        "       for (int j = 0; j < num2p; j++) {\n",
        "@@ -52,7 +55,7 @@ bool after_callback(const std::vector<mindspore::tensor::MSTensor *> &after_inpu\n",
        "     auto d = reinterpret_cast<float *>(after_outputs.at(i)->MutableData());\n",
        "     int num2p = (after_outputs.at(i)->ElementsNum());\n",
        "     std::cout << \"ou\" << i << \"(\" << num2p << \"): \";\n",
        "-    if (num2p > 10) num2p = 10;\n",
        "+    if (num2p > kPrintNum) num2p = kPrintNum;\n",
        "     for (int j = 0; j < num2p; j++) {\n",
        "       std::cout << d[j] << \", \";\n",
        "     }\n",
        "@@ -71,7 +74,7 @@ void NetRunner::InitAndFigureInputs() {\n",
        "   context.thread_num_ = 1;\n",
        " \n",
        "   session_ = mindspore::session::TrainSession::CreateTransferSession(ms_backbone_file_, ms_head_file_, &context);\n",
        "-  MS_ASSERT(nullptr != session_);\n",
        "+  MS_ASSERT(session_ != nullptr);\n",
        " \n",
        "   auto inputs = session_->GetInputs();\n",
        "   MS_ASSERT(inputs.size() > 1);\n",
        "@@ -107,7 +110,8 @@ std::vector<int> NetRunner::FillInputData(const std::vector<DataLabelTuple> &dat\n",
        "   std::fill(labels, labels + inputs.at(label_index_)->ElementsNum(), 0.f);\n",
        "   for (int i = 0; i < batch_size_; i++) {\n",
        "     if (serially >= 0) {\n",
        "-      idx = ++idx % total_size;\n",
        "+      auto reminder = ++idx % total_size;\n",
        "+      idx = reminder;\n",
        "     } else {\n",
        "       idx = rand_r(&seed) % total_size;\n",
        "     }\n",
        "@@ -190,12 +194,12 @@ int NetRunner::TrainLoop() {\n",
        "       session_->SaveToFile(cpkt_fn);\n",
        "     }\n",
        " \n",
        "-    std::cout << i + 1 << \": Loss is \" << loss << \" [min=\" << min_loss << \"]\" << std::endl;\n",
        "-    if ((i + 1) % 20 == 0) {\n",
        "+    std::cout << (i + 1) << \": Loss is \" << loss << \" [min=\" << min_loss << \"]\" << std::endl;\n",
        "+    if ((i + 1) % kBatchNum == 0) {\n",
        "       float acc = CalculateAccuracy(ds_.test_data());\n",
        "       if (max_acc < acc) max_acc = acc;\n",
        "       std::cout << \"accuracy on test data = \" << acc << \" max accuracy = \" << max_acc << std::endl;\n",
        "-      if (acc > 0.9) return 0;\n",
        "+      if (acc > kThreshold) return 0;\n",
        "     }\n",
        "   }\n",
        "   return 0;\n",
        "diff --git a/mindspore/lite/src/dequant.cc b/mindspore/lite/src/dequant.cc\n",
        "index 6987c9a..49ae0bb 100644\n",
        "--- a/mindspore/lite/src/dequant.cc\n",
        "+++ b/mindspore/lite/src/dequant.cc\n",
        "@@ -38,7 +38,7 @@ float *DequantUtil::DequantWeight(lite::Tensor *input_tensor, bool channel_first\n",
        "   }\n",
        " }\n",
        " \n",
        "-int DequantUtil::UnPackToInt(const schema::Tensor *input_tensor, void *unpack_int_data) {\n",
        "+int DequantUtil::UnPackToInt(const schema::Tensor *input_tensor, void *unpack_int_data, int data_len) {\n",
        "   MS_ASSERT(input_tensor != nullptr);\n",
        "   MS_ASSERT(unpack_int_data != nullptr);\n",
        "   auto quant_params = input_tensor->quantParams();\n",
        "@@ -50,7 +50,7 @@ int DequantUtil::UnPackToInt(const schema::Tensor *input_tensor, void *unpack_in\n",
        "   if (enable_huffman_code) {\n",
        "     std::string encode_str(input_tensor->data()->begin(), input_tensor->data()->end());\n",
        "     auto huffman_decode = std::make_unique<lite::HuffmanDecode>();\n",
        "-    auto ret = huffman_decode->DoHuffmanDecode(encode_str, unpack_int_data);\n",
        "+    auto ret = huffman_decode->DoHuffmanDecode(encode_str, unpack_int_data, data_len);\n",
        "     if (ret != RET_OK) {\n",
        "       MS_LOG(ERROR) << \"DoHuffmanDecode failed.\";\n",
        "       return ret;\n",
        "@@ -121,5 +121,4 @@ void DequantUtil::RestoreTensorData(const std::map<Tensor *, std::pair<TypeId, v\n",
        "     tensor->set_data(data);\n",
        "   }\n",
        " }\n",
        "-\n",
        " }  // namespace mindspore::lite\n",
        "diff --git a/mindspore/lite/src/dequant.h b/mindspore/lite/src/dequant.h\n",
        "index 98072bf..3385f7f 100644\n",
        "--- a/mindspore/lite/src/dequant.h\n",
        "+++ b/mindspore/lite/src/dequant.h\n",
        "@@ -31,7 +31,7 @@ class DequantUtil {\n",
        "  public:\n",
        "   static float *DequantWeight(lite::Tensor *input_tensor, bool);\n",
        " \n",
        "-  static int UnPackToInt(const schema::Tensor *input_tensor, void *weight_unpack_data);\n",
        "+  static int UnPackToInt(const schema::Tensor *input_tensor, void *weight_unpack_data, int weight_len);\n",
        " \n",
        "   static std::map<Tensor *, std::pair<TypeId, void *>> DequantTensor(OpParameter *op_param,\n",
        "                                                                      const std::vector<Tensor *> &in_tensors,\n",
        "diff --git a/mindspore/lite/src/huffman_decode.cc b/mindspore/lite/src/huffman_decode.cc\n",
        "index 8432571..dd173d4 100644\n",
        "--- a/mindspore/lite/src/huffman_decode.cc\n",
        "+++ b/mindspore/lite/src/huffman_decode.cc\n",
        "@@ -18,8 +18,7 @@\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        "-STATUS HuffmanDecode::DoHuffmanDecode(const std::string &input_str, void *decoded_data) {\n",
        "+STATUS HuffmanDecode::DoHuffmanDecode(const std::string &input_str, void *decoded_data, int data_len) {\n",
        "   if (decoded_data == nullptr) {\n",
        "     MS_LOG(ERROR) << \"decoded_data is nullptr.\";\n",
        "     return RET_ERROR;\n",
        "@@ -58,8 +57,11 @@ STATUS HuffmanDecode::DoHuffmanDecode(const std::string &input_str, void *decode\n",
        "   }\n",
        " \n",
        "   size_t len = huffman_decoded_str.length();\n",
        "-  memcpy(decoded_data, huffman_decoded_str.c_str(), len);\n",
        "-\n",
        "+  if (data_len >= len) {\n",
        "+    memcpy(decoded_data, huffman_decoded_str.c_str(), len);\n",
        "+  } else {\n",
        "+    return RET_ERROR;\n",
        "+  }\n",
        "   delete root;\n",
        "   return RET_OK;\n",
        " }\n",
        "@@ -163,6 +165,5 @@ HuffmanDecode::~HuffmanDecode() {\n",
        "   }\n",
        "   this->huffman_nodes_.resize(0);\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/huffman_decode.h b/mindspore/lite/src/huffman_decode.h\n",
        "index 9f15537..5a534d5 100644\n",
        "--- a/mindspore/lite/src/huffman_decode.h\n",
        "+++ b/mindspore/lite/src/huffman_decode.h\n",
        "@@ -44,7 +44,7 @@ class HuffmanDecode {\n",
        " \n",
        "   ~HuffmanDecode();\n",
        " \n",
        "-  STATUS DoHuffmanDecode(const std::string &input_str, void *decoded_data);\n",
        "+  STATUS DoHuffmanDecode(const std::string &input_str, void *decoded_data, int data_len);\n",
        " \n",
        "  private:\n",
        "   std::vector<HuffmanNodePtr> huffman_nodes_;\n",
        "diff --git a/mindspore/lite/src/lite_session.cc b/mindspore/lite/src/lite_session.cc\n",
        "index b78b974..ec5897e 100644\n",
        "--- a/mindspore/lite/src/lite_session.cc\n",
        "+++ b/mindspore/lite/src/lite_session.cc\n",
        "@@ -119,7 +119,7 @@ int LiteSession::ConvertTensorsData(const lite::Model *model, size_t tensor_inde\n",
        "           return RET_NULL_PTR;\n",
        "         }\n",
        "         if (NeedUnPack()) {\n",
        "-          auto ret = DequantUtil::UnPackToInt(src_tensor, dst_data);\n",
        "+          auto ret = DequantUtil::UnPackToInt(src_tensor, dst_data, dst_tensor->Size());\n",
        "           if (ret != RET_OK) {\n",
        "             MS_LOG(ERROR) << \"unpack to int failed.\";\n",
        "             return RET_NULL_PTR;\n",
        "@@ -135,7 +135,7 @@ int LiteSession::ConvertTensorsData(const lite::Model *model, size_t tensor_inde\n",
        "             MS_LOG(ERROR) << \"Data from tensor is nullptr\";\n",
        "             return RET_ERROR;\n",
        "           }\n",
        "-          auto ret = DequantUtil::UnPackToInt(src_tensor, dst_data);\n",
        "+          auto ret = DequantUtil::UnPackToInt(src_tensor, dst_data, dst_tensor->Size());\n",
        "           if (ret != RET_OK) {\n",
        "             MS_LOG(ERROR) << \"unpack to int failed.\";\n",
        "             return RET_ERROR;\n",
        "diff --git a/mindspore/lite/src/ops/populate/arithmetic_populate.cc b/mindspore/lite/src/ops/populate/arithmetic_populate.cc\n",
        "index f4bec62..8dae508 100644\n",
        "--- a/mindspore/lite/src/ops/populate/arithmetic_populate.cc\n",
        "+++ b/mindspore/lite/src/ops/populate/arithmetic_populate.cc\n",
        "@@ -59,5 +59,6 @@ Registry g_floorDivParameterRegistry(schema::PrimitiveType_FloorDiv, PopulateAri\n",
        " Registry g_floorModParameterRegistry(schema::PrimitiveType_FloorMod, PopulateArithmetic, SCHEMA_CUR);\n",
        " Registry g_modParameterRegistry(schema::PrimitiveType_Mod, PopulateArithmetic, SCHEMA_CUR);\n",
        " Registry g_squaredDifferenceParameterRegistry(schema::PrimitiveType_SquaredDifference, PopulateArithmetic, SCHEMA_CUR);\n",
        "+Registry g_populateBiasGradParameterParameterRegistry(schema::PrimitiveType_BiasAddGrad, PopulateArithmetic,SCHEMA_CUR);\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/ops/populate/pooling_populate.cc b/mindspore/lite/src/ops/populate/pooling_populate.cc\n",
        "index af36828..cf3c962 100644\n",
        "--- a/mindspore/lite/src/ops/populate/pooling_populate.cc\n",
        "+++ b/mindspore/lite/src/ops/populate/pooling_populate.cc\n",
        "@@ -19,6 +19,34 @@\n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        " namespace {\n",
        "+void SetPoolingParamPadMod(schema::PadMode pad_mode, PoolingParameter *pooling_param) {\n",
        "+  switch (pad_mode) {\n",
        "+    case schema::PadMode_SAME:\n",
        "+      pooling_param->pad_mode_ = Pad_same;\n",
        "+      break;\n",
        "+    case schema::PadMode_VALID:\n",
        "+      pooling_param->pad_mode_ = Pad_valid;\n",
        "+      break;\n",
        "+    default:\n",
        "+      pooling_param->pad_mode_ = Pad_pad;\n",
        "+      break;\n",
        "+  }\n",
        "+}\n",
        "+\n",
        "+void SetPoolingParamRoundMod(schema::RoundMode round_mode, PoolingParameter *pooling_param) {\n",
        "+  switch (round_mode) {\n",
        "+    case schema::RoundMode_FLOOR:\n",
        "+      pooling_param->round_mode_ = RoundMode_Floor;\n",
        "+      break;\n",
        "+    case schema::RoundMode_CEIL:\n",
        "+      pooling_param->round_mode_ = RoundMode_Ceil;\n",
        "+      break;\n",
        "+    default:\n",
        "+      pooling_param->round_mode_ = RoundMode_No;\n",
        "+      break;\n",
        "+  }\n",
        "+}\n",
        "+\n",
        " OpParameter *PopulateAvgPoolParameter(const void *primitive) {\n",
        "   PoolingParameter *pooling_param = reinterpret_cast<PoolingParameter *>(malloc(sizeof(PoolingParameter)));\n",
        "   if (pooling_param == nullptr) {\n",
        "@@ -45,17 +73,7 @@ OpParameter *PopulateAvgPoolParameter(const void *primitive) {\n",
        "   }\n",
        " \n",
        "   auto round_mode = pooling_primitive->round_mode();\n",
        "-  switch (round_mode) {\n",
        "-    case schema::RoundMode_FLOOR:\n",
        "-      pooling_param->round_mode_ = RoundMode_Floor;\n",
        "-      break;\n",
        "-    case schema::RoundMode_CEIL:\n",
        "-      pooling_param->round_mode_ = RoundMode_Ceil;\n",
        "-      break;\n",
        "-    default:\n",
        "-      pooling_param->round_mode_ = RoundMode_No;\n",
        "-      break;\n",
        "-  }\n",
        "+  SetPoolingParamRoundMod(round_mode, pooling_param);\n",
        " \n",
        "   if (pooling_primitive->activation_type() == schema::ActivationType_RELU) {\n",
        "     pooling_param->act_type_ = ActType_Relu;\n",
        "@@ -64,18 +82,7 @@ OpParameter *PopulateAvgPoolParameter(const void *primitive) {\n",
        "   } else {\n",
        "     pooling_param->act_type_ = ActType_No;\n",
        "   }\n",
        "-\n",
        "-  switch (pooling_primitive->pad_mode()) {\n",
        "-    case schema::PadMode_SAME:\n",
        "-      pooling_param->pad_mode_ = Pad_same;\n",
        "-      break;\n",
        "-    case schema::PadMode_VALID:\n",
        "-      pooling_param->pad_mode_ = Pad_valid;\n",
        "-      break;\n",
        "-    default:\n",
        "-      pooling_param->pad_mode_ = Pad_pad;\n",
        "-      break;\n",
        "-  }\n",
        "+  SetPoolingParamPadMod(pooling_primitive->pad_mode(), pooling_param);\n",
        "   return reinterpret_cast<OpParameter *>(pooling_param);\n",
        " }\n",
        " \n",
        "@@ -105,18 +112,7 @@ OpParameter *PopulateMaxPoolParameter(const void *primitive) {\n",
        "   }\n",
        " \n",
        "   auto round_mode = max_pool_prim->round_mode();\n",
        "-  switch (round_mode) {\n",
        "-    case schema::RoundMode_FLOOR:\n",
        "-      pooling_param->round_mode_ = RoundMode_Floor;\n",
        "-      break;\n",
        "-    case schema::RoundMode_CEIL:\n",
        "-      pooling_param->round_mode_ = RoundMode_Ceil;\n",
        "-      break;\n",
        "-    default:\n",
        "-      pooling_param->round_mode_ = RoundMode_No;\n",
        "-      break;\n",
        "-  }\n",
        "-\n",
        "+  SetPoolingParamRoundMod(round_mode, pooling_param);\n",
        "   if (max_pool_prim->activation_type() == schema::ActivationType_RELU) {\n",
        "     pooling_param->act_type_ = ActType_Relu;\n",
        "   } else if (max_pool_prim->activation_type() == schema::ActivationType_RELU6) {\n",
        "@@ -124,23 +120,67 @@ OpParameter *PopulateMaxPoolParameter(const void *primitive) {\n",
        "   } else {\n",
        "     pooling_param->act_type_ = ActType_No;\n",
        "   }\n",
        "+  SetPoolingParamPadMod(max_pool_prim->pad_mode(), pooling_param);\n",
        "+  return reinterpret_cast<OpParameter *>(pooling_param);\n",
        "+}\n",
        " \n",
        "-  switch (max_pool_prim->pad_mode()) {\n",
        "-    case schema::PadMode_SAME:\n",
        "-      pooling_param->pad_mode_ = Pad_same;\n",
        "-      break;\n",
        "-    case schema::PadMode_VALID:\n",
        "-      pooling_param->pad_mode_ = Pad_valid;\n",
        "-      break;\n",
        "-    default:\n",
        "-      pooling_param->pad_mode_ = Pad_pad;\n",
        "-      break;\n",
        "+OpParameter *PopulateMaxPoolGradParameter(const void *prim) {\n",
        "+  PoolingParameter *pooling_param = reinterpret_cast<PoolingParameter *>(malloc(sizeof(PoolingParameter)));\n",
        "+  if (pooling_param == nullptr) {\n",
        "+    MS_LOG(ERROR) << \"malloc PoolingParameter failed.\";\n",
        "+    return nullptr;\n",
        "+  }\n",
        "+  auto primitive = static_cast<const schema::Primitive *>(prim);\n",
        "+  auto value = primitive->value_as_MaxPoolGrad();\n",
        "+  pooling_param->op_parameter_.type_ = primitive->value_type();\n",
        "+\n",
        "+  pooling_param->global_ = false;\n",
        "+  pooling_param->window_w_ = static_cast<int>(value->kernel_size()->Get(1));\n",
        "+  pooling_param->window_h_ = static_cast<int>(value->kernel_size()->Get(0));\n",
        "+\n",
        "+  pooling_param->pad_u_ = 0;\n",
        "+  pooling_param->pad_d_ = 0;\n",
        "+  pooling_param->pad_l_ = 0;\n",
        "+  pooling_param->pad_r_ = 0;\n",
        "+  pooling_param->stride_w_ = static_cast<int>(value->strides()->Get(1));\n",
        "+  pooling_param->stride_h_ = static_cast<int>(value->strides()->Get(0));\n",
        "+  pooling_param->round_mode_ = RoundMode_No;\n",
        "+  pooling_param->pool_mode_ = PoolMode_MaxPool;\n",
        "+  SetPoolingParamPadMod(value->pad_mode(), pooling_param);\n",
        "+  return reinterpret_cast<OpParameter *>(pooling_param);\n",
        "+}\n",
        "+\n",
        "+OpParameter *PopulateAvgPoolGradParameter(const void *prim) {\n",
        "+  PoolingParameter *pooling_param = reinterpret_cast<PoolingParameter *>(malloc(sizeof(PoolingParameter)));\n",
        "+  if (pooling_param == nullptr) {\n",
        "+    MS_LOG(ERROR) << \"malloc PoolingParameter failed.\";\n",
        "+    return nullptr;\n",
        "   }\n",
        "+  auto primitive = static_cast<const schema::Primitive *>(prim);\n",
        "+  auto value = primitive->value_as_AvgPoolGrad();\n",
        "+  pooling_param->op_parameter_.type_ = primitive->value_type();\n",
        "+\n",
        "+  pooling_param->global_ = false;\n",
        "+  pooling_param->window_w_ = static_cast<int>(value->kernel_size()->Get(1));\n",
        "+  pooling_param->window_h_ = static_cast<int>(value->kernel_size()->Get(0));\n",
        "+\n",
        "+  pooling_param->pad_u_ = 0;\n",
        "+  pooling_param->pad_d_ = 0;\n",
        "+  pooling_param->pad_l_ = 0;\n",
        "+  pooling_param->pad_r_ = 0;\n",
        "+  pooling_param->stride_w_ = static_cast<int>(value->strides()->Get(1));\n",
        "+  pooling_param->stride_h_ = static_cast<int>(value->strides()->Get(0));\n",
        "+\n",
        "+  SetPoolingParamPadMod(value->pad_mode(), pooling_param);\n",
        "+  pooling_param->round_mode_ = RoundMode_No;\n",
        "+  pooling_param->pool_mode_ = PoolMode_AvgPool;\n",
        "   return reinterpret_cast<OpParameter *>(pooling_param);\n",
        " }\n",
        " }  // namespace\n",
        " \n",
        " Registry g_avgPoolParameterRegistry(schema::PrimitiveType_AvgPoolFusion, PopulateAvgPoolParameter, SCHEMA_CUR);\n",
        " Registry g_maxPoolParameterRegistry(schema::PrimitiveType_MaxPoolFusion, PopulateMaxPoolParameter, SCHEMA_CUR);\n",
        "+Registry g_avgPoolGradParameterRegistry(schema::PrimitiveType_AvgPoolGrad, PopulateAvgPoolGradParameter, SCHEMA_CUR);\n",
        "+Registry g_maxPoolGradParameterRegistry(schema::PrimitiveType_MaxPoolGrad, PopulateMaxPoolGradParameter, SCHEMA_CUR);\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/accuracy_metrics.cc b/mindspore/lite/src/train/accuracy_metrics.cc\n",
        "index 6b79088..6d6a5c5 100644\n",
        "--- a/mindspore/lite/src/train/accuracy_metrics.cc\n",
        "+++ b/mindspore/lite/src/train/accuracy_metrics.cc\n",
        "@@ -22,7 +22,6 @@\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        " AccuracyMetrics::AccuracyMetrics(int accuracy_metrics, const std::vector<int> &input_indexes,\n",
        "                                  const std::vector<int> &output_indexes)\n",
        "     : Metrics() {\n",
        "@@ -66,6 +65,5 @@ float AccuracyMetrics::Eval() {\n",
        " \n",
        "   return (total_accuracy_ / total_steps_);\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/accuracy_monitor.cc b/mindspore/lite/src/train/accuracy_monitor.cc\n",
        "index a9aabdc..0cb3b5d 100644\n",
        "--- a/mindspore/lite/src/train/accuracy_monitor.cc\n",
        "+++ b/mindspore/lite/src/train/accuracy_monitor.cc\n",
        "@@ -29,7 +29,6 @@\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        " void AccuracyMonitor::Begin(const session::TrainLoopCallBackData &cb_data) {\n",
        "   if (cb_data.epoch_ == 0) accuracies_.clear();\n",
        " }\n",
        "@@ -40,6 +39,5 @@ int AccuracyMonitor::EpochEnd(const session::TrainLoopCallBackData &cb_data) {\n",
        "   accuracies_.push_back(std::make_pair(cb_data.epoch_, 0.0));\n",
        "   return mindspore::session::RET_CONTINUE;\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/classification_train_accuracy_monitor.cc b/mindspore/lite/src/train/classification_train_accuracy_monitor.cc\n",
        "index b373fd1..7cf7da8 100644\n",
        "--- a/mindspore/lite/src/train/classification_train_accuracy_monitor.cc\n",
        "+++ b/mindspore/lite/src/train/classification_train_accuracy_monitor.cc\n",
        "@@ -27,7 +27,6 @@ using mindspore::WARNING;\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        " ClassificationTrainAccuracyMonitor::ClassificationTrainAccuracyMonitor(int print_every_n, int accuracy_metrics,\n",
        "                                                                        const std::vector<int> &input_indexes,\n",
        "                                                                        const std::vector<int> &output_indexes) {\n",
        "@@ -60,7 +59,7 @@ void ClassificationTrainAccuracyMonitor::EpochBegin(const session::TrainLoopCall\n",
        " int ClassificationTrainAccuracyMonitor::EpochEnd(const session::TrainLoopCallBackData &cb_data) {\n",
        "   if (cb_data.step_ > 0) accuracies_.at(cb_data.epoch_).second /= static_cast<float>(cb_data.step_ + 1);\n",
        "   if ((cb_data.epoch_ + 1) % print_every_n_ == 0) {\n",
        "-    std::cout << \"Epoch (\" << cb_data.epoch_ + 1 << \"):\\tTraining Accuracy is \" << accuracies_.at(cb_data.epoch_).second\n",
        "+    std::cout << \"Epoch (\" << (cb_data.epoch_ + 1) << \"):\\tTraining Accuracy is \" << accuracies_.at(cb_data.epoch_).second\n",
        "               << std::endl;\n",
        "   }\n",
        "   return mindspore::session::RET_CONTINUE;\n",
        "@@ -86,6 +85,5 @@ void ClassificationTrainAccuracyMonitor::StepEnd(const session::TrainLoopCallBac\n",
        "   }\n",
        "   accuracies_.at(cb_data.epoch_).second += accuracy;\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/loss_monitor.cc b/mindspore/lite/src/train/loss_monitor.cc\n",
        "index 2230316..7e9eb3d 100644\n",
        "--- a/mindspore/lite/src/train/loss_monitor.cc\n",
        "+++ b/mindspore/lite/src/train/loss_monitor.cc\n",
        "@@ -26,7 +26,6 @@\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        " void LossMonitor::Begin(const session::TrainLoopCallBackData &cb_data) {\n",
        "   if (cb_data.epoch_ == 0) losses_.clear();\n",
        " }\n",
        "@@ -42,7 +41,7 @@ void LossMonitor::EpochBegin(const session::TrainLoopCallBackData &cb_data) {\n",
        " int LossMonitor::EpochEnd(const session::TrainLoopCallBackData &cb_data) {\n",
        "   if (cb_data.step_ > 0) losses_.at(cb_data.epoch_).second /= static_cast<float>(cb_data.step_ + 1);\n",
        "   if (print_every_n_ > 0) {\n",
        "-    std::cout << \"Epoch (\" << cb_data.epoch_ + 1 << \"):\\tLoss is \" << losses_.at(cb_data.epoch_).second << std::endl;\n",
        "+    std::cout << \"Epoch (\" << (cb_data.epoch_ + 1) << \"):\\tLoss is \" << losses_.at(cb_data.epoch_).second << std::endl;\n",
        "   }\n",
        "   return mindspore::session::RET_CONTINUE;\n",
        " }\n",
        "@@ -54,12 +53,11 @@ void LossMonitor::StepEnd(const session::TrainLoopCallBackData &cb_data) {\n",
        "       auto loss = reinterpret_cast<float *>(it->second->MutableData());\n",
        "       losses_.at(cb_data.epoch_).second += loss[0];\n",
        "       if ((cb_data.step_ + 1) % print_every_n_ == 0)\n",
        "-        std::cout << cb_data.epoch_ + 1 << \".\" << cb_data.step_ + 1 << \":\\tLoss is \" << loss[0] << std::endl;\n",
        "+        std::cout << (cb_data.epoch_ + 1) << \".\" << (cb_data.step_ + 1) << \":\\tLoss is \" << loss[0] << std::endl;\n",
        "       return;\n",
        "     }\n",
        "   }\n",
        "   MS_LOG(WARNING) << \"Model does not have a loss output tensor of size 1\";\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/lr_scheduler.cc b/mindspore/lite/src/train/lr_scheduler.cc\n",
        "index 461043d..60c07f9 100644\n",
        "--- a/mindspore/lite/src/train/lr_scheduler.cc\n",
        "+++ b/mindspore/lite/src/train/lr_scheduler.cc\n",
        "@@ -29,7 +29,6 @@\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        " int MultiplicativeLRLambda(float *lr, int epoch, void *lr_cb_data) {\n",
        "   if ((lr == nullptr) || (lr_cb_data == nullptr)) {\n",
        "     MS_LOG(ERROR) << \"nullptr passed as input to MultiplicativeLRLambda\";\n",
        "@@ -70,6 +69,5 @@ int LRScheduler::EpochEnd(const session::TrainLoopCallBackData &cb_data) {\n",
        "   }\n",
        "   return mindspore::session::RET_CONTINUE;\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/train_loop.cc b/mindspore/lite/src/train/train_loop.cc\n",
        "index fd4b265..d8fe4dd 100644\n",
        "--- a/mindspore/lite/src/train/train_loop.cc\n",
        "+++ b/mindspore/lite/src/train/train_loop.cc\n",
        "@@ -26,7 +26,6 @@\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        " using dataset::Dataset;\n",
        " using dataset::Iterator;\n",
        " using dataset::MSTensorVec;\n",
        "@@ -133,28 +132,8 @@ int TrainLoop::LoadData(std::vector<tensor::MSTensor *> inputs, dataset::MSTenso\n",
        "   }\n",
        " \n",
        "   for (unsigned int i = 0; i < num_of_inputs; i++) {\n",
        "-    unsigned char *input_data = reinterpret_cast<unsigned char *>(inputs.at(i)->MutableData());\n",
        "-    const unsigned char *row_data = reinterpret_cast<const unsigned char *>(row_vec->at(i).MutableData());\n",
        "-    auto data_size = row_vec->at(i).DataSize();\n",
        "-    if (data_size != inputs.at(i)->Size()) {\n",
        "-      MS_LOG(WARNING) << \"Model Input tensor \" << i << \" size (\" << inputs.at(i)->Size()\n",
        "-                      << \") does not match dataset size (\" << data_size << \")\\n\";\n",
        "-      return RET_STOP_TRAINING;\n",
        "-    }\n",
        "-    std::copy(row_data, row_data + data_size, input_data);\n",
        "-  }\n",
        "-  return RET_OK;\n",
        "-}\n",
        "-\n",
        "-int TrainLoop::LoadPartialData(std::vector<tensor::MSTensor *> inputs, dataset::MSTensorVec *row_vec) {\n",
        "-  auto num_of_inputs = inputs.size();\n",
        "-  if ((num_of_inputs == 0) || (row_vec == nullptr) || (num_of_inputs < row_vec->size())) {\n",
        "-    return RET_STOP_TRAINING;\n",
        "-  }\n",
        "-\n",
        "-  for (unsigned int i = 0; i < row_vec->size(); i++) {\n",
        "-    unsigned char *input_data = reinterpret_cast<unsigned char *>(inputs.at(i)->MutableData());\n",
        "-    const unsigned char *row_data = reinterpret_cast<const unsigned char *>(row_vec->at(i).MutableData());\n",
        "+    auto *input_data = reinterpret_cast<unsigned char *>(inputs.at(i)->MutableData());\n",
        "+    const auto *row_data = reinterpret_cast<const unsigned char *>(row_vec->at(i).MutableData());\n",
        "     auto data_size = row_vec->at(i).DataSize();\n",
        "     if (data_size != inputs.at(i)->Size()) {\n",
        "       MS_LOG(WARNING) << \"Model Input tensor \" << i << \" size (\" << inputs.at(i)->Size()\n",
        "@@ -165,12 +144,10 @@ int TrainLoop::LoadPartialData(std::vector<tensor::MSTensor *> inputs, dataset::\n",
        "   }\n",
        "   return RET_OK;\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " \n",
        " session::TrainLoop *session::TrainLoop::CreateTrainLoop(session::TrainSession *train_session) {\n",
        "   auto loop = new (std::nothrow) lite::TrainLoop(train_session);\n",
        "   return loop;\n",
        " }\n",
        "-\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/train_loop.h b/mindspore/lite/src/train/train_loop.h\n",
        "index 0098be3..f0a75fa 100644\n",
        "--- a/mindspore/lite/src/train/train_loop.h\n",
        "+++ b/mindspore/lite/src/train/train_loop.h\n",
        "@@ -63,7 +63,6 @@ class TrainLoop : virtual public session::TrainLoop {\n",
        " \n",
        "  protected:\n",
        "   static int LoadData(std::vector<tensor::MSTensor *> inputs, dataset::MSTensorVec *dataset_vec);\n",
        "-  static int LoadPartialData(std::vector<tensor::MSTensor *> inputs, dataset::MSTensorVec *dataset_vec);\n",
        " \n",
        "   session::TrainSession *train_session_ = nullptr;\n",
        "   unsigned int epoch_ = 0;\n",
        "diff --git a/mindspore/lite/src/train/train_model.cc b/mindspore/lite/src/train/train_model.cc\n",
        "index bab09e3..3b0b600 100644\n",
        "--- a/mindspore/lite/src/train/train_model.cc\n",
        "+++ b/mindspore/lite/src/train/train_model.cc\n",
        "@@ -19,7 +19,6 @@\n",
        " #include \"src/common/graph_util.h\"\n",
        " \n",
        " namespace mindspore::lite {\n",
        "-\n",
        " TrainModel *TrainModel::Import(const char *model_buf, size_t size) {\n",
        "   if (model_buf == nullptr) {\n",
        "     MS_LOG(ERROR) << \"The model buf is nullptr\";\n",
        "diff --git a/mindspore/lite/src/train/train_populate_parameter.cc b/mindspore/lite/src/train/train_populate_parameter.cc\n",
        "index 1d4a836b..7d7f155 100644\n",
        "--- a/mindspore/lite/src/train/train_populate_parameter.cc\n",
        "+++ b/mindspore/lite/src/train/train_populate_parameter.cc\n",
        "@@ -31,7 +31,10 @@\n",
        " #include \"nnacl/fp32_grad/resize_grad.h\"\n",
        " namespace mindspore {\n",
        " namespace kernel {\n",
        "-\n",
        "+namespace {\n",
        "+constexpr int kNHWCWDim = 2;\n",
        "+constexpr int kNHWCCDim = 3;\n",
        "+}  //  namespace\n",
        " OpParameter *PopulateSmoothL1LossParameter(const void *prim) {\n",
        "   SmoothL1LossParameter *p = reinterpret_cast<SmoothL1LossParameter *>(malloc(sizeof(SmoothL1LossParameter)));\n",
        "   if (p == nullptr) {\n",
        "@@ -152,91 +155,6 @@ OpParameter *PopulateSoftmaxCrossEntropyParameter(const void *prim) {\n",
        "   return reinterpret_cast<OpParameter *>(sce_param);\n",
        " }\n",
        " \n",
        "-OpParameter *PopulateMaxPoolGradParameter(const void *prim) {\n",
        "-  PoolingParameter *pooling_param = reinterpret_cast<PoolingParameter *>(malloc(sizeof(PoolingParameter)));\n",
        "-  if (pooling_param == nullptr) {\n",
        "-    MS_LOG(ERROR) << \"malloc PoolingParameter failed.\";\n",
        "-    return nullptr;\n",
        "-  }\n",
        "-  auto primitive = static_cast<const schema::Primitive *>(prim);\n",
        "-  auto value = primitive->value_as_MaxPoolGrad();\n",
        "-  pooling_param->op_parameter_.type_ = primitive->value_type();\n",
        "-\n",
        "-  pooling_param->global_ = false;\n",
        "-  pooling_param->window_w_ = static_cast<int>(value->kernel_size()->Get(1));\n",
        "-  pooling_param->window_h_ = static_cast<int>(value->kernel_size()->Get(0));\n",
        "-\n",
        "-  pooling_param->pad_u_ = 0;\n",
        "-  pooling_param->pad_d_ = 0;\n",
        "-  pooling_param->pad_l_ = 0;\n",
        "-  pooling_param->pad_r_ = 0;\n",
        "-  pooling_param->stride_w_ = static_cast<int>(value->strides()->Get(1));\n",
        "-  pooling_param->stride_h_ = static_cast<int>(value->strides()->Get(0));\n",
        "-  pooling_param->round_mode_ = RoundMode_No;\n",
        "-  pooling_param->pool_mode_ = PoolMode_MaxPool;\n",
        "-  switch (value->pad_mode()) {\n",
        "-    case schema::PadMode_SAME:\n",
        "-      pooling_param->pad_mode_ = Pad_same;\n",
        "-      break;\n",
        "-    case schema::PadMode_VALID:\n",
        "-      pooling_param->pad_mode_ = Pad_valid;\n",
        "-      break;\n",
        "-    default:\n",
        "-      pooling_param->pad_mode_ = Pad_pad;\n",
        "-      break;\n",
        "-  }\n",
        "-\n",
        "-  return reinterpret_cast<OpParameter *>(pooling_param);\n",
        "-}\n",
        "-\n",
        "-OpParameter *PopulateAvgPoolGradParameter(const void *prim) {\n",
        "-  PoolingParameter *pooling_param = reinterpret_cast<PoolingParameter *>(malloc(sizeof(PoolingParameter)));\n",
        "-  if (pooling_param == nullptr) {\n",
        "-    MS_LOG(ERROR) << \"malloc PoolingParameter failed.\";\n",
        "-    return nullptr;\n",
        "-  }\n",
        "-  auto primitive = static_cast<const schema::Primitive *>(prim);\n",
        "-  auto value = primitive->value_as_AvgPoolGrad();\n",
        "-  pooling_param->op_parameter_.type_ = primitive->value_type();\n",
        "-\n",
        "-  pooling_param->global_ = false;\n",
        "-  pooling_param->window_w_ = static_cast<int>(value->kernel_size()->Get(1));\n",
        "-  pooling_param->window_h_ = static_cast<int>(value->kernel_size()->Get(0));\n",
        "-\n",
        "-  pooling_param->pad_u_ = 0;\n",
        "-  pooling_param->pad_d_ = 0;\n",
        "-  pooling_param->pad_l_ = 0;\n",
        "-  pooling_param->pad_r_ = 0;\n",
        "-  pooling_param->stride_w_ = static_cast<int>(value->strides()->Get(1));\n",
        "-  pooling_param->stride_h_ = static_cast<int>(value->strides()->Get(0));\n",
        "-\n",
        "-  switch (value->pad_mode()) {\n",
        "-    case schema::PadMode_SAME:\n",
        "-      pooling_param->pad_mode_ = Pad_same;\n",
        "-      break;\n",
        "-    case schema::PadMode_VALID:\n",
        "-      pooling_param->pad_mode_ = Pad_valid;\n",
        "-      break;\n",
        "-    default:\n",
        "-      pooling_param->pad_mode_ = Pad_pad;\n",
        "-      break;\n",
        "-  }\n",
        "-  pooling_param->round_mode_ = RoundMode_No;\n",
        "-  pooling_param->pool_mode_ = PoolMode_AvgPool;\n",
        "-  switch (value->pad_mode()) {\n",
        "-    case schema::PadMode_SAME:\n",
        "-      pooling_param->pad_mode_ = Pad_same;\n",
        "-      break;\n",
        "-    case schema::PadMode_VALID:\n",
        "-      pooling_param->pad_mode_ = Pad_valid;\n",
        "-      break;\n",
        "-    default:\n",
        "-      pooling_param->pad_mode_ = Pad_pad;\n",
        "-      break;\n",
        "-  }\n",
        "-  return reinterpret_cast<OpParameter *>(pooling_param);\n",
        "-}\n",
        "-\n",
        " OpParameter *PopulateActivationGradParameter(const void *prim) {\n",
        "   ActivationParameter *act_param = reinterpret_cast<ActivationParameter *>(malloc(sizeof(ActivationParameter)));\n",
        "   if (act_param == nullptr) {\n",
        "@@ -251,6 +169,21 @@ OpParameter *PopulateActivationGradParameter(const void *prim) {\n",
        "   return reinterpret_cast<OpParameter *>(act_param);\n",
        " }\n",
        " \n",
        "+void SetConvParam(ConvParameter *param, const flatbuffers::Vector<int64_t> *kernel_size,\n",
        "+                  const flatbuffers::Vector<int64_t> *stride, const flatbuffers::Vector<int64_t> *dilation,\n",
        "+                  const flatbuffers::Vector<int64_t> *pad_list) {\n",
        "+  param->kernel_h_ = kernel_size->Get(0);\n",
        "+  param->kernel_w_ = kernel_size->Get(1);\n",
        "+  param->stride_h_ = stride->Get(0);\n",
        "+  param->stride_w_ = stride->Get(1);\n",
        "+  param->dilation_h_ = dilation->Get(0);\n",
        "+  param->dilation_w_ = dilation->Get(1);\n",
        "+  param->pad_u_ = pad_list->Get(0);\n",
        "+  param->pad_d_ = pad_list->Get(1);\n",
        "+  param->pad_l_ = pad_list->Get(kNHWCWDim);\n",
        "+  param->pad_r_ = pad_list->Get(kNHWCCDim);\n",
        "+}\n",
        "+\n",
        " OpParameter *PopulateConvolutionGradFilterParameter(const void *prim) {\n",
        "   ConvParameter *param = reinterpret_cast<ConvParameter *>(malloc(sizeof(ConvParameter)));\n",
        "   if (param == nullptr) {\n",
        "@@ -261,17 +194,7 @@ OpParameter *PopulateConvolutionGradFilterParameter(const void *prim) {\n",
        "   auto primitive = static_cast<const schema::Primitive *>(prim);\n",
        "   auto value = primitive->value_as_Conv2DBackpropFilterFusion();\n",
        "   param->op_parameter_.type_ = primitive->value_type();\n",
        "-\n",
        "-  param->kernel_h_ = value->kernel_size()->Get(0);\n",
        "-  param->kernel_w_ = value->kernel_size()->Get(1);\n",
        "-  param->stride_h_ = value->stride()->Get(0);\n",
        "-  param->stride_w_ = value->stride()->Get(1);\n",
        "-  param->dilation_h_ = value->dilation()->Get(0);\n",
        "-  param->dilation_w_ = value->dilation()->Get(1);\n",
        "-  param->pad_u_ = value->pad_list()->Get(0);\n",
        "-  param->pad_d_ = value->pad_list()->Get(1);\n",
        "-  param->pad_l_ = value->pad_list()->Get(2);\n",
        "-  param->pad_r_ = value->pad_list()->Get(3);\n",
        "+  SetConvParam(param, value->kernel_size(), value->stride(), value->dilation(), value->pad_list());\n",
        "   param->group_ = value->group();\n",
        "   param->act_type_ = ActType_No;\n",
        "   switch (value->activation_type()) {\n",
        "@@ -284,7 +207,6 @@ OpParameter *PopulateConvolutionGradFilterParameter(const void *prim) {\n",
        "     default:\n",
        "       break;\n",
        "   }\n",
        "-\n",
        "   return reinterpret_cast<OpParameter *>(param);\n",
        " }\n",
        " \n",
        "@@ -297,17 +219,7 @@ OpParameter *PopulateConvolutionGradInputParameter(const void *prim) {\n",
        "   auto primitive = static_cast<const schema::Primitive *>(prim);\n",
        "   auto value = primitive->value_as_Conv2DBackpropInputFusion();\n",
        "   param->op_parameter_.type_ = primitive->value_type();\n",
        "-\n",
        "-  param->kernel_h_ = value->kernel_size()->Get(0);\n",
        "-  param->kernel_w_ = value->kernel_size()->Get(1);\n",
        "-  param->stride_h_ = value->stride()->Get(0);\n",
        "-  param->stride_w_ = value->stride()->Get(1);\n",
        "-  param->dilation_h_ = value->dilation()->Get(0);\n",
        "-  param->dilation_w_ = value->dilation()->Get(1);\n",
        "-  param->pad_u_ = value->pad_list()->Get(0);\n",
        "-  param->pad_d_ = value->pad_list()->Get(1);\n",
        "-  param->pad_l_ = value->pad_list()->Get(2);\n",
        "-  param->pad_r_ = value->pad_list()->Get(3);\n",
        "+  SetConvParam(param, value->kernel_size(), value->stride(), value->dilation(), value->pad_list());\n",
        "   param->group_ = value->group();\n",
        "   param->act_type_ = ActType_No;\n",
        "   switch (value->activation_type()) {\n",
        "@@ -339,17 +251,6 @@ OpParameter *PopulatePowerGradParameter(const void *prim) {\n",
        "   return reinterpret_cast<OpParameter *>(power_param);\n",
        " }\n",
        " \n",
        "-OpParameter *PopulateBiasGradParameter(const void *prim) {\n",
        "-  ArithmeticParameter *arithmetic_param = reinterpret_cast<ArithmeticParameter *>(malloc(sizeof(ArithmeticParameter)));\n",
        "-  if (arithmetic_param == nullptr) {\n",
        "-    MS_LOG(ERROR) << \"malloc ArithmeticParameter failed.\";\n",
        "-    return nullptr;\n",
        "-  }\n",
        "-  auto primitive = static_cast<const schema::Primitive *>(prim);\n",
        "-  arithmetic_param->op_parameter_.type_ = primitive->value_type();\n",
        "-  return reinterpret_cast<OpParameter *>(arithmetic_param);\n",
        "-}\n",
        "-\n",
        " OpParameter *PopulateBNGradParameter(const void *prim) {\n",
        "   BNGradParameter *bnGrad_param = reinterpret_cast<BNGradParameter *>(malloc(sizeof(BNGradParameter)));\n",
        "   if (bnGrad_param == nullptr) {\n",
        "@@ -430,32 +331,9 @@ OpParameter *PopulateResizeGradParameter(const void *prim) {\n",
        "   return reinterpret_cast<OpParameter *>(resize_grad_param);\n",
        " }\n",
        " \n",
        "-OpParameter *PopulateStridedSliceGradParameter(const void *prim) {\n",
        "-  StridedSliceParameter *strided_slice_param =\n",
        "-    reinterpret_cast<StridedSliceParameter *>(malloc(sizeof(StridedSliceParameter)));\n",
        "-  if (strided_slice_param == nullptr) {\n",
        "-    MS_LOG(ERROR) << \"malloc StridedSliceParameter failed.\";\n",
        "-    return nullptr;\n",
        "-  }\n",
        "-  memset(strided_slice_param, 0, sizeof(StridedSliceParameter));\n",
        "-\n",
        "-  auto primitive = static_cast<const schema::Primitive *>(prim);\n",
        "-  auto value = primitive->value_as_StridedSliceGrad();\n",
        "-  strided_slice_param->op_parameter_.type_ = primitive->value_type();\n",
        "-\n",
        "-  strided_slice_param->begins_mask_ = value->begin_mask();\n",
        "-  strided_slice_param->ends_mask_ = value->end_mask();\n",
        "-  strided_slice_param->ellipsisMask_ = value->ellipsis_mask();\n",
        "-  strided_slice_param->newAxisMask_ = value->new_axis_mask();\n",
        "-  strided_slice_param->shrinkAxisMask_ = value->shrink_axis_mask();\n",
        "-  return reinterpret_cast<OpParameter *>(strided_slice_param);\n",
        "-}\n",
        "-\n",
        " void PopulateTrainParameters() {\n",
        "   lite::Registry ApplyMomentumParameterRegistry(schema::PrimitiveType_ApplyMomentum, PopulateApplyMomentumParameter,\n",
        "                                                 lite::SCHEMA_CUR);\n",
        "-  lite::Registry BiasGradParameterRegistry(schema::PrimitiveType_BiasAddGrad, PopulateBiasGradParameter,\n",
        "-                                           lite::SCHEMA_CUR);\n",
        "   lite::Registry SoftmaxCrossEntropyParameterRegistry(schema::PrimitiveType_SoftmaxCrossEntropyWithLogits,\n",
        "                                                       PopulateSoftmaxCrossEntropyParameter, lite::SCHEMA_CUR);\n",
        "   lite::Registry SparseSoftmaxCrossEntropyParameterRegistry(schema::PrimitiveType_SparseSoftmaxCrossEntropyWithLogits,\n",
        "@@ -469,10 +347,6 @@ void PopulateTrainParameters() {\n",
        "                                                    PopulateConvolutionGradFilterParameter, lite::SCHEMA_CUR);\n",
        "   lite::Registry Conv2DGradInputParameterRegistry(schema::PrimitiveType_Conv2DBackpropInputFusion,\n",
        "                                                   PopulateConvolutionGradInputParameter, lite::SCHEMA_CUR);\n",
        "-  lite::Registry avgPoolParameterRegistry(schema::PrimitiveType_AvgPoolGrad, PopulateAvgPoolGradParameter,\n",
        "-                                          lite::SCHEMA_CUR);\n",
        "-  lite::Registry maxPoolParameterRegistry(schema::PrimitiveType_MaxPoolGrad, PopulateMaxPoolGradParameter,\n",
        "-                                          lite::SCHEMA_CUR);\n",
        "   lite::Registry PowerGradParameterRegistry(schema::PrimitiveType_PowerGrad, PopulatePowerGradParameter,\n",
        "                                             lite::SCHEMA_CUR);\n",
        "   lite::Registry SgdParameterRegistry(schema::PrimitiveType_SGD, PopulateSgdParameter, lite::SCHEMA_CUR);\n",
        "@@ -508,8 +382,6 @@ void PopulateTrainParameters() {\n",
        "                                                            lite::DefaultPopulateParameter, lite::SCHEMA_CUR);\n",
        "   lite::Registry FlattenGradParameterRegistry(schema::PrimitiveType_FlattenGrad, lite::DefaultPopulateParameter,\n",
        "                                               lite::SCHEMA_CUR);\n",
        "-  lite::Registry StridedSliceGradParameterRegistry(schema::PrimitiveType_StridedSliceGrad,\n",
        "-                                                   PopulateStridedSliceGradParameter, lite::SCHEMA_CUR);\n",
        "   lite::Registry SqrtGradParameterRegistry(schema::PrimitiveType_SqrtGrad, lite::DefaultPopulateParameter,\n",
        "                                            lite::SCHEMA_CUR);\n",
        "   lite::Registry RsqrtGradParameterRegistry(schema::PrimitiveType_RsqrtGrad, lite::DefaultPopulateParameter,\n",
        "diff --git a/mindspore/lite/src/train/train_populate_parameter_v0.cc b/mindspore/lite/src/train/train_populate_parameter_v0.cc\n",
        "index 44b19b1..8f52614 100644\n",
        "--- a/mindspore/lite/src/train/train_populate_parameter_v0.cc\n",
        "+++ b/mindspore/lite/src/train/train_populate_parameter_v0.cc\n",
        "@@ -585,7 +585,6 @@ OpParameter *PopulateArithmeticGradParameter(const void *primitive) {\n",
        "   }\n",
        "   return reinterpret_cast<OpParameter *>(arithmetic_param);\n",
        " }\n",
        "-\n",
        " }  // namespace\n",
        " \n",
        " void PopulateTrainV0Parameters() {\n",
        "@@ -658,5 +657,4 @@ void PopulateTrainV0Parameters() {\n",
        "   lite::Registry g_sigmoidCrossEntropyWithLogitsGradRegistry(\n",
        "     schema::v0::PrimitiveType_SigmoidCrossEntropyWithLogitsGrad, DefaultPopulateParameter, mindspore::lite::SCHEMA_V0);\n",
        " }\n",
        "-\n",
        " }  // namespace mindspore::kernel\n",
        "diff --git a/mindspore/lite/src/train/train_session.cc b/mindspore/lite/src/train/train_session.cc\n",
        "index 8dd5fc5..ead56e7 100644\n",
        "--- a/mindspore/lite/src/train/train_session.cc\n",
        "+++ b/mindspore/lite/src/train/train_session.cc\n",
        "@@ -38,7 +38,6 @@\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        " std::unique_ptr<char[]> ReadFileToBuf(const std::string &filename, size_t *size) {\n",
        "   std::ifstream ifs(filename);\n",
        "   if (!ifs.good()) {\n",
        "@@ -222,7 +221,7 @@ int TrainSession::SaveToFile(const std::string &filename) const {\n",
        "     return lite::RET_NULL_PTR;\n",
        "   }\n",
        "   std::ofstream ofs(filename);\n",
        "-  if ((true != ofs.good()) || (true != ofs.is_open())) {\n",
        "+  if (!ofs.good() || !ofs.is_open()) {\n",
        "     MS_LOG(ERROR) << \"Could not open file \\\"\" << filename << \"\\\" for writing\";\n",
        "     return RET_ERROR;\n",
        "   }\n",
        "@@ -276,31 +275,34 @@ void TrainSession::CompileEvalOutputs() {\n",
        "   eval_output_tensor_map_.clear();\n",
        "   eval_output_tensor_names_.clear();\n",
        "   for (auto kernel : this->train_kernels_) {\n",
        "-    if (IsLossKernel(kernel) && !(IsGradKernel(kernel))) {\n",
        "-      for (auto in_kernel : kernel->in_kernels()) {\n",
        "-        if (IsLossKernel(in_kernel) || IsGradKernel(in_kernel)) continue;\n",
        "-        // insert if not already in\n",
        "-        if (eval_output_node_map_.find(in_kernel->name()) == eval_output_node_map_.end()) {\n",
        "-          auto *ms_tensor = in_kernel->out_tensors().at(0);\n",
        "-          if (ms_tensor != nullptr) {\n",
        "-            eval_output_node_map_[in_kernel->name()].emplace_back(ms_tensor);\n",
        "-            auto index = TSFindTensor(tensors_, ms_tensor);\n",
        "-            if (index != tensors_.size()) {\n",
        "-              eval_output_tensor_map_.insert(std::make_pair(std::to_string(index), ms_tensor));\n",
        "-              if (!ms_tensor->tensor_name().empty()) {\n",
        "-                eval_output_tensor_names_.emplace_back(ms_tensor->tensor_name());\n",
        "-              } else {\n",
        "-                eval_output_tensor_names_.emplace_back(std::to_string(index));\n",
        "-              }\n",
        "-            }\n",
        "-          }\n",
        "+    if (!IsLossKernel(kernel) || IsGradKernel(kernel)) {\n",
        "+      continue;\n",
        "+    }\n",
        "+    for (auto in_kernel : kernel->in_kernels()) {\n",
        "+      if (IsLossKernel(in_kernel) || IsGradKernel(in_kernel)) continue;\n",
        "+      // insert if not already in\n",
        "+      if (eval_output_node_map_.find(in_kernel->name()) != eval_output_node_map_.end()) {\n",
        "+        continue;\n",
        "+      }\n",
        "+      auto *ms_tensor = in_kernel->out_tensors().at(0);\n",
        "+      if (ms_tensor != nullptr) {\n",
        "+        eval_output_node_map_[in_kernel->name()].emplace_back(ms_tensor);\n",
        "+        auto index = TSFindTensor(tensors_, ms_tensor);\n",
        "+        if (index == tensors_.size()) {\n",
        "+          continue;\n",
        "+        }\n",
        "+        eval_output_tensor_map_.insert(std::make_pair(std::to_string(index), ms_tensor));\n",
        "+        if (!ms_tensor->tensor_name().empty()) {\n",
        "+          eval_output_tensor_names_.emplace_back(ms_tensor->tensor_name());\n",
        "+        } else {\n",
        "+          eval_output_tensor_names_.emplace_back(std::to_string(index));\n",
        "         }\n",
        "       }\n",
        "     }\n",
        "   }\n",
        "-  if (eval_output_node_map_.size() == 0) eval_output_node_map_ = orig_output_node_map_;\n",
        "-  if (eval_output_tensor_map_.size() == 0) eval_output_tensor_map_ = orig_output_tensor_map_;\n",
        "-  if (eval_output_tensor_names_.size() == 0) eval_output_tensor_names_ = orig_output_tensor_names_;\n",
        "+  if (eval_output_node_map_.empty()) eval_output_node_map_ = orig_output_node_map_;\n",
        "+  if (eval_output_tensor_map_.empty()) eval_output_tensor_map_ = orig_output_tensor_map_;\n",
        "+  if (eval_output_tensor_names_.empty()) eval_output_tensor_names_ = orig_output_tensor_names_;\n",
        " }\n",
        " \n",
        " void TrainSession::CompileTrainOutputs() {\n",
        "@@ -328,9 +330,9 @@ void TrainSession::CompileTrainOutputs() {\n",
        "       }\n",
        "     }\n",
        "   }\n",
        "-  if (train_output_node_map_.size() == 0) train_output_node_map_ = orig_output_node_map_;\n",
        "-  if (train_output_tensor_map_.size() == 0) train_output_tensor_map_ = orig_output_tensor_map_;\n",
        "-  if (train_output_tensor_names_.size() == 0) train_output_tensor_names_ = orig_output_tensor_names_;\n",
        "+  if (train_output_node_map_.empty()) train_output_node_map_ = orig_output_node_map_;\n",
        "+  if (train_output_tensor_map_.empty()) train_output_tensor_map_ = orig_output_tensor_map_;\n",
        "+  if (train_output_tensor_names_.empty()) train_output_tensor_names_ = orig_output_tensor_names_;\n",
        " }\n",
        " \n",
        " void TrainSession::BuildInferenceKernelsRecursive(kernel::LiteKernel *kernel, std::vector<kernel::LiteKernel *> *v) {\n",
        "@@ -363,7 +365,7 @@ void TrainSession::CompileInferenceKernels() {\n",
        "     auto kernel = TSFindKernel(train_kernels_, kernel_name);\n",
        "     BuildInferenceKernelsRecursive(kernel, &inference_kernels_);\n",
        "   }\n",
        "-  if (inference_kernels_.size() == 0) {\n",
        "+  if (inference_kernels_.empty()) {\n",
        "     inference_kernels_ = this->train_kernels_;\n",
        "   }\n",
        " }\n",
        "@@ -574,5 +576,4 @@ session::TrainSession *session::TrainSession::CreateSession(const std::string &f\n",
        "   }\n",
        "   return session::TrainSession::CreateSession(buf.get(), size, context, train_mode);\n",
        " }\n",
        "-\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/train_utils.cc b/mindspore/lite/src/train/train_utils.cc\n",
        "index bf3ac8a..f0cf23f 100644\n",
        "--- a/mindspore/lite/src/train/train_utils.cc\n",
        "+++ b/mindspore/lite/src/train/train_utils.cc\n",
        "@@ -22,9 +22,12 @@\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        "+namespace {\n",
        "+constexpr int kMatrixDims = 2;\n",
        "+}  //  namespace\n",
        " float CalculateSparseClassification(tensor::MSTensor *input, tensor::MSTensor *output) {\n",
        "-  if ((input->shape().size() != 1) || (input->data_type() != kNumberTypeInt32) || (output->shape().size() != 2)) {\n",
        "+  if ((input->shape().size() != 1) || (input->data_type() != kNumberTypeInt32) ||\n",
        "+      (output->shape().size() != kMatrixDims)) {\n",
        "     MS_LOG(WARNING) << \"SparceClassification got a \" << input->shape() << \"-D input tensor, \" << output->shape()\n",
        "                     << \"-D output tensor\";\n",
        "     return 0.0;\n",
        "@@ -50,7 +53,7 @@ float CalculateSparseClassification(tensor::MSTensor *input, tensor::MSTensor *o\n",
        " }\n",
        " \n",
        " float CalculateOneHotClassification(tensor::MSTensor *input, tensor::MSTensor *output) {\n",
        "-  if ((input->shape().size() != 2) || (output->shape().size() != 2)) {\n",
        "+  if ((input->shape().size() != kMatrixDims) || (output->shape().size() != kMatrixDims)) {\n",
        "     MS_LOG(WARNING) << \"OneHotClassification got a \" << input->shape() << \"-D input tensor, \" << output->shape()\n",
        "                     << \"-D output tensor\";\n",
        "     return 0.0;\n",
        "@@ -76,10 +79,11 @@ float CalculateOneHotClassification(tensor::MSTensor *input, tensor::MSTensor *o\n",
        "         label = c;\n",
        "       }\n",
        "     }\n",
        "-    if (label == max_idx) accuracy += 1.0;\n",
        "+    if (label == max_idx) {\n",
        "+      accuracy += 1.0;\n",
        "+    }\n",
        "   }\n",
        "   return accuracy / (static_cast<float>(batch_size));\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " }  // namespace mindspore\n",
        "diff --git a/mindspore/lite/src/train/transfer_session.cc b/mindspore/lite/src/train/transfer_session.cc\n",
        "index 7be49ca..54e02ea 100644\n",
        "--- a/mindspore/lite/src/train/transfer_session.cc\n",
        "+++ b/mindspore/lite/src/train/transfer_session.cc\n",
        "@@ -26,18 +26,16 @@\n",
        " #include \"src/common/utils.h\"\n",
        " #include \"src/tensor.h\"\n",
        " #include \"src/train/loss_kernel.h\"\n",
        "-#include \"src/train/optimizer_kernel.h\"\n",
        "-#include \"src/sub_graph_kernel.h\"\n",
        "-#include \"src/train/train_populate_parameter.h\"\n",
        "-#include \"src/runtime/runtime_api.h\"\n",
        " #include \"src/executor.h\"\n",
        "-#include \"src/kernel_registry.h\"\n",
        "-#include \"src/runtime/kernel/arm/fp32_grad/convolution.h\"\n",
        " #include \"nnacl/fp32/pack_fp32.h\"\n",
        " \n",
        " namespace mindspore {\n",
        " namespace lite {\n",
        "-\n",
        "+namespace {\n",
        "+constexpr int kNHWCHDim = 2;\n",
        "+constexpr int kNHWCCDim = 3;\n",
        "+constexpr int kNHWCDims = 4;\n",
        "+}  //  namespace\n",
        " TransferSession::TransferSession(const char *model_buf_backbone, size_t size_backbone, lite::Context *context)\n",
        "     : is_valid_(false) {\n",
        "   lite_model_ = reinterpret_cast<char *>(malloc(size_backbone));\n",
        "@@ -84,23 +82,23 @@ int TransferSession::CompileTransferGraph() {\n",
        "             break;\n",
        "           }\n",
        "         }\n",
        "-        if (match == false && input->shape().size() == 4) {\n",
        "+        if (!match && input->shape().size() == kNHWCDims) {\n",
        "           int nchw2nhwc_mask[4] = {0, 3, 1, 2};\n",
        "-          nchw2nhwc_ = CompileFormatTransform(output, input, nchw2nhwc_mask, 4);\n",
        "+          nchw2nhwc_ = CompileFormatTransform(output, input, nchw2nhwc_mask, kNHWCDims);\n",
        "           match = nchw2nhwc_;\n",
        "         }\n",
        "-        if (true == match) {\n",
        "+        if (match) {\n",
        "           break;\n",
        "         }\n",
        "       }\n",
        "     }\n",
        "-    if (true == match) {\n",
        "+    if (match) {\n",
        "       backbone_head_map_.push_back(std::make_pair(input, output));\n",
        "     } else {\n",
        "       combined_inputs_.push_back(input);\n",
        "     }\n",
        "   }\n",
        "-  if (0 == backbone_head_map_.size()) {\n",
        "+  if (backbone_head_map_.empty()) {\n",
        "     ret = RET_ERROR;\n",
        "   }\n",
        "   return ret;\n",
        "@@ -110,7 +108,7 @@ mindspore::tensor::MSTensor *TransferSession::GetInputsByTensorName(const std::s\n",
        "   /* First look in backbone netwok */\n",
        "   auto ret = backbone_session_->GetInputsByTensorName(tensor_name);\n",
        "   /* If not found look in head network */\n",
        "-  if (nullptr == ret) {\n",
        "+  if (ret == nullptr) {\n",
        "     ret = TrainSession::GetInputsByTensorName(tensor_name);\n",
        "   }\n",
        "   return ret;\n",
        "@@ -142,9 +140,9 @@ int TransferSession::RunGraph(const KernelCallBack &before, const KernelCallBack\n",
        "     char *input_data = reinterpret_cast<char *>(input->MutableData());\n",
        "     char *output_data = reinterpret_cast<char *>(output->MutableData());\n",
        "     if (nchw2nhwc_) {\n",
        "-      int plane = input->shape().at(1) * input->shape().at(2);\n",
        "+      int plane = input->shape().at(1) * input->shape().at(kNHWCHDim);\n",
        "       int batch = input->shape().at(0);\n",
        "-      int channel = input->shape().at(3);\n",
        "+      int channel = input->shape().at(kNHWCCDim);\n",
        "       PackNCHWToNHWCFp32(output_data, input_data, batch, plane, channel, 0, 1);\n",
        "     } else {\n",
        "       std::copy(output_data, output_data + output->Size(), input_data);\n",
        "@@ -153,7 +151,6 @@ int TransferSession::RunGraph(const KernelCallBack &before, const KernelCallBack\n",
        "   ret = lite::TrainSession::RunGraph(before, after);\n",
        "   return ret;\n",
        " }\n",
        "-\n",
        " }  // namespace lite\n",
        " \n",
        " session::TrainSession *session::TrainSession::CreateTransferSession(const char *model_buf_backbone,\n",
        "@@ -239,5 +236,4 @@ session::TrainSession *session::TrainSession::CreateTransferSession(const std::s\n",
        "   return session::TrainSession::CreateTransferSession(buf_backbone.get(), size_backbone, buf_head.get(), size_head,\n",
        "                                                       context, train_mode);\n",
        " }\n",
        "-\n",
        " }  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}