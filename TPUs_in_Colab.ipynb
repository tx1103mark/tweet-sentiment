{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQJY3euCYdkF"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *conv_activation_fusion.h\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#include \"tools/optimizer/fusion/conv_transform_fusion.h\"\r\n",
        "#include <memory>\r\n",
        "#include \"src/ops/primitive_c.h\"\r\n",
        "#include \"src/ops/conv2d.h\"\r\n",
        "#include \"src/ops/deconv2d.h\"\r\n",
        "#include \"src/ops/depthwise_conv2d.h\"\r\n",
        "#include \"src/param_value_lite.h\"\r\n",
        "#include \"schema/inner/model_generated.h\"\r\n",
        "#include \"tools/optimizer/common/gllo_utils.h\"\r\n",
        "#include \"securec/include/securec.h\"\r\n",
        "\r\n",
        "namespace mindspore::opt {\r\n",
        "namespace {\r\n",
        "constexpr size_t kConvWeightIndex = 2;\r\n",
        "constexpr size_t kConvBiasIndex = 3;\r\n",
        "constexpr size_t kConvNoBiasLen = 3;\r\n",
        "constexpr size_t kConvWithBiasLen = 4;\r\n",
        "int Get_Kenrnel_nums(const CNodePtr &conv_node) {\r\n",
        "  MS_ASSERT(conv_node != nullptr);\r\n",
        "  auto value_primitive = conv_node->input(0);\r\n",
        "  auto value_node = value_primitive->cast<ValueNodePtr>();\r\n",
        "  MS_ASSERT(value_node != nullptr);\r\n",
        "  auto value = value_node->value();\r\n",
        "  MS_ASSERT(value != nullptr);\r\n",
        "  auto primitive = value->cast<PrimitiveCPtr>();\r\n",
        "  MS_ASSERT(primitive != nullptr);\r\n",
        "  auto type = (schema::PrimitiveType) primitive->Type();\r\n",
        "\r\n",
        "  if (type == schema::PrimitiveType_Conv2D) {\r\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::Conv2D>>(primitive));\r\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::Conv2D>>(primitive);\r\n",
        "    MS_ASSERT(primc != nullptr);\r\n",
        "    return primc->GetChannelOut();\r\n",
        "  } else if (type == schema::PrimitiveType_DeConv2D) {\r\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DeConv2D>>(primitive));\r\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::DeConv2D>>(primitive);\r\n",
        "    MS_ASSERT(primc != nullptr);\r\n",
        "    return primc->GetChannelOut();\r\n",
        "  } else if (type == schema::PrimitiveType_DepthwiseConv2D) {\r\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive));\r\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::DepthwiseConv2D>>(primitive);\r\n",
        "    MS_ASSERT(primc != nullptr);\r\n",
        "    return primc->GetChannelMultiplier() * primc->GetChannelIn();\r\n",
        "  } else {\r\n",
        "    MS_LOG(ERROR) << \"Unsupported opType, \" << type;\r\n",
        "    return 0;\r\n",
        "  }\r\n",
        "}\r\n",
        "}  // namespace\r\n",
        "\r\n",
        "const AnfNodePtr ConvTransformFusion::Process(const FuncGraphPtr &func_graph, const AnfNodePtr &node,\r\n",
        "                                              const EquivPtr &) const {\r\n",
        "  MS_LOG(DEBUG) << \"conv activation pass process\";\r\n",
        "  if (CheckIfFuncGraphIsNull(func_graph) != lite::RET_OK || CheckIfAnfNodeIsNull(node) != lite::RET_OK) {\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  // transform node means scale,bn\r\n",
        "  auto transform_node = node->cast<CNodePtr>();\r\n",
        "  if (CheckIfCNodeIsNull(transform_node) != lite::RET_OK || CheckLeastInputSize(transform_node, 2) != lite::RET_OK) {\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "\r\n",
        "  auto pre_node = transform_node->input(1);\r\n",
        "  auto conv_node = pre_node->cast<CNodePtr>();\r\n",
        "  if (IsMultiOutputTensors(func_graph, conv_node)) {\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "\r\n",
        "  auto abstr = transform_node->abstract();\r\n",
        "  int kernel_nums = Get_Kenrnel_nums(conv_node);\r\n",
        "  if (kernel_nums <= 0) {\r\n",
        "    MS_LOG(INFO) << \"Unsupported conv node, \" << conv_node->DebugString();\r\n",
        "    return node;\r\n",
        "  }\r\n",
        "  auto trans_scale = new(std::nothrow) float[kernel_nums];\r\n",
        "  if (trans_scale == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"tensor_data is nullptr\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  auto trans_bias = new(std::nothrow) float[kernel_nums];\r\n",
        "  if (trans_bias == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"tensor_data is nullptr\";\r\n",
        "    delete[] trans_scale;\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  GenTransParam(transform_node, kernel_nums, trans_scale, trans_bias);\r\n",
        "  GenNewConvTensor(func_graph, conv_node, kernel_nums, trans_scale, trans_bias);\r\n",
        "  delete[] trans_bias;\r\n",
        "  delete[] trans_scale;\r\n",
        "  pre_node->set_abstract(abstr);\r\n",
        "  return pre_node;\r\n",
        "}\r\n",
        "\r\n",
        "void ConvTransformFusion::GenTransParam(const CNodePtr &transform_node, int kernel_nums, float *trans_scale,\r\n",
        "                                        float *trans_bias) const {\r\n",
        "  if (trans_scale == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new transScale failed\";\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_NULL_PTR);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  if (trans_bias == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new transBias failed\";\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_NULL_PTR);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  if (0 != memset_s(trans_scale, kernel_nums * sizeof(float), 0, kernel_nums * sizeof(float))) {\r\n",
        "    MS_LOG(ERROR) << \"memset transScale failed\";\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  if (0 != memset_s(trans_bias, kernel_nums * sizeof(float), 0, kernel_nums * sizeof(float))) {\r\n",
        "    MS_LOG(ERROR) << \"memset transBias failed\";\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "\r\n",
        "  InitTransParam(transform_node, kernel_nums, trans_scale, trans_bias);\r\n",
        "}\r\n",
        "\r\n",
        "void ConvTransformFusion::GenNewConvTensor(const FuncGraphPtr &func_graph, const CNodePtr &conv_node, int kernel_num,\r\n",
        "                                           const float *trans_scale, const float *trans_bias) const {\r\n",
        "  MS_ASSERT(conv_node != nullptr);\r\n",
        "  AnfNodePtr conv_weight_node = nullptr;\r\n",
        "  AnfNodePtr conv_bias_node = nullptr;\r\n",
        "  if (conv_node->inputs().size() == kConvNoBiasLen) {\r\n",
        "    conv_weight_node = conv_node->input(kConvWeightIndex);\r\n",
        "  } else if (conv_node->inputs().size() == kConvWithBiasLen) {\r\n",
        "    conv_weight_node = conv_node->input(kConvWeightIndex);\r\n",
        "    conv_bias_node = conv_node->input(kConvBiasIndex);\r\n",
        "  } else {\r\n",
        "    MS_LOG(ERROR) << \"conv node:\" << conv_node->DebugString() << \"inputs size must 3 or 4\";\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  if (!conv_weight_node->isa<Parameter>()) {\r\n",
        "    MS_LOG(ERROR) << \"scale weight node not paramter node\";\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_INVALID_OP_ATTR);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  if (conv_bias_node != nullptr && !conv_bias_node->isa<Parameter>()) {\r\n",
        "    MS_LOG(ERROR) << \"scale bias node not paramter node\";\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_INVALID_OP_ATTR);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  auto conv_weight_param = conv_weight_node->cast<ParameterPtr>()->default_param();\r\n",
        "  auto weight_tensor = std::dynamic_pointer_cast<ParamValueLite>(conv_weight_param);\r\n",
        "  if (kernel_num <= 0) {\r\n",
        "    MS_LOG(ERROR) << \"kernel num less than 0\";\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_INVALID_OP_ATTR);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  CalNewWeightTensor(conv_node, weight_tensor, kernel_num, trans_scale);\r\n",
        "  float *bias_data = nullptr;\r\n",
        "  // conv has bias,bias_flag true\r\n",
        "  bool bias_flag = false;\r\n",
        "  if (conv_bias_node != nullptr) {\r\n",
        "    auto conv_bias_param = conv_bias_node->cast<ParameterPtr>()->default_param();\r\n",
        "    auto bias_tensor = std::dynamic_pointer_cast<ParamValueLite>(conv_bias_param);\r\n",
        "    bias_data = reinterpret_cast<float *>(bias_tensor->tensor_addr());\r\n",
        "    bias_flag = true;\r\n",
        "  } else {\r\n",
        "    bias_data = new(std::nothrow) float[kernel_num];\r\n",
        "    if (bias_data == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"tensor_data is nullptr\";\r\n",
        "      return;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  CalNewBiasTensor(bias_data, kernel_num, bias_flag, trans_scale, trans_bias);\r\n",
        "  if (!bias_flag) {\r\n",
        "    auto bias_node = AddNewBiasNode(bias_data, func_graph, kernel_num, weight_tensor);\r\n",
        "    bias_node->set_name(conv_node->fullname_with_scope() + \"_bias\");\r\n",
        "    conv_node->add_input(bias_node);\r\n",
        "  }\r\n",
        "}\r\n",
        "void ConvTransformFusion::CalNewWeightTensor(const CNodePtr &conv_node,\r\n",
        "                                             const ParamValueLitePtr &weight_tensor,\r\n",
        "                                             int kernel_num,\r\n",
        "                                             const float *trans_scale) const {\r\n",
        "  MS_ASSERT(weight_data != nullptr);\r\n",
        "  MS_ASSERT(trans_scale != nullptr);\r\n",
        "  auto weight_shape_size = weight_tensor->tensor_shape_size();\r\n",
        "  auto tmp_weight_data = new(std::nothrow) float[weight_shape_size];\r\n",
        "  if (tmp_weight_data == nullptr) {\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  MS_ASSERT(new_weight_data != nullptr);\r\n",
        "  auto data_size = weight_shape_size * sizeof(float);\r\n",
        "  if (0 != memset_s(tmp_weight_data, data_size, 0, data_size)) {\r\n",
        "    MS_LOG(ERROR) << \"memset newWeightData failed\";\r\n",
        "    delete[] tmp_weight_data;\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  auto weight_data = reinterpret_cast<float *>(weight_tensor->tensor_addr());\r\n",
        "  auto conv_type = GetCNodeType(conv_node);\r\n",
        "  if (conv_type == schema::PrimitiveType_DeConv2D) {\r\n",
        "    auto value_node = conv_node->input(0)->cast<ValueNodePtr>();\r\n",
        "    MS_ASSERT(value_node != nullptr);\r\n",
        "    auto value = value_node->value();\r\n",
        "    MS_ASSERT(value != nullptr);\r\n",
        "    auto primitive = value->cast<PrimitivePtr>();\r\n",
        "    MS_ASSERT(utils::isa<std::shared_ptr<mindspore::lite::DeConv2D>>(primitive));\r\n",
        "    auto primc = utils::cast<std::shared_ptr<mindspore::lite::DeConv2D>>(primitive);\r\n",
        "    MS_ASSERT(primc != nullptr);\r\n",
        "    if (weight_tensor->tensor_shape().size() != 4) {\r\n",
        "      MS_LOG(ERROR) << \"deconv2d weight tensor shape error\";\r\n",
        "      delete[] tmp_weight_data;\r\n",
        "      return;\r\n",
        "    }\r\n",
        "    auto group = primc->GetGroup();\r\n",
        "    auto cin_group = weight_tensor->tensor_shape()[0] / group;\r\n",
        "    int area_size = weight_tensor->tensor_shape()[2] * weight_tensor->tensor_shape()[3];\r\n",
        "    int cout_size = kernel_num * area_size;\r\n",
        "    for (int k = 0; k < cin_group; ++k) {\r\n",
        "      for (int i = 0; i < kernel_num; ++i) {\r\n",
        "        auto row_addr = weight_data + k * cout_size + i * area_size;\r\n",
        "        auto new_row_addr = tmp_weight_data + k * cout_size + i * area_size;\r\n",
        "        for (int j = 0; j < area_size; j++) {\r\n",
        "          new_row_addr[j] = row_addr[j] * trans_scale[i];\r\n",
        "        }\r\n",
        "      }\r\n",
        "    }\r\n",
        "  } else {\r\n",
        "    if (this->fmk_type_ == lite::converter::FmkType_TF) {\r\n",
        "      for (int i = 0; i < weight_shape_size; i++) {\r\n",
        "        tmp_weight_data[i] = weight_data[i] * trans_scale[i % kernel_num];\r\n",
        "      }\r\n",
        "    } else {\r\n",
        "      auto kernel_size = weight_shape_size / kernel_num;\r\n",
        "      for (int i = 0; i < kernel_num; i++) {\r\n",
        "        for (int j = 0; j < kernel_size; j++) {\r\n",
        "          tmp_weight_data[i * kernel_size + j] = weight_data[i * kernel_size + j] * trans_scale[i];\r\n",
        "        }\r\n",
        "      }\r\n",
        "    }\r\n",
        "  }\r\n",
        "\r\n",
        "  auto ret = memcpy_s(weight_data, data_size, tmp_weight_data, data_size);\r\n",
        "  if (ret != EOK) {\r\n",
        "    MS_LOG(ERROR) << \"memcpy error: \" << ret;\r\n",
        "    lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "    delete[] tmp_weight_data;\r\n",
        "    return;\r\n",
        "  }\r\n",
        "  delete[] tmp_weight_data;\r\n",
        "}\r\n",
        "\r\n",
        "void ConvTransformFusion::CalNewBiasTensor(float *bias_data, int kernel_num, bool bias_flag, const float *trans_scale,\r\n",
        "                                           const float *trans_bias) const {\r\n",
        "  MS_ASSERT(bias_data != nullptr);\r\n",
        "  MS_ASSERT(trans_bias != nullptr);\r\n",
        "  MS_ASSERT(trans_scale != nullptr);\r\n",
        "  if (bias_flag) {\r\n",
        "    auto tmp_bias_data = new(std::nothrow) float[kernel_num];\r\n",
        "    if (tmp_bias_data == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"tensor_data is nullptr\";\r\n",
        "      return;\r\n",
        "    }\r\n",
        "    if (EOK != memset_s(tmp_bias_data, kernel_num * sizeof(float), 0, kernel_num * sizeof(float))) {\r\n",
        "      MS_LOG(ERROR) << \"memset bias data failed\";\r\n",
        "      lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "      delete[] tmp_bias_data;\r\n",
        "      return;\r\n",
        "    }\r\n",
        "    for (int i = 0; i < kernel_num; i++) {\r\n",
        "      tmp_bias_data[i] = bias_data[i] * trans_scale[i] + trans_bias[i];\r\n",
        "    }\r\n",
        "\r\n",
        "    auto ret = memcpy_s(bias_data, kernel_num * sizeof(float), tmp_bias_data, kernel_num * sizeof(float));\r\n",
        "    delete[] tmp_bias_data;\r\n",
        "    if (ret != EOK) {\r\n",
        "      MS_LOG(ERROR) << \"memcpy error: \" << ret;\r\n",
        "      lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "      return;\r\n",
        "    }\r\n",
        "  } else {\r\n",
        "    if (EOK != memset_s(bias_data, kernel_num * sizeof(float), 0, kernel_num * sizeof(float))) {\r\n",
        "      MS_LOG(ERROR) << \"memset bias data failed\";\r\n",
        "      lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "      return;\r\n",
        "    }\r\n",
        "    auto ret = memcpy_s(bias_data, kernel_num * sizeof(float), trans_bias, kernel_num * sizeof(float));\r\n",
        "    if (ret != EOK) {\r\n",
        "      MS_LOG(ERROR) << \"memcpy error: \" << ret;\r\n",
        "      lite::ReturnCode::GetSingleReturnCode()->UpdateReturnCode(lite::RET_MEMORY_FAILED);\r\n",
        "    }\r\n",
        "  }\r\n",
        "}\r\n",
        "}  // namespace mindspore::opt\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm9nDgA4YthN"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *conv_activation_fusion.h\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#ifndef MINDSPORE_LITE_SRC_PASS_FUSION_CONV_TRANSFORM_FUSION_H_\r\n",
        "#define MINDSPORE_LITE_SRC_PASS_FUSION_CONV_TRANSFORM_FUSION_H_\r\n",
        "\r\n",
        "#include <string>\r\n",
        "#include \"backend/optimizer/common/optimizer.h\"\r\n",
        "#include \"tools/converter/converter_flags.h\"\r\n",
        "#include \"src/param_value_lite.h\"\r\n",
        "\r\n",
        "using mindspore::lite::converter::FmkType;\r\n",
        "namespace mindspore::opt {\r\n",
        "class ConvTransformFusion : public PatternProcessPass {\r\n",
        " public:\r\n",
        "  explicit ConvTransformFusion(bool multigraph = true, const std::string &name = \"conv_transform_fusion\")\r\n",
        "      : PatternProcessPass(name, multigraph) {}\r\n",
        "  ~ConvTransformFusion() override = default;\r\n",
        "  const AnfNodePtr Process(const FuncGraphPtr &, const AnfNodePtr &, const EquivPtr &) const override;\r\n",
        "  void GenTransParam(const CNodePtr &, int, float *, float *) const;\r\n",
        "  virtual void InitTransParam(const CNodePtr &, int, float *, float *) const = 0;\r\n",
        "  void GenNewConvTensor(const FuncGraphPtr &, const CNodePtr &, int, const float *, const float *) const;\r\n",
        "  void CalNewWeightTensor(const CNodePtr &conv_node,const ParamValueLitePtr &weight_tensor, int, const float *) const;\r\n",
        "  void CalNewBiasTensor(float *, int, bool, const float *, const float *) const;\r\n",
        "  void SetFmkType(FmkType type) { this->fmk_type_ = type;}\r\n",
        " private:\r\n",
        "  FmkType fmk_type_ = lite::converter::FmkType_TF;\r\n",
        "};\r\n",
        "}  // namespace mindspore::opt\r\n",
        "#endif  // MINDSPORE_LITE_SRC_PASS_FUSION_CONV_TRANSFORM_FUSION_H_\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}