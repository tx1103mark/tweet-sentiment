{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICk1D7_9C34y"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#include \"tools/benchmark/benchmark.h\"\r\n",
        "#define __STDC_FORMAT_MACROS\r\n",
        "#include <cinttypes>\r\n",
        "#undef __STDC_FORMAT_MACROS\r\n",
        "#include <algorithm>\r\n",
        "#include <utility>\r\n",
        "#include <functional>\r\n",
        "#include \"include/context.h\"\r\n",
        "#include \"include/ms_tensor.h\"\r\n",
        "#include \"include/version.h\"\r\n",
        "#include \"src/common/common.h\"\r\n",
        "#include \"src/runtime/runtime_api.h\"\r\n",
        "#ifdef ENABLE_ARM64\r\n",
        "#include <linux/perf_event.h>\r\n",
        "#include <sys/ioctl.h>\r\n",
        "#include <asm/unistd.h>\r\n",
        "#include <unistd.h>\r\n",
        "#endif\r\n",
        "\r\n",
        "namespace mindspore {\r\n",
        "namespace lite {\r\n",
        "static const char *DELIM_COLON = \":\";\r\n",
        "static const char *DELIM_COMMA = \",\";\r\n",
        "static const char *DELIM_SLASH = \"/\";\r\n",
        "\r\n",
        "int Benchmark::GenerateRandomData(size_t size, void *data, TypeId data_type) {\r\n",
        "  MS_ASSERT(data != nullptr);\r\n",
        "  switch (data_type) {\r\n",
        "    case kNumberTypeFloat32:\r\n",
        "    case kNumberTypeFloat:\r\n",
        "      FillInputData<float>(size, data, std::uniform_real_distribution<float>(0.1f, 1.0f));\r\n",
        "      break;\r\n",
        "    case kNumberTypeFloat64:\r\n",
        "      FillInputData<double>(size, data, std::uniform_real_distribution<double>(0.1, 1.0));\r\n",
        "      break;\r\n",
        "    case kNumberTypeInt64:\r\n",
        "      FillInputData<int64_t>(size, data, std::uniform_int_distribution<int64_t>(0, 1));\r\n",
        "      break;\r\n",
        "    case kNumberTypeInt:\r\n",
        "    case kNumberTypeInt32:\r\n",
        "      FillInputData<int32_t>(size, data, std::uniform_int_distribution<int32_t>(0, 1));\r\n",
        "      break;\r\n",
        "    case kNumberTypeInt16:\r\n",
        "      FillInputData<int16_t>(size, data, std::uniform_int_distribution<int16_t>(0, 1));\r\n",
        "      break;\r\n",
        "    case kNumberTypeInt8:\r\n",
        "      FillInputData<int8_t>(size, data, std::uniform_int_distribution<int8_t>(-127, 127));\r\n",
        "      break;\r\n",
        "    case kNumberTypeUInt8:\r\n",
        "      FillInputData<uint8_t>(size, data, std::uniform_int_distribution<uint8_t>(0, 254));\r\n",
        "      break;\r\n",
        "    default:\r\n",
        "      char *casted_data = static_cast<char *>(data);\r\n",
        "      for (size_t i = 0; i < size; i++) {\r\n",
        "        casted_data[i] = static_cast<char>(i);\r\n",
        "      }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::GenerateInputData() {\r\n",
        "  for (auto tensor : ms_inputs_) {\r\n",
        "    MS_ASSERT(tensor != nullptr);\r\n",
        "    auto input_data = tensor->MutableData();\r\n",
        "    if (input_data == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"MallocData for inTensor failed\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    int status;\r\n",
        "    if (tensor->data_type() == kObjectTypeString) {\r\n",
        "      status = StringsToMSTensor({\"you're the best.\"}, tensor);\r\n",
        "    } else {\r\n",
        "      status = GenerateRandomData(tensor->Size(), input_data, tensor->data_type());\r\n",
        "    }\r\n",
        "    if (status != RET_OK) {\r\n",
        "      std::cerr << \"GenerateRandomData for inTensor failed: \" << status << std::endl;\r\n",
        "      MS_LOG(ERROR) << \"GenerateRandomData for inTensor failed:\" << status;\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::LoadInput() {\r\n",
        "  if (flags_->in_data_file_.empty()) {\r\n",
        "    auto status = GenerateInputData();\r\n",
        "    if (status != 0) {\r\n",
        "      std::cerr << \"Generate input data error \" << status << std::endl;\r\n",
        "      MS_LOG(ERROR) << \"Generate input data error \" << status;\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "  } else {\r\n",
        "    auto status = ReadInputFile();\r\n",
        "    if (status != 0) {\r\n",
        "      std::cerr << \"ReadInputFile error, \" << status << std::endl;\r\n",
        "      MS_LOG(ERROR) << \"ReadInputFile error, \" << status;\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::ReadInputFile() {\r\n",
        "  if (ms_inputs_.empty()) {\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (this->flags_->in_data_type_ == kImage) {\r\n",
        "    MS_LOG(ERROR) << \"Not supported image input\";\r\n",
        "    return RET_ERROR;\r\n",
        "  } else {\r\n",
        "    for (size_t i = 0; i < flags_->input_data_list_.size(); i++) {\r\n",
        "      auto cur_tensor = ms_inputs_.at(i);\r\n",
        "      MS_ASSERT(cur_tensor != nullptr);\r\n",
        "      size_t size;\r\n",
        "      char *bin_buf = ReadFile(flags_->input_data_list_[i].c_str(), &size);\r\n",
        "      if (bin_buf == nullptr) {\r\n",
        "        MS_LOG(ERROR) << \"ReadFile return nullptr\";\r\n",
        "        return RET_ERROR;\r\n",
        "      }\r\n",
        "      if (cur_tensor->data_type() == kObjectTypeString) {\r\n",
        "        std::string str(bin_buf, size);\r\n",
        "        auto ret = StringsToMSTensor({str}, cur_tensor);\r\n",
        "        if (ret != RET_OK) {\r\n",
        "          MS_LOG(ERROR) << \"write strings to tensor failed\";\r\n",
        "          delete[] bin_buf;\r\n",
        "          return RET_ERROR;\r\n",
        "        }\r\n",
        "      } else {\r\n",
        "        auto tensor_data_size = cur_tensor->Size();\r\n",
        "        if (size != tensor_data_size) {\r\n",
        "          std::cerr << \"Input binary file size error, required: \" << tensor_data_size << \", in fact: \" << size\r\n",
        "                    << std::endl;\r\n",
        "          MS_LOG(ERROR) << \"Input binary file size error, required: \" << tensor_data_size << \", in fact: \" << size;\r\n",
        "          delete[] bin_buf;\r\n",
        "          return RET_ERROR;\r\n",
        "        }\r\n",
        "        auto input_data = cur_tensor->MutableData();\r\n",
        "        if (input_data == nullptr) {\r\n",
        "          MS_LOG(ERROR) << \"input_data is nullptr.\";\r\n",
        "          return RET_ERROR;\r\n",
        "        }\r\n",
        "        memcpy(input_data, bin_buf, tensor_data_size);\r\n",
        "      }\r\n",
        "      delete[] bin_buf;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "// calibData is FP32\r\n",
        "int Benchmark::ReadCalibData() {\r\n",
        "  const char *calib_data_path = flags_->benchmark_data_file_.c_str();\r\n",
        "  // read calib data\r\n",
        "  std::ifstream in_file(calib_data_path);\r\n",
        "  if (!in_file.good()) {\r\n",
        "    std::cerr << \"file: \" << calib_data_path << \" is not exist\" << std::endl;\r\n",
        "    MS_LOG(ERROR) << \"file: \" << calib_data_path << \" is not exist\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (!in_file.is_open()) {\r\n",
        "    std::cerr << \"file: \" << calib_data_path << \" open failed\" << std::endl;\r\n",
        "    MS_LOG(ERROR) << \"file: \" << calib_data_path << \" open failed\";\r\n",
        "    in_file.close();\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  MS_LOG(INFO) << \"Start reading calibData file\";\r\n",
        "  std::string line;\r\n",
        "  std::string tensor_name;\r\n",
        "\r\n",
        "  while (!in_file.eof()) {\r\n",
        "    getline(in_file, line);\r\n",
        "    std::stringstream string_line1(line);\r\n",
        "    size_t dim = 0;\r\n",
        "    string_line1 >> tensor_name >> dim;\r\n",
        "    std::vector<size_t> dims;\r\n",
        "    for (size_t i = 0; i < dim; i++) {\r\n",
        "      size_t tmp_dim;\r\n",
        "      string_line1 >> tmp_dim;\r\n",
        "      dims.push_back(tmp_dim);\r\n",
        "    }\r\n",
        "    auto ret = ReadTensorData(in_file, tensor_name, dims);\r\n",
        "    if (ret != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"Read tensor data failed, tensor name: \" << tensor_name;\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  in_file.close();\r\n",
        "  MS_LOG(INFO) << \"Finish reading calibData file\";\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::ReadTensorData(std::ifstream &in_file_stream, const std::string &tensor_name,\r\n",
        "                              const std::vector<size_t> &dims) {\r\n",
        "  std::string line;\r\n",
        "  getline(in_file_stream, line);\r\n",
        "  std::stringstream line_stream(line);\r\n",
        "  if (this->benchmark_data_.find(tensor_name) != this->benchmark_data_.end()) {\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "  tensor::MSTensor *tensor = GetTensorByNameOrShape(tensor_name,dims);\r\n",
        "  if (tensor == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"Get tensor failed, tensor name: \" << tensor_name;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  std::vector<float> data;\r\n",
        "  std::vector<std::string> strings_data;\r\n",
        "  size_t shape_size = std::accumulate(dims.begin(), dims.end(), 1, std::multiplies<size_t>());\r\n",
        "  if (tensor->data_type() == kObjectTypeString) {\r\n",
        "    strings_data.push_back(line);\r\n",
        "    for (size_t i = 1; i < shape_size; i++) {\r\n",
        "      getline(in_file_stream, line);\r\n",
        "      strings_data.push_back(line);\r\n",
        "    }\r\n",
        "  } else {\r\n",
        "    for (size_t i = 0; i < shape_size; i++) {\r\n",
        "      float tmp_data;\r\n",
        "      line_stream >> tmp_data;\r\n",
        "      data.push_back(tmp_data);\r\n",
        "    }\r\n",
        "  }\r\n",
        "  auto *check_tensor = new (std::nothrow) CheckTensor(dims, data, strings_data);\r\n",
        "  if (check_tensor == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"New CheckTensor failed, tensor name: \" << tensor_name;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  this->benchmark_data_.insert(std::make_pair(tensor_name, check_tensor));\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::CompareOutput() {\r\n",
        "  std::cout << \"================ Comparing Output data ================\" << std::endl;\r\n",
        "  float total_bias = 0;\r\n",
        "  int total_size = 0;\r\n",
        "  for (const auto &calib_tensor : benchmark_data_) {\r\n",
        "    std::string node_or_tensor_name = calib_tensor.first;\r\n",
        "    tensor::MSTensor *tensor = GetTensorByNameOrShape(node_or_tensor_name,calib_tensor.second->shape);\r\n",
        "    if (tensor == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"Get tensor failed, tensor name: \" << node_or_tensor_name;\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    int ret;\r\n",
        "    if (tensor->data_type() == kObjectTypeString) {\r\n",
        "      ret = CompareStringData(node_or_tensor_name, tensor);\r\n",
        "    } else {\r\n",
        "      ret = CompareDataGetTotalBiasAndSize(node_or_tensor_name, tensor, &total_bias, &total_size);\r\n",
        "    }\r\n",
        "    if (ret != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"Error in CompareData\";\r\n",
        "      std::cerr << \"Error in CompareData\" << std::endl;\r\n",
        "      std::cout << \"=======================================================\" << std::endl << std::endl;\r\n",
        "      return ret;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  float mean_bias;\r\n",
        "  if (total_size != 0) {\r\n",
        "    mean_bias = total_bias / float_t(total_size) * 100;\r\n",
        "  } else {\r\n",
        "    mean_bias = 0;\r\n",
        "  }\r\n",
        "\r\n",
        "  std::cout << \"Mean bias of all nodes/tensors: \" << mean_bias << \"%\" << std::endl;\r\n",
        "  std::cout << \"=======================================================\" << std::endl << std::endl;\r\n",
        "\r\n",
        "  if (mean_bias > this->flags_->accuracy_threshold_) {\r\n",
        "    MS_LOG(ERROR) << \"Mean bias of all nodes/tensors is too big: \" << mean_bias << \"%\";\r\n",
        "    std::cerr << \"Mean bias of all nodes/tensors is too big: \" << mean_bias << \"%\" << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "tensor::MSTensor *Benchmark::GetTensorByNodeShape(const std::vector<size_t> &node_shape) {\r\n",
        "  std::vector<tensor::MSTensor *> match_tensors;\r\n",
        "  std::vector<int> shape_vector;\r\n",
        "  (void)std::transform(node_shape.begin(), node_shape.end(), std::back_inserter(shape_vector),\r\n",
        "                       [](const size_t &value) { return static_cast<int>(value); });\r\n",
        "  auto tensors = session_->GetOutputs();\r\n",
        "  for (auto &out_tensor_pair : tensors) {\r\n",
        "    if (out_tensor_pair.second->shape() == shape_vector) {\r\n",
        "      match_tensors.emplace_back(out_tensor_pair.second);\r\n",
        "    }\r\n",
        "  }\r\n",
        "  if(match_tensors.empty() || match_tensors.size() != 1) {\r\n",
        "    MS_LOG(ERROR) << \"get tensor by node shape failed\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  return match_tensors.front();\r\n",
        "}\r\n",
        "\r\n",
        "tensor::MSTensor *Benchmark::GetTensorByNameOrShape(const std::string &node_or_tensor_name,const std::vector<size_t> &dims) {\r\n",
        "  tensor::MSTensor *tensor = nullptr;\r\n",
        "  auto tensors = session_->GetOutputsByNodeName(node_or_tensor_name);\r\n",
        "  if (tensors.empty() || tensors.size() != 1) {\r\n",
        "    MS_LOG(INFO) << \"Cannot find output node: \" << node_or_tensor_name\r\n",
        "                 << \" or node has more than one output tensor, switch to GetOutputByTensorName\";\r\n",
        "    tensor = session_->GetOutputByTensorName(node_or_tensor_name);\r\n",
        "    if(tensor == nullptr) {\r\n",
        "      return GetTensorByNodeShape(dims);\r\n",
        "    }\r\n",
        "  } else {\r\n",
        "    tensor = tensors.front();\r\n",
        "  }\r\n",
        "  return tensor;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::CompareStringData(const std::string &name, tensor::MSTensor *tensor) {\r\n",
        "  auto iter = this->benchmark_data_.find(name);\r\n",
        "  if (iter != this->benchmark_data_.end()) {\r\n",
        "    std::vector<std::string> calib_strings = iter->second->strings_data;\r\n",
        "    std::vector<std::string> output_strings = MSTensorToStrings(tensor);\r\n",
        "    size_t compare_num = std::min(calib_strings.size(), output_strings.size());\r\n",
        "    size_t print_num = std::min(compare_num, static_cast<size_t>(5));\r\n",
        "\r\n",
        "    std::cout << \"Data of node \" << name << \" : \" << std::endl;\r\n",
        "    for (size_t i = 0; i < compare_num; i++) {\r\n",
        "      if (i < print_num) {\r\n",
        "        std::cout << \"  \" << output_strings[i] << std::endl;\r\n",
        "      }\r\n",
        "      if (calib_strings[i] != output_strings[i]) {\r\n",
        "        MS_LOG(ERROR) << \"Compare failed, index: \" << i;\r\n",
        "        return RET_ERROR;\r\n",
        "      }\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::CompareDataGetTotalBiasAndSize(const std::string &name, tensor::MSTensor *tensor, float *total_bias,\r\n",
        "                                              int *total_size) {\r\n",
        "  float bias = 0;\r\n",
        "  auto mutableData = tensor->MutableData();\r\n",
        "  if (mutableData == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"mutableData is nullptr.\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  switch (tensor->data_type()) {\r\n",
        "    case TypeId::kNumberTypeFloat:\r\n",
        "    case TypeId::kNumberTypeFloat32: {\r\n",
        "      bias = CompareData<float>(name, tensor->shape(), mutableData);\r\n",
        "      break;\r\n",
        "    }\r\n",
        "    case TypeId::kNumberTypeInt8: {\r\n",
        "      bias = CompareData<int8_t>(name, tensor->shape(), mutableData);\r\n",
        "      break;\r\n",
        "    }\r\n",
        "    case TypeId::kNumberTypeUInt8: {\r\n",
        "      bias = CompareData<uint8_t>(name, tensor->shape(), mutableData);\r\n",
        "      break;\r\n",
        "    }\r\n",
        "    case TypeId::kNumberTypeInt32: {\r\n",
        "      bias = CompareData<int32_t>(name, tensor->shape(), mutableData);\r\n",
        "      break;\r\n",
        "    }\r\n",
        "    case TypeId::kNumberTypeInt16: {\r\n",
        "      bias = CompareData<int16_t>(name, tensor->shape(), mutableData);\r\n",
        "      break;\r\n",
        "    }\r\n",
        "    default:\r\n",
        "      MS_LOG(ERROR) << \"Datatype \" << msCalibDataType << \" is not supported.\";\r\n",
        "      return RET_ERROR;\r\n",
        "  }\r\n",
        "  if (bias < 0) {\r\n",
        "    MS_LOG(ERROR) << \"CompareData failed, name: \" << name;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  *total_bias += bias;\r\n",
        "  *total_size += 1;\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::MarkPerformance() {\r\n",
        "  MS_LOG(INFO) << \"Running warm up loops...\";\r\n",
        "  std::cout << \"Running warm up loops...\" << std::endl;\r\n",
        "  for (int i = 0; i < flags_->warm_up_loop_count_; i++) {\r\n",
        "    auto status = session_->RunGraph();\r\n",
        "    if (status != 0) {\r\n",
        "      MS_LOG(ERROR) << \"Inference error \" << status;\r\n",
        "      std::cerr << \"Inference error \" << status << std::endl;\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "  }\r\n",
        "\r\n",
        "  MS_LOG(INFO) << \"Running benchmark loops...\";\r\n",
        "  std::cout << \"Running benchmark loops...\" << std::endl;\r\n",
        "  uint64_t time_min = 1000000;\r\n",
        "  uint64_t time_max = 0;\r\n",
        "  uint64_t time_avg = 0;\r\n",
        "\r\n",
        "  for (int i = 0; i < flags_->loop_count_; i++) {\r\n",
        "    session_->BindThread(true);\r\n",
        "    auto start = GetTimeUs();\r\n",
        "    auto status = (flags_->time_profiling_ || flags_->perf_profiling_)\r\n",
        "                    ? session_->RunGraph(before_call_back_, after_call_back_)\r\n",
        "                    : session_->RunGraph();\r\n",
        "    if (status != 0) {\r\n",
        "      MS_LOG(ERROR) << \"Inference error \" << status;\r\n",
        "      std::cerr << \"Inference error \" << status;\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "\r\n",
        "    auto end = GetTimeUs();\r\n",
        "    auto time = end - start;\r\n",
        "    time_min = std::min(time_min, time);\r\n",
        "    time_max = std::max(time_max, time);\r\n",
        "    time_avg += time;\r\n",
        "    session_->BindThread(false);\r\n",
        "  }\r\n",
        "\r\n",
        "  if (flags_->time_profiling_) {\r\n",
        "    const std::vector<std::string> per_op_name = {\"opName\", \"avg(ms)\", \"percent\", \"calledTimes\", \"opTotalTime\"};\r\n",
        "    const std::vector<std::string> per_op_type = {\"opType\", \"avg(ms)\", \"percent\", \"calledTimes\", \"opTotalTime\"};\r\n",
        "    PrintResult(per_op_name, op_times_by_name_);\r\n",
        "    PrintResult(per_op_type, op_times_by_type_);\r\n",
        "#ifdef ENABLE_ARM64\r\n",
        "  } else if (flags_->perf_profiling_) {\r\n",
        "    if (flags_->perf_event_ == \"CACHE\") {\r\n",
        "      const std::vector<std::string> per_op_name = {\"opName\", \"cache ref(k)\", \"cache ref(%)\", \"miss(k)\", \"miss(%)\"};\r\n",
        "      const std::vector<std::string> per_op_type = {\"opType\", \"cache ref(k)\", \"cache ref(%)\", \"miss(k)\", \"miss(%)\"};\r\n",
        "      PrintPerfResult(per_op_name, op_perf_by_name_);\r\n",
        "      PrintPerfResult(per_op_type, op_perf_by_type_);\r\n",
        "    } else if (flags_->perf_event_ == \"STALL\") {\r\n",
        "      const std::vector<std::string> per_op_name = {\"opName\", \"frontend(k)\", \"frontend(%)\", \"backendend(k)\",\r\n",
        "                                                    \"backendend(%)\"};\r\n",
        "      const std::vector<std::string> per_op_type = {\"opType\", \"frontend(k)\", \"frontend(%)\", \"backendend(k)\",\r\n",
        "                                                    \"backendend(%)\"};\r\n",
        "      PrintPerfResult(per_op_name, op_perf_by_name_);\r\n",
        "      PrintPerfResult(per_op_type, op_perf_by_type_);\r\n",
        "    } else {\r\n",
        "      const std::vector<std::string> per_op_name = {\"opName\", \"cycles(k)\", \"cycles(%)\", \"ins(k)\", \"ins(%)\"};\r\n",
        "      const std::vector<std::string> per_op_type = {\"opType\", \"cycles(k)\", \"cycles(%)\", \"ins(k)\", \"ins(%)\"};\r\n",
        "      PrintPerfResult(per_op_name, op_perf_by_name_);\r\n",
        "      PrintPerfResult(per_op_type, op_perf_by_type_);\r\n",
        "    }\r\n",
        "#endif\r\n",
        "  }\r\n",
        "\r\n",
        "  if (flags_->loop_count_ > 0) {\r\n",
        "    time_avg /= flags_->loop_count_;\r\n",
        "    MS_LOG(INFO) << \"Model = \" << flags_->model_file_.substr(flags_->model_file_.find_last_of(DELIM_SLASH) + 1).c_str()\r\n",
        "                 << \", NumThreads = \" << flags_->num_threads_ << \", MinRunTime = \" << time_min / 1000.0f\r\n",
        "                 << \", MaxRuntime = \" << time_max / 1000.0f << \", AvgRunTime = \" << time_avg / 1000.0f;\r\n",
        "    printf(\"Model = %s, NumThreads = %d, MinRunTime = %f ms, MaxRuntime = %f ms, AvgRunTime = %f ms\\n\",\r\n",
        "           flags_->model_file_.substr(flags_->model_file_.find_last_of(DELIM_SLASH) + 1).c_str(), flags_->num_threads_,\r\n",
        "           time_min / 1000.0f, time_max / 1000.0f, time_avg / 1000.0f);\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::MarkAccuracy() {\r\n",
        "  MS_LOG(INFO) << \"MarkAccuracy\";\r\n",
        "  std::cout << \"MarkAccuracy\" << std::endl;\r\n",
        "\r\n",
        "  auto status = PrintInputData();\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"PrintInputData error \" << status;\r\n",
        "    std::cerr << \"PrintInputData error \" << status << std::endl;\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  status = session_->RunGraph();\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"Inference error \" << status;\r\n",
        "    std::cerr << \"Inference error \" << status << std::endl;\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  status = ReadCalibData();\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"Read calib data error \" << status;\r\n",
        "    std::cerr << \"Read calib data error \" << status << std::endl;\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  status = CompareOutput();\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"Compare output error \" << status;\r\n",
        "    std::cerr << \"Compare output error \" << status << std::endl;\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::PrintInputData() {\r\n",
        "  for (size_t i = 0; i < ms_inputs_.size(); i++) {\r\n",
        "    auto input = ms_inputs_[i];\r\n",
        "    MS_ASSERT(input != nullptr);\r\n",
        "    auto tensor_data_type = input->data_type();\r\n",
        "\r\n",
        "    std::cout << \"InData\" << i << \": \";\r\n",
        "    if (tensor_data_type == TypeId::kObjectTypeString) {\r\n",
        "      std::vector<std::string> output_strings = MSTensorToStrings(input);\r\n",
        "      size_t print_num = std::min(output_strings.size(), static_cast<size_t>(20));\r\n",
        "      for (size_t j = 0; j < print_num; j++) {\r\n",
        "        std::cout << output_strings[j] << std::endl;\r\n",
        "      }\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    size_t print_num = std::min(input->ElementsNum(), 20);\r\n",
        "    const void *in_data = input->MutableData();\r\n",
        "    if (in_data == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"in_data is nullptr.\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "\r\n",
        "    for (size_t j = 0; j < print_num; j++) {\r\n",
        "      if (tensor_data_type == TypeId::kNumberTypeFloat32 || tensor_data_type == TypeId::kNumberTypeFloat) {\r\n",
        "        std::cout << static_cast<const float *>(in_data)[j] << \" \";\r\n",
        "      } else if (tensor_data_type == TypeId::kNumberTypeInt8) {\r\n",
        "        std::cout << static_cast<const int8_t *>(in_data)[j] << \" \";\r\n",
        "      } else if (tensor_data_type == TypeId::kNumberTypeUInt8) {\r\n",
        "        std::cout << static_cast<const uint8_t *>(in_data)[j] << \" \";\r\n",
        "      } else if (tensor_data_type == TypeId::kNumberTypeInt32) {\r\n",
        "        std::cout << static_cast<const int32_t *>(in_data)[j] << \" \";\r\n",
        "      } else if (tensor_data_type == TypeId::kNumberTypeInt64) {\r\n",
        "        std::cout << static_cast<const int64_t *>(in_data)[j] << \" \";\r\n",
        "      } else {\r\n",
        "        MS_LOG(ERROR) << \"Datatype: \" << tensor_data_type << \" is not supported.\";\r\n",
        "        return RET_ERROR;\r\n",
        "      }\r\n",
        "    }\r\n",
        "    std::cout << std::endl;\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::RunBenchmark() {\r\n",
        "  auto start_prepare_time = GetTimeUs();\r\n",
        "  // Load graph\r\n",
        "  std::string model_name = flags_->model_file_.substr(flags_->model_file_.find_last_of(DELIM_SLASH) + 1);\r\n",
        "\r\n",
        "  MS_LOG(INFO) << \"start reading model file\";\r\n",
        "  std::cout << \"start reading model file\" << std::endl;\r\n",
        "  size_t size = 0;\r\n",
        "  char *graph_buf = ReadFile(flags_->model_file_.c_str(), &size);\r\n",
        "  if (graph_buf == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"Read model file failed while running \" << model_name.c_str();\r\n",
        "    std::cerr << \"Read model file failed while running \" << model_name.c_str() << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto model = std::shared_ptr<Model>(lite::Model::Import(graph_buf, size));\r\n",
        "  delete[](graph_buf);\r\n",
        "  if (model == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"Import model file failed while running \" << model_name.c_str();\r\n",
        "    std::cerr << \"Import model file failed while running \" << model_name.c_str() << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto context = std::make_shared<Context>();\r\n",
        "  if (context == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"New context failed while running \" << model_name.c_str();\r\n",
        "    std::cerr << \"New context failed while running \" << model_name.c_str() << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  auto &cpu_device_ctx = context->device_list_[0];\r\n",
        "  if (flags_->cpu_bind_mode_ == MID_CPU) {\r\n",
        "    cpu_device_ctx.device_info_.cpu_device_info_.cpu_bind_mode_ = MID_CPU;\r\n",
        "  } else if (flags_->cpu_bind_mode_ == HIGHER_CPU) {\r\n",
        "    cpu_device_ctx.device_info_.cpu_device_info_.cpu_bind_mode_ = HIGHER_CPU;\r\n",
        "  } else {\r\n",
        "    cpu_device_ctx.device_info_.cpu_device_info_.cpu_bind_mode_ = NO_BIND;\r\n",
        "  }\r\n",
        "  cpu_device_ctx.device_info_.cpu_device_info_.enable_float16_ = flags_->enable_fp16_;\r\n",
        "\r\n",
        "  if (flags_->device_ == \"GPU\") {\r\n",
        "    DeviceContext gpu_device_ctx{DT_GPU, {false}};\r\n",
        "    gpu_device_ctx.device_info_.gpu_device_info_.enable_float16_ = flags_->enable_fp16_;\r\n",
        "    context->device_list_.push_back(gpu_device_ctx);\r\n",
        "  }\r\n",
        "\r\n",
        "  if (flags_->device_ == \"NPU\") {\r\n",
        "    DeviceContext npu_device_ctx{DT_NPU};\r\n",
        "    npu_device_ctx.device_info_.npu_device_info_.frequency_ = 3;\r\n",
        "    context->device_list_.push_back(npu_device_ctx);\r\n",
        "  }\r\n",
        "\r\n",
        "  context->thread_num_ = flags_->num_threads_;\r\n",
        "\r\n",
        "  session_ = session::LiteSession::CreateSession(context.get());\r\n",
        "  if (session_ == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"CreateSession failed while running \", model_name.c_str();\r\n",
        "    std::cout << \"CreateSession failed while running \", model_name.c_str();\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto ret = session_->CompileGraph(model.get());\r\n",
        "  if (ret != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"CompileGraph failed while running \", model_name.c_str();\r\n",
        "    std::cout << \"CompileGraph failed while running \", model_name.c_str();\r\n",
        "    return ret;\r\n",
        "  }\r\n",
        "  if (!flags_->resize_dims_.empty()) {\r\n",
        "    ret = session_->Resize(session_->GetInputs(), flags_->resize_dims_);\r\n",
        "    if (ret != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"Input tensor resize failed.\";\r\n",
        "      std::cout << \"Input tensor resize failed.\";\r\n",
        "      return ret;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  if (model != nullptr) {\r\n",
        "    model->Free();\r\n",
        "  }\r\n",
        "  ms_inputs_ = session_->GetInputs();\r\n",
        "  auto end_prepare_time = GetTimeUs();\r\n",
        "  MS_LOG(INFO) << \"PrepareTime = \" << (end_prepare_time - start_prepare_time) / 1000 << \" ms\";\r\n",
        "  std::cout << \"PrepareTime = \" << (end_prepare_time - start_prepare_time) / 1000 << \" ms\" << std::endl;\r\n",
        "\r\n",
        "  // Load input\r\n",
        "  MS_LOG(INFO) << \"start generate input data\";\r\n",
        "  auto status = LoadInput();\r\n",
        "  if (status != 0) {\r\n",
        "    MS_LOG(ERROR) << \"Generate input data error\";\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  if (!flags_->benchmark_data_file_.empty()) {\r\n",
        "    status = MarkAccuracy();\r\n",
        "    for (auto &data : benchmark_data_) {\r\n",
        "      data.second->shape.clear();\r\n",
        "      data.second->data.clear();\r\n",
        "      delete data.second;\r\n",
        "      data.second = nullptr;\r\n",
        "    }\r\n",
        "    benchmark_data_.clear();\r\n",
        "    if (status != 0) {\r\n",
        "      MS_LOG(ERROR) << \"Run MarkAccuracy error: \" << status;\r\n",
        "      std::cout << \"Run MarkAccuracy error: \" << status << std::endl;\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "  } else {\r\n",
        "    status = MarkPerformance();\r\n",
        "    if (status != 0) {\r\n",
        "      MS_LOG(ERROR) << \"Run MarkPerformance error: \" << status;\r\n",
        "      std::cout << \"Run MarkPerformance error: \" << status << std::endl;\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "void BenchmarkFlags::InitInputDataList() {\r\n",
        "  char *input_list = new char[this->in_data_file_.length() + 1];\r\n",
        "  snprintf(input_list, this->in_data_file_.length() + 1, \"%s\", this->in_data_file_.c_str());\r\n",
        "  char *cur_input;\r\n",
        "  const char *split_c = \",\";\r\n",
        "  cur_input = strtok(input_list, split_c);\r\n",
        "  while (cur_input != nullptr) {\r\n",
        "    input_data_list_.emplace_back(cur_input);\r\n",
        "    cur_input = strtok(nullptr, split_c);\r\n",
        "  }\r\n",
        "  delete[] input_list;\r\n",
        "}\r\n",
        "\r\n",
        "void BenchmarkFlags::InitResizeDimsList() {\r\n",
        "  std::string content;\r\n",
        "  content = this->resize_dims_in_;\r\n",
        "  std::vector<int> shape;\r\n",
        "  auto shape_strs = StringSplit(content, std::string(DELIM_COLON));\r\n",
        "  for (const auto &shape_str : shape_strs) {\r\n",
        "    shape.clear();\r\n",
        "    auto dim_strs = StringSplit(shape_str, std::string(DELIM_COMMA));\r\n",
        "    std::cout << \"Resize Dims: \";\r\n",
        "    for (const auto &dim_str : dim_strs) {\r\n",
        "      std::cout << dim_str << \" \";\r\n",
        "      shape.emplace_back(static_cast<int>(std::stoi(dim_str)));\r\n",
        "    }\r\n",
        "    std::cout << std::endl;\r\n",
        "    this->resize_dims_.emplace_back(shape);\r\n",
        "  }\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::InitCallbackParameter() {\r\n",
        "  if (flags_->time_profiling_) {\r\n",
        "    // before callback\r\n",
        "    before_call_back_ = [&](const std::vector<mindspore::tensor::MSTensor *> &before_inputs,\r\n",
        "                            const std::vector<mindspore::tensor::MSTensor *> &before_outputs,\r\n",
        "                            const CallBackParam &callParam) {\r\n",
        "      if (before_inputs.empty()) {\r\n",
        "        MS_LOG(INFO) << \"The num of beforeInputs is empty\";\r\n",
        "      }\r\n",
        "      if (before_outputs.empty()) {\r\n",
        "        MS_LOG(INFO) << \"The num of beforeOutputs is empty\";\r\n",
        "      }\r\n",
        "      if (op_times_by_type_.find(callParam.node_type) == op_times_by_type_.end()) {\r\n",
        "        op_times_by_type_.insert(std::make_pair(callParam.node_type, std::make_pair(0, 0.0f)));\r\n",
        "      }\r\n",
        "      if (op_times_by_name_.find(callParam.node_name) == op_times_by_name_.end()) {\r\n",
        "        op_times_by_name_.insert(std::make_pair(callParam.node_name, std::make_pair(0, 0.0f)));\r\n",
        "      }\r\n",
        "\r\n",
        "      op_call_times_total_++;\r\n",
        "      op_begin_ = GetTimeUs();\r\n",
        "      return true;\r\n",
        "    };\r\n",
        "\r\n",
        "    // after callback\r\n",
        "    after_call_back_ = [&](const std::vector<mindspore::tensor::MSTensor *> &after_inputs,\r\n",
        "                           const std::vector<mindspore::tensor::MSTensor *> &after_outputs,\r\n",
        "                           const CallBackParam &call_param) {\r\n",
        "      uint64_t opEnd = GetTimeUs();\r\n",
        "\r\n",
        "      if (after_inputs.empty()) {\r\n",
        "        MS_LOG(INFO) << \"The num of after inputs is empty\";\r\n",
        "      }\r\n",
        "      if (after_outputs.empty()) {\r\n",
        "        MS_LOG(INFO) << \"The num of after outputs is empty\";\r\n",
        "      }\r\n",
        "\r\n",
        "      float cost = static_cast<float>(opEnd - op_begin_) / 1000.0f;\r\n",
        "      op_cost_total_ += cost;\r\n",
        "      op_times_by_type_[call_param.node_type].first++;\r\n",
        "      op_times_by_type_[call_param.node_type].second += cost;\r\n",
        "      op_times_by_name_[call_param.node_name].first++;\r\n",
        "      op_times_by_name_[call_param.node_name].second += cost;\r\n",
        "      return true;\r\n",
        "    };\r\n",
        "  } else if (flags_->perf_profiling_) {\r\n",
        "#ifndef ENABLE_ARM64\r\n",
        "    MS_LOG(ERROR) << \"Only support perf_profiling on arm64.\";\r\n",
        "    return RET_ERROR;\r\n",
        "#else\r\n",
        "    struct perf_event_attr pe, pe2;\r\n",
        "    memset(&pe, 0, sizeof(struct perf_event_attr));\r\n",
        "    memset(&pe2, 0, sizeof(struct perf_event_attr));\r\n",
        "    pe.type = PERF_TYPE_HARDWARE;\r\n",
        "    pe2.type = PERF_TYPE_HARDWARE;\r\n",
        "    pe.size = sizeof(struct perf_event_attr);\r\n",
        "    pe2.size = sizeof(struct perf_event_attr);\r\n",
        "    pe.disabled = 1;\r\n",
        "    pe2.disabled = 1;\r\n",
        "    pe.exclude_kernel = 1;   // don't count kernel\r\n",
        "    pe2.exclude_kernel = 1;  // don't count kernel\r\n",
        "    pe.exclude_hv = 1;       // don't count hypervisor\r\n",
        "    pe2.exclude_hv = 1;      // don't count hypervisor\r\n",
        "    pe.read_format = PERF_FORMAT_GROUP | PERF_FORMAT_ID;\r\n",
        "    pe2.read_format = PERF_FORMAT_GROUP | PERF_FORMAT_ID;\r\n",
        "    if (flags_->perf_event_ == \"CACHE\") {\r\n",
        "      pe.config = PERF_COUNT_HW_CACHE_REFERENCES;\r\n",
        "      pe2.config = PERF_COUNT_HW_CACHE_MISSES;\r\n",
        "    } else if (flags_->perf_event_ == \"STALL\") {\r\n",
        "      pe.config = PERF_COUNT_HW_STALLED_CYCLES_FRONTEND;\r\n",
        "      pe2.config = PERF_COUNT_HW_STALLED_CYCLES_BACKEND;\r\n",
        "    } else {\r\n",
        "      pe.config = PERF_COUNT_HW_CPU_CYCLES;\r\n",
        "      pe2.config = PERF_COUNT_HW_INSTRUCTIONS;\r\n",
        "    }\r\n",
        "    perf_fd = syscall(__NR_perf_event_open, pe, 0, -1, -1, 0);\r\n",
        "    if (perf_fd == -1) {\r\n",
        "      MS_LOG(ERROR) << \"Failed to open perf event \" << pe.config;\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    perf_fd2 = syscall(__NR_perf_event_open, pe2, 0, -1, perf_fd, 0);\r\n",
        "    if (perf_fd2 == -1) {\r\n",
        "      MS_LOG(ERROR) << \"Failed to open perf event \" << pe2.config;\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    struct PerfCount zero;\r\n",
        "    zero.value[0] = 0;\r\n",
        "    zero.value[1] = 0;\r\n",
        "    // before callback\r\n",
        "    before_call_back_ = [&](const std::vector<mindspore::tensor::MSTensor *> &before_inputs,\r\n",
        "                            const std::vector<mindspore::tensor::MSTensor *> &before_outputs,\r\n",
        "                            const CallBackParam &callParam) {\r\n",
        "      if (before_inputs.empty()) {\r\n",
        "        MS_LOG(INFO) << \"The num of beforeInputs is empty\";\r\n",
        "      }\r\n",
        "      if (before_outputs.empty()) {\r\n",
        "        MS_LOG(INFO) << \"The num of beforeOutputs is empty\";\r\n",
        "      }\r\n",
        "      if (op_perf_by_type_.find(callParam.node_type) == op_perf_by_type_.end()) {\r\n",
        "        op_perf_by_type_.insert(std::make_pair(callParam.node_type, std::make_pair(0, zero)));\r\n",
        "      }\r\n",
        "      if (op_perf_by_name_.find(callParam.node_name) == op_perf_by_name_.end()) {\r\n",
        "        op_perf_by_name_.insert(std::make_pair(callParam.node_name, std::make_pair(0, zero)));\r\n",
        "      }\r\n",
        "\r\n",
        "      op_call_times_total_++;\r\n",
        "      ioctl(perf_fd, PERF_EVENT_IOC_RESET, PERF_IOC_FLAG_GROUP);\r\n",
        "      ioctl(perf_fd, PERF_EVENT_IOC_ENABLE, PERF_IOC_FLAG_GROUP);\r\n",
        "      return true;\r\n",
        "    };\r\n",
        "\r\n",
        "    // after callback\r\n",
        "    after_call_back_ = [&](const std::vector<mindspore::tensor::MSTensor *> &after_inputs,\r\n",
        "                           const std::vector<mindspore::tensor::MSTensor *> &after_outputs,\r\n",
        "                           const CallBackParam &call_param) {\r\n",
        "      struct PerfResult res;\r\n",
        "      ioctl(perf_fd, PERF_EVENT_IOC_DISABLE, PERF_IOC_FLAG_GROUP);\r\n",
        "      read(perf_fd, &res, sizeof(struct PerfResult));\r\n",
        "\r\n",
        "      if (after_inputs.empty()) {\r\n",
        "        MS_LOG(INFO) << \"The num of after inputs is empty\";\r\n",
        "      }\r\n",
        "      if (after_outputs.empty()) {\r\n",
        "        MS_LOG(INFO) << \"The num of after outputs is empty\";\r\n",
        "      }\r\n",
        "      float cost1 = static_cast<float>(res.values[0].value);\r\n",
        "      float cost2 = static_cast<float>(res.values[1].value);\r\n",
        "      op_cost_total_ += cost1;\r\n",
        "      op_cost2_total_ += cost2;\r\n",
        "      op_perf_by_type_[call_param.node_type].first++;\r\n",
        "      op_perf_by_type_[call_param.node_type].second.value[0] += cost1;\r\n",
        "      op_perf_by_type_[call_param.node_type].second.value[1] += cost2;\r\n",
        "      op_perf_by_name_[call_param.node_name].first++;\r\n",
        "      op_perf_by_name_[call_param.node_name].second.value[0] += cost1;\r\n",
        "      op_perf_by_name_[call_param.node_name].second.value[1] += cost2;\r\n",
        "      return true;\r\n",
        "    };\r\n",
        "#endif\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::Init() {\r\n",
        "  if (this->flags_ == nullptr) {\r\n",
        "    return 1;\r\n",
        "  }\r\n",
        "  MS_LOG(INFO) << \"ModelPath = \" << this->flags_->model_file_;\r\n",
        "  MS_LOG(INFO) << \"InDataPath = \" << this->flags_->in_data_file_;\r\n",
        "  MS_LOG(INFO) << \"InDataType = \" << this->flags_->in_data_type_in_;\r\n",
        "  MS_LOG(INFO) << \"LoopCount = \" << this->flags_->loop_count_;\r\n",
        "  MS_LOG(INFO) << \"DeviceType = \" << this->flags_->device_;\r\n",
        "  MS_LOG(INFO) << \"AccuracyThreshold = \" << this->flags_->accuracy_threshold_;\r\n",
        "  MS_LOG(INFO) << \"WarmUpLoopCount = \" << this->flags_->warm_up_loop_count_;\r\n",
        "  MS_LOG(INFO) << \"NumThreads = \" << this->flags_->num_threads_;\r\n",
        "  MS_LOG(INFO) << \"Fp16Priority = \" << this->flags_->enable_fp16_;\r\n",
        "  MS_LOG(INFO) << \"calibDataPath = \" << this->flags_->benchmark_data_file_;\r\n",
        "  std::cout << \"ModelPath = \" << this->flags_->model_file_ << std::endl;\r\n",
        "  std::cout << \"InDataPath = \" << this->flags_->in_data_file_ << std::endl;\r\n",
        "  std::cout << \"InDataType = \" << this->flags_->in_data_type_in_ << std::endl;\r\n",
        "  std::cout << \"LoopCount = \" << this->flags_->loop_count_ << std::endl;\r\n",
        "  std::cout << \"DeviceType = \" << this->flags_->device_ << std::endl;\r\n",
        "  std::cout << \"AccuracyThreshold = \" << this->flags_->accuracy_threshold_ << std::endl;\r\n",
        "  std::cout << \"WarmUpLoopCount = \" << this->flags_->warm_up_loop_count_ << std::endl;\r\n",
        "  std::cout << \"NumThreads = \" << this->flags_->num_threads_ << std::endl;\r\n",
        "  std::cout << \"Fp16Priority = \" << this->flags_->enable_fp16_ << std::endl;\r\n",
        "  std::cout << \"calibDataPath = \" << this->flags_->benchmark_data_file_ << std::endl;\r\n",
        "  if (this->flags_->loop_count_ < 1) {\r\n",
        "    MS_LOG(ERROR) << \"LoopCount:\" << this->flags_->loop_count_ << \" must be greater than 0\";\r\n",
        "    std::cerr << \"LoopCount:\" << this->flags_->loop_count_ << \" must be greater than 0\" << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (this->flags_->num_threads_ < 1) {\r\n",
        "    MS_LOG(ERROR) << \"numThreads:\" << this->flags_->num_threads_ << \" must be greater than 0\";\r\n",
        "    std::cerr << \"numThreads:\" << this->flags_->num_threads_ << \" must be greater than 0\" << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (this->flags_->cpu_bind_mode_ == 2) {\r\n",
        "    MS_LOG(INFO) << \"cpuBindMode = MID_CPU\";\r\n",
        "    std::cout << \"cpuBindMode = MID_CPU\" << std::endl;\r\n",
        "  } else if (this->flags_->cpu_bind_mode_ == 1) {\r\n",
        "    MS_LOG(INFO) << \"cpuBindMode = HIGHER_CPU\";\r\n",
        "    std::cout << \"cpuBindMode = HIGHER_CPU\" << std::endl;\r\n",
        "  } else {\r\n",
        "    MS_LOG(INFO) << \"cpuBindMode = NO_BIND\";\r\n",
        "    std::cout << \"cpuBindMode = NO_BIND\" << std::endl;\r\n",
        "  }\r\n",
        "\r\n",
        "  this->flags_->in_data_type_ = this->flags_->in_data_type_in_ == \"img\" ? kImage : kBinary;\r\n",
        "\r\n",
        "  if (!flags_->benchmark_data_type_.empty()) {\r\n",
        "    if (data_type_map_.find(flags_->benchmark_data_type_) == data_type_map_.end()) {\r\n",
        "      MS_LOG(ERROR) << \"CalibDataType not supported: \" << flags_->benchmark_data_type_.c_str();\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    msCalibDataType = data_type_map_.at(flags_->benchmark_data_type_);\r\n",
        "    MS_LOG(INFO) << \"CalibDataType = \" << flags_->benchmark_data_type_.c_str();\r\n",
        "    std::cout << \"CalibDataType = \" << flags_->benchmark_data_type_.c_str() << std::endl;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (flags_->model_file_.empty()) {\r\n",
        "    MS_LOG(ERROR) << \"modelPath is required\";\r\n",
        "    std::cerr << \"modelPath is required\" << std::endl;\r\n",
        "    return 1;\r\n",
        "  }\r\n",
        "  flags_->InitInputDataList();\r\n",
        "  flags_->InitResizeDimsList();\r\n",
        "  if (!flags_->resize_dims_.empty() && !flags_->input_data_list_.empty() &&\r\n",
        "      flags_->resize_dims_.size() != flags_->input_data_list_.size()) {\r\n",
        "    MS_LOG(ERROR) << \"Size of input resizeDims should be equal to size of input inDataPath\";\r\n",
        "    std::cerr << \"Size of input resizeDims should be equal to size of input inDataPath\" << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (flags_->device_ != \"CPU\" && flags_->device_ != \"GPU\" && flags_->device_ != \"NPU\") {\r\n",
        "    MS_LOG(ERROR) << \"Device type:\" << flags_->device_ << \" is not supported.\";\r\n",
        "    std::cerr << \"Device type:\" << flags_->device_ << \" is not supported.\" << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (flags_->time_profiling_ || flags_->perf_profiling_) {\r\n",
        "    if (flags_->time_profiling_ && flags_->perf_profiling_) {\r\n",
        "      MS_LOG(INFO) << \"time_profiling is enabled, will not run perf_profiling.\";\r\n",
        "    }\r\n",
        "    auto status = InitCallbackParameter();\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"Init callback Parameter failed.\";\r\n",
        "      std::cerr << \"Init callback Parameter failed.\" << std::endl;\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "  }\r\n",
        "\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int Benchmark::PrintResult(const std::vector<std::string> &title,\r\n",
        "                           const std::map<std::string, std::pair<int, float>> &result) {\r\n",
        "  std::vector<size_t> columnLenMax(5);\r\n",
        "  std::vector<std::vector<std::string>> rows;\r\n",
        "\r\n",
        "  for (auto &iter : result) {\r\n",
        "    char stringBuf[5][100] = {};\r\n",
        "    std::vector<std::string> columns;\r\n",
        "    size_t len = 0;\r\n",
        "\r\n",
        "    len = iter.first.size();\r\n",
        "    if (len > columnLenMax.at(0)) {\r\n",
        "      columnLenMax.at(0) = len + 4;\r\n",
        "    }\r\n",
        "    columns.push_back(iter.first);\r\n",
        "\r\n",
        "    len = snprintf(stringBuf[1], sizeof(stringBuf[1]), \"%f\", iter.second.second / float_t(flags_->loop_count_));\r\n",
        "    if (len > columnLenMax.at(1)) {\r\n",
        "      columnLenMax.at(1) = len + 4;\r\n",
        "    }\r\n",
        "    columns.emplace_back(stringBuf[1]);\r\n",
        "\r\n",
        "    len = snprintf(stringBuf[2], sizeof(stringBuf[2]), \"%f\", iter.second.second / op_cost_total_);\r\n",
        "    if (len > columnLenMax.at(2)) {\r\n",
        "      columnLenMax.at(2) = len + 4;\r\n",
        "    }\r\n",
        "    columns.emplace_back(stringBuf[2]);\r\n",
        "\r\n",
        "    len = snprintf(stringBuf[3], sizeof(stringBuf[3]), \"%d\", iter.second.first);\r\n",
        "    if (len > columnLenMax.at(3)) {\r\n",
        "      columnLenMax.at(3) = len + 4;\r\n",
        "    }\r\n",
        "    columns.emplace_back(stringBuf[3]);\r\n",
        "\r\n",
        "    len = snprintf(stringBuf[4], sizeof(stringBuf[4]), \"%f\", iter.second.second);\r\n",
        "    if (len > columnLenMax.at(4)) {\r\n",
        "      columnLenMax.at(4) = len + 4;\r\n",
        "    }\r\n",
        "    columns.emplace_back(stringBuf[4]);\r\n",
        "\r\n",
        "    rows.push_back(columns);\r\n",
        "  }\r\n",
        "\r\n",
        "  printf(\"-------------------------------------------------------------------------\\n\");\r\n",
        "  for (int i = 0; i < 5; i++) {\r\n",
        "    auto printBuf = title[i];\r\n",
        "    if (printBuf.size() > columnLenMax.at(i)) {\r\n",
        "      columnLenMax.at(i) = printBuf.size();\r\n",
        "    }\r\n",
        "    printBuf.resize(columnLenMax.at(i), ' ');\r\n",
        "    printf(\"%s\\t\", printBuf.c_str());\r\n",
        "  }\r\n",
        "  printf(\"\\n\");\r\n",
        "  for (auto &row : rows) {\r\n",
        "    for (int j = 0; j < 5; j++) {\r\n",
        "      auto printBuf = row[j];\r\n",
        "      printBuf.resize(columnLenMax.at(j), ' ');\r\n",
        "      printf(\"%s\\t\", printBuf.c_str());\r\n",
        "    }\r\n",
        "    printf(\"\\n\");\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "#ifdef ENABLE_ARM64\r\n",
        "int Benchmark::PrintPerfResult(const std::vector<std::string> &title,\r\n",
        "                               const std::map<std::string, std::pair<int, struct PerfCount>> &result) {\r\n",
        "  std::vector<size_t> columnLenMax(5);\r\n",
        "  std::vector<std::vector<std::string>> rows;\r\n",
        "\r\n",
        "  for (auto &iter : result) {\r\n",
        "    char stringBuf[5][100] = {};\r\n",
        "    std::vector<std::string> columns;\r\n",
        "    size_t len = 0;\r\n",
        "\r\n",
        "    len = iter.first.size();\r\n",
        "    if (len > columnLenMax.at(0)) {\r\n",
        "      columnLenMax.at(0) = len + 4;\r\n",
        "    }\r\n",
        "    columns.push_back(iter.first);\r\n",
        "\r\n",
        "    float tmp = float_t(flags_->num_threads_) * iter.second.second.value[0] / float_t(flags_->loop_count_) / 1000.0f;\r\n",
        "    len = snprintf(stringBuf[1], sizeof(stringBuf[1]), \"%.2f\", tmp);\r\n",
        "    if (len > columnLenMax.at(1)) {\r\n",
        "      columnLenMax.at(1) = len + 4;\r\n",
        "    }\r\n",
        "    columns.emplace_back(stringBuf[1]);\r\n",
        "\r\n",
        "    len = snprintf(stringBuf[2], sizeof(stringBuf[2]), \"%f\", iter.second.second.value[0] / op_cost_total_);\r\n",
        "    if (len > columnLenMax.at(2)) {\r\n",
        "      columnLenMax.at(2) = len + 4;\r\n",
        "    }\r\n",
        "    columns.emplace_back(stringBuf[2]);\r\n",
        "\r\n",
        "    tmp = float_t(flags_->num_threads_) * iter.second.second.value[1] / float_t(flags_->loop_count_) / 1000.0f;\r\n",
        "    len = snprintf(stringBuf[3], sizeof(stringBuf[3]), \"%.2f\", tmp);\r\n",
        "    if (len > columnLenMax.at(3)) {\r\n",
        "      columnLenMax.at(3) = len + 4;\r\n",
        "    }\r\n",
        "    columns.emplace_back(stringBuf[3]);\r\n",
        "\r\n",
        "    len = snprintf(stringBuf[4], sizeof(stringBuf[4]), \"%f\", iter.second.second.value[1] / op_cost2_total_);\r\n",
        "    if (len > columnLenMax.at(4)) {\r\n",
        "      columnLenMax.at(4) = len + 4;\r\n",
        "    }\r\n",
        "    columns.emplace_back(stringBuf[4]);\r\n",
        "\r\n",
        "    rows.push_back(columns);\r\n",
        "  }\r\n",
        "\r\n",
        "  printf(\"-------------------------------------------------------------------------\\n\");\r\n",
        "  for (int i = 0; i < 5; i++) {\r\n",
        "    auto printBuf = title[i];\r\n",
        "    if (printBuf.size() > columnLenMax.at(i)) {\r\n",
        "      columnLenMax.at(i) = printBuf.size();\r\n",
        "    }\r\n",
        "    printBuf.resize(columnLenMax.at(i), ' ');\r\n",
        "    printf(\"%s\\t\", printBuf.c_str());\r\n",
        "  }\r\n",
        "  printf(\"\\n\");\r\n",
        "  for (auto &row : rows) {\r\n",
        "    for (int j = 0; j < 5; j++) {\r\n",
        "      auto printBuf = row[j];\r\n",
        "      printBuf.resize(columnLenMax.at(j), ' ');\r\n",
        "      printf(\"%s\\t\", printBuf.c_str());\r\n",
        "    }\r\n",
        "    printf(\"\\n\");\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "#endif\r\n",
        "\r\n",
        "Benchmark::~Benchmark() {\r\n",
        "  for (const auto &iter : this->benchmark_data_) {\r\n",
        "    delete (iter.second);\r\n",
        "  }\r\n",
        "  this->benchmark_data_.clear();\r\n",
        "  delete (session_);\r\n",
        "}\r\n",
        "\r\n",
        "int RunBenchmark(int argc, const char **argv) {\r\n",
        "  BenchmarkFlags flags;\r\n",
        "  Option<std::string> err = flags.ParseFlags(argc, argv);\r\n",
        "\r\n",
        "  if (err.IsSome()) {\r\n",
        "    std::cerr << err.Get() << std::endl;\r\n",
        "    std::cerr << flags.Usage() << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (flags.help) {\r\n",
        "    std::cerr << flags.Usage() << std::endl;\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "\r\n",
        "  Benchmark benchmark(&flags);\r\n",
        "  auto status = benchmark.Init();\r\n",
        "  if (status != 0) {\r\n",
        "    MS_LOG(ERROR) << \"Benchmark init Error : \" << status;\r\n",
        "    std::cerr << \"Benchmark init Error : \" << status << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  status = benchmark.RunBenchmark();\r\n",
        "  if (status != 0) {\r\n",
        "    MS_LOG(ERROR) << \"Run Benchmark \"\r\n",
        "                  << flags.model_file_.substr(flags.model_file_.find_last_of(DELIM_SLASH) + 1).c_str()\r\n",
        "                  << \" Failed : \" << status;\r\n",
        "    std::cerr << \"Run Benchmark \" << flags.model_file_.substr(flags.model_file_.find_last_of(DELIM_SLASH) + 1).c_str()\r\n",
        "              << \" Failed : \" << status << std::endl;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  MS_LOG(INFO) << \"Run Benchmark \" << flags.model_file_.substr(flags.model_file_.find_last_of(DELIM_SLASH) + 1).c_str()\r\n",
        "               << \" Success.\";\r\n",
        "  std::cout << \"Run Benchmark \" << flags.model_file_.substr(flags.model_file_.find_last_of(DELIM_SLASH) + 1).c_str()\r\n",
        "            << \" Success.\" << std::endl;\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "}  // namespace lite\r\n",
        "}  // namespace mindspore\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW0nXyShC79o"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#ifndef MINNIE_BENCHMARK_BENCHMARK_H_\r\n",
        "#define MINNIE_BENCHMARK_BENCHMARK_H_\r\n",
        "\r\n",
        "#include <getopt.h>\r\n",
        "#include <signal.h>\r\n",
        "#include <random>\r\n",
        "#include <unordered_map>\r\n",
        "#include <fstream>\r\n",
        "#include <iostream>\r\n",
        "#include <map>\r\n",
        "#include <cmath>\r\n",
        "#include <string>\r\n",
        "#include <vector>\r\n",
        "#include <memory>\r\n",
        "#include <cfloat>\r\n",
        "#include <utility>\r\n",
        "#include \"include/model.h\"\r\n",
        "#include \"tools/common/flag_parser.h\"\r\n",
        "#include \"src/common/file_utils.h\"\r\n",
        "#include \"src/common/utils.h\"\r\n",
        "#include \"include/lite_session.h\"\r\n",
        "\r\n",
        "namespace mindspore::lite {\r\n",
        "enum MS_API InDataType { kImage = 0, kBinary = 1 };\r\n",
        "\r\n",
        "constexpr float relativeTolerance = 1e-5;\r\n",
        "constexpr float absoluteTolerance = 1e-8;\r\n",
        "\r\n",
        "#ifdef ENABLE_ARM64\r\n",
        "struct PerfResult {\r\n",
        "  int64_t nr;\r\n",
        "  struct {\r\n",
        "    int64_t value;\r\n",
        "    int64_t id;\r\n",
        "  } values[2];\r\n",
        "};\r\n",
        "struct PerfCount {\r\n",
        "  int64_t value[2];\r\n",
        "};\r\n",
        "#endif\r\n",
        "\r\n",
        "struct MS_API CheckTensor {\r\n",
        "  CheckTensor(const std::vector<size_t> &shape, const std::vector<float> &data,\r\n",
        "              const std::vector<std::string> &strings_data = {\"\"}) {\r\n",
        "    this->shape = shape;\r\n",
        "    this->data = data;\r\n",
        "    this->strings_data = strings_data;\r\n",
        "  }\r\n",
        "  std::vector<size_t> shape;\r\n",
        "  std::vector<float> data;\r\n",
        "  std::vector<std::string> strings_data;\r\n",
        "};\r\n",
        "\r\n",
        "class MS_API BenchmarkFlags : public virtual FlagParser {\r\n",
        " public:\r\n",
        "  BenchmarkFlags() {\r\n",
        "    // common\r\n",
        "    AddFlag(&BenchmarkFlags::model_file_, \"modelFile\", \"Input model file\", \"\");\r\n",
        "    AddFlag(&BenchmarkFlags::in_data_file_, \"inDataFile\", \"Input data file, if not set, use random input\", \"\");\r\n",
        "    AddFlag(&BenchmarkFlags::device_, \"device\", \"CPU | GPU | NPU\", \"CPU\");\r\n",
        "    AddFlag(&BenchmarkFlags::cpu_bind_mode_, \"cpuBindMode\",\r\n",
        "            \"Input 0 for NO_BIND, 1 for HIGHER_CPU, 2 for MID_CPU, default value: 1\", 1);\r\n",
        "    // MarkPerformance\r\n",
        "    AddFlag(&BenchmarkFlags::loop_count_, \"loopCount\", \"Run loop count\", 10);\r\n",
        "    AddFlag(&BenchmarkFlags::num_threads_, \"numThreads\", \"Run threads number\", 2);\r\n",
        "    AddFlag(&BenchmarkFlags::enable_fp16_, \"enableFp16\", \"Enable float16\", false);\r\n",
        "    AddFlag(&BenchmarkFlags::warm_up_loop_count_, \"warmUpLoopCount\", \"Run warm up loop\", 3);\r\n",
        "    AddFlag(&BenchmarkFlags::time_profiling_, \"timeProfiling\", \"Run time profiling\", false);\r\n",
        "    AddFlag(&BenchmarkFlags::perf_profiling_, \"perfProfiling\",\r\n",
        "            \"Perf event profiling(only instructions statics enabled currently)\", false);\r\n",
        "    AddFlag(&BenchmarkFlags::perf_event_, \"perfEvent\", \"CYCLE|CACHE|STALL\", \"CYCLE\");\r\n",
        "    // MarkAccuracy\r\n",
        "    AddFlag(&BenchmarkFlags::benchmark_data_file_, \"benchmarkDataFile\", \"Benchmark data file path\", \"\");\r\n",
        "    AddFlag(&BenchmarkFlags::benchmark_data_type_, \"benchmarkDataType\",\r\n",
        "            \"Benchmark data type. FLOAT | INT32 | INT8 | UINT8\", \"FLOAT\");\r\n",
        "    AddFlag(&BenchmarkFlags::accuracy_threshold_, \"accuracyThreshold\", \"Threshold of accuracy\", 0.5);\r\n",
        "    AddFlag(&BenchmarkFlags::resize_dims_in_, \"inputShapes\",\r\n",
        "            \"Shape of input data, the format should be NHWC. e.g. 1,32,32,32:1,1,32,32,1\", \"\");\r\n",
        "  }\r\n",
        "\r\n",
        "  ~BenchmarkFlags() override = default;\r\n",
        "\r\n",
        "  void InitInputDataList();\r\n",
        "\r\n",
        "  void InitResizeDimsList();\r\n",
        "\r\n",
        " public:\r\n",
        "  // common\r\n",
        "  std::string model_file_;\r\n",
        "  std::string in_data_file_;\r\n",
        "  std::vector<std::string> input_data_list_;\r\n",
        "  InDataType in_data_type_ = kBinary;\r\n",
        "  std::string in_data_type_in_ = \"bin\";\r\n",
        "  int cpu_bind_mode_ = 1;\r\n",
        "  // MarkPerformance\r\n",
        "  int loop_count_ = 10;\r\n",
        "  int num_threads_ = 2;\r\n",
        "  bool enable_fp16_ = false;\r\n",
        "  int warm_up_loop_count_ = 3;\r\n",
        "  bool time_profiling_ = false;\r\n",
        "  bool perf_profiling_ = false;\r\n",
        "  std::string perf_event_ = \"CYCLE\";\r\n",
        "  // MarkAccuracy\r\n",
        "  std::string benchmark_data_file_;\r\n",
        "  std::string benchmark_data_type_ = \"FLOAT\";\r\n",
        "  float accuracy_threshold_ = 0.5;\r\n",
        "  // Resize\r\n",
        "  std::string resize_dims_in_;\r\n",
        "  std::vector<std::vector<int>> resize_dims_;\r\n",
        "\r\n",
        "  std::string device_ = \"CPU\";\r\n",
        "};\r\n",
        "\r\n",
        "class MS_API Benchmark {\r\n",
        " public:\r\n",
        "  explicit Benchmark(BenchmarkFlags *flags) : flags_(flags) {}\r\n",
        "\r\n",
        "  virtual ~Benchmark();\r\n",
        "\r\n",
        "  int Init();\r\n",
        "  int RunBenchmark();\r\n",
        "\r\n",
        " private:\r\n",
        "  // call GenerateInputData or ReadInputFile to init inputTensors\r\n",
        "  int LoadInput();\r\n",
        "\r\n",
        "  // call GenerateRandomData to fill inputTensors\r\n",
        "  int GenerateInputData();\r\n",
        "\r\n",
        "  int GenerateRandomData(size_t size, void *data, TypeId data_type);\r\n",
        "\r\n",
        "  int ReadInputFile();\r\n",
        "\r\n",
        "  int ReadCalibData();\r\n",
        "\r\n",
        "  int ReadTensorData(std::ifstream &in_file_stream, const std::string &tensor_name, const std::vector<size_t> &dims);\r\n",
        "\r\n",
        "  int CompareOutput();\r\n",
        "\r\n",
        "  tensor::MSTensor *GetTensorByNameOrShape(const std::string &node_or_tensor_name,const std::vector<size_t> &dims);\r\n",
        "\r\n",
        "  tensor::MSTensor *GetTensorByNodeShape(const std::vector<size_t> &node_shape);\r\n",
        "\r\n",
        "  int CompareStringData(const std::string &name, tensor::MSTensor *tensor);\r\n",
        "\r\n",
        "  int CompareDataGetTotalBiasAndSize(const std::string &name, tensor::MSTensor *tensor, float *total_bias,\r\n",
        "                                     int *total_size);\r\n",
        "\r\n",
        "  int InitCallbackParameter();\r\n",
        "\r\n",
        "  int PrintResult(const std::vector<std::string> &title, const std::map<std::string, std::pair<int, float>> &result);\r\n",
        "\r\n",
        "#ifdef ENABLE_ARM64\r\n",
        "  int PrintPerfResult(const std::vector<std::string> &title,\r\n",
        "                      const std::map<std::string, std::pair<int, struct PerfCount>> &result);\r\n",
        "#endif\r\n",
        "\r\n",
        "  int PrintInputData();\r\n",
        "\r\n",
        "  // tensorData need to be converter first\r\n",
        "  template <typename T>\r\n",
        "  float CompareData(const std::string &nodeName, const std::vector<int> &msShape, const void *tensor_data) {\r\n",
        "    const T *msTensorData = static_cast<const T *>(tensor_data);\r\n",
        "    auto iter = this->benchmark_data_.find(nodeName);\r\n",
        "    if (iter != this->benchmark_data_.end()) {\r\n",
        "      std::vector<size_t> castedMSShape;\r\n",
        "      size_t shapeSize = 1;\r\n",
        "      for (int64_t dim : msShape) {\r\n",
        "        castedMSShape.push_back(size_t(dim));\r\n",
        "        shapeSize *= dim;\r\n",
        "      }\r\n",
        "\r\n",
        "      CheckTensor *calibTensor = iter->second;\r\n",
        "      if (calibTensor->shape != castedMSShape) {\r\n",
        "        std::ostringstream oss;\r\n",
        "        oss << \"Shape of mslite output(\";\r\n",
        "        for (auto dim : castedMSShape) {\r\n",
        "          oss << dim << \",\";\r\n",
        "        }\r\n",
        "        oss << \") and shape source model output(\";\r\n",
        "        for (auto dim : calibTensor->shape) {\r\n",
        "          oss << dim << \",\";\r\n",
        "        }\r\n",
        "        oss << \") are different\";\r\n",
        "        std::cerr << oss.str() << std::endl;\r\n",
        "        MS_LOG(ERROR) << oss.str().c_str();\r\n",
        "        return RET_ERROR;\r\n",
        "      }\r\n",
        "      size_t errorCount = 0;\r\n",
        "      float meanError = 0;\r\n",
        "      std::cout << \"Data of node \" << nodeName << \" : \";\r\n",
        "      for (size_t j = 0; j < shapeSize; j++) {\r\n",
        "        if (j < 50) {\r\n",
        "          std::cout << static_cast<float>(msTensorData[j]) << \" \";\r\n",
        "        }\r\n",
        "\r\n",
        "        if (std::isnan(msTensorData[j]) || std::isinf(msTensorData[j])) {\r\n",
        "          std::cerr << \"Output tensor has nan or inf data, compare fail\" << std::endl;\r\n",
        "          MS_LOG(ERROR) << \"Output tensor has nan or inf data, compare fail\";\r\n",
        "          return RET_ERROR;\r\n",
        "        }\r\n",
        "\r\n",
        "        auto tolerance = absoluteTolerance + relativeTolerance * fabs(calibTensor->data.at(j));\r\n",
        "        auto absoluteError = std::fabs(msTensorData[j] - calibTensor->data.at(j));\r\n",
        "        if (absoluteError > tolerance) {\r\n",
        "          if (fabs(calibTensor->data.at(j) - 0.0f) < FLT_EPSILON) {\r\n",
        "            if (absoluteError > 1e-5) {\r\n",
        "              meanError += absoluteError;\r\n",
        "              errorCount++;\r\n",
        "            } else {\r\n",
        "              continue;\r\n",
        "            }\r\n",
        "          } else {\r\n",
        "            // just assume that atol = rtol\r\n",
        "            meanError += absoluteError / (fabs(calibTensor->data.at(j)) + FLT_MIN);\r\n",
        "            errorCount++;\r\n",
        "          }\r\n",
        "        }\r\n",
        "      }\r\n",
        "      std::cout << std::endl;\r\n",
        "      if (meanError > 0.0f) {\r\n",
        "        meanError /= errorCount;\r\n",
        "      }\r\n",
        "\r\n",
        "      if (meanError <= 0.0000001) {\r\n",
        "        std::cout << \"Mean bias of node/tensor \" << nodeName << \" : 0%\" << std::endl;\r\n",
        "      } else {\r\n",
        "        std::cout << \"Mean bias of node/tensor \" << nodeName << \" : \" << meanError * 100 << \"%\" << std::endl;\r\n",
        "      }\r\n",
        "      return meanError;\r\n",
        "    } else {\r\n",
        "      MS_LOG(INFO) << \"%s is not in Source Model output\", nodeName.c_str();\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "  }\r\n",
        "\r\n",
        "  template <typename T, typename Distribution>\r\n",
        "  void FillInputData(int size, void *data, Distribution distribution) {\r\n",
        "    MS_ASSERT(data != nullptr);\r\n",
        "    int elements_num = size / sizeof(T);\r\n",
        "    (void)std::generate_n(static_cast<T *>(data), elements_num,\r\n",
        "                          [&]() { return static_cast<T>(distribution(random_engine_)); });\r\n",
        "  }\r\n",
        "\r\n",
        "  int MarkPerformance();\r\n",
        "\r\n",
        "  int MarkAccuracy();\r\n",
        "\r\n",
        " private:\r\n",
        "  BenchmarkFlags *flags_;\r\n",
        "  session::LiteSession *session_{nullptr};\r\n",
        "  std::vector<mindspore::tensor::MSTensor *> ms_inputs_;\r\n",
        "  std::unordered_map<std::string, std::vector<mindspore::tensor::MSTensor *>> ms_outputs_;\r\n",
        "  std::unordered_map<std::string, CheckTensor *> benchmark_data_;\r\n",
        "  std::unordered_map<std::string, TypeId> data_type_map_{{\"FLOAT\", TypeId::kNumberTypeFloat},\r\n",
        "                                                         {\"INT8\", TypeId::kNumberTypeInt8},\r\n",
        "                                                         {\"INT32\", TypeId::kNumberTypeInt32},\r\n",
        "                                                         {\"UINT8\", TypeId::kNumberTypeUInt8}};\r\n",
        "  TypeId msCalibDataType = TypeId::kNumberTypeFloat;\r\n",
        "\r\n",
        "  // callback parameters\r\n",
        "  uint64_t op_begin_ = 0;\r\n",
        "  int op_call_times_total_ = 0;\r\n",
        "  float op_cost_total_ = 0.0f;\r\n",
        "  std::map<std::string, std::pair<int, float>> op_times_by_type_;\r\n",
        "  std::map<std::string, std::pair<int, float>> op_times_by_name_;\r\n",
        "#ifdef ENABLE_ARM64\r\n",
        "  int perf_fd = 0;\r\n",
        "  int perf_fd2 = 0;\r\n",
        "  float op_cost2_total_ = 0.0f;\r\n",
        "  std::map<std::string, std::pair<int, struct PerfCount>> op_perf_by_type_;\r\n",
        "  std::map<std::string, std::pair<int, struct PerfCount>> op_perf_by_name_;\r\n",
        "#endif\r\n",
        "  KernelCallBack before_call_back_;\r\n",
        "  KernelCallBack after_call_back_;\r\n",
        "  std::mt19937 random_engine_;\r\n",
        "};\r\n",
        "\r\n",
        "int MS_API RunBenchmark(int argc, const char **argv);\r\n",
        "}  // namespace mindspore::lite\r\n",
        "#endif  // MINNIE_BENCHMARK_BENCHMARK_H_\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}