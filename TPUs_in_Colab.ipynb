{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18a4343c030b4371b899e99d4f8c513c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97212f9b24d549d08e65ef631c788e5e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c9b0b798db64f1298760c85a57f097c",
              "IPY_MODEL_e3fe3c2345634b088bff27a09a10b640"
            ]
          }
        },
        "97212f9b24d549d08e65ef631c788e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c9b0b798db64f1298760c85a57f097c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33c8818e4b764cdcba3e4b6f52f1dbea",
            "_dom_classes": [],
            "description": "Training:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 171,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94e37f508ab34e898ec927961919de34"
          }
        },
        "e3fe3c2345634b088bff27a09a10b640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49f8aa1ae9f84e4b9a2c5177bc74ea4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/171 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c95bbed6e4ba46b18898146970ea9de6"
          }
        },
        "33c8818e4b764cdcba3e4b6f52f1dbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94e37f508ab34e898ec927961919de34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49f8aa1ae9f84e4b9a2c5177bc74ea4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c95bbed6e4ba46b18898146970ea9de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBPxeSSlAF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#include \"tools/anf_importer/import_from_protobuf.h\"\n",
        "\n",
        "#include <fcntl.h>\n",
        "#include <unistd.h>\n",
        "\n",
        "#include <fstream>\n",
        "#include <map>\n",
        "#include <memory>\n",
        "#include <stack>\n",
        "#include <unordered_map>\n",
        "#include <vector>\n",
        "#include \"src/ops/primitive_c.h\"\n",
        "#include \"frontend/operator/ops.h\"\n",
        "#include \"include/errorcode.h\"\n",
        "#include \"ir/anf.h\"\n",
        "#include \"ir/func_graph.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"securec/include/securec.h\"\n",
        "#include \"src/ir/tensor.h\"\n",
        "#include \"src/param_value_lite.h\"\n",
        "#include \"tools/converter/parser/onnx/onnx.pb.h\"\n",
        "#include \"utils/log_adapter.h\"\n",
        "#include \"tools/common/protobuf_utils.h\"\n",
        "\n",
        "using string = std::string;\n",
        "using int32 = int32_t;\n",
        "using int64 = int64_t;\n",
        "using uint64 = uint64_t;\n",
        "\n",
        "namespace mindspore::lite {\n",
        "\n",
        "static constexpr char kConstantValueNode[] = \"Constant\";\n",
        "\n",
        "enum ParseForm : int {\n",
        "  FORM_PARSE_TYPE = 0,\n",
        "  FORM_PARSE_SCALAR = 1,\n",
        "  FORM_PARSE_TENSOR = 2,\n",
        "};\n",
        "\n",
        "static std::map<std::string, ParseForm> kParseTypeSwitchMap{\n",
        "    {\"type\", FORM_PARSE_TYPE}, {\"scalar\", FORM_PARSE_SCALAR}, {\"tensor\", FORM_PARSE_TENSOR}};\n",
        "\n",
        "static std::unordered_map<int, TypeId> kDefaultValueSwitchMap{\n",
        "    {onnx::TensorProto_DataType_BOOL, kNumberTypeBool}, {onnx::TensorProto_DataType_INT8, kNumberTypeInt8},\n",
        "    {onnx::TensorProto_DataType_INT16, kNumberTypeInt16}, {onnx::TensorProto_DataType_INT32, kNumberTypeInt32},\n",
        "    {onnx::TensorProto_DataType_INT64, kNumberTypeInt64}, {onnx::TensorProto_DataType_UINT8, kNumberTypeUInt8},\n",
        "    {onnx::TensorProto_DataType_UINT16, kNumberTypeUInt16}, {onnx::TensorProto_DataType_UINT32, kNumberTypeUInt32},\n",
        "    {onnx::TensorProto_DataType_UINT64, kNumberTypeUInt64}, {onnx::TensorProto_DataType_FLOAT16, kNumberTypeFloat16},\n",
        "    {onnx::TensorProto_DataType_FLOAT, kNumberTypeFloat32}, {onnx::TensorProto_DataType_DOUBLE, kNumberTypeFloat64},\n",
        "    {onnx::TensorProto_DataType_STRING, kObjectTypeString},\n",
        "};\n",
        "\n",
        "std::shared_ptr<ValueTuple> ParserScalarAttrValue(const std::string &attr_name,\n",
        "                                                  const std::unordered_map<string, ValuePtr> &kv) {\n",
        "  std::string str = attr_name;\n",
        "  auto replace = [&](const string &orgStr, const string &newStr) {\n",
        "    std::string::size_type pos(0);\n",
        "    while ((pos = str.find(orgStr)) != std::string::npos) {\n",
        "      str.replace(pos, orgStr.length(), newStr);\n",
        "    }\n",
        "    return str;\n",
        "  };\n",
        "  // remove \"scalar:\"\n",
        "  str = replace(\"scalar:\", \"\");\n",
        "  // remove \"Tuple\"\n",
        "  str = replace(\"Tuple\", \"\");\n",
        "  // remove \"List\"\n",
        "  str = replace(\"List\", \"\");\n",
        "  std::stack<std::string> rules;\n",
        "  std::stack<ValuePtr> value;\n",
        "  int num = 0, count = 0;\n",
        "  for (size_t i = 0; i < str.length(); i++) {\n",
        "    if (str[i] == '[') {\n",
        "      rules.push(\"[\");\n",
        "    } else if (str[i] == ']') {\n",
        "      // rules\n",
        "      std::vector<ValuePtr> vec;\n",
        "      while (rules.top() != \"[\") {\n",
        "        rules.pop();\n",
        "        vec.push_back(value.top());\n",
        "        value.pop();\n",
        "      }\n",
        "      // pop \"[\"\n",
        "      rules.pop();\n",
        "      // make tuple for names\n",
        "      std::string res = \"dummy\";\n",
        "      // make tuple for values\n",
        "      reverse(vec.begin(), vec.end());\n",
        "      auto vt = std::make_shared<ValueTuple>(vec);\n",
        "      if (rules.empty() && value.empty()) {\n",
        "        return vt;\n",
        "      }\n",
        "      rules.push(res);\n",
        "      value.push(vt);\n",
        "    } else if (str[i] == ',') {\n",
        "      continue;\n",
        "    } else {\n",
        "      count++;\n",
        "      if (str[i + 1] == '[' || str[i + 1] == ']' || str[i + 1] == ',') {\n",
        "        auto value_name = str.substr(i - count + 1, count);\n",
        "        value.push(kv.at(value_name));\n",
        "        rules.push(value_name);\n",
        "        count = 0;\n",
        "        num++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  return {};\n",
        "}\n",
        "\n",
        "std::shared_ptr<abstract::AbstractTuple>\n",
        "ParserAttrShape(const std::string &attr_name, const std::unordered_map<string, abstract::AbstractTensorPtr> &kv) {\n",
        "  std::string str = attr_name;\n",
        "  auto replace = [&](const string &orgStr, const string &newStr) {\n",
        "    std::string::size_type pos(0);\n",
        "    while ((pos = str.find(orgStr)) != std::string::npos) {\n",
        "      str.replace(pos, orgStr.length(), newStr);\n",
        "    }\n",
        "    return str;\n",
        "  };\n",
        "  // remove \"scalar:\"\n",
        "  str = replace(\"shape:\", \"\");\n",
        "  // remove \"Tuple\"\n",
        "  str = replace(\"Tuple\", \"\");\n",
        "  // remove \"List\"\n",
        "  str = replace(\"List\", \"\");\n",
        "  std::stack<std::string> rules;\n",
        "  std::stack<abstract::AbstractBasePtr> value;\n",
        "  int num = 0, count = 0;\n",
        "  for (size_t i = 0; i < str.length(); i++) {\n",
        "    if (str[i] == '[') {\n",
        "      rules.push(\"[\");\n",
        "    } else if (str[i] == ']') {\n",
        "      // rules\n",
        "      std::vector<abstract::AbstractBasePtr> vec;\n",
        "      while (rules.top() != \"[\") {\n",
        "        rules.pop();\n",
        "        vec.push_back(value.top());\n",
        "        value.pop();\n",
        "      }\n",
        "      // pop \"[\"\n",
        "      rules.pop();\n",
        "      // make tuple for names\n",
        "      std::string res = \"dummy\";\n",
        "      // make tuple for values\n",
        "      reverse(vec.begin(), vec.end());\n",
        "      auto vt = std::make_shared<abstract::AbstractTuple>(vec);\n",
        "      if (rules.empty() && value.empty()) {\n",
        "        return vt;\n",
        "      }\n",
        "      rules.push(res);\n",
        "      value.push(vt);\n",
        "    } else if (str[i] == ',') {\n",
        "      continue;\n",
        "    } else {\n",
        "      count++;\n",
        "      if (str[i + 1] == '[' || str[i + 1] == ']' || str[i + 1] == ',') {\n",
        "        auto value_name = str.substr(i - count + 1, count);\n",
        "        value.push(kv.at(value_name));\n",
        "        rules.push(value_name);\n",
        "        count = 0;\n",
        "        num++;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  return {};\n",
        "}\n",
        "\n",
        "#define PARSE_ONNXATTR_IN_SCALAR_FORM(type, valuetype)                                    \\\n",
        "  ValuePtr ParseAttrInScalar_##type##_##valuetype(const onnx::TensorProto &attr_tensor) { \\\n",
        "    if (attr_tensor.type##_data_size() == 1) {                                            \\\n",
        "      auto value = static_cast<valuetype>(attr_tensor.type##_data(0));                    \\\n",
        "      return MakeValue<valuetype>(value);                                                 \\\n",
        "    } else {                                                                              \\\n",
        "      MS_LOG(ERROR) << \"size of scalar tensor doesn't equal 1!\";                          \\\n",
        "    }                                                                                     \\\n",
        "    return {};                                                                            \\\n",
        "  }\n",
        "\n",
        "PARSE_ONNXATTR_IN_SCALAR_FORM(double, double)\n",
        "PARSE_ONNXATTR_IN_SCALAR_FORM(float, float)\n",
        "PARSE_ONNXATTR_IN_SCALAR_FORM(string, string)\n",
        "PARSE_ONNXATTR_IN_SCALAR_FORM(int32, int32)\n",
        "PARSE_ONNXATTR_IN_SCALAR_FORM(int32, bool)\n",
        "PARSE_ONNXATTR_IN_SCALAR_FORM(int64, int64)\n",
        "PARSE_ONNXATTR_IN_SCALAR_FORM(uint64, uint64)\n",
        "\n",
        "bool AnfImporterFromProtobuf::BuildParameterForFuncGraph(const ParameterPtr &node,\n",
        "                                                         const onnx::ValueInfoProto &value_proto) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  if (!value_proto.has_type() || !value_proto.has_name()) {\n",
        "    MS_LOG(ERROR) << \"onnx ValueInfoProto has no type or name! \";\n",
        "    return false;\n",
        "  }\n",
        "  node->set_name(value_proto.name());\n",
        "  const auto &type_proto = value_proto.type();\n",
        "  if (!type_proto.has_tensor_type()) {\n",
        "    MS_LOG(ERROR) << \"onnx TypeProto has no tesor_type! \";\n",
        "    return false;\n",
        "  }\n",
        "  const onnx::TypeProto_Tensor &tensor_typeproto = type_proto.tensor_type();\n",
        "  if (!tensor_typeproto.has_elem_type() || !tensor_typeproto.has_shape()) {\n",
        "    MS_LOG(ERROR) << \"onnx TypeProto_Tensor has no elem_type or shape! \";\n",
        "    return false;\n",
        "  }\n",
        "  const onnx::TensorShapeProto &tensor_shape = tensor_typeproto.shape();\n",
        "  std::vector<int> shape;\n",
        "  for (int i = 0; i < tensor_shape.dim_size(); ++i) {\n",
        "    shape.push_back(tensor_shape.dim(i).dim_value());\n",
        "  }\n",
        "\n",
        "  if (kDefaultValueSwitchMap.find(tensor_typeproto.elem_type()) == kDefaultValueSwitchMap.end()) {\n",
        "    MS_LOG(ERROR) << \"onnx TypeProto_Tensor  elem_type is not support yet!\";\n",
        "    return false;\n",
        "  }\n",
        "\n",
        "  auto type_ptr = TypeIdToType(kDefaultValueSwitchMap[tensor_typeproto.elem_type()]);\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, shape);\n",
        "  node->set_abstract(abstract_tensor);\n",
        "\n",
        "  if (default_para_map_.find(value_proto.name()) != default_para_map_.end()) {\n",
        "    tensor::Tensor *tensor_info = new tensor::Tensor(kDefaultValueSwitchMap[tensor_typeproto.elem_type()], shape);\n",
        "    MS_EXCEPTION_IF_NULL(tensor_info);\n",
        "    tensor_info->MallocData();\n",
        "    const onnx::TensorProto initialize_proto = default_para_map_[value_proto.name()];\n",
        "    std::string initial_data = initialize_proto.raw_data();\n",
        "    auto *tensor_data_buf = reinterpret_cast<uint8_t *>(tensor_info->Data());\n",
        "    MS_EXCEPTION_IF_NULL(tensor_data_buf);\n",
        "    tensor_info->SetData(nullptr);\n",
        "    auto ret = memcpy_s(tensor_data_buf, tensor_info->Size(), initial_data.data(), initial_data.size());\n",
        "    if (EOK != ret) {\n",
        "      MS_LOG(ERROR) << \"memcpy_s error\";\n",
        "      delete tensor_data_buf;\n",
        "      delete tensor_info;\n",
        "      return false;\n",
        "    }\n",
        "\n",
        "    ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\n",
        "    MS_EXCEPTION_IF_NULL(param_value);\n",
        "    param_value->set_tensor_addr(tensor_data_buf);\n",
        "    param_value->set_tensor_size(tensor_info->Size());\n",
        "    param_value->set_tensor_type(tensor_info->data_type());\n",
        "    param_value->set_tensor_shape(tensor_info->shape());\n",
        "    node->set_default_param(param_value);\n",
        "    delete tensor_info;\n",
        "  }\n",
        "  anfnode_build_map_[value_proto.name()] = node;\n",
        "  return true;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::ImportParametersForGraph(const FuncGraphPtr &outputFuncGraph,\n",
        "                                                       const onnx::GraphProto &importProto) {\n",
        "  MS_EXCEPTION_IF_NULL(outputFuncGraph);\n",
        "  MS_LOG(INFO) << \"Parameters had default paramerer size is: \" << importProto.initializer_size();\n",
        "\n",
        "  for (int i = 0; i < importProto.initializer_size(); ++i) {\n",
        "    const onnx::TensorProto &initializer_proto = importProto.initializer(i);\n",
        "    if (!initializer_proto.has_name()) {\n",
        "      MS_LOG(ERROR) << \"initializer vector of onnx GraphProto has no name at index: \" << i;\n",
        "      return false;\n",
        "    }\n",
        "    default_para_map_[initializer_proto.name()] = initializer_proto;\n",
        "  }\n",
        "\n",
        "  MS_LOG(INFO) << \"all parameters size: \" << importProto.input_size();\n",
        "  for (int i = 0; i < importProto.input_size(); ++i) {\n",
        "    const onnx::ValueInfoProto &input_proto = importProto.input(i);\n",
        "    if (!BuildParameterForFuncGraph(outputFuncGraph->add_parameter(), input_proto)) {\n",
        "      MS_LOG(ERROR) << \"Build parameter for funcgraph fail at index: \" << i;\n",
        "      return false;\n",
        "    }\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::ObtainCNodeAttrInTypeForm(const PrimitivePtr &prim, const std::string &attr_name,\n",
        "                                                        const onnx::TensorProto &attr_tensor) {\n",
        "  MS_EXCEPTION_IF_NULL(prim);\n",
        "  const int attr_tensor_type = attr_tensor.data_type();\n",
        "  if (kDefaultValueSwitchMap.find(attr_tensor_type) == kDefaultValueSwitchMap.end()) {\n",
        "    MS_LOG(ERROR) << \"Obtain attr in type-form has not support input type:\" << attr_tensor_type;\n",
        "    return false;\n",
        "  }\n",
        "  prim->AddAttr(attr_name, TypeIdToType(kDefaultValueSwitchMap[attr_tensor_type]));\n",
        "  return true;\n",
        "}\n",
        "\n",
        "ValuePtr AnfImporterFromProtobuf::ObtainCNodeAttrInScalarForm(const onnx::TensorProto &attr_tensor) {\n",
        "  const int attr_tensor_type = attr_tensor.data_type();\n",
        "  switch (attr_tensor_type) {\n",
        "    case onnx::TensorProto_DataType_STRING: {\n",
        "      return ParseAttrInScalar_string_string(attr_tensor);\n",
        "      break;\n",
        "    }\n",
        "    case onnx::TensorProto_DataType_INT32: {\n",
        "      return ParseAttrInScalar_int32_int32(attr_tensor);\n",
        "    }\n",
        "    case onnx::TensorProto_DataType_INT64: {\n",
        "      return ParseAttrInScalar_int64_int64(attr_tensor);\n",
        "    }\n",
        "    case onnx::TensorProto_DataType_UINT64: {\n",
        "      return ParseAttrInScalar_uint64_uint64(attr_tensor);\n",
        "    }\n",
        "    case onnx::TensorProto_DataType_FLOAT: {\n",
        "      return ParseAttrInScalar_float_float(attr_tensor);\n",
        "    }\n",
        "    case onnx::TensorProto_DataType_DOUBLE: {\n",
        "      return ParseAttrInScalar_double_double(attr_tensor);\n",
        "    }\n",
        "    case onnx::TensorProto_DataType_BOOL: {\n",
        "      return ParseAttrInScalar_int32_bool(attr_tensor);\n",
        "    }\n",
        "    default:MS_LOG(ERROR) << \"Obtain attr in scalar-form has not support input type: \" << attr_tensor_type;\n",
        "      return {};\n",
        "  }\n",
        "  return {};\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::ObtainCNodeAttrInTensorForm(const PrimitivePtr &prim, const std::string &attr_name,\n",
        "                                                          const onnx::TensorProto &attr_tensor) {\n",
        "  MS_EXCEPTION_IF_NULL(prim);\n",
        "  const int attr_tensor_type = attr_tensor.data_type();\n",
        "  const std::string &tensor_buf = attr_tensor.raw_data();\n",
        "  std::vector<int> shape;\n",
        "  auto ret = EOK;\n",
        "  if (attr_tensor.dims_size() != 0) {\n",
        "    for (int i = 0; i < attr_tensor.dims_size(); ++i) {\n",
        "      shape.push_back(attr_tensor.dims(i));\n",
        "    }\n",
        "    tensor::TensorPtr tensor_info = std::make_shared<tensor::Tensor>(kDefaultValueSwitchMap[attr_tensor_type], shape);\n",
        "    tensor_info->MallocData();\n",
        "    auto *tensor_data_buf = reinterpret_cast<uint8_t *>(tensor_info->Data());\n",
        "    ret = memcpy_s(tensor_data_buf, tensor_info->Size(), tensor_buf.data(), tensor_buf.size());\n",
        "    prim->set_attr(attr_name, MakeValue(tensor_info));\n",
        "  } else {\n",
        "    if (attr_tensor_type == onnx::TensorProto_DataType_DOUBLE) {\n",
        "      size_t data_size = sizeof(double);\n",
        "      double attr_value = 0.0;\n",
        "      ret = memcpy_s(&attr_value, data_size, tensor_buf.data(), tensor_buf.size());\n",
        "      prim->set_attr(attr_name, MakeValue<double>(attr_value));\n",
        "    } else if (attr_tensor_type == onnx::TensorProto_DataType_INT64) {\n",
        "      size_t data_size = sizeof(int64_t);\n",
        "      int32_t attr_value = 0;\n",
        "      ret = memcpy_s(&attr_value, data_size, tensor_buf.data(), tensor_buf.size());\n",
        "      prim->set_attr(attr_name, MakeValue<int32_t>(attr_value));\n",
        "    } else if (attr_tensor_type == onnx::TensorProto_DataType_BOOL) {\n",
        "      size_t data_size = sizeof(bool);\n",
        "      bool attr_value = false;\n",
        "      ret = memcpy_s(&attr_value, data_size, tensor_buf.data(), tensor_buf.size());\n",
        "      prim->set_attr(attr_name, MakeValue<bool>(attr_value));\n",
        "    }\n",
        "  }\n",
        "  return ret == EOK;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::GetAttrValueForCNode(const PrimitivePtr &prim, const onnx::AttributeProto &attr_proto) {\n",
        "  MS_EXCEPTION_IF_NULL(prim);\n",
        "  const std::string &attr_name = attr_proto.name();\n",
        "  if (!attr_proto.has_ref_attr_name()) {\n",
        "    MS_LOG(ERROR) << \"CNode parse attr type has no ref_attr_name\";\n",
        "    return false;\n",
        "  }\n",
        "  const std::string &ref_attr_name = attr_proto.ref_attr_name();\n",
        "  string type;\n",
        "  std::size_t pos(0);\n",
        "  if ((pos = ref_attr_name.find(\"scalar:\")) != std::string::npos) {\n",
        "    type = ref_attr_name.substr(pos, string(\"scalar:\").length() - 1);\n",
        "  } else if ((pos = ref_attr_name.find(\"type:\")) != std::string::npos) {\n",
        "    type = ref_attr_name.substr(pos, string(\"type:\").length() - 1);\n",
        "  } else if ((pos = ref_attr_name.find(\"tensor:\")) != std::string::npos) {\n",
        "    type = ref_attr_name.substr(pos, string(\"tensor:\").length() - 1);\n",
        "  }\n",
        "  std::unordered_map<std::string, ValuePtr> kv;\n",
        "  for (int i = 0; i < attr_proto.tensors_size(); i++) {\n",
        "    const onnx::TensorProto &attr_tensor = attr_proto.tensors(i);\n",
        "    switch (kParseTypeSwitchMap[type]) {\n",
        "      case FORM_PARSE_TYPE: {\n",
        "        return ObtainCNodeAttrInTypeForm(prim, attr_name, attr_tensor);\n",
        "      }\n",
        "      case FORM_PARSE_SCALAR: {\n",
        "        auto res = ObtainCNodeAttrInScalarForm(attr_tensor);\n",
        "        kv.insert(std::pair<string, ValuePtr>(attr_tensor.name(), res));\n",
        "        break;\n",
        "      }\n",
        "      case FORM_PARSE_TENSOR: {\n",
        "        return ObtainCNodeAttrInTensorForm(prim, attr_name, attr_tensor);\n",
        "      }\n",
        "      default:MS_LOG(ERROR) << \"parse attr type don't support input of ref_attr_name\";\n",
        "        return false;\n",
        "    }\n",
        "  }\n",
        "  if (kParseTypeSwitchMap[type] == FORM_PARSE_SCALAR) {\n",
        "    if (kv.size() == 1) {\n",
        "      std::unordered_map<std::string, ValuePtr>::iterator iter = kv.begin();\n",
        "      prim->AddAttr(attr_name, iter->second);\n",
        "    } else {\n",
        "      auto res = ParserScalarAttrValue(ref_attr_name, kv);\n",
        "      prim->AddAttr(attr_name, res);\n",
        "    }\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::ObtainValueNodeInTensorForm(const std::string &value_node_name,\n",
        "                                                          const onnx::TensorProto &attr_tensor) {\n",
        "  const int attr_tensor_type = attr_tensor.data_type();\n",
        "  std::vector<int> shape;\n",
        "  for (int i = 0; i < attr_tensor.dims_size(); ++i) {\n",
        "    shape.push_back(attr_tensor.dims(i));\n",
        "  }\n",
        "  tensor::TensorPtr tensor_info = std::make_shared<tensor::Tensor>(kDefaultValueSwitchMap[attr_tensor_type], shape);\n",
        "  tensor_info->MallocData();\n",
        "  const std::string &tensor_buf = attr_tensor.raw_data();\n",
        "  auto *tensor_data_buf = reinterpret_cast<uint8_t *>(tensor_info->Data());\n",
        "  auto ret = memcpy_s(tensor_data_buf, tensor_info->Size(), tensor_buf.data(), tensor_buf.size());\n",
        "  if (EOK != ret) {\n",
        "    MS_LOG(ERROR) << \"memcpy_s error\";\n",
        "    return false;\n",
        "  }\n",
        "  auto new_value_node = NewValueNode(MakeValue(tensor_info));\n",
        "  MS_EXCEPTION_IF_NULL(new_value_node);\n",
        "  auto type_ptr = TypeIdToType(kDefaultValueSwitchMap[attr_tensor_type]);\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, shape);\n",
        "  new_value_node->set_abstract(abstract_tensor);\n",
        "  anfnode_build_map_[value_node_name] = new_value_node;\n",
        "  return true;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::ObtainValueNodeInTypeForm(const std::string &value_node_name,\n",
        "                                                        const onnx::TensorProto &attr_tensor) {\n",
        "  const int attr_tensor_type = attr_tensor.data_type();\n",
        "  if (kDefaultValueSwitchMap.find(attr_tensor_type) == kDefaultValueSwitchMap.end()) {\n",
        "    MS_LOG(ERROR) << \"Obtain ValueNode attr in type-form has not support input type: \" << attr_tensor_type;\n",
        "    return false;\n",
        "  }\n",
        "  auto new_value_node = NewValueNode(TypeIdToType(kDefaultValueSwitchMap[attr_tensor_type]));\n",
        "  abstract::AbstractTypePtr abs_type = std::make_shared<abstract::AbstractType>(std::make_shared<TypeType>());\n",
        "  new_value_node->set_abstract(abs_type);\n",
        "  anfnode_build_map_[value_node_name] = new_value_node;\n",
        "  return true;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::GetAttrValueForValueNode(const std::string &value_node_name,\n",
        "                                                       const onnx::AttributeProto &attr_proto) {\n",
        "  //const std::string &attr_name = attr_proto.name();\n",
        "  if (!attr_proto.has_ref_attr_name()) {\n",
        "    MS_LOG(ERROR) << \"CNode parse attr type has no ref_attr_name\";\n",
        "    return false;\n",
        "  }\n",
        "  const std::string &ref_attr_name = attr_proto.ref_attr_name();\n",
        "  string type;\n",
        "  std::size_t pos(0);\n",
        "  if ((pos = ref_attr_name.find(\"scalar:\")) != std::string::npos) {\n",
        "    type = ref_attr_name.substr(pos, string(\"scalar:\").length() - 1);\n",
        "  } else if ((pos = ref_attr_name.find(\"type:\")) != std::string::npos) {\n",
        "    type = ref_attr_name.substr(pos, string(\"type:\").length() - 1);\n",
        "  } else if ((pos = ref_attr_name.find(\"tensor:\")) != std::string::npos) {\n",
        "    type = ref_attr_name.substr(pos, string(\"tensor:\").length() - 1);\n",
        "  }\n",
        "  std::unordered_map<std::string, ValuePtr> kv;\n",
        "  for (int i = 0; i < attr_proto.tensors_size(); i++) {\n",
        "    const onnx::TensorProto &attr_tensor = attr_proto.tensors(i);\n",
        "    switch (kParseTypeSwitchMap[type]) {\n",
        "      case FORM_PARSE_TYPE: {\n",
        "        return ObtainValueNodeInTypeForm(value_node_name, attr_tensor);\n",
        "      }\n",
        "      case FORM_PARSE_SCALAR: {\n",
        "        auto res = ObtainCNodeAttrInScalarForm(attr_tensor);\n",
        "        kv.insert(std::pair<string, ValuePtr>(attr_tensor.name(), res));\n",
        "        break;\n",
        "      }\n",
        "      case FORM_PARSE_TENSOR: {\n",
        "        return ObtainValueNodeInTensorForm(value_node_name, attr_tensor);\n",
        "      }\n",
        "      default:MS_LOG(ERROR) << \"parse attr type don't support input of ref_attr_name\";\n",
        "        return false;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  ValueNodePtr new_value_node;\n",
        "  if (kParseTypeSwitchMap[type] == FORM_PARSE_SCALAR) {\n",
        "    if (kv.size() == 1) {\n",
        "      auto iter = kv.begin();\n",
        "      new_value_node = NewValueNode(iter->second);\n",
        "      new_value_node->set_abstract(iter->second->ToAbstract());\n",
        "    } else {\n",
        "      auto value_ptr = ParserScalarAttrValue(ref_attr_name, kv);\n",
        "      new_value_node = NewValueNode(value_ptr);\n",
        "      new_value_node->set_abstract(value_ptr->ToAbstract());\n",
        "    }\n",
        "    anfnode_build_map_[value_node_name] = new_value_node;\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::BuildValueNodeForFuncGraph(const onnx::NodeProto &node_proto) {\n",
        "  const std::string &value_node_name = node_proto.output(0);\n",
        "  const onnx::AttributeProto &attr_proto = node_proto.attribute(0);\n",
        "  if (!attr_proto.has_ref_attr_name()) {\n",
        "    MS_LOG(ERROR) << \"parse ValueNode  don't have ref_attr_name\";\n",
        "    return false;\n",
        "  }\n",
        "  return GetAttrValueForValueNode(value_node_name, attr_proto);\n",
        "}\n",
        "\n",
        "std::unordered_map<std::string, abstract::AbstractTensorPtr>\n",
        "AnfImporterFromProtobuf::GetAbstractForCNode(const onnx::AttributeProto &attr_proto) {\n",
        "  std::unordered_map<std::string, abstract::AbstractTensorPtr> kv;\n",
        "  for (int i = 0; i < attr_proto.tensors_size(); i++) {\n",
        "    std::vector<int> shape_vec;\n",
        "    const onnx::TensorProto &attr_tensor = attr_proto.tensors(i);\n",
        "    for (int j = 0; j < attr_tensor.dims_size(); ++j) {\n",
        "      shape_vec.push_back(attr_tensor.dims(j));\n",
        "    }\n",
        "    auto type_ptr = TypeIdToType(kDefaultValueSwitchMap[attr_tensor.data_type()]);\n",
        "    auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, shape_vec);\n",
        "    kv.insert(std::pair<string, abstract::AbstractTensorPtr>(attr_tensor.name(), abstract_tensor));\n",
        "  }\n",
        "  return kv;\n",
        "}\n",
        "\n",
        "CNodePtr AnfImporterFromProtobuf::BuildCNodeForFuncGraph(const FuncGraphPtr &outputFuncGraph,\n",
        "                                                         const onnx::NodeProto &node_proto,\n",
        "                                                         const schema::QuantType &quantType) {\n",
        "  MS_EXCEPTION_IF_NULL(outputFuncGraph);\n",
        "  if (!node_proto.has_op_type()) {\n",
        "    MS_LOG(ERROR) << \"Get CNode op_type failed!\";\n",
        "    return nullptr;\n",
        "  }\n",
        "  const std::string &node_name = node_proto.output(0);\n",
        "  const std::string &fullname_with_scope = node_proto.domain();\n",
        "  const std::string &node_type = node_proto.op_type();\n",
        "  PrimitivePtr prim = std::make_shared<mindspore::Primitive>(node_type);\n",
        "  MS_EXCEPTION_IF_NULL(prim);\n",
        "  prim->set_instance_name(node_type);\n",
        "  std::unordered_map<std::string, abstract::AbstractTensorPtr> kv;\n",
        "  string shape_ref_attr_name;\n",
        "  for (int i = 0; i < node_proto.attribute_size(); ++i) {\n",
        "    const onnx::AttributeProto &attr_proto = node_proto.attribute(i);\n",
        "    if (attr_proto.ref_attr_name().find(\"shape:\") != string::npos) {\n",
        "      shape_ref_attr_name = attr_proto.ref_attr_name();\n",
        "      kv = GetAbstractForCNode(attr_proto);\n",
        "      continue;\n",
        "    }\n",
        "    if (!GetAttrValueForCNode(prim, attr_proto)) {\n",
        "      MS_LOG(ERROR) << \"Get CNode attr failed!\";\n",
        "      return nullptr;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  std::vector<AnfNodePtr> inputs;\n",
        "  inputs.clear();\n",
        "  for (int i = 0; i < node_proto.input_size(); ++i) {\n",
        "    const std::string &input_name = node_proto.input(i);\n",
        "    if (anfnode_build_map_.find(input_name) == anfnode_build_map_.end()) {\n",
        "      MS_LOG(ERROR) << node_name << \" input \" << i << input_name << \"can't find in nodes have parsed\";\n",
        "      return nullptr;\n",
        "    }\n",
        "    inputs.push_back(anfnode_build_map_[input_name]);\n",
        "  }\n",
        "  auto primitivec_ptr = PrimitiveC::UnPackFromPrimitive(*prim, inputs, quantType);\n",
        "  if (primitivec_ptr == nullptr) {\n",
        "    MS_LOG(ERROR) << \"Create PrimitiveC return nullptr, \" << prim->name();\n",
        "    return nullptr;\n",
        "  }\n",
        "  inputs.insert(inputs.begin(), NewValueNode(primitivec_ptr));\n",
        "  CNodePtr cnode_ptr = outputFuncGraph->NewCNode(inputs);\n",
        "  MS_EXCEPTION_IF_NULL(cnode_ptr);\n",
        "  if (0 == kv.size()) {\n",
        "    AbstractBasePtrList elem;\n",
        "    for (size_t index = 1; index < cnode_ptr->inputs().size(); ++index) {\n",
        "      elem.push_back(cnode_ptr->input(index)->abstract());\n",
        "    }\n",
        "    cnode_ptr->set_abstract(std::make_shared<abstract::AbstractTuple>(elem));\n",
        "  } else if (1 == kv.size()) {\n",
        "    std::unordered_map<std::string, abstract::AbstractTensorPtr>::iterator iter = kv.begin();\n",
        "    cnode_ptr->set_abstract(iter->second);\n",
        "  } else {\n",
        "    auto abstract = ParserAttrShape(shape_ref_attr_name, kv);\n",
        "    cnode_ptr->set_abstract(abstract);\n",
        "  }\n",
        "\n",
        "  cnode_ptr->set_fullname_with_scope(fullname_with_scope);\n",
        "  anfnode_build_map_[node_name] = cnode_ptr;\n",
        "  return cnode_ptr;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::BuildReturnForFuncGraph(const FuncGraphPtr &outputFuncGraph,\n",
        "                                                      const onnx::GraphProto &importProto, const CNodePtr &cnode_ptr) {\n",
        "  MS_EXCEPTION_IF_NULL(outputFuncGraph);\n",
        "  MS_EXCEPTION_IF_NULL(cnode_ptr);\n",
        "  std::vector<AnfNodePtr> inputs;\n",
        "  if (importProto.output_size() > 1) {\n",
        "    inputs.clear();\n",
        "    auto primitiveT = std::make_unique<schema::PrimitiveT>();\n",
        "    MS_ASSERT(primitiveT != nullptr);\n",
        "    primitiveT->value.type = schema::PrimitiveType_MakeTuple;\n",
        "    std::shared_ptr<PrimitiveC> primitivec_ptr = std::make_shared<PrimitiveC>(primitiveT.release());\n",
        "    MS_ASSERT(primitivec_ptr != nullptr);\n",
        "    inputs.push_back(NewValueNode(primitivec_ptr));\n",
        "    AbstractBasePtrList elem;\n",
        "    for (int out_size = 0; out_size < importProto.output_size(); ++out_size) {\n",
        "      const onnx::ValueInfoProto &output_node = importProto.output(out_size);\n",
        "      const std::string &out_tuple = output_node.name();\n",
        "      inputs.push_back(anfnode_build_map_[out_tuple]);\n",
        "      elem.push_back(anfnode_build_map_[out_tuple]->abstract());\n",
        "    }\n",
        "    auto maketuple_ptr = outputFuncGraph->NewCNode(inputs);\n",
        "    maketuple_ptr->set_abstract(std::make_shared<abstract::AbstractTuple>(elem));\n",
        "    inputs.clear();\n",
        "    auto primReturn = std::make_unique<schema::PrimitiveT>();\n",
        "    MS_ASSERT(primReturn != nullptr);\n",
        "    primReturn->value.type = schema::PrimitiveType_Return;\n",
        "    std::shared_ptr<PrimitiveC> primitive_return_value_ptr = std::make_shared<PrimitiveC>(primReturn.release());\n",
        "    MS_ASSERT(primitive_return_value_ptr != nullptr);\n",
        "    inputs.push_back(NewValueNode(primitive_return_value_ptr));\n",
        "    inputs.push_back(maketuple_ptr);\n",
        "    auto return_node = outputFuncGraph->NewCNode(inputs);\n",
        "    MS_EXCEPTION_IF_NULL(return_node);\n",
        "    outputFuncGraph->set_return(return_node);\n",
        "    MS_LOG(INFO) << \"Construct funcgraph finined, all success.\";\n",
        "  } else {\n",
        "    const onnx::ValueInfoProto &output_node = importProto.output(0);\n",
        "    const onnx::TypeProto &output_typeproto = output_node.type();\n",
        "    int output_type = output_typeproto.tensor_type().elem_type();\n",
        "    std::vector<int> output_shape;\n",
        "    for (int i = 0; i < output_typeproto.tensor_type().shape().dim_size(); ++i) {\n",
        "      output_shape.push_back(output_typeproto.tensor_type().shape().dim(i).dim_value());\n",
        "    }\n",
        "    auto type_ptr = TypeIdToType(kDefaultValueSwitchMap[output_type]);\n",
        "    auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, output_shape);\n",
        "\n",
        "    inputs.clear();\n",
        "    auto primReturn = std::make_unique<schema::PrimitiveT>();\n",
        "    MS_ASSERT(primReturn != nullptr);\n",
        "    primReturn->value.type = schema::PrimitiveType_Return;\n",
        "    std::shared_ptr<PrimitiveC> primitiveTReturnValuePtr = std::make_shared<PrimitiveC>(primReturn.release());\n",
        "    MS_ASSERT(primitiveTReturnValuePtr != nullptr);\n",
        "    inputs.push_back(NewValueNode(primitiveTReturnValuePtr));\n",
        "    inputs.push_back(cnode_ptr);\n",
        "    auto return_node = outputFuncGraph->NewCNode(inputs);\n",
        "    MS_EXCEPTION_IF_NULL(return_node);\n",
        "    return_node->set_abstract(abstract_tensor);\n",
        "    outputFuncGraph->set_return(return_node);\n",
        "    MS_LOG(INFO) << \"Construct funcgraph finined, all success!\";\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::ImportNodesForGraph(const FuncGraphPtr &outputFuncGraph,\n",
        "                                                  const onnx::GraphProto &importProto,\n",
        "                                                  const schema::QuantType &quantType) {\n",
        "  MS_EXCEPTION_IF_NULL(outputFuncGraph);\n",
        "  MS_LOG(INFO) << \"The CNdoe size : \" << importProto.node_size();\n",
        "  CNodePtr cnode_ptr = nullptr;\n",
        "  for (int i = 0; i < importProto.node_size(); ++i) {\n",
        "    const onnx::NodeProto &node_proto = importProto.node(i);\n",
        "    const std::string &node_type = node_proto.op_type();\n",
        "    if (node_type == kConstantValueNode) {\n",
        "      if (!BuildValueNodeForFuncGraph(node_proto)) {\n",
        "        MS_LOG(ERROR) << \"Build ValueNode for funcgraph fail at index: : \" << i;\n",
        "        return false;\n",
        "      }\n",
        "      continue;\n",
        "    }\n",
        "    cnode_ptr = BuildCNodeForFuncGraph(outputFuncGraph, node_proto, quantType);\n",
        "    if (cnode_ptr == nullptr) {\n",
        "      MS_LOG(ERROR) << \"Build CNode for funcgraph fail at index: : \" << i;\n",
        "      return false;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  BuildReturnForFuncGraph(outputFuncGraph, importProto, cnode_ptr);\n",
        "  return true;\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::BuildFuncGraph(const FuncGraphPtr &outputFuncGraph, const onnx::GraphProto &importProto,\n",
        "                                             const schema::QuantType &quantType) {\n",
        "  MS_EXCEPTION_IF_NULL(outputFuncGraph);\n",
        "  GraphDebugInfoPtr debug_info_ptr = outputFuncGraph->debug_info();\n",
        "  MS_EXCEPTION_IF_NULL(debug_info_ptr);\n",
        "  if (importProto.has_name()) {\n",
        "    debug_info_ptr->set_name(importProto.name());\n",
        "  } else {\n",
        "    MS_LOG(ERROR) << \"FuncGraph under converting has not name!\";\n",
        "  }\n",
        "\n",
        "  if (!ImportParametersForGraph(outputFuncGraph, importProto)) {\n",
        "    return false;\n",
        "  }\n",
        "  return ImportNodesForGraph(outputFuncGraph, importProto, quantType);\n",
        "}\n",
        "\n",
        "bool AnfImporterFromProtobuf::ParseModelConfigureInfo(const onnx::ModelProto &model_proto) {\n",
        "  if (!model_proto.has_producer_name()) {\n",
        "    MS_LOG(ERROR) << \"Parse model producer name from pb file failed!\";\n",
        "    return false;\n",
        "  }\n",
        "  producer_name_ = model_proto.producer_name();\n",
        "\n",
        "  if (!model_proto.has_model_version()) {\n",
        "    MS_LOG(ERROR) << \"Parse model producer version from pb file failed!\";\n",
        "    return false;\n",
        "  }\n",
        "  model_version_ = model_proto.model_version();\n",
        "\n",
        "  if (!model_proto.has_ir_version()) {\n",
        "    MS_LOG(ERROR) << \"Parse model version from pb file failed!\";\n",
        "    return false;\n",
        "  }\n",
        "  ir_version_ = model_proto.ir_version();\n",
        "  return true;\n",
        "}\n",
        "\n",
        "int AnfImporterFromProtobuf::Import(const schema::QuantType &quantType) {\n",
        "  FuncGraphPtr dstGraph = std::make_shared<mindspore::FuncGraph>();\n",
        "  MS_EXCEPTION_IF_NULL(dstGraph);\n",
        "  if (!ParseModelConfigureInfo(*onnx_model_)) {\n",
        "    MS_LOG(ERROR) << \"Parse configuration info for pb file failed!\";\n",
        "  }\n",
        "  const onnx::GraphProto &graphBuild = onnx_model_->graph();\n",
        "  if (!BuildFuncGraph(dstGraph, graphBuild, quantType)) {\n",
        "    MS_LOG(ERROR) << \"Build funcgraph failed!\";\n",
        "    func_graph_ = nullptr;\n",
        "    return RET_ERROR;\n",
        "  }\n",
        "  func_graph_ = dstGraph;\n",
        "  MS_LOG(INFO) << \"Parse pb to build FuncGraph Success!\";\n",
        "  return RET_OK;\n",
        "}\n",
        "\n",
        "onnx::ModelProto *AnfImporterFromProtobuf::ReadOnnxFromBinary(const std::string &model_path) {\n",
        "  auto onnx_model = new onnx::ModelProto;\n",
        "  if (ReadProtoFromBinaryFile((const char *) model_path.c_str(), onnx_model) != RET_OK) {\n",
        "    MS_LOG(ERROR) << \"Read onnx model file failed, model path: \" << model_path;\n",
        "    return nullptr;\n",
        "  }\n",
        "  return onnx_model;\n",
        "}\n",
        "\n",
        "FuncGraphPtr AnfImporterFromProtobuf::GetResult() { return this->func_graph_; }\n",
        "}  // namespace mindspore::lite\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIWO5XRfhbXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#ifndef MINDSPORE_LITE_SRC_ANF_IMPORTER_IMPORTER_FROM_PROTOBUF_H_\n",
        "#define MINDSPORE_LITE_SRC_ANF_IMPORTER_IMPORTER_FROM_PROTOBUF_H_\n",
        "\n",
        "#include <map>\n",
        "#include <string>\n",
        "#include <unordered_map>\n",
        "#include <utility>\n",
        "\n",
        "#include \"include/errorcode.h\"\n",
        "#include \"tools/converter/parser/onnx/onnx.pb.h\"\n",
        "#include \"tools/anf_importer/anf_importer.h\"\n",
        "#include \"abstract/abstract_value.h\"\n",
        "\n",
        "namespace mindspore::lite {\n",
        "class AnfImporterFromProtobuf : public AnfImporter {\n",
        " public:\n",
        "  explicit AnfImporterFromProtobuf(onnx::ModelProto *onnx_model, FuncGraphPtr func_graph)\n",
        "      : onnx_model_(onnx_model), func_graph_(std::move(func_graph)) {}\n",
        "\n",
        "  ~AnfImporterFromProtobuf() override = default;\n",
        "\n",
        "  static onnx::ModelProto *ReadOnnxFromBinary(const std::string &model_path);\n",
        "\n",
        "  FuncGraphPtr GetResult() override;\n",
        "\n",
        "  int Import(const schema::QuantType &quantType = schema::QuantType_QUANT_NONE) override;\n",
        "\n",
        " private:\n",
        "  int ConverterConstTensor() override { return RET_ERROR; };\n",
        "  int ConverterCNode() override { return RET_ERROR; };\n",
        "  int AddReturnCNode() override { return RET_ERROR; };\n",
        "  bool ParseModelConfigureInfo(const onnx::ModelProto &model_proto);\n",
        "  bool BuildFuncGraph(const FuncGraphPtr &outputFuncGraph, const onnx::GraphProto &importProto,\n",
        "                      const schema::QuantType &quantType);\n",
        "  bool ImportParametersForGraph(const FuncGraphPtr &outputFuncGraph, const onnx::GraphProto &importProto);\n",
        "  bool ImportNodesForGraph(const FuncGraphPtr &outputFuncGraph, const onnx::GraphProto &importProto,\n",
        "                           const schema::QuantType &quantType);\n",
        "  bool BuildParameterForFuncGraph(const ParameterPtr &node, const onnx::ValueInfoProto &value_proto);\n",
        "  CNodePtr BuildCNodeForFuncGraph(const FuncGraphPtr &outputFuncGraph, const onnx::NodeProto &node_proto,\n",
        "                                  const schema::QuantType &quantType);\n",
        "  bool BuildReturnForFuncGraph(const FuncGraphPtr &outputFuncGraph, const onnx::GraphProto &importProto,\n",
        "                               const CNodePtr &cnode_ptr);\n",
        "  bool GetAttrValueForCNode(const PrimitivePtr &prim, const onnx::AttributeProto &attr_proto);\n",
        "  bool ObtainCNodeAttrInTypeForm(const PrimitivePtr &prim, const std::string &attr_name,\n",
        "                                 const onnx::TensorProto &attr_tensor);\n",
        "  ValuePtr ObtainCNodeAttrInScalarForm(const onnx::TensorProto &attr_tensor);\n",
        "  bool ObtainCNodeAttrInTensorForm(const PrimitivePtr &prim, const std::string &attr_name,\n",
        "                                   const onnx::TensorProto &attr_tensor);\n",
        "  bool BuildValueNodeForFuncGraph(const onnx::NodeProto &node_proto);\n",
        "  bool ObtainValueNodeInTensorForm(const string &value_node_name, const onnx::TensorProto &attr_tensor);\n",
        "  bool GetAttrValueForValueNode(const std::string &value_node_name, const onnx::AttributeProto &attr_proto);\n",
        "  bool ObtainValueNodeInTypeForm(const string &value_node_name, const onnx::TensorProto &attr_tensor);\n",
        "  std::unordered_map<std::string,\n",
        "                     abstract::AbstractTensorPtr> GetAbstractForCNode(const onnx::AttributeProto &attr_proto);\n",
        "\n",
        " private:\n",
        "  std::string producer_name_;\n",
        "  int model_version_{};\n",
        "  int ir_version_{};\n",
        "  std::unordered_map<std::string, AnfNodePtr> anfnode_build_map_;\n",
        "  std::map<std::string, onnx::TensorProto> default_para_map_;\n",
        "  onnx::ModelProto *onnx_model_;\n",
        "  FuncGraphPtr func_graph_;\n",
        "};\n",
        "}  // namespace mindspore::lite\n",
        "\n",
        "#endif  // MINDSPORE_LITE_SRC_ANF_IMPORTER_IMPORTER_FROM_PROTOBUF_H_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVuWr1Zqq_Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "import tokenizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZGU4PDAsNQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ./input/roberta-base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B24P1lcrlmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = './input/roberta-base'\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaModel.from_pretrained('roberta-base')\n",
        "config = RobertaConfig.from_pretrained('roberta-base')\n",
        "tokenizer.save_vocabulary(save_path)\n",
        "model.save_pretrained(save_path)\n",
        "config.save_pretrained(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWGS_5Sfsenj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class config:\n",
        "    FOLD = 0\n",
        "    LEARNING_RATE = 0.2 * 3e-5\n",
        "    MAX_LEN = 192\n",
        "    TRAIN_BATCH_SIZE = 16\n",
        "    VALID_BATCH_SIZE = 8\n",
        "    EPOCHS = 3\n",
        "    TRAINING_FILE = \"./tweet-sentiment/train_folds.csv\"\n",
        "    ROBERTA_PATH = \"./input/roberta-base\"\n",
        "    TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
        "        vocab_file=f\"{ROBERTA_PATH}/vocab.json\", \n",
        "        merges_file=f\"{ROBERTA_PATH}/merges.txt\", \n",
        "        lowercase=True,\n",
        "        add_prefix_space=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk",
        "colab_type": "text"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nl8SqDItPsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
        "    tweet = \" \" + \" \".join(str(tweet).split())\n",
        "    selected_text = \" \" + \" \".join(str(selected_text).split())\n",
        "\n",
        "    len_st = len(selected_text) - 1\n",
        "    idx0 = None\n",
        "    idx1 = None\n",
        "\n",
        "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
        "        if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
        "            idx0 = ind\n",
        "            idx1 = ind + len_st - 1\n",
        "            break\n",
        "\n",
        "    char_targets = [0] * len(tweet)\n",
        "    if idx0 != None and idx1 != None:\n",
        "        for ct in range(idx0, idx1 + 1):\n",
        "            char_targets[ct] = 1\n",
        "    \n",
        "    tok_tweet = tokenizer.encode(tweet)\n",
        "    input_ids_orig = tok_tweet.ids\n",
        "    tweet_offsets = tok_tweet.offsets\n",
        "    \n",
        "    target_idx = []\n",
        "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
        "        if sum(char_targets[offset1: offset2]) > 0:\n",
        "            target_idx.append(j)\n",
        "    \n",
        "    targets_start = target_idx[0]\n",
        "    targets_end = target_idx[-1]\n",
        "\n",
        "    sentiment_id = {\n",
        "        'positive': 1313,\n",
        "        'negative': 2430,\n",
        "        'neutral': 7974\n",
        "    }\n",
        "    \n",
        "    input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]\n",
        "    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n",
        "    mask = [1] * len(token_type_ids)\n",
        "    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n",
        "    targets_start += 4\n",
        "    targets_end += 4\n",
        "\n",
        "    padding_length = max_len - len(input_ids)\n",
        "    if padding_length > 0:\n",
        "        input_ids = input_ids + ([1] * padding_length)\n",
        "        mask = mask + ([0] * padding_length)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
        "    \n",
        "    return {\n",
        "        'ids': input_ids,\n",
        "        'mask': mask,\n",
        "        'token_type_ids': token_type_ids,\n",
        "        'targets_start': targets_start,\n",
        "        'targets_end': targets_end,\n",
        "        'orig_tweet': tweet,\n",
        "        'orig_selected': selected_text,\n",
        "        'sentiment': sentiment,\n",
        "        'offsets': tweet_offsets\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1XkJ_uOtk5U",
        "colab_type": "text"
      },
      "source": [
        "#Data loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOidlXY8uO8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TweetDataset:\n",
        "    def __init__(self, tweet, sentiment, selected_text):\n",
        "        self.tweet = tweet\n",
        "        self.sentiment = sentiment\n",
        "        self.selected_text = selected_text\n",
        "        self.tokenizer = config.TOKENIZER\n",
        "        self.max_len = config.MAX_LEN\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tweet)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        data = process_data(\n",
        "            self.tweet[item], \n",
        "            self.selected_text[item], \n",
        "            self.sentiment[item],\n",
        "            self.tokenizer,\n",
        "            self.max_len\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n",
        "            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
        "            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n",
        "            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n",
        "            'orig_tweet': data[\"orig_tweet\"],\n",
        "            'orig_selected': data[\"orig_selected\"],\n",
        "            'sentiment': data[\"sentiment\"],\n",
        "            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n",
        "        }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1tiaim0uWB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TweetModel(transformers.BertPreTrainedModel):\n",
        "    def __init__(self, conf):\n",
        "        super(TweetModel, self).__init__(conf)\n",
        "        self.roberta = transformers.RobertaModel.from_pretrained(config.ROBERTA_PATH, config=conf)\n",
        "        self.drop_out = nn.Dropout(0.1)\n",
        "        self.l0 = nn.Linear(768 * 2, 2)\n",
        "        torch.nn.init.normal_(self.l0.weight, std=0.02)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, _, out = self.roberta(\n",
        "            ids,\n",
        "            attention_mask=mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        out = torch.cat((out[-1], out[-2]), dim=-1)\n",
        "        out = self.drop_out(out)\n",
        "        logits = self.l0(out)\n",
        "\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "\n",
        "        start_logits = start_logits.squeeze(-1)\n",
        "        end_logits = end_logits.squeeze(-1)\n",
        "\n",
        "        return start_logits, end_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_D9iCOPueGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
        "    loss_fct = nn.CrossEntropyLoss()\n",
        "    start_loss = loss_fct(start_logits, start_positions)\n",
        "    end_loss = loss_fct(end_logits, end_positions)\n",
        "    total_loss = (start_loss + end_loss)\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EJr5IHPuji1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(data_loader, model, optimizer, device, num_batches, scheduler=None):\n",
        "    model.train()\n",
        "    tk0 = tqdm(data_loader, total=num_batches, desc=\"Training\", disable=not xm.is_master_ordinal())\n",
        "    for bi, d in enumerate(tk0):\n",
        "        ids = d[\"ids\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        targets_start = d[\"targets_start\"]\n",
        "        targets_end = d[\"targets_end\"]\n",
        "        sentiment = d[\"sentiment\"]\n",
        "        orig_selected = d[\"orig_selected\"]\n",
        "        orig_tweet = d[\"orig_tweet\"]\n",
        "        targets_start = d[\"targets_start\"]\n",
        "        targets_end = d[\"targets_end\"]\n",
        "        offsets = d[\"offsets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        targets_start = targets_start.to(device, dtype=torch.long)\n",
        "        targets_end = targets_end.to(device, dtype=torch.long)\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs_start, outputs_end = model(\n",
        "            ids=ids,\n",
        "            mask=mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
        "        loss.backward()\n",
        "        xm.optimizer_step(optimizer)\n",
        "        scheduler.step()\n",
        "        print_loss = xm.mesh_reduce('loss_reduce', loss, reduce_fn)\n",
        "        tk0.set_postfix(loss=print_loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDxCSB91unsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_jaccard_score(\n",
        "    original_tweet, \n",
        "    target_string, \n",
        "    sentiment_val, \n",
        "    idx_start, \n",
        "    idx_end, \n",
        "    offsets,\n",
        "    verbose=False):\n",
        "    \n",
        "    if idx_end < idx_start:\n",
        "        idx_end = idx_start\n",
        "    \n",
        "    filtered_output  = \"\"\n",
        "    for ix in range(idx_start, idx_end + 1):\n",
        "        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n",
        "        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n",
        "            filtered_output += \" \"\n",
        "\n",
        "    if len(original_tweet.split()) < 2:\n",
        "        filtered_output = original_tweet\n",
        "\n",
        "    jac = jaccard(target_string.strip(), filtered_output.strip())\n",
        "    return jac, filtered_output\n",
        "\n",
        "\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    jaccards = AverageMeter()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for bi, d in enumerate(data_loader):\n",
        "            ids = d[\"ids\"]\n",
        "            token_type_ids = d[\"token_type_ids\"]\n",
        "            mask = d[\"mask\"]\n",
        "            sentiment = d[\"sentiment\"]\n",
        "            orig_selected = d[\"orig_selected\"]\n",
        "            orig_tweet = d[\"orig_tweet\"]\n",
        "            targets_start = d[\"targets_start\"]\n",
        "            targets_end = d[\"targets_end\"]\n",
        "            offsets = d[\"offsets\"].cpu().numpy()\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets_start = targets_start.to(device, dtype=torch.long)\n",
        "            targets_end = targets_end.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs_start, outputs_end = model(\n",
        "                ids=ids,\n",
        "                mask=mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
        "            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
        "            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
        "            jaccard_scores = []\n",
        "            for px, tweet in enumerate(orig_tweet):\n",
        "                selected_tweet = orig_selected[px]\n",
        "                tweet_sentiment = sentiment[px]\n",
        "                jaccard_score, _ = calculate_jaccard_score(\n",
        "                    original_tweet=tweet,\n",
        "                    target_string=selected_tweet,\n",
        "                    sentiment_val=tweet_sentiment,\n",
        "                    idx_start=np.argmax(outputs_start[px, :]),\n",
        "                    idx_end=np.argmax(outputs_end[px, :]),\n",
        "                    offsets=offsets[px]\n",
        "                )\n",
        "                jaccard_scores.append(jaccard_score)\n",
        "\n",
        "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
        "            losses.update(loss.item(), ids.size(0))\n",
        "\n",
        "    return jaccards.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb7KafbguwPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_config = transformers.RobertaConfig.from_pretrained(config.ROBERTA_PATH)\n",
        "model_config.output_hidden_states = True\n",
        "MX = TweetModel(conf=model_config)\n",
        "\n",
        "dfx = pd.read_csv(config.TRAINING_FILE)\n",
        "\n",
        "df_train = dfx[dfx.kfold != config.FOLD].reset_index(drop=True)\n",
        "df_valid = dfx[dfx.kfold == config.FOLD].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehNC95DRu3EL",
        "colab_type": "text"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqDrsrE2u1oI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run():\n",
        "    device = xm.xla_device()\n",
        "    model = MX.to(device)\n",
        "\n",
        "    train_dataset = TweetDataset(\n",
        "        tweet=df_train.text.values,\n",
        "        sentiment=df_train.sentiment.values,\n",
        "        selected_text=df_train.selected_text.values\n",
        "    )\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "      train_dataset,\n",
        "      num_replicas=xm.xrt_world_size(),\n",
        "      rank=xm.get_ordinal(),\n",
        "      shuffle=True\n",
        "    )\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.TRAIN_BATCH_SIZE,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    valid_dataset = TweetDataset(\n",
        "        tweet=df_valid.text.values,\n",
        "        sentiment=df_valid.sentiment.values,\n",
        "        selected_text=df_valid.selected_text.values\n",
        "    )\n",
        "\n",
        "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "      valid_dataset,\n",
        "      num_replicas=xm.xrt_world_size(),\n",
        "      rank=xm.get_ordinal(),\n",
        "      shuffle=False\n",
        "    )\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        sampler=valid_sampler,\n",
        "        drop_last=False,\n",
        "        num_workers=1\n",
        "    )\n",
        "\n",
        "    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\n",
        "        \"bias\",\n",
        "        \"LayerNorm.bias\",\n",
        "        \"LayerNorm.weight\"\n",
        "    ]\n",
        "    optimizer_parameters = [\n",
        "        {\n",
        "            'params': [\n",
        "                p for n, p in param_optimizer if not any(\n",
        "                    nd in n for nd in no_decay\n",
        "                )\n",
        "            ], \n",
        "         'weight_decay': 0.001\n",
        "        },\n",
        "        {\n",
        "            'params': [\n",
        "                p for n, p in param_optimizer if any(\n",
        "                    nd in n for nd in no_decay\n",
        "                )\n",
        "            ], \n",
        "            'weight_decay': 0.0\n",
        "        },\n",
        "    ]\n",
        "    num_train_steps = int(\n",
        "        len(df_train) / config.TRAIN_BATCH_SIZE / xm.xrt_world_size() * config.EPOCHS\n",
        "    )\n",
        "    optimizer = AdamW(\n",
        "        optimizer_parameters, \n",
        "        lr=config.LEARNING_RATE * xm.xrt_world_size()\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_jac = 0\n",
        "    es = EarlyStopping(patience=2, mode=\"max\")\n",
        "    num_batches = int(len(df_train) / (config.TRAIN_BATCH_SIZE * xm.xrt_world_size()))\n",
        "    \n",
        "    xm.master_print(\"Training is Starting....\")\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
        "        train_fn(\n",
        "            para_loader.per_device_loader(device), \n",
        "            model, \n",
        "            optimizer, \n",
        "            device,\n",
        "            num_batches,\n",
        "            scheduler\n",
        "        )\n",
        "\n",
        "        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
        "        jac = eval_fn(\n",
        "            para_loader.per_device_loader(device), \n",
        "            model, \n",
        "            device\n",
        "        )\n",
        "        jac = xm.mesh_reduce('jac_reduce', jac, reduce_fn)\n",
        "        xm.master_print(f'Epoch={epoch}, Jaccard={jac}')\n",
        "        if jac > best_jac:\n",
        "            xm.master_print(\"Model Improved!!! Saving Model\")\n",
        "            xm.save(model.state_dict(), f\"model_{config.FOLD}.bin\")\n",
        "            best_jac = jac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHlyHRTVvEwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _mp_fn(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    a = run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99O6yUgLvHgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "18a4343c030b4371b899e99d4f8c513c",
            "97212f9b24d549d08e65ef631c788e5e",
            "2c9b0b798db64f1298760c85a57f097c",
            "e3fe3c2345634b088bff27a09a10b640",
            "33c8818e4b764cdcba3e4b6f52f1dbea",
            "94e37f508ab34e898ec927961919de34",
            "49f8aa1ae9f84e4b9a2c5177bc74ea4b",
            "c95bbed6e4ba46b18898146970ea9de6"
          ]
        },
        "outputId": "30bc90da-0640-45d1-8873-5724f16c8935"
      },
      "source": [
        "FLAGS={}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training is Starting....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18a4343c030b4371b899e99d4f8c513c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training', max=171.0, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}