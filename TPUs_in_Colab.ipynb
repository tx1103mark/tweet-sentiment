{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xicq53SkeQ6_"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#include \"tools/converter/parser/onnx/onnx_model_parser.h\"\r\n",
        "#include <algorithm>\r\n",
        "#include <set>\r\n",
        "#include <utility>\r\n",
        "#include <unordered_map>\r\n",
        "#include \"src/common/utils.h\"\r\n",
        "#include \"tools/common/graph_util.h\"\r\n",
        "#include \"tools/common/protobuf_utils.h\"\r\n",
        "\r\n",
        "namespace mindspore {\r\n",
        "namespace lite {\r\n",
        "static const std::unordered_map<int, mindspore::TypeId> TYPE_MAP = {\r\n",
        "    {onnx::TensorProto_DataType_INT8, mindspore::kNumberTypeInt8},\r\n",
        "    {onnx::TensorProto_DataType_UINT8, mindspore::kNumberTypeUInt8},\r\n",
        "    {onnx::TensorProto_DataType_INT16, mindspore::kNumberTypeInt16},\r\n",
        "    {onnx::TensorProto_DataType_INT32, mindspore::kNumberTypeInt32},\r\n",
        "    {onnx::TensorProto_DataType_UINT32, mindspore::kNumberTypeUInt32},\r\n",
        "    {onnx::TensorProto_DataType_INT64, mindspore::kNumberTypeInt64},\r\n",
        "    {onnx::TensorProto_DataType_FLOAT16, mindspore::kNumberTypeFloat16},\r\n",
        "    {onnx::TensorProto_DataType_FLOAT, mindspore::kNumberTypeFloat32},\r\n",
        "    {onnx::TensorProto_DataType_BOOL, mindspore::kNumberTypeBool}};\r\n",
        "\r\n",
        "std::set<std::string> SPECIAL_NODE = {\"Gemm\"};\r\n",
        "FuncGraphPtr OnnxModelParser::Parse(const std::string &model_file, const std::string &weight_file,\r\n",
        "                                    const QuantType &quant_type) {\r\n",
        "  NoSupportOp::GetInstance()->SetFmkType(\"ONNX\");\r\n",
        "  auto status = InitOriginModel(model_file);\r\n",
        "  if (RET_OK != status) {\r\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\r\n",
        "    MS_LOG(ERROR) << \"init origin model failed.\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "\r\n",
        "  anf_root_graph_ = std::make_shared<FuncGraph>();\r\n",
        "  if (anf_root_graph_ == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"funcgraph is nullptr.\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "//  std::vector<FuncGraphPtr> roots = {anf_root_graph_};\r\n",
        "//  auto root_func_manager = std::make_shared<FuncGraphManager>(roots);\r\n",
        "  static auto root_func_manager = Manage(anf_root_graph_);\r\n",
        "  status = ConvertOnnxGraph(onnx_root_graph_, anf_root_graph_, &anf_nodes_map_, {}, \"root_node\");\r\n",
        "  if (RET_OK != status) {\r\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\r\n",
        "    MS_LOG(ERROR) << \"convert onnx graph failed.\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  anf_root_graph_->set_attr(\"graph_name\", MakeValue(\"main_graph\"));\r\n",
        "  return anf_root_graph_;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::InitOriginModel(const std::string &model_file) {\r\n",
        "  auto status = ValidateFileStr(model_file, \".onnx\");\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"INPUT ILLEGAL: modelFile must be *.onnx\";\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "\r\n",
        "  status = ReadProtoFromBinaryFile((const char *) model_file.c_str(), &onnx_model_);\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"Read onnx model file failed, model path: \" << model_file;\r\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  OnnxNodeParser::set_opset_version(onnx_model_.opset_import().Get(0).version());\r\n",
        "  onnx_root_graph_ = onnx_model_.graph();\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "STATUS OnnxModelParser::ConvertOnnxGraph(const onnx::GraphProto &onnx_graph,\r\n",
        "                                         const FuncGraphPtr &anf_graph,\r\n",
        "                                         std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                                         std::vector<AnfNodePtr> *extra_subgraph_inputs,\r\n",
        "                                         const std::string &root_node_name) {\r\n",
        "  STATUS status = RET_OK;\r\n",
        "  status = ConvertConstTensors(onnx_graph, anf_graph, anf_nodes_map);\r\n",
        "  if (RET_OK != status) {\r\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\r\n",
        "    MS_LOG(ERROR) << \"convert const nodes failed.\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  status = ConvertGraphInputs(onnx_graph, anf_graph, anf_nodes_map);\r\n",
        "  if (RET_OK != status) {\r\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\r\n",
        "    MS_LOG(ERROR) << \"convert graph inputs failed.\";\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "\r\n",
        "  status = ConvertNodes(onnx_graph, anf_graph, anf_nodes_map, extra_subgraph_inputs, root_node_name);\r\n",
        "  if (RET_OK != status) {\r\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\r\n",
        "    MS_LOG(ERROR) << \"convert nodes failed.\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "\r\n",
        "  status = ConvertGraphOutputs(onnx_graph, anf_graph, *anf_nodes_map);\r\n",
        "  if (RET_OK != status) {\r\n",
        "    ReturnCode::GetSingleReturnCode()->UpdateReturnCode(status);\r\n",
        "    MS_LOG(ERROR) << \"convert graph outputs failed.\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  return status;\r\n",
        "}\r\n",
        "STATUS OnnxModelParser::ConvertConstTensors(const onnx::GraphProto &onnx_graph, const FuncGraphPtr &func_graph_ptr,\r\n",
        "                                            std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map) {\r\n",
        "  for (const auto &onnx_const_value : onnx_graph.initializer()) {\r\n",
        "    auto parameter = func_graph_ptr->add_parameter();\r\n",
        "\r\n",
        "    auto status = BuildParameterNode(parameter, onnx_const_value);\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"parameter node build failed.\";\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "    anf_nodes_map->emplace(onnx_const_value.name(), parameter);\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertGraphInputs(const onnx::GraphProto &onnx_graph, const FuncGraphPtr &func_graph_ptr,\r\n",
        "                                           std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map) {\r\n",
        "  for (int i = 0; i < onnx_graph.input().size(); ++i) {\r\n",
        "    const auto &input_value = onnx_graph.input(i);\r\n",
        "    if (anf_nodes_map->find(input_value.name()) != anf_nodes_map->end()) {\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    auto parameter = func_graph_ptr->add_parameter();\r\n",
        "    auto data_type =\r\n",
        "        GetDataTypeFromOnnx(static_cast<onnx::TensorProto_DataType>(input_value.type().tensor_type().elem_type()));\r\n",
        "    if (data_type == kTypeUnknown) {\r\n",
        "      MS_LOG(ERROR) << \"not support onnx data type \"\r\n",
        "                    << static_cast<onnx::TensorProto_DataType>(input_value.type().tensor_type().elem_type());\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    auto type_ptr = TypeIdToType(data_type);\r\n",
        "    std::vector<int64_t> shape_vector;\r\n",
        "    auto onnx_shape = input_value.type().tensor_type().shape().dim();\r\n",
        "    std::transform(onnx_shape.begin(), onnx_shape.end(), std::back_inserter(shape_vector),\r\n",
        "                   [](const onnx::TensorShapeProto_Dimension &val) { return static_cast<int64_t>(val.dim_value()); });\r\n",
        "    auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, shape_vector);\r\n",
        "    parameter->set_abstract(abstract_tensor);\r\n",
        "    parameter->set_name(input_value.name());\r\n",
        "    anf_nodes_map->emplace(input_value.name(), parameter);\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertNodes(const onnx::GraphProto &onnx_graph,\r\n",
        "                                     const FuncGraphPtr &anf_graph,\r\n",
        "                                     std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                                     std::vector<AnfNodePtr> *graph_inputs, const std::string &root_node_name) {\r\n",
        "  STATUS status = RET_OK;\r\n",
        "  for (const auto &onnx_node : onnx_graph.node()) {\r\n",
        "    auto node_parser = OnnxNodeParserRegistry::GetInstance()->GetNodeParser(onnx_node.op_type());\r\n",
        "    if (node_parser == nullptr) {\r\n",
        "      NoSupportOp::GetInstance()->InsertOp(onnx_node.op_type());\r\n",
        "      status = status == RET_OK ? RET_NOT_FIND_OP : status;\r\n",
        "      MS_LOG(ERROR) << \"not support onnx data type \" << onnx_node.op_type();\r\n",
        "    }\r\n",
        "    if (status != RET_OK) {\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    auto primitive_c = node_parser->ParseLitePrimitive(onnx_graph, onnx_node);\r\n",
        "    if (primitive_c == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"parse node \" << onnx_node.op_type() << \" failed.\";\r\n",
        "      status = RET_ERROR;\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    status = ConvertOpQuantParams(onnx_node, primitive_c);\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"convert \" << onnx_node.op_type() << \" quant param failed.\";\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    if (IsSpecialOnnxNode(onnx_node)) {\r\n",
        "\r\n",
        "      auto status_node = ConvertSpecialOnnxNode(onnx_node, anf_graph, anf_nodes_map, primitive_c);\r\n",
        "      status = status == RET_OK ? status_node : status;\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    // build CNode\r\n",
        "    status = BuildCNode(onnx_node, anf_graph, anf_nodes_map, graph_inputs, primitive_c, root_node_name);\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"build cnode \" << onnx_node.op_type() << \" failed.\";\r\n",
        "    }\r\n",
        "\r\n",
        "    if (onnx_node.op_type() == \"Loop\") {\r\n",
        "      child_root_map_[onnx_node.name()] = root_node_name;\r\n",
        "      control_nodes_map_[onnx_node.name()] = anf_nodes_map;\r\n",
        "\r\n",
        "      status = ConvertLoopOnnxNode(onnx_node, anf_nodes_map, root_node_name);\r\n",
        "      if (status != RET_OK) {\r\n",
        "        MS_LOG(ERROR) << \"build loop node  failed.\";\r\n",
        "      }\r\n",
        "    }\r\n",
        "    if (onnx_node.op_type() == \"If\") {\r\n",
        "      child_root_map_[onnx_node.name()] = root_node_name;\r\n",
        "      control_nodes_map_[onnx_node.name()] = anf_nodes_map;\r\n",
        "\r\n",
        "      status = ConvertIfOnnxNode(onnx_node, anf_nodes_map, root_node_name);\r\n",
        "      if (status != RET_OK) {\r\n",
        "        MS_LOG(ERROR) << \"build if node  failed.\";\r\n",
        "      }\r\n",
        "    }\r\n",
        "\r\n",
        "  }\r\n",
        "  return status;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertIfSubgraph(const onnx::GraphProto &subgraph_proto,\r\n",
        "                                          const FuncGraphPtr &subgraph,\r\n",
        "                                          const std::string &subgraph_name,\r\n",
        "                                          const std::string &if_node_name,\r\n",
        "                                          const std::string &root_node_name) {\r\n",
        "  std::unordered_map<std::string, AnfNodePtr> anf_nodes_map;\r\n",
        "  std::vector<AnfNodePtr> subgraph_extra_inputs;\r\n",
        "  auto status = ConvertOnnxGraph(subgraph_proto, subgraph, &anf_nodes_map, &subgraph_extra_inputs, if_node_name);\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"convert loop OnnxGraph failed\";\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  subgraph->set_attr(\"graph_name\", MakeValue(subgraph_name));\r\n",
        "  // update subgraph in out name\r\n",
        "  for (int j = 0; j < subgraph_proto.input_size(); j++) {\r\n",
        "    anf_nodes_map[subgraph_proto.input(j).name()]->cast<ParameterPtr>()->set_name(\r\n",
        "        subgraph_name + \"_input_\" + std::to_string(j) + \"_parameter\");\r\n",
        "  }\r\n",
        "  for (int j = 0; j < subgraph_extra_inputs.size(); j++) {\r\n",
        "    subgraph_extra_inputs[j]->cast<ParameterPtr>()->set_name(\r\n",
        "        subgraph_name + \"_input_\" + std::to_string(j + subgraph_proto.input_size()) + \"_parameter\");\r\n",
        "  }\r\n",
        "  auto return_cnode = subgraph->get_return();\r\n",
        "  std::vector<AnfNodePtr> return_act_inputs;\r\n",
        "  int start_index = 0;\r\n",
        "  if (subgraph_proto.output_size() > 1) {\r\n",
        "    return_act_inputs = return_cnode->input(1)->cast<CNodePtr>()->inputs();\r\n",
        "    start_index = 1;\r\n",
        "  } else {\r\n",
        "    return_act_inputs = {return_cnode->input(1)};\r\n",
        "  }\r\n",
        "  for (int j = start_index; j < return_act_inputs.size(); j++) {\r\n",
        "    if (utils::isa<CNodePtr>(return_act_inputs[j])) {\r\n",
        "      return_act_inputs[start_index]->cast<CNodePtr>()->set_fullname_with_scope(subgraph_name + \"_output_\" +\r\n",
        "          std::to_string(j - start_index) + \"_cnode\");\r\n",
        "    } else if (utils::isa<ParameterPtr>(return_act_inputs[start_index])) {\r\n",
        "      return_act_inputs[j]->cast<ParameterPtr>()->set_name(\r\n",
        "          subgraph_name + \"_output_\" + std::to_string(j - start_index) +\r\n",
        "              \"_parameter\");\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertIfOnnxNode(const onnx::NodeProto &onnx_node,\r\n",
        "                                          std::unordered_map<std::string, AnfNodePtr> *anf_root_nodes_map,\r\n",
        "                                          const std::string &root_node_name) {\r\n",
        "  FuncGraphPtr then_branch_graph = nullptr;\r\n",
        "  FuncGraphPtr else_branch_graph = nullptr;\r\n",
        "  FuncGraphPtr subgraph = nullptr;\r\n",
        "  std::string subgraph_name;\r\n",
        "  auto &if_node_name = onnx_node.name();\r\n",
        "\r\n",
        "  for (int i = 0; i < onnx_node.attribute_size(); i++) {\r\n",
        "    auto &attr = onnx_node.attribute(i);\r\n",
        "    auto &subgraph_proto = attr.g();\r\n",
        "    if (attr.name().find(\"then_branch\") != std::string::npos) {\r\n",
        "      subgraph_name = if_node_name + \"_then_branch\";\r\n",
        "      then_branch_graph = std::make_shared<FuncGraph>();;\r\n",
        "      auto status = ConvertIfSubgraph(subgraph_proto, then_branch_graph, subgraph_name, if_node_name, root_node_name);\r\n",
        "      if (status != RET_OK) {\r\n",
        "        MS_LOG(ERROR) << \"build if node else branch failed.\";\r\n",
        "      }\r\n",
        "    } else if (attr.name().find(\"else_branch\") != std::string::npos) {\r\n",
        "      subgraph_name = if_node_name + \"_else_branch\";\r\n",
        "      else_branch_graph = std::make_shared<FuncGraph>();;\r\n",
        "      auto status = ConvertIfSubgraph(subgraph_proto, else_branch_graph, subgraph_name, if_node_name, root_node_name);\r\n",
        "      if (status != RET_OK) {\r\n",
        "        MS_LOG(ERROR) << \"build if node else branch failed.\";\r\n",
        "      }\r\n",
        "    } else {\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "  }\r\n",
        "\r\n",
        "  static auto root_func_manager = Manage(anf_root_graph_);\r\n",
        "  then_branch_graph->set_manager(root_func_manager);\r\n",
        "  auto then_value_node = NewValueNode(then_branch_graph);\r\n",
        "  else_branch_graph->set_manager(root_func_manager);\r\n",
        "  auto else_value_node = NewValueNode(else_branch_graph);\r\n",
        "  auto root_if_node = control_nodes_map_.at(if_node_name)->at(if_node_name)->cast<CNodePtr>();\r\n",
        "  auto if_new_inputs = root_if_node->inputs();\r\n",
        "  if_new_inputs.insert(if_new_inputs.begin() + 1, {then_value_node, then_value_node});\r\n",
        "  root_if_node->set_inputs(if_new_inputs);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertGraphOutputs(const onnx::GraphProto &onnx_graph, const FuncGraphPtr &anf_graph,\r\n",
        "                                            const std::unordered_map<std::string, AnfNodePtr> &anf_nodes_map) {\r\n",
        "  std::vector<AnfNodePtr> return_inputs;\r\n",
        "  if (onnx_graph.output_size() > 1) {\r\n",
        "    std::vector<AnfNodePtr> make_tuple_inputs;\r\n",
        "    auto make_tuple_prim_ptr = GetMakeTuplePrim();\r\n",
        "    if (make_tuple_prim_ptr == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"GetMakeTuplePrim return nullptr\";\r\n",
        "      return RET_NULL_PTR;\r\n",
        "    }\r\n",
        "    for (const auto &graph_out : onnx_graph.output()) {\r\n",
        "      if (anf_nodes_map.find(graph_out.name()) == anf_nodes_map.end()) {\r\n",
        "        MS_LOG(ERROR) << \"graph output get failed.\";\r\n",
        "        return RET_ERROR;\r\n",
        "      }\r\n",
        "      auto cnode = anf_nodes_map.at(graph_out.name());\r\n",
        "      if (nullptr == cnode) {\r\n",
        "        MS_LOG(ERROR) << \"Can't find input node.\";\r\n",
        "        return RET_NOT_FIND_OP;\r\n",
        "      }\r\n",
        "      make_tuple_inputs.emplace_back(cnode);\r\n",
        "    }\r\n",
        "    auto make_tuple_cnode = anf_graph->NewCNode(make_tuple_prim_ptr, make_tuple_inputs);\r\n",
        "    make_tuple_cnode->set_fullname_with_scope(\"return tuple\");\r\n",
        "    return_inputs.emplace_back(make_tuple_cnode);\r\n",
        "  } else {\r\n",
        "    const auto &graph_out = onnx_graph.output(0);\r\n",
        "    if (anf_nodes_map.find(graph_out.name()) == anf_nodes_map.end()) {\r\n",
        "      MS_LOG(ERROR) << \"graph output get failed.\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    auto cnode = anf_nodes_map.at(graph_out.name());\r\n",
        "    if (nullptr == cnode) {\r\n",
        "      MS_LOG(ERROR) << \"Can't find input node.\";\r\n",
        "      return RET_NOT_FIND_OP;\r\n",
        "    }\r\n",
        "    return_inputs.emplace_back(cnode);\r\n",
        "  }\r\n",
        "  if (BuildReturnNode(anf_graph, return_inputs) != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"build return node failed.\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::BuildReturnNode(const FuncGraphPtr &anf_graph,\r\n",
        "                                        const std::vector<AnfNodePtr> &return_inputs) {\r\n",
        "  auto returnPrim = GetReturnPrim();\r\n",
        "  if (returnPrim == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"GetReturnPrim return nullptr\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  auto returnCnode = anf_graph->NewCNode(returnPrim, return_inputs);\r\n",
        "  returnCnode->set_fullname_with_scope(\"return\");\r\n",
        "  anf_graph->set_return(returnCnode);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "STATUS OnnxModelParser::BuildCNode(const onnx::NodeProto &onnx_node,\r\n",
        "                                   const FuncGraphPtr &anf_graph,\r\n",
        "                                   std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                                   std::vector<AnfNodePtr> *graph_inputs,\r\n",
        "                                   lite::PrimitiveC *primitive_c,\r\n",
        "                                   std::string loop_name) {\r\n",
        "  if (primitive_c == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"primitive_c is nullptr.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  std::vector<AnfNodePtr> op_inputs;\r\n",
        "  for (const auto &input_name : onnx_node.input()) {\r\n",
        "    if (input_name.empty()) {\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    if (anf_nodes_map->find(input_name) != anf_nodes_map->end()) {\r\n",
        "      op_inputs.push_back(anf_nodes_map->at(input_name));\r\n",
        "    } else {\r\n",
        "      // subgraph may refer root graph nodes\r\n",
        "      std::vector<CNodePtr> need_add_input_nodes;\r\n",
        "      auto ext_subgraph_input = anf_graph->add_parameter();\r\n",
        "      ParameterPtr inner_extra_paramter = nullptr;\r\n",
        "      while (!loop_name.empty() && child_root_map_.find(loop_name) != child_root_map_.end()) {\r\n",
        "        auto cur_node_map = control_nodes_map_[loop_name];\r\n",
        "        if (cur_node_map->find(input_name) != cur_node_map->end()) {\r\n",
        "          auto outside_input_node = cur_node_map->at(input_name);\r\n",
        "          // copy outside input parameter value to inside subgraph\r\n",
        "          ext_subgraph_input->set_abstract(outside_input_node->abstract());\r\n",
        "          ext_subgraph_input->set_name(input_name);\r\n",
        "          if (outside_input_node->isa<Parameter>()) {\r\n",
        "            auto param_value = outside_input_node->cast<ParameterPtr>()->default_param()->cast<ParamValueLitePtr>();\r\n",
        "            auto copy_param_value = std::make_shared<ParamValueLite>();\r\n",
        "            auto copy_data = new(std::nothrow) char[param_value->tensor_size()];\r\n",
        "            auto ret =\r\n",
        "                memcpy_s(copy_data, param_value->tensor_size(), param_value->tensor_addr(), param_value->tensor_size());\r\n",
        "            if (ret != EOK) {\r\n",
        "              delete[](copy_data);\r\n",
        "              MS_LOG(ERROR) << \"memcpy error: \" << ret;\r\n",
        "              return RET_ERROR;\r\n",
        "            }\r\n",
        "            copy_param_value->SetTensorData(copy_data, param_value->tensor_size());\r\n",
        "            ext_subgraph_input->set_default_param(copy_param_value);\r\n",
        "          } else {\r\n",
        "            // output inside cnode need make extra input\r\n",
        "            graph_inputs->emplace_back(ext_subgraph_input);\r\n",
        "            if (cur_node_map->find(loop_name) != cur_node_map->end()) {\r\n",
        "              auto control_node = cur_node_map->at(loop_name)->cast<CNodePtr>();\r\n",
        "              control_node->add_input(outside_input_node);\r\n",
        "            } else {\r\n",
        "              MS_LOG(ERROR) << \"loop node: \" << loop_name << \" not found in cur node map.\";\r\n",
        "              return RET_ERROR;\r\n",
        "            }\r\n",
        "            for (auto &control_node:need_add_input_nodes) {\r\n",
        "              auto func_graph = control_node->func_graph();\r\n",
        "              auto extra_input_parameter = func_graph->add_parameter();\r\n",
        "              extra_input_parameter->set_name(input_name);\r\n",
        "              extra_input_parameter->set_abstract(outside_input_node->abstract());\r\n",
        "              control_node->add_input(extra_input_parameter);\r\n",
        "            }\r\n",
        "          }\r\n",
        "          anf_nodes_map->emplace(input_name, ext_subgraph_input);\r\n",
        "          break;\r\n",
        "        } else {\r\n",
        "          if (cur_node_map->find(loop_name) != cur_node_map->end()) {\r\n",
        "            need_add_input_nodes.emplace_back(cur_node_map->at(loop_name)->cast<CNodePtr>());\r\n",
        "          } else {\r\n",
        "            MS_LOG(ERROR) << \"loop node: \" << loop_name << \" not found in cur node map.\";\r\n",
        "            return RET_ERROR;\r\n",
        "          }\r\n",
        "          loop_name = child_root_map_[loop_name];\r\n",
        "        }\r\n",
        "      }\r\n",
        "    }\r\n",
        "  }\r\n",
        "  auto new_cnode = anf_graph->NewCNode(std::shared_ptr<lite::PrimitiveC>(primitive_c), op_inputs);\r\n",
        "  new_cnode->set_fullname_with_scope(onnx_node.name());\r\n",
        "  auto status = BuildOpOutputs(onnx_node, anf_graph, anf_nodes_map, new_cnode);\r\n",
        "  return status;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::BuildOpOutputs(const onnx::NodeProto &onnx_node,\r\n",
        "                                       const FuncGraphPtr &anf_graph,\r\n",
        "                                       std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                                       const CNodePtr &cnode) {\r\n",
        "  if (cnode == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"parameter is null, get output tensor failed.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  if (onnx_node.output_size() == 1) {\r\n",
        "    auto type_ptr = TypeIdToType(kNumberTypeFloat32);\r\n",
        "    std::vector<int64_t> shape_vector;\r\n",
        "    cnode->set_abstract(std::make_shared<abstract::AbstractTensor>(type_ptr, shape_vector));\r\n",
        "    anf_nodes_map->emplace(onnx_node.output(0), cnode);\r\n",
        "  } else {\r\n",
        "    AbstractBasePtrList abstract_list;\r\n",
        "    int op_idx = 0;\r\n",
        "    for (const auto &output_name : onnx_node.output()) {\r\n",
        "      std::vector<int64_t> shape_vector;\r\n",
        "      auto type_ptr = TypeIdToType(kNumberTypeFloat32);\r\n",
        "      abstract_list.emplace_back(std::make_shared<abstract::AbstractTensor>(type_ptr, shape_vector));\r\n",
        "      auto tuple_get_item_prim_ptr = GetTupleGetItemPrim();\r\n",
        "      if (tuple_get_item_prim_ptr == nullptr) {\r\n",
        "        MS_LOG(ERROR) << \"GetTupleGetItemPrim return nullptr\";\r\n",
        "        return RET_NULL_PTR;\r\n",
        "      }\r\n",
        "      auto tuple_get_item_prim = NewValueNode(tuple_get_item_prim_ptr);\r\n",
        "      auto get_item_value = NewValueNode(MakeValue<int>(op_idx));\r\n",
        "      std::vector<AnfNodePtr> inputs{tuple_get_item_prim, cnode, get_item_value};\r\n",
        "      CNodePtr get_item_cnode = anf_graph->NewCNode(inputs);\r\n",
        "      get_item_cnode->set_fullname_with_scope(cnode->fullname_with_scope() + \"_getitem_\" + std::to_string(op_idx));\r\n",
        "      anf_nodes_map->emplace(output_name, get_item_cnode);\r\n",
        "      op_idx++;\r\n",
        "    }\r\n",
        "    cnode->set_abstract(std::make_shared<abstract::AbstractTuple>(abstract_list));\r\n",
        "  }\r\n",
        "  anf_nodes_map->emplace(onnx_node.name(), cnode);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertOpQuantParams(const onnx::NodeProto &onnx_node, lite::PrimitiveC *primitive_c) {\r\n",
        "  if (primitive_c == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"primitive_c is null, get quant params failed.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  auto status = ParseQuantParam(onnx_node);\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"parse quant param failed.\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  // set input tensors\r\n",
        "  for (int i = 0; i < onnx_node.input_size(); ++i) {\r\n",
        "    const auto &input_name = onnx_node.input(i);\r\n",
        "    std::vector<schema::QuantParamT> quant_params;\r\n",
        "    status = SetTensorQuantParam(input_name, &quant_params);\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"set input tensor quant param failed.\";\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "    primitive_c->AddInputQuantParam(quant_params);\r\n",
        "  }\r\n",
        "  // set out tensors\r\n",
        "  for (int i = 0; i < onnx_node.output_size(); ++i) {\r\n",
        "    const auto &output_name = onnx_node.output(i);\r\n",
        "    std::vector<schema::QuantParamT> quant_params;\r\n",
        "    status = SetTensorQuantParam(output_name, &quant_params);\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"set output tensor quant param failed.\";\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "    primitive_c->AddOutputQuantParam(quant_params);\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ParseQuantParam(const onnx::NodeProto &onnx_node) {\r\n",
        "  for (const auto &onnx_node_attr : onnx_node.attribute()) {\r\n",
        "    if (onnx_node_attr.name() == \"Y_scale\") {\r\n",
        "      float scale = onnx_node_attr.f();\r\n",
        "      if (BuildParameterNodeForQuantParam(&scale, \"scale_\" + onnx_node.output(0), kNumberTypeFloat32) != RET_OK) {\r\n",
        "        MS_LOG(ERROR) << \"parse quant param failed.\";\r\n",
        "        return RET_ERROR;\r\n",
        "      }\r\n",
        "    } else if (onnx_node_attr.name() == \"Y_zero_point\") {\r\n",
        "      int64_t zero_point = onnx_node_attr.i();\r\n",
        "      if (BuildParameterNodeForQuantParam(&zero_point, \"zero_point_\" + onnx_node.output(0), kNumberTypeInt64) !=\r\n",
        "          RET_OK) {\r\n",
        "        MS_LOG(ERROR) << \"parse quant param failed.\";\r\n",
        "        return RET_ERROR;\r\n",
        "      }\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::SetTensorQuantParam(const std::string &tensor_name, std::vector<QuantParamT> *quant_params) {\r\n",
        "  quant_params->clear();\r\n",
        "  auto quant_param = std::make_unique<QuantParamT>();\r\n",
        "  for (int i = 0; i < onnx_root_graph_.quantization_annotation_size(); ++i) {\r\n",
        "    auto tensor_annotation = onnx_root_graph_.quantization_annotation(i);\r\n",
        "    if (!tensor_annotation.has_tensor_name() || tensor_annotation.tensor_name() != tensor_name) {\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    for (const auto &item : tensor_annotation.quant_parameter_tensor_names()) {\r\n",
        "      if (!item.has_key() || !item.has_value()) {\r\n",
        "        continue;\r\n",
        "      }\r\n",
        "\r\n",
        "      const auto &quant_tensor_name = item.value();\r\n",
        "      if (item.key() == \"SCALE_TENSOR\") {\r\n",
        "        auto status = CopyTensorQuantParam(quant_tensor_name, quant_param.get(), true);\r\n",
        "        if (status != RET_OK) {\r\n",
        "          MS_LOG(ERROR) << \"quant param scale get failed\";\r\n",
        "          return status;\r\n",
        "        }\r\n",
        "      } else if (item.key() == \"ZERO_POINT_TENSOR\") {\r\n",
        "        auto status = CopyTensorQuantParam(quant_tensor_name, quant_param.get(), false);\r\n",
        "        if (status != RET_OK) {\r\n",
        "          MS_LOG(ERROR) << \"quant param zero_point get failed\";\r\n",
        "          return status;\r\n",
        "        }\r\n",
        "      }\r\n",
        "    }\r\n",
        "    break;\r\n",
        "  }\r\n",
        "  if (quant_param->inited) {\r\n",
        "    quant_params->push_back(*std::move(quant_param));\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "  return SetTensorQuantParamFromNode(tensor_name, quant_params);\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::SetTensorQuantParamFromNode(const std::string &tensor_name,\r\n",
        "                                                    std::vector<QuantParamT> *quant_params) {\r\n",
        "  quant_params->clear();\r\n",
        "  auto quant_param = std::make_unique<QuantParamT>();\r\n",
        "  std::string quant_tensor_name = \"scale_\" + tensor_name;\r\n",
        "  auto status = CopyTensorQuantParam(quant_tensor_name, quant_param.get(), true);\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"quant param scale get failed\";\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  quant_tensor_name = \"zero_point_\" + tensor_name;\r\n",
        "  status = CopyTensorQuantParam(quant_tensor_name, quant_param.get(), false);\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"quant param zero_point get failed\";\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  if (quant_param->inited) {\r\n",
        "    quant_params->push_back(*std::move(quant_param));\r\n",
        "  } else {\r\n",
        "    std::vector<schema::QuantParamT> notinited_quant_params(1);\r\n",
        "    *quant_params = notinited_quant_params;\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::CopyTensorQuantParam(const std::string &tensor_name, QuantParamT *quant_param,\r\n",
        "                                             bool scale_or_not) {\r\n",
        "  if (quant_param == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"quant_param is nullptr\";\r\n",
        "\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  auto iter = anf_nodes_map_.find(tensor_name);\r\n",
        "  if (iter == anf_nodes_map_.end()) {\r\n",
        "    MS_LOG(DEBUG) << \"has no quant param\";\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "  if (!utils::isa<ParameterPtr>(iter->second)) {\r\n",
        "    MS_LOG(ERROR) << \"quant param get failed\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto quant_parameter_node = iter->second->cast<ParameterPtr>();\r\n",
        "  if (!quant_parameter_node->has_default()) {\r\n",
        "    MS_LOG(ERROR) << \"quant param get failed\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto param_value_lite = quant_parameter_node->default_param()->cast<ParamValueLitePtr>();\r\n",
        "  if (param_value_lite == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"parameterNode's default param is not paramValueLite\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  if (scale_or_not) {\r\n",
        "    quant_param->scale = *reinterpret_cast<float *>(param_value_lite->tensor_addr());\r\n",
        "    quant_param->inited = true;\r\n",
        "  } else {\r\n",
        "    quant_param->zeroPoint = *reinterpret_cast<int64_t *>(param_value_lite->tensor_addr());\r\n",
        "    quant_param->inited = true;\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "ParameterPtr CreateConstParamter(const FuncGraphPtr &anf_graph, int val) {\r\n",
        "  auto const_node = anf_graph->add_parameter();\r\n",
        "  auto const_abstract = std::make_shared<abstract::AbstractTensor>(kInt32, std::vector<int64_t>());\r\n",
        "  const_node->set_abstract(const_abstract);\r\n",
        "  int *tensor_data = new(std::nothrow) int[1];\r\n",
        "  tensor_data[0] = val;\r\n",
        "  auto param_value = std::make_shared<ParamValueLite>();\r\n",
        "  MS_ASSERT(param_value != nullptr);\r\n",
        "  param_value->set_tensor_shape({});\r\n",
        "  param_value->SetTensorData(tensor_data, 4);\r\n",
        "  const_node->set_default_param(param_value);\r\n",
        "  return const_node;\r\n",
        "}\r\n",
        "\r\n",
        "ValueNodePtr CreateValueNode(void *attr, const PrimitiveType &op_type) {\r\n",
        "  auto primitive = std::make_unique<schema::PrimitiveT>();\r\n",
        "  if (primitive == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new primitive failed\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  primitive->value.type = op_type;\r\n",
        "  primitive->value.value = attr;\r\n",
        "  auto primitive_c = PrimitiveC::Create(primitive.release());\r\n",
        "  return NewValueNode(std::shared_ptr<PrimitiveC>(primitive_c));\r\n",
        "}\r\n",
        "\r\n",
        "STATUS AddIterNumsUpdateEdge(const FuncGraphPtr &anf_graph, std::vector<AnfNodePtr> *return_new_inputs,\r\n",
        "                             const std::unordered_map<std::string, AnfNodePtr> &anf_nodes_map,\r\n",
        "                             const std::string &trip_cout_name, const std::string &loop_node_name) {\r\n",
        "  // trip_cout need -1 after every iteration\r\n",
        "  auto attr = std::make_unique<schema::SubT>();\r\n",
        "  auto sub_value_node = CreateValueNode(attr.release(), schema::PrimitiveType_Sub);\r\n",
        "\r\n",
        "  auto &trip_cout_paramter = anf_nodes_map.at(trip_cout_name);\r\n",
        "  if (trip_cout_paramter == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"trip_cout_paramter found failed\";\r\n",
        "    return ERROR;\r\n",
        "  }\r\n",
        "  auto const_one_parameter = CreateConstParamter(anf_graph, 1);\r\n",
        "  const_one_parameter->set_name(loop_node_name + \"_index_update_parameter\");\r\n",
        "\r\n",
        "  std::vector<AnfNodePtr> sub_inputs = {sub_value_node, trip_cout_paramter, const_one_parameter};\r\n",
        "  auto sub_cnode = anf_graph->NewCNode(sub_inputs);\r\n",
        "  sub_cnode->set_fullname_with_scope(loop_node_name + \"_sub\");\r\n",
        "  sub_cnode->set_abstract(trip_cout_paramter->abstract());\r\n",
        "  return_new_inputs->insert(return_new_inputs->begin() + 1, sub_cnode);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "// onnx loop scan_output need through tensorlist op,while node need add new inputs\r\n",
        "STATUS OnnxModelParser::AddTensorArrayEdge(const FuncGraphPtr &anf_graph,\r\n",
        "                                           std::vector<AnfNodePtr> *return_new_inputs,\r\n",
        "                                           const std::string &loop_node_name,\r\n",
        "                                           std::vector<AnfNodePtr> *body_graph_inputs,\r\n",
        "                                           int act_output_num) {\r\n",
        "  // body graph output is  trip_count,cond_count,loop_var,placeholder,scan_outputs\r\n",
        "  auto root_while_node = control_nodes_map_[loop_node_name]->at(loop_node_name)->cast<CNodePtr>();\r\n",
        "  if (root_while_node == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"anf root node map cannot find loop node\" << loop_node_name;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto anf_root_graph = root_while_node->func_graph();\r\n",
        "  auto root_item_index_parameter = CreateConstParamter(anf_root_graph, 0);\r\n",
        "  root_item_index_parameter->set_name(loop_node_name + \"_item_index\");\r\n",
        "  MS_LOG(ERROR) << \"find loop node name:\" << loop_node_name;\r\n",
        "  root_while_node->add_input(root_item_index_parameter);\r\n",
        "  // fake parameter need pass by root while node input\r\n",
        "  auto item_index_parameter = anf_graph->add_parameter();\r\n",
        "  item_index_parameter->set_name(loop_node_name + \"_item_index\");\r\n",
        "  item_index_parameter->set_abstract(root_item_index_parameter->abstract());\r\n",
        "  body_graph_inputs->emplace_back(item_index_parameter);\r\n",
        "  // item index++ edge\r\n",
        "  auto add_attr = std::make_unique<schema::AddT>();\r\n",
        "  if (add_attr == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new op failed\";\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto add_value_node = CreateValueNode(add_attr.release(), schema::PrimitiveType_Add);\r\n",
        "  auto add_one_input = CreateConstParamter(anf_graph, 1);\r\n",
        "  add_one_input->set_name(loop_node_name + \"_const_placeholder_1\");\r\n",
        "  std::vector<AnfNodePtr> add_inputs = {add_value_node, item_index_parameter, add_one_input};\r\n",
        "  auto add_cnode = anf_graph->NewCNode(add_inputs);\r\n",
        "  add_cnode->set_fullname_with_scope(loop_node_name + \"item_index_add_node\");\r\n",
        "  add_cnode->set_abstract(root_item_index_parameter->abstract());\r\n",
        "  // return node inputs will be trip_count,cond_out,loop_var,placeholder,tensorarray...\r\n",
        "  return_new_inputs->insert(return_new_inputs->end() - act_output_num, add_cnode);\r\n",
        "\r\n",
        "  for (int i = 0; i < act_output_num; i++) {\r\n",
        "    // tensor_array need as root while input\r\n",
        "    auto while_tensor_array_input = anf_root_graph->add_parameter();\r\n",
        "    std::vector<int64_t> shape_vector;\r\n",
        "    auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(kTensorType, shape_vector);\r\n",
        "    if (abstract_tensor == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"abstract_tensor is nullptr\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    auto param_value = std::make_shared<ParamValueLite>();\r\n",
        "    param_value->set_tensor_type(kObjectTypeTensorType);\r\n",
        "    while_tensor_array_input->set_abstract(abstract_tensor);\r\n",
        "    while_tensor_array_input->set_default_param(param_value);\r\n",
        "    while_tensor_array_input->set_name(loop_node_name + \"_scan_outputs_tensorarray\");\r\n",
        "    root_while_node->add_input(while_tensor_array_input);\r\n",
        "\r\n",
        "    auto subgraph_tensor_array_input = anf_graph->add_parameter();\r\n",
        "    subgraph_tensor_array_input->set_name(loop_node_name + \"_scan_outputs_tensorarray\");\r\n",
        "    subgraph_tensor_array_input->set_abstract(abstract_tensor);\r\n",
        "    body_graph_inputs->emplace_back(subgraph_tensor_array_input);\r\n",
        "    auto set_item_attr = std::make_unique<schema::TensorListSetItemT>();\r\n",
        "    if (set_item_attr == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"new op failed\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    // skip trip_count ,cond_out,loop_var,no_loop_var,place_holder, output\r\n",
        "    auto loop_output_idx = return_new_inputs->size() - act_output_num + i;\r\n",
        "    auto loop_output_node = (*return_new_inputs)[loop_output_idx];\r\n",
        "    auto set_item_value_node = CreateValueNode(set_item_attr.release(), schema::PrimitiveType_TensorListSetItem);\r\n",
        "    std::vector<AnfNodePtr>\r\n",
        "        set_item_inputs =\r\n",
        "        {set_item_value_node, subgraph_tensor_array_input, item_index_parameter, loop_output_node};\r\n",
        "    auto tensorlist_setitem_cnode = anf_graph->NewCNode(set_item_inputs);\r\n",
        "    tensorlist_setitem_cnode->set_fullname_with_scope(loop_node_name + \"_tensorlist_setitem_node\");\r\n",
        "    tensorlist_setitem_cnode->set_abstract(abstract_tensor);\r\n",
        "    // loop output need replace by tensorliststack_output\r\n",
        "    (*return_new_inputs)[loop_output_idx] = tensorlist_setitem_cnode;\r\n",
        "  }\r\n",
        "\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertLoopOnnxNode(const onnx::NodeProto &onnx_node,\r\n",
        "                                            std::unordered_map<std::string, AnfNodePtr> *anf_root_nodes_map,\r\n",
        "                                            const std::string &root_node_name) {\r\n",
        "  auto node_inputs_num = onnx_node.input_size();\r\n",
        "  auto node_outputs_num = onnx_node.output_size();\r\n",
        "  // skip trip_cout and cond input,scan_output nums\r\n",
        "  auto act_outputs_num = node_outputs_num - (node_inputs_num - 2);\r\n",
        "  for (int i = 0; i < onnx_node.attribute_size(); i++) {\r\n",
        "    auto &attr = onnx_node.attribute(i);\r\n",
        "    if (attr.name() != \"body\" || attr.type() != onnx::AttributeProto_AttributeType_GRAPH) {\r\n",
        "      continue;\r\n",
        "    }\r\n",
        "    auto &subgraph_proto = attr.g();\r\n",
        "    auto loop_body_graph = std::make_shared<FuncGraph>();\r\n",
        "    if (loop_body_graph == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"funcgraph is nullptr.\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    std::unordered_map<std::string, AnfNodePtr> anf_nodes_map;\r\n",
        "    std::vector<AnfNodePtr> gen_subgraph_inputs;\r\n",
        "    auto status =\r\n",
        "        ConvertOnnxGraph(subgraph_proto, loop_body_graph, &anf_nodes_map, &gen_subgraph_inputs, onnx_node.name());\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"convert loop OnnxGraph \";\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "    // while node add outside_input\r\n",
        "    auto &loop_node_name = onnx_node.name();\r\n",
        "    // update body graph input node\r\n",
        "\r\n",
        "    auto return_tuple_cnode = loop_body_graph->get_return()->input(1)->cast<CNodePtr>();\r\n",
        "    auto return_new_inputs = return_tuple_cnode->inputs();\r\n",
        "    return_new_inputs.insert(return_new_inputs.end() - act_outputs_num,\r\n",
        "                             gen_subgraph_inputs.begin(),\r\n",
        "                             gen_subgraph_inputs.end());\r\n",
        "\r\n",
        "    std::string max_trip_count_name = subgraph_proto.input(0).name();\r\n",
        "    status = AddIterNumsUpdateEdge(loop_body_graph, &return_new_inputs,\r\n",
        "                                   anf_nodes_map, max_trip_count_name,\r\n",
        "                                   loop_node_name);\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"add iter nums update edge failed\";\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "    auto root_while_node = control_nodes_map_[loop_node_name]->at(loop_node_name)->cast<CNodePtr>();\r\n",
        "    std::vector<AnfNodePtr> body_graph_inputs;\r\n",
        "    for (int j = 0; j < subgraph_proto.input_size(); j++) {\r\n",
        "      body_graph_inputs.emplace_back(anf_nodes_map[subgraph_proto.input(j).name()]);\r\n",
        "    }\r\n",
        "    body_graph_inputs.insert(body_graph_inputs.end(), gen_subgraph_inputs.begin(),\r\n",
        "                             gen_subgraph_inputs.end());\r\n",
        "    if (act_outputs_num != 0) {\r\n",
        "      status = AddTensorArrayEdge(loop_body_graph, &return_new_inputs,\r\n",
        "                                  loop_node_name, &body_graph_inputs,\r\n",
        "                                  act_outputs_num);\r\n",
        "      if (status != RET_OK) {\r\n",
        "        MS_LOG(ERROR) << \"add tensorarray update edge failed\";\r\n",
        "        return status;\r\n",
        "      }\r\n",
        "      // insert tensorliststack after while output\r\n",
        "\r\n",
        "      auto root_anf_graph = root_while_node->func_graph();\r\n",
        "      auto stack_elem_node = CreateConstParamter(root_anf_graph,-1);\r\n",
        "      stack_elem_node->set_name(loop_node_name + \"_element_shape\");\r\n",
        "      for (int j = 0; j < act_outputs_num; j++) {\r\n",
        "        auto output_size = onnx_node.output_size();\r\n",
        "        auto &loop_output_name = onnx_node.output(output_size - act_outputs_num + j);\r\n",
        "        auto &while_output_node = control_nodes_map_[loop_node_name]->at(loop_output_name);\r\n",
        "        auto stack_attr = std::make_unique<schema::TensorListStackT>();\r\n",
        "        if (stack_attr == nullptr) {\r\n",
        "          MS_LOG(ERROR) << \"new op failed\";\r\n",
        "          return RET_ERROR;\r\n",
        "        }\r\n",
        "        auto stack_value_node = CreateValueNode(stack_attr.release(), schema::PrimitiveType_TensorListStack);\r\n",
        "        std::vector<AnfNodePtr>\r\n",
        "            stack_inputs = {stack_value_node, while_output_node, stack_elem_node};\r\n",
        "        auto tensorlist_stack_cnode = root_anf_graph->NewCNode(stack_inputs);\r\n",
        "        tensorlist_stack_cnode->set_fullname_with_scope(\r\n",
        "            loop_node_name + \"_tensorlist_stack_node_\" + std::to_string(j));\r\n",
        "        tensorlist_stack_cnode->set_abstract(stack_elem_node->abstract());\r\n",
        "\r\n",
        "        // update getitem value output index\r\n",
        "        auto new_get_item_value = NewValueNode(MakeValue<int>(body_graph_inputs.size() - act_outputs_num + i));\r\n",
        "        while_output_node->cast<CNodePtr>()->set_input(2,new_get_item_value);\r\n",
        "        // insert tensorliststack after while_output\r\n",
        "        (*control_nodes_map_[loop_node_name])[loop_output_name] = tensorlist_stack_cnode;\r\n",
        "      }\r\n",
        "    }\r\n",
        "    return_tuple_cnode->set_inputs(return_new_inputs);\r\n",
        "    auto loop_cond_graph = std::make_shared<FuncGraph>();\r\n",
        "    if (loop_cond_graph == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"funcgraph is nullptr.\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    auto cond_graph_name = loop_node_name + \"_cond_graph\";\r\n",
        "    status = BuildCondGraph(loop_cond_graph, root_while_node, return_new_inputs.size() - 1, cond_graph_name);\r\n",
        "    if (status != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"build cond graph failed\";\r\n",
        "      return status;\r\n",
        "    }\r\n",
        "\r\n",
        "    auto body_graph_name = loop_node_name + \"_body_graph\";\r\n",
        "    for (size_t j = 0; j < body_graph_inputs.size(); j++) {\r\n",
        "      body_graph_inputs[j]->cast<ParameterPtr>()->set_name(\r\n",
        "          body_graph_name + \"_input_\" + std::to_string(j) + \"_parameter\");\r\n",
        "    }\r\n",
        "    for (size_t j = 1; j < return_new_inputs.size(); j++) {\r\n",
        "      if (utils::isa<CNodePtr>(return_new_inputs[j])) {\r\n",
        "        return_new_inputs[j]->cast<CNodePtr>()->set_fullname_with_scope(body_graph_name + \"_output_\" +\r\n",
        "            std::to_string(j - 1) + \"_cnode\");\r\n",
        "      } else if (utils::isa<ParameterPtr>(return_new_inputs[j])) {\r\n",
        "        return_new_inputs[j]->cast<ParameterPtr>()->set_name(body_graph_name + \"_output_\" + std::to_string(j - 1) +\r\n",
        "            \"_parameter\");\r\n",
        "      }\r\n",
        "    }\r\n",
        "    loop_cond_graph->set_attr(\"graph_name\", MakeValue(cond_graph_name));\r\n",
        "    loop_body_graph->set_attr(\"graph_name\", MakeValue(body_graph_name));\r\n",
        "    loop_cond_graph->set_manager(anf_root_graph_->manager());\r\n",
        "    loop_body_graph->set_manager(anf_root_graph_->manager());\r\n",
        "    auto cond_value_node = NewValueNode(loop_cond_graph);\r\n",
        "    auto body_value_node = NewValueNode(loop_body_graph);\r\n",
        "    auto inputs = root_while_node->inputs();\r\n",
        "    inputs.insert(inputs.begin() + 1, {cond_value_node, body_value_node});\r\n",
        "    root_while_node->set_inputs(inputs);\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "}\r\n",
        "STATUS OnnxModelParser::BuildCondGraph(const FuncGraphPtr &cond_graph,\r\n",
        "                                       const AnfNodePtr &root_while_node,\r\n",
        "                                       int inputs_num, const std::string &cond_graph_name) {\r\n",
        "  STATUS status = RET_OK;\r\n",
        "  CNodePtr less_cnode = nullptr;\r\n",
        "  for (int i = 0; i < inputs_num; i++) {\r\n",
        "    auto input_paramter = cond_graph->add_parameter();\r\n",
        "    input_paramter->set_name(cond_graph_name + \"_input_\" + std::to_string(i) + \"_parameter\");\r\n",
        "    auto root_while_inputs = root_while_node->cast<CNodePtr>()->inputs();\r\n",
        "    auto input_abstract = std::make_shared<abstract::AbstractTensor>(kInt32, std::vector<int64_t>());\r\n",
        "    input_paramter->set_abstract(input_abstract);\r\n",
        "    if (i == 0) {\r\n",
        "      auto zero_parameter = CreateConstParamter(cond_graph, 0);\r\n",
        "      zero_parameter->set_name(root_while_node->fullname_with_scope() + \"_const_0\");\r\n",
        "      auto attr = std::make_unique<schema::LessT>();\r\n",
        "      auto less_value_node = CreateValueNode(attr.release(), schema::PrimitiveType_Less);\r\n",
        "      std::vector<AnfNodePtr> less_inputs = {less_value_node, zero_parameter, input_paramter};\r\n",
        "      less_cnode = cond_graph->NewCNode(less_inputs);\r\n",
        "      auto less_abstract = std::make_shared<abstract::AbstractTensor>(kBool, std::vector<int64_t>());\r\n",
        "      less_cnode->set_abstract(less_abstract);\r\n",
        "      less_cnode->set_fullname_with_scope(cond_graph_name + \"_less_cnode\");\r\n",
        "    }\r\n",
        "    if (i == 1) {\r\n",
        "      auto attr = std::make_unique<schema::LogicalAndT>();\r\n",
        "      auto and_value_node = CreateValueNode(attr.release(), schema::PrimitiveType_LogicalAnd);\r\n",
        "      std::vector<AnfNodePtr> and_inputs = {and_value_node, less_cnode, input_paramter};\r\n",
        "      auto and_cnode = cond_graph->NewCNode(and_inputs);\r\n",
        "      and_cnode->set_abstract(less_cnode->abstract());\r\n",
        "      and_cnode->set_fullname_with_scope(cond_graph_name + \"_output_\" +\r\n",
        "          std::to_string(0) + \"_cnode\");\r\n",
        "      status = BuildReturnNode(cond_graph, {and_cnode});\r\n",
        "      if (status != RET_OK) {\r\n",
        "        MS_LOG(ERROR) << \"build return node failed.\";\r\n",
        "        return status;\r\n",
        "      }\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return status;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertSpecialOnnxNode(const onnx::NodeProto &onnx_node,\r\n",
        "                                               const FuncGraphPtr &anf_graph,\r\n",
        "                                               std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                                               lite::PrimitiveC *primitive_c) {\r\n",
        "  if (primitive_c == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"imitive_c is nullptr.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  STATUS status = RET_OK;\r\n",
        "  if (onnx_node.op_type() == \"Gemm\") {\r\n",
        "    status = ConvertOnnxGemmNode(onnx_node, anf_graph, anf_nodes_map, primitive_c);\r\n",
        "  } else {\r\n",
        "    MS_LOG(ERROR) << \"the node is not special node.\";\r\n",
        "    status = RET_ERROR;\r\n",
        "  }\r\n",
        "  delete primitive_c;\r\n",
        "  return status;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::ConvertOnnxGemmNode(const onnx::NodeProto &onnx_node,\r\n",
        "                                            const FuncGraphPtr &anf_graph,\r\n",
        "                                            std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                                            lite::PrimitiveC *primitive_c) {\r\n",
        "  if (onnx_node.op_type() != \"Gemm\") {\r\n",
        "    MS_LOG(ERROR) << \"this op is not gemm, it is \" << onnx_node.op_type();\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  if (primitive_c == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"primitive_c is nullptr.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  auto status = BuildCNodeForGemm(onnx_node, anf_graph, anf_nodes_map, primitive_c, \"MatMul\");\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"convert gemm node failed.\";\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  status = BuildCNodeForGemm(onnx_node, anf_graph, anf_nodes_map, primitive_c, \"BiasAdd\");\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"convert gemm node failed.\";\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::BuildCNodeForGemm(const onnx::NodeProto &onnx_node,\r\n",
        "                                          const FuncGraphPtr &anf_graph,\r\n",
        "                                          std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                                          lite::PrimitiveC *primitive_c,\r\n",
        "                                          const std::string &name) {\r\n",
        "  if (primitive_c == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"primitive_c is nullptr.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  auto value = primitive_c->GetAttr(name);\r\n",
        "  primitive_c->EraseAttr(name);\r\n",
        "  if (value == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"op parse failed.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  auto prim_ptr = value->cast<std::shared_ptr<lite::PrimitiveC>>();\r\n",
        "  if (prim_ptr == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"p parse failed.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  auto type_ptr = TypeIdToType(kTypeUnknown);\r\n",
        "  std::vector<int64_t> shape_vector;\r\n",
        "  std::vector<AnfNodePtr> op_inputs;\r\n",
        "  if (name == \"MatMul\") {\r\n",
        "    for (int i = 0; i < 2; ++i) {\r\n",
        "      if (anf_nodes_map->find(onnx_node.input(i)) == anf_nodes_map->end()) {\r\n",
        "        MS_LOG(ERROR) << \"op \" << onnx_node.op_type() << \" inputs get failed.\";\r\n",
        "        return RET_ERROR;\r\n",
        "      } else {\r\n",
        "        op_inputs.push_back(anf_nodes_map->at(onnx_node.input(i)));\r\n",
        "        prim_ptr->AddInputQuantParam(primitive_c->input_quant_params().at(i));\r\n",
        "      }\r\n",
        "    }\r\n",
        "    prim_ptr->AddOutputQuantParam(std::vector<schema::QuantParamT>(1));\r\n",
        "    auto new_cnode = anf_graph->NewCNode(prim_ptr, op_inputs);\r\n",
        "    new_cnode->set_fullname_with_scope(\"Gemm_MatMul_\" + onnx_node.output(0));\r\n",
        "    new_cnode->set_abstract(std::make_shared<abstract::AbstractTensor>(type_ptr, shape_vector));\r\n",
        "    anf_nodes_map->emplace(\"Gemm_MatMul_\" + onnx_node.output(0), new_cnode);\r\n",
        "  } else {\r\n",
        "    if (anf_nodes_map->find(\"Gemm_MatMul_\" + onnx_node.output(0)) == anf_nodes_map->end() ||\r\n",
        "        anf_nodes_map->find(onnx_node.input(2)) == anf_nodes_map->end()) {\r\n",
        "      MS_LOG(ERROR) << \"op \" << onnx_node.op_type() << \" inputs get failed.\";\r\n",
        "      return RET_ERROR;\r\n",
        "    }\r\n",
        "    op_inputs.push_back(anf_nodes_map->at(\"Gemm_MatMul_\" + onnx_node.output(0)));\r\n",
        "    op_inputs.push_back(anf_nodes_map->at(onnx_node.input(2)));\r\n",
        "    prim_ptr->AddInputQuantParam(std::vector<schema::QuantParamT>(1));\r\n",
        "    prim_ptr->AddInputQuantParam(primitive_c->input_quant_params().at(2));\r\n",
        "    prim_ptr->AddOutputQuantParam(primitive_c->output_quant_params().front());\r\n",
        "    auto new_cnode = anf_graph->NewCNode(prim_ptr, op_inputs);\r\n",
        "    new_cnode->set_fullname_with_scope(\"Gemm_BiasAdd_\" + onnx_node.output(0));\r\n",
        "    new_cnode->set_abstract(std::make_shared<abstract::AbstractTensor>(type_ptr, shape_vector));\r\n",
        "    anf_nodes_map->emplace(onnx_node.output(0), new_cnode);\r\n",
        "  }\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::BuildParameterNodeForQuantParam(void *data, const std::string &name, TypeId type) {\r\n",
        "  if (data == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"value is nullptr.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  if (type != kNumberTypeInt64 && type != kNumberTypeFloat32) {\r\n",
        "    MS_LOG(ERROR) << \"quant param type don't support.\";\r\n",
        "    return RET_NOT_SUPPORT;\r\n",
        "  }\r\n",
        "  std::vector<int64_t> shape_vector;\r\n",
        "  auto parameter_node = anf_root_graph_->add_parameter();\r\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(TypeIdToType(type), shape_vector);\r\n",
        "  parameter_node->set_abstract(abstract_tensor);\r\n",
        "  parameter_node->set_name(name);\r\n",
        "  std::vector<int> shape;\r\n",
        "  ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\r\n",
        "  MS_ASSERT(param_value != nullptr);\r\n",
        "  param_value->set_tensor_shape(shape);\r\n",
        "  param_value->set_format(schema::Format_NUM_OF_FORMAT);\r\n",
        "  param_value->set_tensor_type(type);\r\n",
        "  int data_size = 0;\r\n",
        "  if (type == kNumberTypeFloat32) {\r\n",
        "    data_size = sizeof(float);\r\n",
        "  } else {\r\n",
        "    data_size = sizeof(int64_t);\r\n",
        "  }\r\n",
        "  auto *tensor_data = new(std::nothrow) char[data_size];\r\n",
        "  if (memcpy_s(tensor_data, data_size, data, data_size) != EOK) {\r\n",
        "    MS_LOG(ERROR) << \"memcpy data failed.\";\r\n",
        "    delete[] tensor_data;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  param_value->SetTensorData(tensor_data, data_size);\r\n",
        "  parameter_node->set_default_param(param_value);\r\n",
        "  anf_nodes_map_.emplace(name, parameter_node);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::BuildParameterNode(const ParameterPtr &parameter_node, const onnx::TensorProto &tensor) {\r\n",
        "  auto data_type = GetDataTypeFromOnnx(static_cast<onnx::TensorProto_DataType>(tensor.data_type()));\r\n",
        "  if (data_type == kTypeUnknown) {\r\n",
        "    MS_LOG(ERROR) << \"not support onnx data type \" << static_cast<onnx::TensorProto_DataType>(tensor.data_type());\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  auto type_ptr = TypeIdToType(data_type);\r\n",
        "  std::vector<int64_t> shape_vector(tensor.dims().begin(), tensor.dims().end());\r\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(type_ptr, shape_vector);\r\n",
        "  parameter_node->set_abstract(abstract_tensor);\r\n",
        "  parameter_node->set_name(tensor.name());\r\n",
        "\r\n",
        "  ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\r\n",
        "  MS_ASSERT(param_value != nullptr);\r\n",
        "  std::vector<int> shape;\r\n",
        "  std::transform(shape_vector.begin(), shape_vector.end(), std::back_inserter(shape),\r\n",
        "                 [](const int64_t &value) { return static_cast<int>(value); });\r\n",
        "  param_value->set_tensor_shape(shape);\r\n",
        "  param_value->set_tensor_type(data_type);\r\n",
        "  param_value->set_format(schema::Format::Format_NCHW);\r\n",
        "  auto status = CopyOnnxTensorData(tensor, param_value);\r\n",
        "  if (status != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"copy data failed.\";\r\n",
        "    return status;\r\n",
        "  }\r\n",
        "  parameter_node->set_default_param(param_value);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "STATUS OnnxModelParser::CopyOnnxTensorData(const onnx::TensorProto &onnx_const_tensor,\r\n",
        "                                           const ParamValueLitePtr &param_value_lite) {\r\n",
        "  if (param_value_lite == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"param_value_lite is nullptr.\";\r\n",
        "    return RET_NULL_PTR;\r\n",
        "  }\r\n",
        "  size_t data_count = 1;\r\n",
        "  std::for_each(onnx_const_tensor.dims().begin(), onnx_const_tensor.dims().end(),\r\n",
        "                [&data_count](int dim) { data_count *= dim; });\r\n",
        "  size_t data_size = 0;\r\n",
        "  const void *onnx_data = nullptr;\r\n",
        "  auto data_type = GetDataTypeFromOnnx(static_cast<onnx::TensorProto_DataType>(onnx_const_tensor.data_type()));\r\n",
        "  switch (data_type) {\r\n",
        "    case kNumberTypeFloat32:data_size = data_count * sizeof(float);\r\n",
        "      if (onnx_const_tensor.float_data_size() == 0) {\r\n",
        "        onnx_data = onnx_const_tensor.raw_data().data();\r\n",
        "      } else {\r\n",
        "        onnx_data = onnx_const_tensor.float_data().data();\r\n",
        "      }\r\n",
        "      break;\r\n",
        "    case kNumberTypeInt32:data_size = data_count * sizeof(int);\r\n",
        "      if (onnx_const_tensor.int32_data_size() == 0) {\r\n",
        "        onnx_data = onnx_const_tensor.raw_data().data();\r\n",
        "      } else {\r\n",
        "        onnx_data = onnx_const_tensor.int32_data().data();\r\n",
        "      }\r\n",
        "      break;\r\n",
        "    case kNumberTypeInt64:data_size = data_count * sizeof(int64_t);\r\n",
        "      if (onnx_const_tensor.int64_data_size() == 0) {\r\n",
        "        onnx_data = onnx_const_tensor.raw_data().data();\r\n",
        "      } else {\r\n",
        "        onnx_data = onnx_const_tensor.int64_data().data();\r\n",
        "      }\r\n",
        "      break;\r\n",
        "    case kNumberTypeUInt8:\r\n",
        "    case kNumberTypeInt8:\r\n",
        "    case kNumberTypeBool:data_size = data_count * sizeof(uint8_t);\r\n",
        "      onnx_data = onnx_const_tensor.raw_data().data();\r\n",
        "      break;\r\n",
        "    default:MS_LOG(ERROR) << \"unsupported data type \" << data_type;\r\n",
        "      return RET_ERROR;\r\n",
        "  }\r\n",
        "  if (data_size == 0) {\r\n",
        "    return RET_OK;\r\n",
        "  }\r\n",
        "  char *param_data = new(std::nothrow) char[data_size];\r\n",
        "  if (param_data == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new char[] failed\";\r\n",
        "    return RET_MEMORY_FAILED;\r\n",
        "  }\r\n",
        "  if (memcpy_s(static_cast<void *>(param_data), data_size, onnx_data, data_size) != EOK) {\r\n",
        "    MS_LOG(ERROR) << \"memcpy_s failed\";\r\n",
        "    delete[] param_data;\r\n",
        "    return RET_ERROR;\r\n",
        "  }\r\n",
        "  param_value_lite->SetTensorData(param_data, data_size);\r\n",
        "  return RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "bool OnnxModelParser::IsSpecialOnnxNode(const onnx::NodeProto &onnx_node) {\r\n",
        "  return SPECIAL_NODE.find(onnx_node.op_type()) != SPECIAL_NODE.end();\r\n",
        "}\r\n",
        "\r\n",
        "TypeId OnnxModelParser::GetDataTypeFromOnnx(onnx::TensorProto_DataType onnx_type) {\r\n",
        "  auto iter = TYPE_MAP.find(onnx_type);\r\n",
        "  if (iter == TYPE_MAP.end()) {\r\n",
        "    MS_LOG(ERROR) << \"unsupported onnx data type: \" << onnx_type;\r\n",
        "    return kTypeUnknown;\r\n",
        "  }\r\n",
        "  return iter->second;\r\n",
        "}\r\n",
        "}  // namespace lite\r\n",
        "}  // namespace mindspore\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnCvRtW4eWPg"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#ifndef MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_ONNX_MODEL_PARSER_H\r\n",
        "#define MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_ONNX_MODEL_PARSER_H\r\n",
        "\r\n",
        "#include <google/protobuf/io/coded_stream.h>\r\n",
        "#include <google/protobuf/io/zero_copy_stream_impl.h>\r\n",
        "#include <google/protobuf/text_format.h>\r\n",
        "#include <fcntl.h>\r\n",
        "#include <unistd.h>\r\n",
        "#include <string>\r\n",
        "#include <vector>\r\n",
        "#include <memory>\r\n",
        "#include <set>\r\n",
        "#include <unordered_map>\r\n",
        "#include \"securec/include/securec.h\"\r\n",
        "#include \"tools/converter/model_parser.h\"\r\n",
        "#include \"tools/converter/parser/onnx/onnx_node_parser_registry.h\"\r\n",
        "#include \"proto/onnx.pb.h\"\r\n",
        "#include \"src/param_value_lite.h\"\r\n",
        "\r\n",
        "namespace mindspore {\r\n",
        "namespace lite {\r\n",
        "class OnnxModelParser : public ModelParser {\r\n",
        " public:\r\n",
        "  OnnxModelParser() = default;\r\n",
        "\r\n",
        "  ~OnnxModelParser() override = default;\r\n",
        "\r\n",
        "  MetaGraphT *ParseToFb(const std::string &model_file, const std::string &weight_file,\r\n",
        "                        const QuantType &quant_type) override {\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "\r\n",
        "  FuncGraphPtr Parse(const std::string &model_file, const std::string &weight_file,\r\n",
        "                     const QuantType &quant_type) override;\r\n",
        "  static TypeId GetDataTypeFromOnnx(onnx::TensorProto_DataType onnx_type);\r\n",
        "  static STATUS CopyOnnxTensorData(const onnx::TensorProto &onnx_const_value,\r\n",
        "                                   const ParamValueLitePtr &param_value_lite);\r\n",
        "\r\n",
        " private:\r\n",
        "  STATUS InitOriginModel(const std::string &model_file);\r\n",
        "  STATUS ConvertNodes(const onnx::GraphProto &onnx_graph,\r\n",
        "                      const FuncGraphPtr &func_graph_ptr,\r\n",
        "                      std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                      std::vector<AnfNodePtr> *graph_inputs,const std::string &root_node_name);\r\n",
        "  STATUS ConvertOnnxGraph(const onnx::GraphProto &onnx_graph,\r\n",
        "                          const FuncGraphPtr &func_graph_ptr,\r\n",
        "                          std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                          std::vector<AnfNodePtr> *graph_inputs,const std::string &root_node_name);\r\n",
        "  STATUS ConvertConstTensors(const onnx::GraphProto &onnx_graph, const FuncGraphPtr &func_graph_ptr,\r\n",
        "                             std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map);\r\n",
        "  STATUS ConvertGraphInputs(const onnx::GraphProto &onnx_graph, const FuncGraphPtr &func_graph_ptr,\r\n",
        "                            std::unordered_map<std::string, AnfNodePtr> *nodes_map);\r\n",
        "  STATUS ConvertGraphOutputs(const onnx::GraphProto &onnx_graph, const FuncGraphPtr &func_graph_ptr,\r\n",
        "                             const std::unordered_map<std::string, AnfNodePtr> &anf_nodes_map);\r\n",
        "  STATUS BuildReturnNode(const FuncGraphPtr &func_graph_ptr, const std::vector<AnfNodePtr> &return_inputs);\r\n",
        "  STATUS BuildParameterNode(const ParameterPtr &parameter_node, const onnx::TensorProto &tensor);\r\n",
        "  STATUS BuildParameterNodeForQuantParam(void *data, const std::string &name, TypeId type);\r\n",
        "  STATUS BuildCNode(const onnx::NodeProto &onnx_node,\r\n",
        "                    const FuncGraphPtr &func_graph_ptr,\r\n",
        "                    std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                    std::vector<AnfNodePtr> *graph_inputs,\r\n",
        "                    lite::PrimitiveC *primitive_c, std::string loop_name);\r\n",
        "  STATUS BuildOpOutputs(const onnx::NodeProto &onnx_node, const FuncGraphPtr &func_graph_ptr,\r\n",
        "                        std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map, const CNodePtr &cnode);\r\n",
        "  STATUS ConvertSpecialOnnxNode(const onnx::NodeProto &onnx_node,\r\n",
        "                                const FuncGraphPtr &func_graph_ptr,\r\n",
        "                                std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                                lite::PrimitiveC *primitive_c);\r\n",
        "  STATUS ConvertOnnxGemmNode(const onnx::NodeProto &onnx_node, const FuncGraphPtr &func_graph_ptr,\r\n",
        "                             std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map, lite::PrimitiveC *primitive_c);\r\n",
        "  STATUS BuildCNodeForGemm(const onnx::NodeProto &onnx_node,\r\n",
        "                           const FuncGraphPtr &func_graph_ptr,\r\n",
        "                           std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,\r\n",
        "                           lite::PrimitiveC *primitive_c,\r\n",
        "                           const std::string &name);\r\n",
        "  STATUS ConvertOpQuantParams(const onnx::NodeProto &onnx_node, lite::PrimitiveC *primitive_c);\r\n",
        "  STATUS ParseQuantParam(const onnx::NodeProto &onnx_node);\r\n",
        "  STATUS SetTensorQuantParam(const std::string &tensor_name, std::vector<QuantParamT> *quant_params);\r\n",
        "  STATUS SetTensorQuantParamFromNode(const std::string &tensor_name, std::vector<QuantParamT> *quant_params);\r\n",
        "  STATUS CopyTensorQuantParam(const std::string &tensor_name, QuantParamT *quant_param, bool scale_or_not);\r\n",
        "  bool IsSpecialOnnxNode(const onnx::NodeProto &onnx_node);\r\n",
        "  STATUS ConvertLoopOnnxNode(const onnx::NodeProto &onnx_node,\r\n",
        "                             std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,const std::string &root_node_name);\r\n",
        "  STATUS ConvertIfOnnxNode(const onnx::NodeProto &onnx_node,\r\n",
        "                           std::unordered_map<std::string, AnfNodePtr> *anf_nodes_map,const std::string &root_node_name);\r\n",
        "  STATUS AddTensorArrayEdge(const FuncGraphPtr &anf_graph,\r\n",
        "                            std::vector<AnfNodePtr> *return_new_inputs,\r\n",
        "                            const std::string &loop_node_name,\r\n",
        "                            std::vector<AnfNodePtr> *body_graph_inputs,\r\n",
        "                            int act_output_num);\r\n",
        "  STATUS BuildCondGraph(const FuncGraphPtr &cond_graph,\r\n",
        "                        const AnfNodePtr &root_while_node,\r\n",
        "                        int inputs_num,\r\n",
        "                        const std::string &cond_graph_name);\r\n",
        "  STATUS ConvertIfSubgraph(const onnx::GraphProto &onnx_graph,\r\n",
        "                           const FuncGraphPtr &anf_graph,\r\n",
        "                           const std::string &subgrah_name, const std::string &if_node_name,const std::string &root_node_name);\r\n",
        "  onnx::ModelProto onnx_model_;\r\n",
        "  onnx::GraphProto onnx_root_graph_;\r\n",
        "  std::unordered_map<std::string, AnfNodePtr> anf_nodes_map_;\r\n",
        "  std::unordered_map<std::string,std::unordered_map<std::string, AnfNodePtr>*> control_nodes_map_;\r\n",
        "  std::unordered_map<std::string,std::string> child_root_map_;  // for nest control flow node\r\n",
        "  FuncGraphPtr anf_root_graph_ = nullptr;\r\n",
        "};\r\n",
        "}  // namespace lite\r\n",
        "}  // namespace mindspore\r\n",
        "\r\n",
        "#endif  // MINDSPORE_LITE_TOOLS_CONVERTER_PARSER_ONNX_MODEL_PARSER_H\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}