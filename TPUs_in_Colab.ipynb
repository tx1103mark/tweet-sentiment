{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQjHY8m1WpJ7"
      },
      "source": [
        "/**\n",
        " * Copyright 2021 Huawei Technologies Co., Ltd\n",
        " * <p>\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " * <p>\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " * <p>\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "package com.huawei.flclient.model;\n",
        "\n",
        "import com.huawei.flclient.Common;\n",
        "import com.mindspore.lite.MSTensor;\n",
        "\n",
        "import java.nio.ByteBuffer;\n",
        "import java.nio.ByteOrder;\n",
        "import java.util.ArrayList;\n",
        "import java.util.List;\n",
        "import java.util.logging.Logger;\n",
        "\n",
        "public class AdBert extends TrainModel {\n",
        "    private static final Logger logger = Logger.getLogger(AdBert.class.toString());\n",
        "\n",
        "    private static final int NUM_OF_CLASS = 5;\n",
        "\n",
        "    List<Feature> features;\n",
        "\n",
        "    private int dataSize;\n",
        "\n",
        "    private ByteBuffer inputIdBufffer;\n",
        "\n",
        "    private ByteBuffer tokenIdBufffer;\n",
        "\n",
        "    private ByteBuffer maskIdBufffer;\n",
        "\n",
        "    private ByteBuffer labelIdBufffer;\n",
        "\n",
        "    @Override\n",
        "    public int initSessionAndInputs(String modelPath, boolean trainMod) {\n",
        "        int ret = -1;\n",
        "        trainSession = SessionUtil.initSession(modelPath);\n",
        "        if (trainSession == null) {\n",
        "            logger.severe(Common.addTag(\"session init failed\"));\n",
        "            return ret;\n",
        "        }\n",
        "        List<MSTensor> inputs = trainSession.getInputs();\n",
        "        MSTensor labelIdTensor = inputs.get(0);\n",
        "        int inputSize = labelIdTensor.elementsNum(); // labelId,tokenId,inputId,maskId has same size\n",
        "        batchSize = labelIdTensor.getShape()[0];\n",
        "        if (batchSize <= 0) {\n",
        "            logger.severe(Common.addTag(\"batch size should bigger than 0\"));\n",
        "            return ret;\n",
        "        }\n",
        "        dataSize = inputSize / batchSize;\n",
        "        inputIdBufffer = ByteBuffer.allocateDirect(inputSize * Integer.BYTES);\n",
        "        tokenIdBufffer = ByteBuffer.allocateDirect(inputSize * Integer.BYTES);\n",
        "        maskIdBufffer = ByteBuffer.allocateDirect(inputSize * Integer.BYTES);\n",
        "        inputIdBufffer.order(ByteOrder.nativeOrder());\n",
        "        tokenIdBufffer.order(ByteOrder.nativeOrder());\n",
        "        maskIdBufffer.order(ByteOrder.nativeOrder());\n",
        "        if (trainMod) {\n",
        "            labelIdBufffer = ByteBuffer.allocateDirect(inputSize * Integer.BYTES);\n",
        "            labelIdBufffer.order(ByteOrder.nativeOrder());\n",
        "        }\n",
        "        numOfClass = NUM_OF_CLASS;\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    @Override\n",
        "    public List<Integer> fillModelInput(int batchIdx, boolean trainMod) {\n",
        "        inputIdBufffer.clear();\n",
        "        tokenIdBufffer.clear();\n",
        "        maskIdBufffer.clear();\n",
        "        if (trainMod) {\n",
        "            labelIdBufffer.clear();\n",
        "        }\n",
        "        List<Integer> labels = new ArrayList<>();\n",
        "        for (int i = 0; i < batchSize; i++) {\n",
        "            Feature feature = features.get(batchIdx * batchSize + i);\n",
        "            for (int j = 0; j < dataSize; j++) {\n",
        "                inputIdBufffer.putInt(feature.inputIds[j]);\n",
        "            }\n",
        "            for (int j = 0; j < dataSize; j++) {\n",
        "                tokenIdBufffer.putInt(feature.tokenIds[j]);\n",
        "            }\n",
        "            for (int j = 0; j < dataSize; j++) {\n",
        "                maskIdBufffer.putInt(feature.inputMasks[j]);\n",
        "            }\n",
        "            if (!trainMod) {\n",
        "                labels.add(feature.labelIds);\n",
        "            }\n",
        "            if (trainMod) {\n",
        "                for (int j = 0; j < dataSize; j++) {\n",
        "                    labelIdBufffer.putInt(feature.inputIds[j]);\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        List<MSTensor> inputs = trainSession.getInputs();\n",
        "        MSTensor labelIdTensor;\n",
        "        MSTensor tokenIdTensor;\n",
        "        MSTensor inputIdTensor;\n",
        "        MSTensor maskIdTensor;\n",
        "        if (trainMod) {\n",
        "            labelIdTensor = inputs.get(0);\n",
        "            tokenIdTensor = inputs.get(1);\n",
        "            inputIdTensor = inputs.get(2);\n",
        "            maskIdTensor = inputs.get(3);\n",
        "            labelIdTensor.setData(labelIdBufffer);\n",
        "        } else {\n",
        "            tokenIdTensor = inputs.get(0);\n",
        "            inputIdTensor = inputs.get(1);\n",
        "            maskIdTensor = inputs.get(2);\n",
        "        }\n",
        "        tokenIdTensor.setData(tokenIdBufffer);\n",
        "        inputIdTensor.setData(inputIdBufffer);\n",
        "        maskIdTensor.setData(maskIdBufffer);\n",
        "        return labels;\n",
        "    }\n",
        "\n",
        "    @Override\n",
        "    public int padSamples() {\n",
        "        if (batchSize <= 0) {\n",
        "            logger.severe(Common.addTag(\"batch size should bigger than 0\"));\n",
        "            return -1;\n",
        "        }\n",
        "        logger.info(Common.addTag(\"before pad samples size:\" + features.size()));\n",
        "        int curSize = features.size();\n",
        "        int modSize = curSize - curSize / batchSize * batchSize;\n",
        "        padSize = modSize != 0 ? batchSize - modSize : 0;\n",
        "        for (int i = 0; i < padSize; i++) {\n",
        "            int idx = (int) (Math.random() * curSize);\n",
        "            features.add(features.get(idx));\n",
        "        }\n",
        "        trainSampleSize = features.size();\n",
        "        batchNum = features.size() / batchSize;\n",
        "        logger.info(Common.addTag(\"after pad samples size:\" + features.size()));\n",
        "        return 0;\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VolmJb3lwMH5"
      },
      "source": [
        "/**\n",
        " * Copyright 2021 Huawei Technologies Co., Ltd\n",
        " * <p>\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " * <p>\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " * <p>\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "package com.huawei.flclient.model;\n",
        "\n",
        "import com.huawei.flclient.Common;\n",
        "\n",
        "import java.util.Arrays;\n",
        "import java.util.logging.Logger;\n",
        "\n",
        "public class AdInferBert extends AdBert {\n",
        "    private static final Logger logger = Logger.getLogger(AdInferBert.class.toString());\n",
        "\n",
        "    private static AdInferBert adInferBert;\n",
        "\n",
        "    public static synchronized AdInferBert getInstance() {\n",
        "        if (adInferBert == null) {\n",
        "            adInferBert = new AdInferBert();\n",
        "        }\n",
        "        return adInferBert;\n",
        "    }\n",
        "\n",
        "    public int initDataSet(String exampleFile, String vocabFile, String idsFile, boolean evalMod) {\n",
        "        if (evalMod) {\n",
        "            features = DataSet.init(exampleFile, vocabFile, idsFile, false);\n",
        "        } else {\n",
        "            features = DataSet.readInferData(exampleFile, vocabFile, idsFile, false);\n",
        "        }\n",
        "        if (features == null) {\n",
        "            logger.severe(Common.addTag(\"features cannot be null\"));\n",
        "            return -1;\n",
        "        }\n",
        "        return features.size();\n",
        "    }\n",
        "\n",
        "    private int[] infer() {\n",
        "        boolean success = trainSession.eval();\n",
        "        if (!success) {\n",
        "            logger.severe(Common.addTag(\"trainSession switch eval mode failed\"));\n",
        "            return new int[0];\n",
        "        }\n",
        "        int[] predictLabels = new int[features.size()];\n",
        "        for (int j = 0; j < batchNum; j++) {\n",
        "            fillModelInput(j, false);\n",
        "            success = trainSession.runGraph();\n",
        "            if (!success) {\n",
        "                logger.severe(Common.addTag(\"run graph failed\"));\n",
        "                return new int[0];\n",
        "            }\n",
        "            int[] batchLabels = getBatchLabel();\n",
        "            System.arraycopy(batchLabels, 0, predictLabels, j * batchSize, batchSize);\n",
        "        }\n",
        "        return predictLabels;\n",
        "    }\n",
        "\n",
        "    public int[] inferModel(String modelPath, String dataFile, String vocabFile, String idsFile) {\n",
        "        logger.info(Common.addTag(\"Infer model,\" + modelPath + \",Data file,\" + dataFile + \",vocab file,\" + vocabFile + \",idsFile,\" + idsFile));\n",
        "        int inferSize = initDataSet(dataFile, vocabFile, idsFile, false);\n",
        "        if (inferSize == 0) {\n",
        "            logger.severe(Common.addTag(\"infer size should more than 0\"));\n",
        "            return new int[0];\n",
        "        }\n",
        "        int status = initSessionAndInputs(modelPath, false);\n",
        "        if (status == -1) {\n",
        "            logger.severe(Common.addTag(\"init session and inputs failed\"));\n",
        "            return new int[0];\n",
        "        }\n",
        "        status = padSamples();\n",
        "        if (status == -1) {\n",
        "            logger.severe(Common.addTag(\"infer model failed\"));\n",
        "            return new int[0];\n",
        "        }\n",
        "        if (batchSize <= 0) {\n",
        "            logger.severe(Common.addTag(\"batch size must bigger than 0\"));\n",
        "            return new int[0];\n",
        "        }\n",
        "        batchNum = features.size() / batchSize;\n",
        "        int[] predictLabels = infer();\n",
        "        if (predictLabels.length == 0) {\n",
        "            return new int[0];\n",
        "        }\n",
        "        return Arrays.copyOfRange(predictLabels, 0, inferSize);\n",
        "    }\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2kV7VAWwMzw"
      },
      "source": [
        "/**\n",
        " * Copyright 2021 Huawei Technologies Co., Ltd\n",
        " * <p>\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " * <p>\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " * <p>\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "package com.huawei.flclient.model;\n",
        "\n",
        "import com.huawei.flclient.Common;\n",
        "\n",
        "import java.util.logging.Logger;\n",
        "\n",
        "public class AdTrainBert extends AdBert {\n",
        "    private static final Logger logger = Logger.getLogger(AdTrainBert.class.toString());\n",
        "\n",
        "    private static AdTrainBert adTrainBert;\n",
        "\n",
        "    public static synchronized AdTrainBert getInstance() {\n",
        "        if (adTrainBert == null) {\n",
        "            adTrainBert = new AdTrainBert();\n",
        "        }\n",
        "        return adTrainBert;\n",
        "    }\n",
        "\n",
        "    public int initDataSet(String dataFile, String vocabFile, String idsFile) {\n",
        "        features = DataSet.init(dataFile, vocabFile, idsFile, true);\n",
        "        if (features == null) {\n",
        "            logger.severe(Common.addTag(\"features cannot be null\"));\n",
        "            return -1;\n",
        "        }\n",
        "        return features.size();\n",
        "    }\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0MbSK2xwSO5"
      },
      "source": [
        "/**\n",
        " * Copyright 2021 Huawei Technologies Co., Ltd\n",
        " * <p>\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " * <p>\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " * <p>\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "package com.huawei.flclient.model;\n",
        "\n",
        "import com.huawei.flclient.Common;\n",
        "\n",
        "import java.io.IOException;\n",
        "import java.nio.charset.StandardCharsets;\n",
        "import java.nio.file.Files;\n",
        "import java.nio.file.Path;\n",
        "import java.nio.file.Paths;\n",
        "import java.util.*;\n",
        "import java.util.logging.Logger;\n",
        "\n",
        "public class CustomTokenizer {\n",
        "    private static final Logger logger = Logger.getLogger(AdInferBert.class.toString());\n",
        "    private Map<String, Integer> vocabs = new HashMap<>();\n",
        "    private Boolean doLowerCase = Boolean.TRUE;\n",
        "    private int maxInputChars = 100;\n",
        "    private String[] NotSplitStrs = {\"UNK\"};\n",
        "    private String unkToken = \"[UNK]\";\n",
        "    private int maxSeqLen = 16;\n",
        "    private int vocabSize = 11682;\n",
        "    private Map<String, Integer> labelMap = new HashMap<String, Integer>() {{\n",
        "        put(\"beauty\", 0);\n",
        "        put(\"education\", 1);\n",
        "        put(\"hotel\", 2);\n",
        "        put(\"travel\", 3);\n",
        "        put(\"other\", 4);\n",
        "    }};\n",
        "\n",
        "    public void init(String vocabFile, String idsFile, boolean trainMod, boolean doLowerCase) {\n",
        "        this.doLowerCase = doLowerCase;\n",
        "        Path vocabPath = Paths.get(vocabFile);\n",
        "        List<String> vocabLines = null;\n",
        "        try {\n",
        "            vocabLines = Files.readAllLines(vocabPath, StandardCharsets.UTF_8);\n",
        "        } catch (IOException e) {\n",
        "            logger.severe(Common.addTag(\"read vocab file failed,\" + e.getMessage()));\n",
        "        }\n",
        "        if (vocabLines == null) {\n",
        "            logger.severe(Common.addTag(\"vocabLines cannot be null\"));\n",
        "            return;\n",
        "        }\n",
        "        Path idsPath = Paths.get(idsFile);\n",
        "        List<String> idsLines = null;\n",
        "        try {\n",
        "            idsLines = Files.readAllLines(idsPath, StandardCharsets.UTF_8);\n",
        "        } catch (IOException e) {\n",
        "            logger.severe(Common.addTag(\"read ids file failed,\" + e.getMessage()));\n",
        "        }\n",
        "        if (idsLines == null) {\n",
        "            logger.severe(Common.addTag(\"idsLines cannot be null\"));\n",
        "            return;\n",
        "        }\n",
        "        for (int i = 0; i < idsLines.size(); ++i) {\n",
        "            vocabs.put(vocabLines.get(i), Integer.parseInt(idsLines.get(i)));\n",
        "        }\n",
        "        if (!trainMod) {\n",
        "            maxSeqLen = 256;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // is chinses or punctuation\n",
        "    public Boolean isChineseOrPunc(char trimChar) {\n",
        "        // is chinese char\n",
        "        if (trimChar >= '\\u4e00' && trimChar <= '\\u9fa5') {\n",
        "            return true;\n",
        "        }\n",
        "        // is puncuation char\n",
        "        return (trimChar >= 33 && trimChar <= 47) || (trimChar >= 58 && trimChar <= 64) || (trimChar >= 91 && trimChar\n",
        "                <= 96) || (trimChar >= 123 && trimChar <= 126);\n",
        "    }\n",
        "\n",
        "    public String[] splitText(String text) {\n",
        "        if (text.isEmpty()) {\n",
        "            return new String[0];\n",
        "        }\n",
        "        // clean remove white and control char\n",
        "        String trimText = text.trim();\n",
        "        StringBuilder cleanText = new StringBuilder();\n",
        "        for (int i = 0; i < trimText.length(); i++) {\n",
        "            if (isChineseOrPunc(trimText.charAt(i))) {\n",
        "                cleanText.append(\" \").append(trimText.charAt(i)).append(\" \");\n",
        "            } else {\n",
        "                cleanText.append(trimText.charAt(i));\n",
        "            }\n",
        "        }\n",
        "        return cleanText.toString().trim().split(\"\\\\s+\");\n",
        "    }\n",
        "\n",
        "    //   input = \"unaffable\" , output = [\"un\", \"##aff\", \"##able\"]\n",
        "    public List<String> wordPieceTokenize(String[] tokens) {\n",
        "        List<String> outputTokens = new ArrayList<>();\n",
        "        for (String token : tokens) {\n",
        "            List<String> subTokens = new ArrayList<>();\n",
        "            boolean isBad = false;\n",
        "            int start = 0;\n",
        "            while (start < token.length()) {\n",
        "                int end = token.length();\n",
        "                String curStr = \"\";\n",
        "                while (start < end) {\n",
        "                    String subStr = token.substring(start, end);\n",
        "                    if (start > 0) {\n",
        "                        subStr = \"##\" + subStr;\n",
        "                    }\n",
        "                    if (vocabs.get(subStr) != null) {\n",
        "                        curStr = subStr;\n",
        "                        break;\n",
        "                    }\n",
        "                    end = end - 1;\n",
        "                }\n",
        "                if (curStr.isEmpty()) {\n",
        "                    isBad = true;\n",
        "                    break;\n",
        "                }\n",
        "                subTokens.add(curStr);\n",
        "                start = end;\n",
        "            }\n",
        "            if (isBad) {\n",
        "                outputTokens.add(unkToken);\n",
        "            } else {\n",
        "                outputTokens.addAll(subTokens);\n",
        "            }\n",
        "        }\n",
        "        return outputTokens;\n",
        "\n",
        "    }\n",
        "\n",
        "    public List<Integer> convertTokensToIds(List<String> tokens, boolean cycTrunc) {\n",
        "        int seqLen = tokens.size();\n",
        "        if (tokens.size() > maxSeqLen - 2) {\n",
        "            if (cycTrunc) {\n",
        "                int randIndex = (int) (Math.random() * seqLen);\n",
        "                if (randIndex > seqLen - maxSeqLen + 2) {\n",
        "                    List<String> rearPart = tokens.subList(randIndex, seqLen);\n",
        "                    List<String> frontPart = tokens.subList(0, randIndex + maxSeqLen - 2 - seqLen);\n",
        "                    rearPart.addAll(frontPart);\n",
        "                    tokens = rearPart;\n",
        "                } else {\n",
        "                    tokens = tokens.subList(randIndex, randIndex + maxSeqLen - 2);\n",
        "                }\n",
        "            } else {\n",
        "                tokens = tokens.subList(0, maxSeqLen - 2);\n",
        "            }\n",
        "        }\n",
        "        tokens.add(0, \"[CLS]\");\n",
        "        tokens.add(\"[SEP]\");\n",
        "        List<Integer> ids = new ArrayList<>(tokens.size());\n",
        "        for (String token : tokens) {\n",
        "            ids.add(vocabs.getOrDefault(token, vocabs.get(\"[UNK]\")));\n",
        "        }\n",
        "        return ids;\n",
        "    }\n",
        "\n",
        "    public void addRandomMaskAndReplace(Feature feature, boolean keepFirstUnchange, boolean keepLastUnchange) {\n",
        "        int[] masks = new int[maxSeqLen];\n",
        "        Arrays.fill(masks, 1);\n",
        "        int[] replaces = new int[maxSeqLen];\n",
        "        Arrays.fill(replaces, 1);\n",
        "        int[] inputIds = feature.inputIds;\n",
        "        for (int i = 0; i < feature.seqLen; i++) {\n",
        "            double rand1 = Math.random();\n",
        "            if (rand1 < 0.15) {\n",
        "                masks[i] = 0;\n",
        "                double rand2 = Math.random();\n",
        "                if (rand2 < 0.8) {\n",
        "                    replaces[i] = 103;\n",
        "                } else if (rand2 < 0.9) {\n",
        "                    masks[i] = 1;\n",
        "                } else {\n",
        "                    replaces[i] = (int) (Math.random() * vocabSize);\n",
        "                }\n",
        "            }\n",
        "            if (keepFirstUnchange) {\n",
        "                masks[i] = 1;\n",
        "                replaces[i] = 0;\n",
        "            }\n",
        "            if (keepLastUnchange) {\n",
        "                masks[feature.seqLen - 1] = 1;\n",
        "                replaces[feature.seqLen - 1] = 0;\n",
        "            }\n",
        "            inputIds[i] = inputIds[i] * masks[i] + replaces[i];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    public Feature getFeatures(List<Integer> tokens, String label) {\n",
        "        int[] segmentIds = new int[maxSeqLen];\n",
        "        Arrays.fill(segmentIds, 0);\n",
        "        int[] masks = new int[maxSeqLen];\n",
        "        Arrays.fill(masks, 0);\n",
        "        Arrays.fill(masks, 0, tokens.size(), 1); // tokens size can ensure less than masks\n",
        "        int[] inputIds = new int[maxSeqLen];\n",
        "        Arrays.fill(inputIds, 0);\n",
        "        for (int i = 0; i < tokens.size(); i++) {\n",
        "            inputIds[i] = tokens.get(i);\n",
        "        }\n",
        "        return new Feature(inputIds, masks, segmentIds, labelMap.get(label), tokens.size());\n",
        "    }\n",
        "\n",
        "    public List<Integer> tokenize(String text, boolean trainMod) {\n",
        "        String[] splitTokens = splitText(text);\n",
        "        List<String> wordPieceTokens = wordPieceTokenize(splitTokens);\n",
        "        return convertTokensToIds(wordPieceTokens, trainMod); // trainMod need cyclicTrunc\n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3_g3H4qwWp7"
      },
      "source": [
        "/**\n",
        " * Copyright 2021 Huawei Technologies Co., Ltd\n",
        " * <p>\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " * <p>\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " * <p>\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "package com.huawei.flclient.model;\n",
        "\n",
        "import com.huawei.flclient.Common;\n",
        "\n",
        "import java.io.IOException;\n",
        "import java.nio.charset.StandardCharsets;\n",
        "import java.nio.file.Files;\n",
        "import java.nio.file.Path;\n",
        "import java.nio.file.Paths;\n",
        "import java.util.ArrayList;\n",
        "import java.util.List;\n",
        "import java.util.logging.Logger;\n",
        "\n",
        "public class DataSet {\n",
        "    private static final Logger logger = Logger.getLogger(DataSet.class.toString());\n",
        "\n",
        "    public static List<Feature> init(String trainFile, String vocabFile, String idsFile, boolean trainMod) {\n",
        "        if (trainFile.isEmpty() || vocabFile.isEmpty() || idsFile.isEmpty()) {\n",
        "            logger.severe(Common.addTag(\"dataset init failed,trainFile,idsFile,vocabFile cannot be empty\"));\n",
        "            return null;\n",
        "        }\n",
        "        // read train file\n",
        "        CustomTokenizer customTokenizer = new CustomTokenizer();\n",
        "        customTokenizer.init(vocabFile, idsFile, trainMod, true);\n",
        "        List<String> allLines = readTxtFile(trainFile);\n",
        "        if (allLines == null) {\n",
        "            logger.severe(Common.addTag(\"all lines cannot be null\"));\n",
        "            return null;\n",
        "        }\n",
        "        List<String> examples = new ArrayList<>();\n",
        "        List<String> labels = new ArrayList<>();\n",
        "        for (String line : allLines) {\n",
        "            String[] tokens = line.split(\">>>\");\n",
        "            if (tokens.length != 2) {\n",
        "                logger.warning(Common.addTag(\"line may have format problem,need include >>>\"));\n",
        "                continue;\n",
        "            }\n",
        "            examples.add(tokens[1]);\n",
        "            tokens = tokens[0].split(\"<<<\");\n",
        "            if (tokens.length != 2) {\n",
        "                logger.warning(Common.addTag(\"line may have format problem,need include >>>\"));\n",
        "                continue;\n",
        "            }\n",
        "            labels.add(tokens[1]);\n",
        "        }\n",
        "\n",
        "        List<Feature> features = new ArrayList<>(examples.size());\n",
        "        for (int i = 0; i < examples.size(); i++) {\n",
        "            List<Integer> tokens = customTokenizer.tokenize(examples.get(i), trainMod);\n",
        "            Feature feature = customTokenizer.getFeatures(tokens, labels.get(i));\n",
        "            if (trainMod) {\n",
        "                customTokenizer.addRandomMaskAndReplace(feature, true, true);\n",
        "            }\n",
        "            features.add(feature);\n",
        "        }\n",
        "        return features;\n",
        "    }\n",
        "\n",
        "    public static List<Feature> readInferData(String inferFile, String vocabFile, String idsFile, boolean trainMod) {\n",
        "        if (inferFile.isEmpty() || vocabFile.isEmpty() || idsFile.isEmpty()) {\n",
        "            logger.severe(Common.addTag(\"dataset init failed,trainFile,idsFile,vocabFile cannot be empty\"));\n",
        "            return null;\n",
        "        }\n",
        "        // read train file\n",
        "        CustomTokenizer customTokenizer = new CustomTokenizer();\n",
        "        customTokenizer.init(vocabFile, idsFile, false, true);\n",
        "        List<String> allLines = readTxtFile(inferFile);\n",
        "        if (allLines == null) {\n",
        "            logger.severe(Common.addTag(\"all lines cannot be null\"));\n",
        "            return null;\n",
        "        }\n",
        "        List<Feature> features = new ArrayList<>(allLines.size());\n",
        "        for (String line : allLines) {\n",
        "            if (line.isEmpty()) {\n",
        "                continue;\n",
        "            }\n",
        "            List<Integer> tokens = customTokenizer.tokenize(line, trainMod);\n",
        "            Feature feature = customTokenizer.getFeatures(tokens, \"other\");\n",
        "            features.add(feature);\n",
        "        }\n",
        "        return features;\n",
        "    }\n",
        "\n",
        "    public static byte[] readBinFile(String dataFile) {\n",
        "        // read train file\n",
        "        Path path = Paths.get(dataFile);\n",
        "        byte[] data = null;\n",
        "        try {\n",
        "            data = Files.readAllBytes(path);\n",
        "        } catch (IOException e) {\n",
        "            logger.severe(Common.addTag(\"read ids file failed,\" + e.getMessage()));\n",
        "        }\n",
        "        return data;\n",
        "    }\n",
        "\n",
        "    private static List<String> readTxtFile(String file) {\n",
        "        Path path = Paths.get(file);\n",
        "        List<String> allLines = null;\n",
        "        try {\n",
        "            allLines = Files.readAllLines(path, StandardCharsets.UTF_8);\n",
        "        } catch (IOException e) {\n",
        "            logger.severe(Common.addTag(\"read file failed,\" + e.getMessage()));\n",
        "        }\n",
        "        return allLines;\n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}