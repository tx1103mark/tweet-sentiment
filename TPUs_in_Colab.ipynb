{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93a3Yz_tHf4"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#include \"src/ops/primitive_c.h\"\r\n",
        "#ifdef PRIMITIVE_WRITEABLE\r\n",
        "#include <memory>\r\n",
        "#include <map>\r\n",
        "#include \"tools/converter/quantizer/quantize_util.h\"\r\n",
        "#include \"src/ops/assert_op.h\"\r\n",
        "#include \"src/ops/space_to_batch.h\"\r\n",
        "#include \"src/ops/space_to_batch_nd.h\"\r\n",
        "#include \"src/ops/conv2d.h\"\r\n",
        "#include \"src/ops/roi_pooling.h\"\r\n",
        "#include \"src/ops/topk.h\"\r\n",
        "#include \"src/ops/broadcast_to.h\"\r\n",
        "#include \"src/ops/unsqueeze.h\"\r\n",
        "#include \"src/ops/unstack.h\"\r\n",
        "#include \"src/ops/depth_to_space.h\"\r\n",
        "#include \"src/ops/batch_to_space.h\"\r\n",
        "#include \"src/ops/prior_box.h\"\r\n",
        "#include \"src/ops/lstm.h\"\r\n",
        "#include \"src/ops/softmax.h\"\r\n",
        "#include \"src/ops/activation.h\"\r\n",
        "#include \"src/ops/deconv2d.h\"\r\n",
        "#include \"src/ops/reduce.h\"\r\n",
        "#include \"src/ops/pooling.h\"\r\n",
        "#include \"src/ops/fused_batchnorm.h\"\r\n",
        "#include \"src/ops/batch_norm.h\"\r\n",
        "#include \"src/ops/power.h\"\r\n",
        "#include \"src/ops/range.h\"\r\n",
        "#include \"src/ops/add.h\"\r\n",
        "#include \"src/ops/sub.h\"\r\n",
        "#include \"src/ops/div.h\"\r\n",
        "#include \"src/ops/bias_add.h\"\r\n",
        "#include \"src/ops/expand_dims.h\"\r\n",
        "#include \"src/ops/full_connection.h\"\r\n",
        "#include \"src/ops/shape.h\"\r\n",
        "#include \"src/ops/elu.h\"\r\n",
        "#include \"src/ops/embedding_lookup.h\"\r\n",
        "#include \"src/ops/quant_dtype_cast.h\"\r\n",
        "#include \"src/ops/matmul.h\"\r\n",
        "#include \"src/ops/resize.h\"\r\n",
        "#include \"src/ops/tile.h\"\r\n",
        "#include \"src/ops/one_hot.h\"\r\n",
        "#include \"src/ops/space_to_depth.h\"\r\n",
        "#include \"src/ops/split.h\"\r\n",
        "#include \"src/ops/argmax.h\"\r\n",
        "#include \"src/ops/argmin.h\"\r\n",
        "#include \"src/ops/cast.h\"\r\n",
        "#include \"src/ops/reshape.h\"\r\n",
        "#include \"src/ops/scale.h\"\r\n",
        "#include \"src/ops/concat.h\"\r\n",
        "#include \"src/ops/nchw2nhwc.h\"\r\n",
        "#include \"src/ops/slice.h\"\r\n",
        "#include \"src/ops/squeeze.h\"\r\n",
        "#include \"src/ops/flatten.h\"\r\n",
        "#include \"src/ops/nhwc2nchw.h\"\r\n",
        "#include \"src/ops/stack.h\"\r\n",
        "#include \"src/ops/crop.h\"\r\n",
        "#include \"src/ops/addn.h\"\r\n",
        "#include \"src/ops/gather.h\"\r\n",
        "#include \"src/ops/gather_nd.h\"\r\n",
        "#include \"src/ops/local_response_normalization.h\"\r\n",
        "#include \"src/ops/pad.h\"\r\n",
        "#include \"src/ops/p_relu.h\"\r\n",
        "#include \"src/ops/leaky_relu.h\"\r\n",
        "#include \"src/ops/reverse_sequence.h\"\r\n",
        "#include \"src/ops/dedepthwise_conv2d.h\"\r\n",
        "#include \"src/ops/depthwise_conv2d.h\"\r\n",
        "#include \"src/ops/mul.h\"\r\n",
        "#include \"src/ops/eltwise.h\"\r\n",
        "#include \"src/ops/fill.h\"\r\n",
        "#include \"src/ops/transpose.h\"\r\n",
        "#include \"src/ops/log.h\"\r\n",
        "#include \"src/ops/abs.h\"\r\n",
        "#include \"src/ops/sin.h\"\r\n",
        "#include \"src/ops/cos.h\"\r\n",
        "#include \"src/ops/sqrt.h\"\r\n",
        "#include \"src/ops/square.h\"\r\n",
        "#include \"src/ops/exp.h\"\r\n",
        "#include \"src/ops/rsqrt.h\"\r\n",
        "#include \"src/ops/maximum.h\"\r\n",
        "#include \"src/ops/minimum.h\"\r\n",
        "#include \"src/ops/strided_slice.h\"\r\n",
        "#include \"src/ops/reverse.h\"\r\n",
        "#include \"src/ops/logical_and.h\"\r\n",
        "#include \"src/ops/logical_or.h\"\r\n",
        "#include \"src/ops/logical_not.h\"\r\n",
        "#include \"src/ops/floor_div.h\"\r\n",
        "#include \"src/ops/floor_mod.h\"\r\n",
        "#include \"src/ops/mod.h\"\r\n",
        "#include \"src/ops/equal.h\"\r\n",
        "#include \"src/ops/not_equal.h\"\r\n",
        "#include \"src/ops/less.h\"\r\n",
        "#include \"src/ops/less_equal.h\"\r\n",
        "#include \"src/ops/greater_equal.h\"\r\n",
        "#include \"src/ops/greater.h\"\r\n",
        "#include \"src/ops/floor.h\"\r\n",
        "#include \"src/ops/squared_difference.h\"\r\n",
        "#include \"src/ops/ceil.h\"\r\n",
        "#include \"src/ops/round.h\"\r\n",
        "#include \"src/ops/unique.h\"\r\n",
        "#include \"src/ops/zeros_like.h\"\r\n",
        "#include \"src/ops/return.h\"\r\n",
        "#include \"src/ops/where.h\"\r\n",
        "#include \"src/ops/scatter_nd.h\"\r\n",
        "#include \"src/ops/constant_of_shape.h\"\r\n",
        "#include \"src/ops/dequant.h\"\r\n",
        "#include \"src/ops/make_tuple.h\"\r\n",
        "#include \"src/ops/quant.h\"\r\n",
        "#include \"src/ops/tuple_get_item.h\"\r\n",
        "#include \"src/ops/l2_norm.h\"\r\n",
        "#include \"src/ops/neg.h\"\r\n",
        "#include \"src/ops/sparse_to_dense.h\"\r\n",
        "#include \"src/ops/detection_post_process.h\"\r\n",
        "#include \"src/ops/dropout.h\"\r\n",
        "#include \"src/ops/real_div.h\"\r\n",
        "#include \"src/ops/lsh_projection.h\"\r\n",
        "#include \"src/ops/hashtable_lookup.h\"\r\n",
        "#include \"src/ops/skip_gram.h\"\r\n",
        "#include \"src/ops/clip.h\"\r\n",
        "#include \"src/ops/adder.h\"\r\n",
        "#include \"src/ops/custom_predict.h\"\r\n",
        "#include \"src/ops/custom_normalize.h\"\r\n",
        "#include \"src/ops/custom_extract_features.h\"\r\n",
        "#include \"src/ops/upsample.h\"\r\n",
        "#include \"src/ops/layer_norm.h\"\r\n",
        "#include \"src/ops/non_max_suppression.h\"\r\n",
        "#include \"src/ops/rfft.h\"\r\n",
        "#include \"src/ops/fft_real.h\"\r\n",
        "#include \"src/ops/fft_imag.h\"\r\n",
        "#include \"src/ops/audio_spectrogram.h\"\r\n",
        "#include \"src/ops/mfcc.h\"\r\n",
        "#include \"src/ops/identity.h\"\r\n",
        "#include \"src/ops/instance_norm.h\"\r\n",
        "#include \"src/ops/while.h\"\r\n",
        "#include \"src/ops/oneslike.h\"\r\n",
        "#include \"src/ops/unsorted_segment_sum.h\"\r\n",
        "#include \"src/ops/reciprocal.h\"\r\n",
        "#include \"src/ops/constant.h\"\r\n",
        "#include \"src/ops/tensorlist_fromtensor.h\"\r\n",
        "#include \"src/ops/tensorlist_getitem.h\"\r\n",
        "#include \"src/ops/tensorlist_setitem.h\"\r\n",
        "#include \"src/ops/tensorlist_reserve.h\"\r\n",
        "#include \"src/ops/tensorlist_stack.h\"\r\n",
        "#include \"src/ops/merge.h\"\r\n",
        "#include \"src/ops/switch.h\"\r\n",
        "#include \"src/ops/partial.h\"\r\n",
        "#include \"src/ops/if.h\"\r\n",
        "#include \"src/ops/select.h\"\r\n",
        "#include \"src/ops/gelu.h\"\r\n",
        "#include \"src/ops/gru.h\"\r\n",
        "#include \"src/ops/size.h\"\r\n",
        "#include \"src/ops/random_standard_normal.h\"\r\n",
        "#include \"src/ops/invert_permutation.h\"\r\n",
        "#include \"src/ops/crop_and_resize.h\"\r\n",
        "#include \"src/ops/nonzero.h\"\r\n",
        "#include \"src/ops/erf.h\"\r\n",
        "#include \"src/ops/is_finite.h\"\r\n",
        "#include \"src/ops/batch_matmul.h\"\r\n",
        "#include \"src/ops/neg_grad.h\"\r\n",
        "#include \"src/ops/activation_grad.h\"\r\n",
        "#include \"src/ops/apply_momentum.h\"\r\n",
        "#include \"src/ops/bias_grad.h\"\r\n",
        "#include \"src/ops/pooling_grad.h\"\r\n",
        "#include \"src/ops/conv2d_grad_filter.h\"\r\n",
        "#include \"src/ops/conv2d_grad_input.h\"\r\n",
        "#include \"src/ops/group_conv2d_grad_input.h\"\r\n",
        "#include \"src/ops/power_grad.h\"\r\n",
        "#include \"src/ops/softmax_cross_entropy.h\"\r\n",
        "#include \"src/ops/sparse_softmax_cross_entropy.h\"\r\n",
        "#include \"src/ops/bn_grad.h\"\r\n",
        "#include \"src/ops/arithmetic_grad.h\"\r\n",
        "#include \"src/ops/depend.h\"\r\n",
        "#include \"src/ops/flatten_grad.h\"\r\n",
        "#include \"src/ops/log_grad.h\"\r\n",
        "#include \"src/ops/sgd.h\"\r\n",
        "#include \"src/ops/adam.h\"\r\n",
        "#include \"src/ops/assign.h\"\r\n",
        "#include \"src/ops/dropout_grad.h\"\r\n",
        "#include \"src/ops/maximum_grad.h\"\r\n",
        "#include \"src/ops/minimum_grad.h\"\r\n",
        "#include \"src/ops/control_depend.h\"\r\n",
        "#include \"src/ops/assign_add.h\"\r\n",
        "#include \"src/ops/binary_cross_entropy.h\"\r\n",
        "#include \"src/ops/binary_cross_entropy_grad.h\"\r\n",
        "#include \"src/ops/smooth_l1_loss.h\"\r\n",
        "#include \"src/ops/smooth_l1_loss_grad.h\"\r\n",
        "#include \"src/ops/sigmoid_cross_entropy_with_logits.h\"\r\n",
        "#include \"src/ops/sigmoid_cross_entropy_with_logits_grad.h\"\r\n",
        "#include \"src/ops/strided_slice_grad.h\"\r\n",
        "#endif\r\n",
        "namespace mindspore {\r\n",
        "namespace lite {\r\n",
        "#ifdef PRIMITIVE_WRITEABLE\r\n",
        "std::vector<int> CastToInt(const ValuePtr &value) {\r\n",
        "  if (value == nullptr) {\r\n",
        "    MS_LOG(WARNING) << \"valueptr is nullptr.\";\r\n",
        "    return {};\r\n",
        "  }\r\n",
        "  std::vector<int> cur_value;\r\n",
        "  if (utils::isa<ValueSequeuePtr>(value)) {\r\n",
        "    if (value->cast<ValueSequeuePtr>()->value().front()->type()->number_type() == kNumberTypeInt64) {\r\n",
        "      auto origin_value = GetValue<std::vector<int64_t>>(value);\r\n",
        "      for (size_t index = 0; index < origin_value.size(); ++index) {\r\n",
        "        cur_value.push_back(static_cast<int>(origin_value[index]));\r\n",
        "      }\r\n",
        "    } else {\r\n",
        "      cur_value = GetValue<std::vector<int>>(value);\r\n",
        "    }\r\n",
        "  } else {\r\n",
        "    if (value->type()->number_type() == kNumberTypeInt64) {\r\n",
        "      cur_value.push_back(static_cast<int>(GetValue<int64_t>(value)));\r\n",
        "    } else {\r\n",
        "      cur_value.push_back(GetValue<int>(value));\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return cur_value;\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::CalFloatScopeByMeanAndStddev(const double &mean, const double &stdDev, float *mMin, float *mMax) {\r\n",
        "  const float qmin = 0;\r\n",
        "  const float qmax = 255;\r\n",
        "  *mMin = static_cast<float>((qmin - mean) / stdDev);\r\n",
        "  *mMax = static_cast<float>((qmax - mean) / stdDev);\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::FillDefaultInputQuantParamIfNeed(const size_t &inputSize) {\r\n",
        "  std::vector<schema::QuantParamT> quants;\r\n",
        "  schema::QuantParamT quantParam;\r\n",
        "\r\n",
        "  if (input_quant_param_.size() == kDoubleNum) {\r\n",
        "    quants.clear();\r\n",
        "    quantParam.min = 0.0;\r\n",
        "    quantParam.max = 0.0;\r\n",
        "    quantParam.zeroPoint = 0;\r\n",
        "    quantParam.scale = input_quant_param_.at(0).at(0).scale * input_quant_param_.at(1).at(0).scale;\r\n",
        "    quants.emplace_back(quantParam);\r\n",
        "    input_quant_param_.emplace_back(quants);\r\n",
        "  }\r\n",
        "  // fill input_quant_param_ by not inited quant_parm\r\n",
        "  if (input_quant_param_.size() < inputSize) {\r\n",
        "    schema::QuantParamT tmpQuantParam;\r\n",
        "    quants.emplace_back(tmpQuantParam);\r\n",
        "    input_quant_param_.insert(input_quant_param_.end(), inputSize - input_quant_param_.size(), quants);\r\n",
        "  }\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::PopulaterInputQuantParam(const Primitive &prim, const std::vector<AnfNodePtr> &inputs,\r\n",
        "                                          bool narrowRangeQuantParam, int32_t numbitsRangeQuantParam) {\r\n",
        "  std::vector<schema::QuantParamT> quants;\r\n",
        "  schema::QuantParamT quantParam;\r\n",
        "  auto inputMin = prim.GetAttr(\"input_minq\");\r\n",
        "  auto inputMax = prim.GetAttr(\"input_maxq\");\r\n",
        "  if (inputMin != nullptr && inputMax != nullptr) {\r\n",
        "    auto inputMinPtr = inputMin->cast<TensorPtr>();\r\n",
        "    auto inputMaxPtr = inputMax->cast<TensorPtr>();\r\n",
        "    auto *minBuf = static_cast<float *>(inputMinPtr->data_c());\r\n",
        "    auto *maxBuf = static_cast<float *>(inputMaxPtr->data_c());\r\n",
        "    quantParam.min = *minBuf;\r\n",
        "    quantParam.max = *maxBuf;\r\n",
        "    auto ret = quant::CalQuantizationParams(&quantParam, quantParam.min, quantParam.max, narrowRangeQuantParam,\r\n",
        "                                            numbitsRangeQuantParam);\r\n",
        "    if (ret != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"Can't calculate quant parameters\";\r\n",
        "      return;\r\n",
        "    }\r\n",
        "    quants.emplace_back(quantParam);\r\n",
        "    input_quant_param_.emplace_back(quants);\r\n",
        "  }\r\n",
        "\r\n",
        "  quants.clear();\r\n",
        "  auto filterMin = prim.GetAttr(\"filter_minq\");\r\n",
        "  auto filterMax = prim.GetAttr(\"filter_maxq\");\r\n",
        "  if (filterMin != nullptr && filterMax != nullptr) {\r\n",
        "    auto filterMinPtr = filterMin->cast<TensorPtr>();\r\n",
        "    auto filterMaxPtr = filterMax->cast<TensorPtr>();\r\n",
        "    auto *minBuf = static_cast<float *>(filterMinPtr->data_c());\r\n",
        "    auto *maxBuf = static_cast<float *>(filterMaxPtr->data_c());\r\n",
        "    quantParam.min = FLT_MAX;\r\n",
        "    quantParam.max = FLT_MIN;\r\n",
        "    for (int i = 0; i < filterMinPtr->ElementsNum(); ++i) {\r\n",
        "      quantParam.min = (*(minBuf) < quantParam.min) ? (*minBuf) : quantParam.min;\r\n",
        "      quantParam.max = (*(maxBuf) > quantParam.max) ? (*maxBuf) : quantParam.max;\r\n",
        "      minBuf++;\r\n",
        "      maxBuf++;\r\n",
        "    }\r\n",
        "    auto ret = quant::CalQuantizationParams(&quantParam, quantParam.min, quantParam.max, true, numbitsRangeQuantParam);\r\n",
        "    if (ret != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"Can't calculate quant parameters\";\r\n",
        "      return;\r\n",
        "    }\r\n",
        "    quants.emplace_back(quantParam);\r\n",
        "    input_quant_param_.emplace_back(quants);\r\n",
        "  }\r\n",
        "  FillDefaultInputQuantParamIfNeed(inputs.size());\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::PopulaterOutputQuantParam(const Primitive &prim, bool narrowRangeQuantParam,\r\n",
        "                                           int32_t numbitsRangeQuantParam) {\r\n",
        "  std::vector<schema::QuantParamT> quants;\r\n",
        "  schema::QuantParamT quantParam;\r\n",
        "  auto outputMin = prim.GetAttr(\"output_minq\");\r\n",
        "  auto outputMax = prim.GetAttr(\"output_maxq\");\r\n",
        "  if (outputMin != nullptr && outputMax != nullptr) {\r\n",
        "    auto outputMinPtr = outputMin->cast<TensorPtr>();\r\n",
        "    auto outputMaxPtr = outputMax->cast<TensorPtr>();\r\n",
        "    auto *minBuf = static_cast<float *>(outputMinPtr->data_c());\r\n",
        "    auto *maxBuf = static_cast<float *>(outputMaxPtr->data_c());\r\n",
        "    quantParam.min = *minBuf;\r\n",
        "    quantParam.max = *maxBuf;\r\n",
        "    auto ret = quant::CalQuantizationParams(&quantParam, quantParam.min, quantParam.max, narrowRangeQuantParam,\r\n",
        "                                            numbitsRangeQuantParam);\r\n",
        "    if (ret != RET_OK) {\r\n",
        "      MS_LOG(ERROR) << \"Can't calculate quant parameters\";\r\n",
        "      return;\r\n",
        "    }\r\n",
        "    quants.emplace_back(quantParam);\r\n",
        "    output_quant_param_.emplace_back(quants);\r\n",
        "  } else {\r\n",
        "    schema::QuantParamT tmpQuantParam;\r\n",
        "    quants.emplace_back(tmpQuantParam);\r\n",
        "    output_quant_param_.emplace_back(quants);\r\n",
        "  }\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::PopulaterQuantParam(const Primitive &prim, const std::vector<AnfNodePtr> &inputs) {\r\n",
        "  auto narrow_range = prim.GetAttr(\"narrow_range\");\r\n",
        "  bool narrowRangeQuantParam = false;\r\n",
        "  if (narrow_range != nullptr) {\r\n",
        "    if (utils::isa<tensor::TensorPtr>(narrow_range)) {\r\n",
        "      auto narrow_range_tensor = narrow_range->cast<tensor::TensorPtr>();\r\n",
        "      narrowRangeQuantParam = *reinterpret_cast<bool *>(narrow_range_tensor->data_c());\r\n",
        "    } else if (utils::isa<ImmTraits<bool>::type>(narrow_range)) {\r\n",
        "      narrowRangeQuantParam = GetValue<bool>(narrow_range);\r\n",
        "    } else {\r\n",
        "      MS_LOG(ERROR) << \"valueptr is invalid.\";\r\n",
        "      return;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  auto num_bits = prim.GetAttr(\"num_bits\");\r\n",
        "  int32_t numbitsRangeQuantParam = 8;\r\n",
        "  if (num_bits != nullptr) {\r\n",
        "    if (utils::isa<tensor::TensorPtr>(num_bits)) {\r\n",
        "      auto num_bits_tensor = num_bits->cast<tensor::TensorPtr>();\r\n",
        "      numbitsRangeQuantParam = *reinterpret_cast<int64_t *>(num_bits_tensor->data_c());\r\n",
        "    } else if (utils::isa<ImmTraits<int64_t>::type>(num_bits)) {\r\n",
        "      numbitsRangeQuantParam = GetValue<int64_t>(num_bits);\r\n",
        "    }\r\n",
        "  }\r\n",
        "  PopulaterInputQuantParam(prim, inputs, narrowRangeQuantParam, numbitsRangeQuantParam);\r\n",
        "  PopulaterOutputQuantParam(prim, narrowRangeQuantParam, numbitsRangeQuantParam);\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::GetAttrDataFromInput(const AnfNodePtr &inputNode, std::vector<int> *data) {\r\n",
        "  if (inputNode->isa<ValueNode>()) {\r\n",
        "    auto valNode = inputNode->cast<ValueNodePtr>();\r\n",
        "    MS_ASSERT(valNode != nullptr);\r\n",
        "    auto val = valNode->value();\r\n",
        "    MS_ASSERT(val != nullptr);\r\n",
        "    if (val->isa<ValueTuple>()) {\r\n",
        "      auto tuple = val->cast<ValueTuplePtr>();\r\n",
        "      MS_ASSERT(tuple != nullptr);\r\n",
        "      for (size_t i = 0; i < tuple->size(); i++) {\r\n",
        "        auto elem = tuple->value().at(i);\r\n",
        "        MS_ASSERT(elem != nullptr);\r\n",
        "        data->emplace_back(CastToInt(elem).front());\r\n",
        "      }\r\n",
        "    }\r\n",
        "  }\r\n",
        "}\r\n",
        "\r\n",
        "schema::PrimitiveT *PrimitiveC::primitiveT() const { return this->primitive_; }\r\n",
        "\r\n",
        "void PrimitiveC::ClearPrimitiveT() { this->primitive_ = nullptr; }\r\n",
        "\r\n",
        "void PrimitiveC::set_input_quant_params(const std::vector<std::vector<schema::QuantParamT>> &input_quant_param) {\r\n",
        "  this->input_quant_param_ = input_quant_param;\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::set_input_quant_param(const size_t &index, const std::vector<schema::QuantParamT> &input_quant_param) {\r\n",
        "  if (index >= this->input_quant_param_.size()) {\r\n",
        "    this->input_quant_param_.resize(index + 1);\r\n",
        "  }\r\n",
        "  this->input_quant_param_.at(index) = input_quant_param;\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::set_output_quant_params(const std::vector<std::vector<schema::QuantParamT>> &output_quant_param) {\r\n",
        "  this->output_quant_param_ = output_quant_param;\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::set_output_quant_param(const size_t &index,\r\n",
        "                                        const std::vector<schema::QuantParamT> &output_quant_param) {\r\n",
        "  MS_ASSERT(index < this->output_quant_param_.size());\r\n",
        "  this->output_quant_param_.at(index) = output_quant_param;\r\n",
        "}\r\n",
        "\r\n",
        "bool PrimitiveC::IsInputQuantParamsInited() {\r\n",
        "  if (this->input_quant_param_.empty()) {\r\n",
        "    return false;\r\n",
        "  }\r\n",
        "  for (auto &quant_param : this->input_quant_param_) {\r\n",
        "    if (!quant_param.front().inited) {\r\n",
        "      return false;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return true;\r\n",
        "}\r\n",
        "\r\n",
        "bool PrimitiveC::IsOutputQuantParamsInited() {\r\n",
        "  if (this->output_quant_param_.empty()) {\r\n",
        "    return false;\r\n",
        "  }\r\n",
        "  for (auto &quant_param : this->output_quant_param_) {\r\n",
        "    if (!quant_param.front().inited) {\r\n",
        "      return false;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  return true;\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::ClearInputOutputQuantParam() {\r\n",
        "  input_quant_param_.clear();\r\n",
        "  output_quant_param_.clear();\r\n",
        "}\r\n",
        "\r\n",
        "void PrimitiveC::AddInputQuantParam(const std::vector<schema::QuantParamT> &quant_param) {\r\n",
        "  this->input_quant_param_.emplace_back(quant_param);\r\n",
        "}\r\n",
        "std::vector<std::vector<schema::QuantParamT>> PrimitiveC::input_quant_params() const { return input_quant_param_; }\r\n",
        "\r\n",
        "void PrimitiveC::AddOutputQuantParam(const std::vector<schema::QuantParamT> &quant_param) {\r\n",
        "  this->output_quant_param_.emplace_back(quant_param);\r\n",
        "}\r\n",
        "std::vector<std::vector<schema::QuantParamT>> PrimitiveC::output_quant_params() const { return output_quant_param_; }\r\n",
        "\r\n",
        "void PrimitiveC::set_quant_type(const schema::QuantType &quant_type) { this->quant_type_ = quant_type; }\r\n",
        "\r\n",
        "schema::QuantType PrimitiveC::quant_type() const { return quant_type_; }\r\n",
        "\r\n",
        "bool PrimitiveC::enable_huffman_code() const { return enable_huffman_code_; }\r\n",
        "\r\n",
        "void PrimitiveC::set_enable_huffman_code(bool enable_huffman_code) { this->enable_huffman_code_ = enable_huffman_code; }\r\n",
        "\r\n",
        "std::shared_ptr<PrimitiveC> GetReturnPrim() {\r\n",
        "  auto return_primitiveT = new (std::nothrow) schema::PrimitiveT;\r\n",
        "  if (return_primitiveT == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new PrimitiveT failed\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  return_primitiveT->value.type = schema::PrimitiveType_Return;\r\n",
        "  return_primitiveT->value.value = new (std::nothrow) schema::ReturnT;\r\n",
        "  if (return_primitiveT->value.value == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new ReturnT failed\";\r\n",
        "    delete (return_primitiveT);\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  return std::make_shared<Return>(return_primitiveT);\r\n",
        "}\r\n",
        "\r\n",
        "std::shared_ptr<PrimitiveC> GetMakeTuplePrim() {\r\n",
        "  auto make_tuple_primitiveT = new (std::nothrow) schema::PrimitiveT;\r\n",
        "  if (make_tuple_primitiveT == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new PrimitiveT failed\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  make_tuple_primitiveT->value.type = schema::PrimitiveType_MakeTuple;\r\n",
        "  make_tuple_primitiveT->value.value = new (std::nothrow) schema::MakeTupleT;\r\n",
        "  if (make_tuple_primitiveT->value.value == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new MakeTupleT failed\";\r\n",
        "    delete (make_tuple_primitiveT);\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  return std::make_shared<MakeTuple>(make_tuple_primitiveT);\r\n",
        "}\r\n",
        "\r\n",
        "std::shared_ptr<PrimitiveC> GetTupleGetItemPrim() {\r\n",
        "  auto tuple_get_item_primitiveT = new (std::nothrow) schema::PrimitiveT();\r\n",
        "  if (tuple_get_item_primitiveT == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new PrimitiveT failed\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  tuple_get_item_primitiveT->value.type = schema::PrimitiveType_TupleGetItem;\r\n",
        "  tuple_get_item_primitiveT->value.value = new (std::nothrow) schema::TupleGetItemT;\r\n",
        "  if (tuple_get_item_primitiveT->value.value == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new TupleGetItemT failed\";\r\n",
        "    delete (tuple_get_item_primitiveT);\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  return std::make_shared<TupleGetItem>(tuple_get_item_primitiveT);\r\n",
        "}\r\n",
        "\r\n",
        "template <typename T, typename = std::enable_if<std::is_base_of<PrimitiveC, T>::value>>\r\n",
        "std::shared_ptr<PrimitiveC> NewPrimitiveC(const mindspore::Primitive &prim, const std::vector<AnfNodePtr> &inputs,\r\n",
        "                                          const schema::QuantType &quantType, bool train_flag = false) {\r\n",
        "  auto primc = std::make_shared<T>();\r\n",
        "  if (primc == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"make_shared PrimitiveC failed\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  primc->set_quant_type(quantType);\r\n",
        "  primc->set_train_flag(train_flag);\r\n",
        "  auto ret = primc->UnPackAttr(prim, inputs);\r\n",
        "  if (ret != RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"UnPackAttr failed\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  return primc;\r\n",
        "}\r\n",
        "\r\n",
        "std::shared_ptr<PrimitiveC> PrimitiveC::Create(const Primitive &prim, const std::vector<AnfNodePtr> &inputs,\r\n",
        "                                               const schema::QuantType &quantType, bool train_flag) {\r\n",
        "  const auto &op_type = prim.name();\r\n",
        "  if (op_type == \"ReLU\" || op_type == \"ReLU6\" || op_type == \"Sigmoid\" || op_type == \"HSwish\" || op_type == \"HSigmoid\") {\r\n",
        "    return NewPrimitiveC<Activation>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Abs\") {\r\n",
        "    return NewPrimitiveC<Abs>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"AddN\") {\r\n",
        "    return NewPrimitiveC<AddN>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"BatchNorm\") {\r\n",
        "    return NewPrimitiveC<BatchNorm>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"BiasAdd\") {\r\n",
        "    return NewPrimitiveC<BiasAdd>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Concat\") {\r\n",
        "    return NewPrimitiveC<Concat>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Conv2D\") {\r\n",
        "    return NewPrimitiveC<Conv2D>(prim, inputs, quantType, train_flag);\r\n",
        "    return NewPrimitiveC<Conv2D>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Cos\") {\r\n",
        "    return NewPrimitiveC<Cos>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"DepthwiseConv2dNative\" || op_type == \"DepthwiseConv2D\") {\r\n",
        "    return NewPrimitiveC<DepthwiseConv2D>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Dequant\") {\r\n",
        "    return NewPrimitiveC<Dequant>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Flatten\") {\r\n",
        "    return NewPrimitiveC<Flatten>(prim, inputs, quantType);\r\n",
        "  } else if ((op_type == \"FusedBatchNorm\") || (op_type == \"FusedBatchNormEx\")) {\r\n",
        "    return NewPrimitiveC<FusedBatchNorm>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"make_tuple\") {\r\n",
        "    return NewPrimitiveC<MakeTuple>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"MatMul\" || op_type == \"BatchMatMul\") {\r\n",
        "    return NewPrimitiveC<MatMul>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Mul\") {\r\n",
        "    return NewPrimitiveC<Mul>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"MaxPool\" || op_type == \"AvgPool\") {\r\n",
        "    return NewPrimitiveC<Pooling>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Quant\") {\r\n",
        "    return NewPrimitiveC<Quant>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"RealDiv\") {\r\n",
        "    return NewPrimitiveC<RealDiv>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Reciprocal\") {\r\n",
        "    return NewPrimitiveC<Reciprocal>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ReduceMax\") {\r\n",
        "    return NewPrimitiveC<Reduce>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ReduceMean\") {\r\n",
        "    return NewPrimitiveC<Reduce>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ReduceMin\") {\r\n",
        "    return NewPrimitiveC<Reduce>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ReduceProd\") {\r\n",
        "    return NewPrimitiveC<Reduce>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ReduceSum\") {\r\n",
        "    return NewPrimitiveC<Reduce>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ReduceSumSquare\") {\r\n",
        "    return NewPrimitiveC<Reduce>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Reshape\") {\r\n",
        "    return NewPrimitiveC<Reshape>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Sin\") {\r\n",
        "    return NewPrimitiveC<Sin>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Slice\") {\r\n",
        "    return NewPrimitiveC<Slice>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Squeeze\") {\r\n",
        "    return NewPrimitiveC<Squeeze>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"TensorAdd\") {\r\n",
        "    return NewPrimitiveC<Add>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Transpose\") {\r\n",
        "    return NewPrimitiveC<Transpose>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Elu\") {\r\n",
        "    return NewPrimitiveC<Elu>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Log\") {\r\n",
        "    return NewPrimitiveC<Log>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Exp\") {\r\n",
        "    return NewPrimitiveC<Exp>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Neg\") {\r\n",
        "    return NewPrimitiveC<Neg>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"DeConv2D\") {\r\n",
        "    return NewPrimitiveC<DeConv2D>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"tuple_getitem\") {\r\n",
        "    return NewPrimitiveC<TupleGetItem>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Softmax\") {\r\n",
        "    return NewPrimitiveC<SoftMax>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"StridedSlice\") {\r\n",
        "    return NewPrimitiveC<StridedSlice>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Cast\") {\r\n",
        "    return NewPrimitiveC<Cast>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Maximum\") {\r\n",
        "    return NewPrimitiveC<Maximum>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Split\") {\r\n",
        "    return NewPrimitiveC<Split>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"OneHot\") {\r\n",
        "    return NewPrimitiveC<OneHot>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Dropout\") {\r\n",
        "    return NewPrimitiveC<Dropout>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"While\") {\r\n",
        "    return NewPrimitiveC<While>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"MirrorPad\") {\r\n",
        "    return NewPrimitiveC<Pad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Gather\") {\r\n",
        "    return NewPrimitiveC<Gather>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"OnesLike\") {\r\n",
        "    return NewPrimitiveC<OnesLike>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Pow\") {\r\n",
        "    return NewPrimitiveC<Power>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Sub\") {\r\n",
        "    return NewPrimitiveC<Sub>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ExpandDims\") {\r\n",
        "    return NewPrimitiveC<ExpandDims>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"UnsortedSegmentSum\") {\r\n",
        "    return NewPrimitiveC<UnsortedSegmentSum>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ResizeNearestNeighbor\") {\r\n",
        "    return NewPrimitiveC<Resize>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ResizeBilinear\") {\r\n",
        "    return NewPrimitiveC<Resize>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Floor\") {\r\n",
        "    return NewPrimitiveC<Floor>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Minimum\") {\r\n",
        "    return NewPrimitiveC<Minimum>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Div\") {\r\n",
        "    return NewPrimitiveC<Div>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Tanh\") {\r\n",
        "    return NewPrimitiveC<Activation>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Equal\") {\r\n",
        "    return NewPrimitiveC<Equal>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"TopK\") {\r\n",
        "    return NewPrimitiveC<TopK>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Mod\") {\r\n",
        "    return NewPrimitiveC<Mod>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ArgMin\" || op_type == \"ArgMinWithValue\") {\r\n",
        "    return NewPrimitiveC<ArgMin>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Range\") {\r\n",
        "    return NewPrimitiveC<Range>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Tile\") {\r\n",
        "    return NewPrimitiveC<Tile>(prim, inputs, quantType, train_flag);\r\n",
        "  } else if (op_type == \"GatherNd\") {\r\n",
        "    return NewPrimitiveC<GatherNd>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Square\") {\r\n",
        "    return NewPrimitiveC<Square>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Sqrt\") {\r\n",
        "    return NewPrimitiveC<Sqrt>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Greater\") {\r\n",
        "    return NewPrimitiveC<Greater>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Switch\") {\r\n",
        "    return NewPrimitiveC<Switch>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Partial\") {\r\n",
        "    return NewPrimitiveC<Partial>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Merge\") {\r\n",
        "    return NewPrimitiveC<Merge>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"LayerNorm\") {\r\n",
        "    return NewPrimitiveC<LayerNorm>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ArgMax\" || op_type == \"ArgMaxWithValue\") {\r\n",
        "    return NewPrimitiveC<ArgMax>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Gelu\") {\r\n",
        "    return NewPrimitiveC<GeLU>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"SoftmaxCrossEntropyWithLogits\") {\r\n",
        "    return NewPrimitiveC<SoftmaxCrossEntropy>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"SparseSoftmaxCrossEntropyWithLogits\") {\r\n",
        "    return NewPrimitiveC<SparseSoftmaxCrossEntropy>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"BiasAddGrad\") {\r\n",
        "    return NewPrimitiveC<BiasGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ApplyMomentum\") {\r\n",
        "    return NewPrimitiveC<ApplyMomentum>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Depend\") {\r\n",
        "    return NewPrimitiveC<Depend>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"ControlDepend\") {\r\n",
        "    return NewPrimitiveC<ControlDepend>(prim, inputs, quantType);\r\n",
        "  } else if ((op_type == \"ReluGrad\" || op_type == \"ReLU6Grad\" || op_type == \"SigmoidGrad\" ||\r\n",
        "              op_type == \"HSigmoidGrad\" || op_type == \"HSwishGrad\")) {\r\n",
        "    return NewPrimitiveC<ActivationGrad>(prim, inputs, quantType);\r\n",
        "  } else if ((op_type == \"MaxPoolGrad\") || (op_type == \"AvgPoolGrad\") || (op_type == \"AvgPoolGradGpu\") ||\r\n",
        "             (op_type == \"AvgPoolGradCpu\")) {\r\n",
        "    return NewPrimitiveC<PoolingGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Conv2DBackpropFilter\") {\r\n",
        "    return NewPrimitiveC<Conv2DGradFilter>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Conv2DBackpropInput\" && train_flag) {\r\n",
        "    return NewPrimitiveC<Conv2DGradInput>(prim, inputs, quantType);\r\n",
        "  } else if ((op_type == \"BatchNormGrad\") || (op_type == \"FusedBatchNormGradEx\")) {\r\n",
        "    return NewPrimitiveC<BNGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"FlattenGrad\") {\r\n",
        "    return NewPrimitiveC<FlattenGrad>(prim, inputs, quantType);\r\n",
        "  } else if ((op_type == \"FusedBatchNormGrad\") || (op_type == \"FusedBatchNormGradCpu\")) {\r\n",
        "    return NewPrimitiveC<BNGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"PowerGrad\") {\r\n",
        "    return NewPrimitiveC<PowerGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"SGD\") {\r\n",
        "    return NewPrimitiveC<Sgd>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Adam\") {\r\n",
        "    return NewPrimitiveC<Adam>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Assign\") {\r\n",
        "    return NewPrimitiveC<Assign>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"DropoutGrad\") {\r\n",
        "    return NewPrimitiveC<DropoutGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"MaximumGrad\") {\r\n",
        "    return NewPrimitiveC<MaximumGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"MinimumGrad\") {\r\n",
        "    return NewPrimitiveC<MinimumGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"AssignAdd\") {\r\n",
        "    return NewPrimitiveC<AssignAdd>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"BinaryCrossEntropy\") {\r\n",
        "    return NewPrimitiveC<BinaryCrossEntropy>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"BinaryCrossEntropyGrad\") {\r\n",
        "    return NewPrimitiveC<BinaryCrossEntropyGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"SmoothL1Loss\") {\r\n",
        "    return NewPrimitiveC<SmoothL1Loss>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"SmoothL1LossGrad\") {\r\n",
        "    return NewPrimitiveC<SmoothL1LossGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"SigmoidCrossEntropyWithLogits\") {\r\n",
        "    return NewPrimitiveC<SigmoidCrossEntropyWithLogits>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"SigmoidCrossEntropyWithLogitsGrad\") {\r\n",
        "    return NewPrimitiveC<SigmoidCrossEntropyWithLogitsGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Pad\") {\r\n",
        "    return NewPrimitiveC<Pad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"StridedSliceGrad\") {\r\n",
        "    return NewPrimitiveC<StridedSliceGrad>(prim, inputs, quantType);\r\n",
        "  } else if (op_type == \"Conv2DBackpropInput\" && !train_flag) {\r\n",
        "    return NewPrimitiveC<DeConv2D>(prim, inputs, quantType);\r\n",
        "  } else {\r\n",
        "    MS_LOG(ERROR) << \"Unsupported primitive type in Create : \" << op_type;\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "}\r\n",
        "\r\n",
        "PrimitiveC *PrimitiveC::Create(mindspore::schema::PrimitiveT *primitive) {\r\n",
        "  MS_ASSERT(primitive != nullptr);\r\n",
        "  auto op_type = primitive->value.type;\r\n",
        "  switch (op_type) {\r\n",
        "    case schema::PrimitiveType_SoftMax:\r\n",
        "      return new (std::nothrow) SoftMax(primitive);\r\n",
        "    case schema::PrimitiveType_Activation:\r\n",
        "      return new (std::nothrow) Activation(primitive);\r\n",
        "    case schema::PrimitiveType_Conv2D:\r\n",
        "      return new (std::nothrow) Conv2D(primitive);\r\n",
        "    case schema::PrimitiveType_DeConv2D:\r\n",
        "      return new (std::nothrow) DeConv2D(primitive);\r\n",
        "    case schema::PrimitiveType_Reduce:\r\n",
        "      return new (std::nothrow) Reduce(primitive);\r\n",
        "    case schema::PrimitiveType_Pooling:\r\n",
        "      return new (std::nothrow) Pooling(primitive);\r\n",
        "    case schema::PrimitiveType_ROIPooling:\r\n",
        "      return new (std::nothrow) ROIPooling(primitive);\r\n",
        "    case schema::PrimitiveType_DepthwiseConv2D:\r\n",
        "      return new (std::nothrow) DepthwiseConv2D(primitive);\r\n",
        "    case schema::PrimitiveType_FusedBatchNorm:\r\n",
        "      return new (std::nothrow) FusedBatchNorm(primitive);\r\n",
        "    case schema::PrimitiveType_BatchNorm:\r\n",
        "      return new (std::nothrow) BatchNorm(primitive);\r\n",
        "    case schema::PrimitiveType_FullConnection:\r\n",
        "      return new (std::nothrow) FullConnection(primitive);\r\n",
        "    case schema::PrimitiveType_Power:\r\n",
        "      return new (std::nothrow) Power(primitive);\r\n",
        "    case schema::PrimitiveType_Pad:\r\n",
        "      return new (std::nothrow) Pad(primitive);\r\n",
        "    case schema::PrimitiveType_Range:\r\n",
        "      return new (std::nothrow) Range(primitive);\r\n",
        "    case schema::PrimitiveType_Mul:\r\n",
        "      return new (std::nothrow) Mul(primitive);\r\n",
        "    case schema::PrimitiveType_Add:\r\n",
        "      return new (std::nothrow) Add(primitive);\r\n",
        "    case schema::PrimitiveType_Sub:\r\n",
        "      return new (std::nothrow) Sub(primitive);\r\n",
        "    case schema::PrimitiveType_Div:\r\n",
        "      return new (std::nothrow) Div(primitive);\r\n",
        "    case schema::PrimitiveType_BiasAdd:\r\n",
        "      return new (std::nothrow) BiasAdd(primitive);\r\n",
        "    case schema::PrimitiveType_ExpandDims:\r\n",
        "      return new (std::nothrow) ExpandDims(primitive);\r\n",
        "    case schema::PrimitiveType_ArgMax:\r\n",
        "      return new (std::nothrow) ArgMax(primitive);\r\n",
        "    case schema::PrimitiveType_ArgMin:\r\n",
        "      return new (std::nothrow) ArgMin(primitive);\r\n",
        "    case schema::PrimitiveType_Cast:\r\n",
        "      return new (std::nothrow) Cast(primitive);\r\n",
        "    case schema::PrimitiveType_Reshape:\r\n",
        "      return new (std::nothrow) Reshape(primitive);\r\n",
        "    case schema::PrimitiveType_Scale:\r\n",
        "      return new (std::nothrow) Scale(primitive);\r\n",
        "    case schema::PrimitiveType_Eltwise:\r\n",
        "      return new (std::nothrow) Eltwise(primitive);\r\n",
        "    case schema::PrimitiveType_Ceil:\r\n",
        "      return new (std::nothrow) Ceil(primitive);\r\n",
        "    case schema::PrimitiveType_Concat:\r\n",
        "      return new (std::nothrow) Concat(primitive);\r\n",
        "    case schema::PrimitiveType_Fill:\r\n",
        "      return new (std::nothrow) Fill(primitive);\r\n",
        "    case schema::PrimitiveType_Nhwc2Nchw:\r\n",
        "      return new (std::nothrow) Nhwc2Nchw(primitive);\r\n",
        "    case schema::PrimitiveType_Nchw2Nhwc:\r\n",
        "      return new (std::nothrow) Nchw2Nhwc(primitive);\r\n",
        "    case schema::PrimitiveType_Transpose:\r\n",
        "      return new (std::nothrow) Transpose(primitive);\r\n",
        "    case schema::PrimitiveType_Slice:\r\n",
        "      return new (std::nothrow) Slice(primitive);\r\n",
        "    case schema::PrimitiveType_Squeeze:\r\n",
        "      return new (std::nothrow) Squeeze(primitive);\r\n",
        "    case schema::PrimitiveType_Flatten:\r\n",
        "      return new (std::nothrow) Flatten(primitive);\r\n",
        "    case schema::PrimitiveType_Stack:\r\n",
        "      return new (std::nothrow) Stack(primitive);\r\n",
        "    case schema::PrimitiveType_Crop:\r\n",
        "      return new (std::nothrow) Crop(primitive);\r\n",
        "    case schema::PrimitiveType_SquaredDifference:\r\n",
        "      return new (std::nothrow) SquaredDifference(primitive);\r\n",
        "    case schema::PrimitiveType_AddN:\r\n",
        "      return new (std::nothrow) AddN(primitive);\r\n",
        "    case schema::PrimitiveType_Abs:\r\n",
        "      return new (std::nothrow) Abs(primitive);\r\n",
        "    case schema::PrimitiveType_Sin:\r\n",
        "      return new (std::nothrow) Sin(primitive);\r\n",
        "    case schema::PrimitiveType_Cos:\r\n",
        "      return new (std::nothrow) Cos(primitive);\r\n",
        "    case schema::PrimitiveType_Log:\r\n",
        "      return new (std::nothrow) Log(primitive);\r\n",
        "    case schema::PrimitiveType_Sqrt:\r\n",
        "      return new (std::nothrow) Sqrt(primitive);\r\n",
        "    case schema::PrimitiveType_Rsqrt:\r\n",
        "      return new (std::nothrow) Rsqrt(primitive);\r\n",
        "    case schema::PrimitiveType_Square:\r\n",
        "      return new (std::nothrow) Square(primitive);\r\n",
        "    case schema::PrimitiveType_Exp:\r\n",
        "      return new (std::nothrow) Exp(primitive);\r\n",
        "    case schema::PrimitiveType_Gather:\r\n",
        "      return new (std::nothrow) Gather(primitive);\r\n",
        "    case schema::PrimitiveType_GatherNd:\r\n",
        "      return new (std::nothrow) GatherNd(primitive);\r\n",
        "    case schema::PrimitiveType_LocalResponseNormalization:\r\n",
        "      return new (std::nothrow) LocalResponseNormalization(primitive);\r\n",
        "    case schema::PrimitiveType_Maximum:\r\n",
        "      return new (std::nothrow) Maximum(primitive);\r\n",
        "    case schema::PrimitiveType_Minimum:\r\n",
        "      return new (std::nothrow) Minimum(primitive);\r\n",
        "    case schema::PrimitiveType_StridedSlice:\r\n",
        "      return new (std::nothrow) StridedSlice(primitive);\r\n",
        "    case schema::PrimitiveType_LeakyReLU:\r\n",
        "      return new (std::nothrow) LeakyReLU(primitive);\r\n",
        "    case schema::PrimitiveType_PReLU:\r\n",
        "      return new (std::nothrow) PReLU(primitive);\r\n",
        "    case schema::PrimitiveType_Round:\r\n",
        "      return new (std::nothrow) Round(primitive);\r\n",
        "    case schema::PrimitiveType_Reverse:\r\n",
        "      return new (std::nothrow) Reverse(primitive);\r\n",
        "    case schema::PrimitiveType_ReverseSequence:\r\n",
        "      return new (std::nothrow) ReverseSequence(primitive);\r\n",
        "    case schema::PrimitiveType_LogicalAnd:\r\n",
        "      return new (std::nothrow) LogicalAnd(primitive);\r\n",
        "    case schema::PrimitiveType_LogicalOr:\r\n",
        "      return new (std::nothrow) LogicalOr(primitive);\r\n",
        "    case schema::PrimitiveType_LogicalNot:\r\n",
        "      return new (std::nothrow) LogicalNot(primitive);\r\n",
        "    case schema::PrimitiveType_FloorDiv:\r\n",
        "      return new (std::nothrow) FloorDiv(primitive);\r\n",
        "    case schema::PrimitiveType_FloorMod:\r\n",
        "      return new (std::nothrow) FloorMod(primitive);\r\n",
        "    case schema::PrimitiveType_Mod:\r\n",
        "      return new (std::nothrow) Mod(primitive);\r\n",
        "    case schema::PrimitiveType_Equal:\r\n",
        "      return new (std::nothrow) Equal(primitive);\r\n",
        "    case schema::PrimitiveType_NotEqual:\r\n",
        "      return new (std::nothrow) NotEqual(primitive);\r\n",
        "    case schema::PrimitiveType_Less:\r\n",
        "      return new (std::nothrow) Less(primitive);\r\n",
        "    case schema::PrimitiveType_LessEqual:\r\n",
        "      return new (std::nothrow) LessEqual(primitive);\r\n",
        "    case schema::PrimitiveType_Greater:\r\n",
        "      return new (std::nothrow) Greater(primitive);\r\n",
        "    case schema::PrimitiveType_GreaterEqual:\r\n",
        "      return new (std::nothrow) GreaterEqual(primitive);\r\n",
        "    case schema::PrimitiveType_Floor:\r\n",
        "      return new (std::nothrow) Floor(primitive);\r\n",
        "    case schema::PrimitiveType_Split:\r\n",
        "      return new (std::nothrow) Split(primitive);\r\n",
        "    case schema::PrimitiveType_OneHot:\r\n",
        "      return new (std::nothrow) OneHot(primitive);\r\n",
        "    case schema::PrimitiveType_PriorBox:\r\n",
        "      return new (std::nothrow) PriorBox(primitive);\r\n",
        "    case schema::PrimitiveType_SpaceToDepth:\r\n",
        "      return new (std::nothrow) SpaceToDepth(primitive);\r\n",
        "    case schema::PrimitiveType_Tile:\r\n",
        "      return new (std::nothrow) Tile(primitive);\r\n",
        "    case schema::PrimitiveType_Resize:\r\n",
        "      return new (std::nothrow) Resize(primitive);\r\n",
        "    case schema::PrimitiveType_Unstack:\r\n",
        "      return new (std::nothrow) Unstack(primitive);\r\n",
        "    case schema::PrimitiveType_Unique:\r\n",
        "      return new (std::nothrow) Unique(primitive);\r\n",
        "    case schema::PrimitiveType_TopK:\r\n",
        "      return new (std::nothrow) TopK(primitive);\r\n",
        "    case schema::PrimitiveType_MatMul:\r\n",
        "      return new (std::nothrow) MatMul(primitive);\r\n",
        "    case schema::PrimitiveType_QuantDTypeCast:\r\n",
        "      return new (std::nothrow) QuantDTypeCast(primitive);\r\n",
        "    case schema::PrimitiveType_EmbeddingLookup:\r\n",
        "      return new (std::nothrow) EmbeddingLookup(primitive);\r\n",
        "    case schema::PrimitiveType_Elu:\r\n",
        "      return new (std::nothrow) Elu(primitive);\r\n",
        "    case schema::PrimitiveType_DeDepthwiseConv2D:\r\n",
        "      return new (std::nothrow) DeDepthwiseConv2D(primitive);\r\n",
        "    case schema::PrimitiveType_Shape:\r\n",
        "      return new (std::nothrow) Shape(primitive);\r\n",
        "    case schema::PrimitiveType_Unsqueeze:\r\n",
        "      return new (std::nothrow) Unsqueeze(primitive);\r\n",
        "    case schema::PrimitiveType_BatchToSpace:\r\n",
        "    case schema::PrimitiveType_BatchToSpaceND:\r\n",
        "      return new (std::nothrow) BatchToSpace(primitive);\r\n",
        "    case schema::PrimitiveType_SpaceToBatch:\r\n",
        "      return new (std::nothrow) SpaceToBatch(primitive);\r\n",
        "    case schema::PrimitiveType_SpaceToBatchND:\r\n",
        "      return new (std::nothrow) SpaceToBatchND(primitive);\r\n",
        "    case schema::PrimitiveType_BroadcastTo:\r\n",
        "      return new (std::nothrow) BroadcastTo(primitive);\r\n",
        "    case schema::PrimitiveType_DepthToSpace:\r\n",
        "      return new (std::nothrow) DepthToSpace(primitive);\r\n",
        "    case schema::PrimitiveType_Lstm:\r\n",
        "      return new (std::nothrow) Lstm(primitive);\r\n",
        "    case schema::PrimitiveType_ZerosLike:\r\n",
        "      return new (std::nothrow) ZerosLike(primitive);\r\n",
        "    case schema::PrimitiveType_MakeTuple:\r\n",
        "      return new (std::nothrow) MakeTuple(primitive);\r\n",
        "    case schema::PrimitiveType_Where:\r\n",
        "      return new (std::nothrow) Where(primitive);\r\n",
        "    case schema::PrimitiveType_ScatterND:\r\n",
        "      return new (std::nothrow) ScatterND(primitive);\r\n",
        "    case schema::PrimitiveType_ConstantOfShape:\r\n",
        "      return new (std::nothrow) ConstantOfShape(primitive);\r\n",
        "    case schema::PrimitiveType_L2Norm:\r\n",
        "      return new (std::nothrow) L2Norm(primitive);\r\n",
        "    case schema::PrimitiveType_SparseToDense:\r\n",
        "      return new (std::nothrow) SparseToDense(primitive);\r\n",
        "    case schema::PrimitiveType_DetectionPostProcess:\r\n",
        "      return new (std::nothrow) DetectionPostProcess(primitive);\r\n",
        "    case schema::PrimitiveType_Dropout:\r\n",
        "      return new (std::nothrow) Dropout(primitive);\r\n",
        "    case schema::PrimitiveType_Neg:\r\n",
        "      return new (std::nothrow) Neg(primitive);\r\n",
        "    case schema::PrimitiveType_RealDiv:\r\n",
        "      return new (std::nothrow) RealDiv(primitive);\r\n",
        "    case schema::PrimitiveType_LshProjection:\r\n",
        "      return new (std::nothrow) LshProjection(primitive);\r\n",
        "    case schema::PrimitiveType_HashtableLookup:\r\n",
        "      return new (std::nothrow) HashtableLookup(primitive);\r\n",
        "    case schema::PrimitiveType_SkipGram:\r\n",
        "      return new (std::nothrow) SkipGram(primitive);\r\n",
        "    case schema::PrimitiveType_Clip:\r\n",
        "      return new (std::nothrow) Clip(primitive);\r\n",
        "    case schema::PrimitiveType_Adder:\r\n",
        "      return new (std::nothrow) Adder(primitive);\r\n",
        "    case schema::PrimitiveType_CustomPredict:\r\n",
        "      return new (std::nothrow) CustomPredict(primitive);\r\n",
        "    case schema::PrimitiveType_CustomNormalize:\r\n",
        "      return new (std::nothrow) CustomNormalize(primitive);\r\n",
        "    case schema::PrimitiveType_CustomExtractFeatures:\r\n",
        "      return new (std::nothrow) CustomExtractFeatures(primitive);\r\n",
        "    case schema::PrimitiveType_Upsample:\r\n",
        "      return new (std::nothrow) Upsample(primitive);\r\n",
        "    case schema::PrimitiveType_LayerNorm:\r\n",
        "      return new (std::nothrow) LayerNorm(primitive);\r\n",
        "    case schema::PrimitiveType_NonMaxSuppression:\r\n",
        "      return new (std::nothrow) NonMaxSuppression(primitive);\r\n",
        "    case schema::PrimitiveType_Identity:\r\n",
        "      return new (std::nothrow) Identity(primitive);\r\n",
        "    case schema::PrimitiveType_Rfft:\r\n",
        "      return new (std::nothrow) Rfft(primitive);\r\n",
        "    case schema::PrimitiveType_FftReal:\r\n",
        "      return new (std::nothrow) FftReal(primitive);\r\n",
        "    case schema::PrimitiveType_FftImag:\r\n",
        "      return new (std::nothrow) FftImag(primitive);\r\n",
        "    case schema::PrimitiveType_AudioSpectrogram:\r\n",
        "      return new (std::nothrow) AudioSpectrogram(primitive);\r\n",
        "    case schema::PrimitiveType_Mfcc:\r\n",
        "      return new (std::nothrow) Mfcc(primitive);\r\n",
        "    case schema::PrimitiveType_InstanceNorm:\r\n",
        "      return new (std::nothrow) InstanceNorm(primitive);\r\n",
        "    case schema::PrimitiveType_While:\r\n",
        "      return new (std::nothrow) While(primitive);\r\n",
        "    case schema::PrimitiveType_OnnxInt8Quantize:\r\n",
        "      return new (std::nothrow) Quant(primitive);\r\n",
        "    case schema::PrimitiveType_OnnxInt8Dequantize:\r\n",
        "      return new (std::nothrow) Dequant(primitive);\r\n",
        "    case schema::PrimitiveType_Reciprocal:\r\n",
        "      return new (std::nothrow) Reciprocal(primitive);\r\n",
        "    case schema::PrimitiveType_Constant:\r\n",
        "      return new (std::nothrow) Constant(primitive);\r\n",
        "    case schema::PrimitiveType_TensorListFromTensor:\r\n",
        "      return new (std::nothrow) TensorListFromTensor(primitive);\r\n",
        "    case schema::PrimitiveType_TensorListGetItem:\r\n",
        "      return new (std::nothrow) TensorListGetItem(primitive);\r\n",
        "    case schema::PrimitiveType_TensorListSetItem:\r\n",
        "      return new (std::nothrow) TensorListSetItem(primitive);\r\n",
        "    case schema::PrimitiveType_TensorListReserve:\r\n",
        "      return new (std::nothrow) TensorListReserve(primitive);\r\n",
        "    case schema::PrimitiveType_TensorListStack:\r\n",
        "      return new (std::nothrow) TensorListStack(primitive);\r\n",
        "    case schema::PrimitiveType_Switch:\r\n",
        "      return new (std::nothrow) Switch(primitive);\r\n",
        "    case schema::PrimitiveType_Merge:\r\n",
        "      return new (std::nothrow) Merge(primitive);\r\n",
        "    case schema::PrimitiveType_Partial:\r\n",
        "      return new (std::nothrow) Partial(primitive);\r\n",
        "    case schema::PrimitiveType_Assert:\r\n",
        "      return new (std::nothrow) AssertOP(primitive);\r\n",
        "    case schema::PrimitiveType_GeLU:\r\n",
        "      return new (std::nothrow) GeLU(primitive);\r\n",
        "    case schema::PrimitiveType_If:\r\n",
        "      return new (std::nothrow) If(primitive);\r\n",
        "    case schema::PrimitiveType_Select:\r\n",
        "      return new (std::nothrow) Select(primitive);\r\n",
        "    case schema::PrimitiveType_Gru:\r\n",
        "      return new (std::nothrow) Gru(primitive);\r\n",
        "    case schema::PrimitiveType_Size:\r\n",
        "      return new (std::nothrow) Size(primitive);\r\n",
        "    case schema::PrimitiveType_InvertPermutation:\r\n",
        "      return new (std::nothrow) InvertPermutation(primitive);\r\n",
        "    case schema::PrimitiveType_RandomStandardNormal:\r\n",
        "      return new (std::nothrow) RandomStandardNormal(primitive);\r\n",
        "    case schema::PrimitiveType_CropAndResize:\r\n",
        "      return new (std::nothrow) CropAndResize(primitive);\r\n",
        "    case schema::PrimitiveType_NonZero:\r\n",
        "      return new (std::nothrow) NonZero(primitive);\r\n",
        "    case schema::PrimitiveType_Erf:\r\n",
        "      return new (std::nothrow) Erf(primitive);\r\n",
        "    case schema::PrimitiveType_IsFinite:\r\n",
        "      return new (std::nothrow) IsFinite(primitive);\r\n",
        "    case schema::PrimitiveType_BatchMatMul:\r\n",
        "      return new (std::nothrow) BatchMatMul(primitive);\r\n",
        "    case schema::PrimitiveType_ActivationGrad:\r\n",
        "      return new (std::nothrow) ActivationGrad(primitive);\r\n",
        "    case schema::PrimitiveType_PoolingGrad:\r\n",
        "      return new (std::nothrow) PoolingGrad(primitive);\r\n",
        "    case schema::PrimitiveType_Conv2DGradFilter:\r\n",
        "      return new (std::nothrow) Conv2DGradFilter(primitive);\r\n",
        "    case schema::PrimitiveType_Conv2DGradInput:\r\n",
        "      return new (std::nothrow) Conv2DGradInput(primitive);\r\n",
        "    case schema::PrimitiveType_GroupConv2DGradInput:\r\n",
        "      return new (std::nothrow) GroupConv2DGradInput(primitive);\r\n",
        "    case schema::PrimitiveType_BiasGrad:\r\n",
        "      return new (std::nothrow) BiasGrad(primitive);\r\n",
        "    case schema::PrimitiveType_ApplyMomentum:\r\n",
        "      return new (std::nothrow) ApplyMomentum(primitive);\r\n",
        "    case schema::PrimitiveType_BNGrad:\r\n",
        "      return new (std::nothrow) BNGrad(primitive);\r\n",
        "    case schema::PrimitiveType_AddGrad:\r\n",
        "      return new (std::nothrow) ArithmeticGrad(primitive);\r\n",
        "    case schema::PrimitiveType_SubGrad:\r\n",
        "      return new (std::nothrow) ArithmeticGrad(primitive);\r\n",
        "    case schema::PrimitiveType_MulGrad:\r\n",
        "      return new (std::nothrow) ArithmeticGrad(primitive);\r\n",
        "    case schema::PrimitiveType_DivGrad:\r\n",
        "      return new (std::nothrow) ArithmeticGrad(primitive);\r\n",
        "    case schema::PrimitiveType_SoftmaxCrossEntropy:\r\n",
        "      return new (std::nothrow) SoftmaxCrossEntropy(primitive);\r\n",
        "    case schema::PrimitiveType_SparseSoftmaxCrossEntropy:\r\n",
        "      return new (std::nothrow) SparseSoftmaxCrossEntropy(primitive);\r\n",
        "    case schema::PrimitiveType_PowerGrad:\r\n",
        "      return new (std::nothrow) PowerGrad(primitive);\r\n",
        "    case schema::PrimitiveType_Depend:\r\n",
        "      return new (std::nothrow) Depend(primitive);\r\n",
        "    case schema::PrimitiveType_ControlDepend:\r\n",
        "      return new (std::nothrow) ControlDepend(primitive);\r\n",
        "    case schema::PrimitiveType_FlattenGrad:\r\n",
        "      return new (std::nothrow) FlattenGrad(primitive);\r\n",
        "    case schema::PrimitiveType_NegGrad:\r\n",
        "      return new (std::nothrow) NegGrad(primitive);\r\n",
        "    case schema::PrimitiveType_LogGrad:\r\n",
        "      return new (std::nothrow) LogGrad(primitive);\r\n",
        "    case schema::PrimitiveType_Sgd:\r\n",
        "      return new (std::nothrow) Sgd(primitive);\r\n",
        "    case schema::PrimitiveType_Adam:\r\n",
        "      return new (std::nothrow) Adam(primitive);\r\n",
        "    case schema::PrimitiveType_Assign:\r\n",
        "      return new (std::nothrow) Assign(primitive);\r\n",
        "    case schema::PrimitiveType_AssignAdd:\r\n",
        "      return new (std::nothrow) AssignAdd(primitive);\r\n",
        "    case schema::PrimitiveType_OnesLike:\r\n",
        "      return new (std::nothrow) OnesLike(primitive);\r\n",
        "    case schema::PrimitiveType_UnsortedSegmentSum:\r\n",
        "      return new (std::nothrow) UnsortedSegmentSum(primitive);\r\n",
        "    case schema::PrimitiveType_BinaryCrossEntropyGrad:\r\n",
        "      return new (std::nothrow) BinaryCrossEntropyGrad(primitive);\r\n",
        "    case schema::PrimitiveType_BinaryCrossEntropy:\r\n",
        "      return new (std::nothrow) BinaryCrossEntropy(primitive);\r\n",
        "    case schema::PrimitiveType_DropoutGrad:\r\n",
        "      return new (std::nothrow) DropoutGrad(primitive);\r\n",
        "    case schema::PrimitiveType_MaximumGrad:\r\n",
        "      return new (std::nothrow) MaximumGrad(primitive);\r\n",
        "    case schema::PrimitiveType_MinimumGrad:\r\n",
        "      return new (std::nothrow) MinimumGrad(primitive);\r\n",
        "    case schema::PrimitiveType_SmoothL1Loss:\r\n",
        "      return new (std::nothrow) SmoothL1Loss(primitive);\r\n",
        "    case schema::PrimitiveType_SmoothL1LossGrad:\r\n",
        "      return new (std::nothrow) SmoothL1LossGrad(primitive);\r\n",
        "    case schema::PrimitiveType_SigmoidCrossEntropyWithLogits:\r\n",
        "      return new (std::nothrow) SigmoidCrossEntropyWithLogits(primitive);\r\n",
        "    case schema::PrimitiveType_SigmoidCrossEntropyWithLogitsGrad:\r\n",
        "      return new (std::nothrow) SigmoidCrossEntropyWithLogitsGrad(primitive);\r\n",
        "    case schema::PrimitiveType_StridedSliceGrad:\r\n",
        "      return new (std::nothrow) StridedSliceGrad(primitive);\r\n",
        "    default:\r\n",
        "      MS_LOG(ERROR) << \"Unsupported primitive type in Create : \" << schema::EnumNamePrimitiveType(op_type);\r\n",
        "      break;\r\n",
        "  }\r\n",
        "  return nullptr;\r\n",
        "}\r\n",
        "\r\n",
        "#else\r\n",
        "void PrimitiveC::set_quant_type(schema::QuantType quant_type) { this->quant_type_ = quant_type; }\r\n",
        "schema::QuantType PrimitiveC::quant_type() const { return quant_type_; }\r\n",
        "#endif\r\n",
        "\r\n",
        "int PrimitiveC::Type() const {\r\n",
        "  if (this->primitive_ == nullptr && this->op_type_ == OP_TYPE_NOT_SET) {\r\n",
        "    return schema::PrimitiveType_NONE;\r\n",
        "  }\r\n",
        "#ifdef PRIMITIVE_WRITEABLE\r\n",
        "  if (op_type_ != OP_TYPE_NOT_SET) {\r\n",
        "    return op_type_;\r\n",
        "  }\r\n",
        "  return this->primitive_->value.type;\r\n",
        "#else\r\n",
        "  return this->primitive_->value_type();\r\n",
        "#endif\r\n",
        "}\r\n",
        "bool PrimitiveC::infer_flag() const { return this->infer_flag_; }\r\n",
        "\r\n",
        "void PrimitiveC::set_infer_flag(bool flag) { this->infer_flag_ = flag; }\r\n",
        "\r\n",
        "bool PrimitiveC::train_flag() const { return this->train_flag_; }\r\n",
        "\r\n",
        "void PrimitiveC::set_train_flag(bool flag) { this->train_flag_ = flag; }\r\n",
        "\r\n",
        "int PrimitiveC::InferShape(std::vector<lite::Tensor *> inputs, std::vector<lite::Tensor *> outputs) {\r\n",
        "  auto input = inputs.front();\r\n",
        "  MS_ASSERT(input != nullptr);\r\n",
        "  auto output = outputs.front();\r\n",
        "  MS_ASSERT(output != nullptr);\r\n",
        "  output->set_shape(input->shape());\r\n",
        "  output->set_data_type(input->data_type());\r\n",
        "  output->set_format(input->format());\r\n",
        "  return 0;\r\n",
        "}\r\n",
        "\r\n",
        "}  // namespace lite\r\n",
        "}  // namespace mindspore\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}