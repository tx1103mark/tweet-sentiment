{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93a3Yz_tHf4"
      },
      "source": [
        "cmake_minimum_required(VERSION 3.14)\r\n",
        "\r\n",
        "project(FederalLearning)\r\n",
        "\r\n",
        "option(SUPPORT_GPU \"if support gpu\" off)\r\n",
        "set(BUILD_LITE \"on\")\r\n",
        "set(SUPPORT_TRAIN \"on\")\r\n",
        "set(PLATFORM_ARM \"on\")\r\n",
        "\r\n",
        "set(TOP_DIR ${CMAKE_CURRENT_SOURCE_DIR}/../../../../../../)\r\n",
        "set(LITE_DIR ${TOP_DIR}/mindspore/lite)\r\n",
        "set(MS_VERSION_MAJOR ${MS_VERSION_MAJOR})\r\n",
        "set(MS_VERSION_MINOR ${MS_VERSION_MINOR})\r\n",
        "set(MS_VERSION_REVISION ${MS_VERSION_REVISION})\r\n",
        "set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} -DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        "set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -DMS_VERSION_MAJOR=${MS_VERSION_MAJOR} -DMS_VERSION_MINOR=${MS_VERSION_MINOR} -DMS_VERSION_REVISION=${MS_VERSION_REVISION}\")\r\n",
        "set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++17\")\r\n",
        "\r\n",
        "include_directories(${CMAKE_CURRENT_SOURCE_DIR})\r\n",
        "include_directories(${CMAKE_CURRENT_SOURCE_DIR}/linux)\r\n",
        "include_directories(${CMAKE_CURRENT_SOURCE_DIR}/include)\r\n",
        "include_directories(${CMAKE_CURRENT_SOURCE_DIR}/src)\r\n",
        "if (ENABLE_MICRO)\r\n",
        "include_directories(${CMAKE_CURRENT_SOURCE_DIR}/src/runtime)\r\n",
        "endif()\r\n",
        "include_directories(${LITE_DIR}) ## lite include\r\n",
        "include_directories(${TOP_DIR}) ## api include\r\n",
        "include_directories(${TOP_DIR}/mindspore/core/) ## core include\r\n",
        "include_directories(${LITE_DIR}/build) ## flatbuffers\r\n",
        "\r\n",
        "if (ENABLE_MICRO)\r\n",
        "set(OP_SRC\r\n",
        "    src/nnacl/arithmetic_common.c\r\n",
        "    src/nnacl/common_func.c\r\n",
        "    src/nnacl/fp32/activation.c\r\n",
        "    src/nnacl/fp32/arithmetic.c\r\n",
        "    src/nnacl/fp32/common_func.c\r\n",
        "    src/nnacl/fp32/conv.c\r\n",
        "    src/nnacl/fp32/matmul.c\r\n",
        "    src/nnacl/fp32/softmax.c\r\n",
        "    src/nnacl/fp32_grad/activation_grad.c\r\n",
        "    src/nnacl/fp32_grad/gemm.c\r\n",
        "    src/nnacl/fp32_grad/pack_ext.c\r\n",
        "    src/nnacl/fp32_grad/pooling_grad.c\r\n",
        "    src/nnacl/int8/conv_int8.c\r\n",
        "    src/nnacl/int8/matmul_int8.c\r\n",
        "    src/nnacl/minimal_filtering_generator.c\r\n",
        "    src/nnacl/pack.c\r\n",
        "    src/nnacl/quantization/fixed_point.c\r\n",
        "    src/nnacl/reshape.c\r\n",
        "    src/nnacl/winograd_transform.c\r\n",
        "    src/nnacl/winograd_utils.c\r\n",
        "    src/runtime/kernel/fp32/max_pooling.c\r\n",
        "    src/runtime/kernel/fp32_grad/apply_momentum.c\r\n",
        "    src/runtime/kernel/fp32_grad/biasadd_grad.c\r\n",
        "    src/runtime/kernel/fp32_grad/compute_gradient.c\r\n",
        "    src/runtime/kernel/fp32_grad/conv_filter_grad.c\r\n",
        "    src/runtime/kernel/fp32_grad/conv_input_grad.c\r\n",
        "    src/runtime/kernel/fp32_grad/init_matrix.c\r\n",
        "    src/runtime/kernel/fp32_grad/sparse_softmax_cross_entropy_with_logist.c\r\n",
        "    src/runtime/load_input.c\r\n",
        "    src/fl_lenet.c\r\n",
        "    src/weight_files/fl_lenet_weight_epoch_0.c\r\n",
        ")\r\n",
        "else()\r\n",
        "    set(OP_SRC\r\n",
        "            src/lenet_train.cpp\r\n",
        "            )\r\n",
        "    endif()\r\n",
        "if (ENABLE_MICRO)\r\n",
        "    set(SRC_FILES\r\n",
        "            flearning.cpp)\r\n",
        "    else()\r\n",
        "set(SRC_FILES\r\n",
        "        lenet_train_jni.cpp\r\n",
        "        )\r\n",
        "endif()\r\n",
        "find_library(log-lib glog)\r\n",
        "\r\n",
        "add_library(fl SHARED ${SRC_FILES} ${OP_SRC})\r\n",
        "target_link_libraries(fl mindspore-lite  glog)\r\n",
        "link_directories(${CMAKE_CURRENT_SOURCE_DIR}/lib/)\r\n",
        "\r\n",
        "install(TARGETS fl LIBRARY DESTINATION ${CMAKE_CURRENT_SOURCE_DIR}/lib)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZPfMVSsAy1M"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "#include <jni.h>\r\n",
        "#include \"include/train_session.h\"\r\n",
        "#include \"include/errorcode.h\"\r\n",
        "#include \"lenet_train.h\"\r\n",
        "#include <cstring>\r\n",
        "#include \"src/common/log_adapter.h\"\r\n",
        "\r\n",
        "static jobject fbb;\r\n",
        "static jmethodID create_string_char;\r\n",
        "\r\n",
        "char *JstringToChar(JNIEnv *env, jstring jstr) {\r\n",
        "  char *rtn = nullptr;\r\n",
        "  jclass clsstring = env->FindClass(\"java/lang/String\");\r\n",
        "  jstring strencode = env->NewStringUTF(\"GB2312\");\r\n",
        "  jmethodID mid = env->GetMethodID(clsstring, \"getBytes\", \"(Ljava/lang/String;)[B\");\r\n",
        "  jbyteArray barr = (jbyteArray)env->CallObjectMethod(jstr, mid, strencode);\r\n",
        "  jsize alen = env->GetArrayLength(barr);\r\n",
        "  jbyte *ba = env->GetByteArrayElements(barr, JNI_FALSE);\r\n",
        "  if (alen > 0) {\r\n",
        "    rtn = new char[alen + 1];\r\n",
        "    memcpy(rtn, ba, alen);\r\n",
        "    rtn[alen] = 0;\r\n",
        "  }\r\n",
        "  env->ReleaseByteArrayElements(barr, ba, 0);\r\n",
        "  return rtn;\r\n",
        "}\r\n",
        "extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_train(JNIEnv *env, jobject thiz, jstring ms_file,\r\n",
        "                                                                           jint batch_num, jint iterations) {\r\n",
        "  return fl_lenet_lite_Train(JstringToChar(env, ms_file), batch_num, iterations);\r\n",
        "}\r\n",
        "\r\n",
        "extern \"C\" jint CreateFeatureMap(JNIEnv *env, const char *name, float *data, size_t size) {\r\n",
        "  jstring name1 = env->NewStringUTF(name);\r\n",
        "  jint name_offset = env->CallIntMethod(fbb, create_string_char, name1);\r\n",
        "  // 1. set data size\r\n",
        "  jfloatArray ret = env->NewFloatArray(size);\r\n",
        "  env->SetFloatArrayRegion(ret, 0, size, data);\r\n",
        "  // 2. get methodid createDataVector\r\n",
        "  jclass fm_cls = env->FindClass(\"mindspore/schema/FeatureMap\");\r\n",
        "  jmethodID createDataVector =\r\n",
        "    env->GetStaticMethodID(fm_cls, \"createDataVector\", \"(Lcom/google/flatbuffers/FlatBufferBuilder;[F)I\");\r\n",
        "  // 3. calc data offset\r\n",
        "  jint data_offset = env->CallStaticIntMethod(fm_cls, createDataVector, fbb, ret);\r\n",
        "  jmethodID createFeatureMap =\r\n",
        "    env->GetStaticMethodID(fm_cls, \"createFeatureMap\", \"(Lcom/google/flatbuffers/FlatBufferBuilder;II)I\");\r\n",
        "  jint fm_offset = env->CallStaticIntMethod(fm_cls, createFeatureMap, fbb, name_offset, data_offset);\r\n",
        "  return fm_offset;\r\n",
        "}\r\n",
        "\r\n",
        "extern \"C\" JNIEXPORT jintArray JNICALL Java_com_huawei_flclient_LiteTrain_getFeaturesMap(JNIEnv *env, jobject thiz,\r\n",
        "                                                                                         jstring ms_file,\r\n",
        "                                                                                         jobject builder) {\r\n",
        "  fbb = builder;\r\n",
        "  jclass fb_clazz = env->GetObjectClass(builder);\r\n",
        "  create_string_char = env->GetMethodID(fb_clazz, \"createString\", \"(Ljava/lang/CharSequence;)I\");\r\n",
        "  TrainFeatureParam **train_features = nullptr;\r\n",
        "  int feature_size = 0;\r\n",
        "  auto status = fl_lenet_lite_GetFeatures(JstringToChar(env, ms_file), &train_features, &feature_size);\r\n",
        "  if(status != mindspore::lite::RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"get features failed:\" << ms_file;\r\n",
        "    return env->NewIntArray(0);\r\n",
        "  }\r\n",
        "  jintArray ret = env->NewIntArray(feature_size);\r\n",
        "  jint *data = env->GetIntArrayElements(ret, NULL);\r\n",
        "\r\n",
        "  for (int i = 0; i < feature_size; i++) {\r\n",
        "        data[i] =\r\n",
        "          CreateFeatureMap(env, train_features[i]->name, (float *)train_features[i]->data,\r\n",
        "          train_features[i]->elenums);\r\n",
        "        MS_LOG(INFO) << \"upload feature:\"<< \", name:\" << train_features[i]->name << \", elenums:\" <<\r\n",
        "        train_features[i]->elenums;\r\n",
        "  }\r\n",
        "    env->ReleaseIntArrayElements(ret, data, 0);\r\n",
        "    for (int i = 0; i < feature_size; i++) {\r\n",
        "      delete  train_features[i];\r\n",
        "    }\r\n",
        "  return ret;\r\n",
        "}\r\n",
        "\r\n",
        "extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_updateFeatures(JNIEnv *env, jobject,\r\n",
        "                                                                                    jstring ms_file, jobject features) {\r\n",
        "  jclass arr_cls = env->GetObjectClass(features);\r\n",
        "  jmethodID size_method = env->GetMethodID(arr_cls, \"size\", \"()I\");\r\n",
        "  jmethodID get_method = env->GetMethodID(arr_cls, \"get\", \"(I)Ljava/lang/Object;\");\r\n",
        "\r\n",
        "  jclass fm_cls = env->FindClass(\"mindspore/schema/FeatureMap\");\r\n",
        "  jmethodID weight_name_method = env->GetMethodID(fm_cls, \"weightFullname\", \"()Ljava/lang/String;\");\r\n",
        "  jmethodID data_length_method = env->GetMethodID(fm_cls, \"dataLength\", \"()I\");\r\n",
        "  jmethodID data_method = env->GetMethodID(fm_cls, \"data\", \"(I)F\");\r\n",
        "  jclass clsstring = env->FindClass(\"java/lang/String\");\r\n",
        "  jmethodID mid = env->GetMethodID(clsstring, \"getBytes\", \"(Ljava/lang/String;)[B\");\r\n",
        "  int size = env->CallIntMethod(features, size_method);\r\n",
        "  // transform FeatureMap to TrainFeatureParm\r\n",
        "  TrainFeatureParam *features_param = (TrainFeatureParam *)malloc(size * sizeof(TrainFeatureParam));\r\n",
        "  for (int i = 0; i < size; ++i) {\r\n",
        "    TrainFeatureParam *param = features_param + i;\r\n",
        "    jobject feature = env->CallObjectMethod(features, get_method, i);\r\n",
        "    // set feature_param name\r\n",
        "    jstring weight_full_name = (jstring)env->CallObjectMethod(feature, weight_name_method);\r\n",
        "    jstring strencode = env->NewStringUTF(\"GB2312\");\r\n",
        "    jbyteArray barr = (jbyteArray)env->CallObjectMethod(weight_full_name, mid, strencode);\r\n",
        "    char *name = nullptr;\r\n",
        "    jsize alen = env->GetArrayLength(barr);\r\n",
        "    jbyte *ba = env->GetByteArrayElements(barr, JNI_FALSE);\r\n",
        "    if (alen > 0) {\r\n",
        "      name = new char[alen + 1];\r\n",
        "      if (ba == nullptr) {\r\n",
        "        MS_LOG(ERROR) << \"name is nullptr\";\r\n",
        "        return mindspore::lite::RET_ERROR;\r\n",
        "      }\r\n",
        "      memcpy(name, ba, alen);\r\n",
        "      name[alen] = 0;\r\n",
        "    }\r\n",
        "    param->name = name;\r\n",
        "    env->ReleaseByteArrayElements(barr, ba, 0);\r\n",
        "    int data_length = env->CallIntMethod(feature, data_length_method);\r\n",
        "    float *data = static_cast<float *>(malloc(data_length * sizeof(float)));\r\n",
        "    memset(data, 0, data_length * sizeof(float));\r\n",
        "    for (int j = 0; j < data_length; ++j) {\r\n",
        "      float *addr = data + j;\r\n",
        "      *addr = env->CallFloatMethod(feature, data_method, j);\r\n",
        "    }\r\n",
        "    param->data = data;\r\n",
        "    param->elenums = data_length;\r\n",
        "    param->type = mindspore::kNumberTypeFloat32;\r\n",
        "    MS_LOG(INFO) << \"get feature:\" << param->name << \",elenums:\" << param->elenums;\r\n",
        "  }\r\n",
        "  return fl_lenet_lite_UpdateFeatures(JstringToChar(env, ms_file), features_param, size);\r\n",
        "}\r\n",
        "\r\n",
        "extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_setInput(JNIEnv *env, jobject, jstring files,\r\n",
        "                                                                              jint nums) {\r\n",
        "  return fl_lenet_lite_SetInputs(JstringToChar(env, files),nums);\r\n",
        "}\r\n",
        "\r\n",
        "extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_inference(JNIEnv *env, jobject, jstring ms_file,\r\n",
        "                                                                               jint batch_num, jint test_nums) {;\r\n",
        "  auto accuary = fl_lenet_lite_Inference(JstringToChar(env, ms_file), batch_num, test_nums);\r\n",
        "  return accuary;\r\n",
        "}\r\n",
        "\r\n",
        "extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_free(JNIEnv *, jobject) { return 0; }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKbScM1gA1DG"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " *\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " *\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " *\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "#include \"lenet_train.h\"\r\n",
        "#include \"include/errorcode.h\"\r\n",
        "#include \"include/context.h\"\r\n",
        "#include <cstring>\r\n",
        "#include <iostream>\r\n",
        "#include <fstream>\r\n",
        "#include \"include/api/lite_context.h\"\r\n",
        "#include \"src/common/log_adapter.h\"\r\n",
        "\r\n",
        "static char *fl_lenet_I0 = 0;\r\n",
        "static char *fl_lenet_I1 = 0;\r\n",
        "unsigned int seed_ = time(NULL);\r\n",
        "\r\n",
        "std::vector<int> FillInputData(mindspore::session::TrainSession *train_session, int batch_num, bool serially) {\r\n",
        "  std::vector<int> labels_vec;\r\n",
        "  auto inputs = train_session->GetInputs();\r\n",
        "  int batch_size = inputs[0]->shape()[0];\r\n",
        "  static unsigned int idx = 1;\r\n",
        "  int data_size = inputs[0]->ElementsNum() / batch_size;\r\n",
        "  int num_classes = inputs[1]->shape()[1];\r\n",
        "  char *input_data = reinterpret_cast<char *>(inputs.at(0)->MutableData());\r\n",
        "  auto labels = reinterpret_cast<float *>(inputs.at(1)->MutableData());\r\n",
        "  std::fill(labels, labels + inputs.at(1)->ElementsNum(), 0.f);\r\n",
        "  for (int i = 0; i < batch_size; i++) {\r\n",
        "    if (serially) {\r\n",
        "      idx = ++idx % batch_num;\r\n",
        "    } else {\r\n",
        "      idx = rand_r(&seed_) % batch_num;\r\n",
        "    }\r\n",
        "    std::memcpy(input_data + i * data_size, fl_lenet_I0 + idx * data_size, data_size);\r\n",
        "    int label_idx = *((int *)(fl_lenet_I1) + idx);\r\n",
        "    labels[i * num_classes + label_idx] = 1.0;  // Model expects labels in onehot representation\r\n",
        "    labels_vec.push_back(label_idx);\r\n",
        "  }\r\n",
        "  return labels_vec;\r\n",
        "}\r\n",
        "\r\n",
        "mindspore::tensor::MSTensor *SearchOutputsForSize(mindspore::session::TrainSession *train_session, size_t size) {\r\n",
        "  auto outputs = train_session->GetOutputs();\r\n",
        "  for (auto it = outputs.begin(); it != outputs.end(); ++it) {\r\n",
        "    if (it->second->ElementsNum() == size) return it->second;\r\n",
        "  }\r\n",
        "  MS_LOG(ERROR) << \"Model does not have an output tensor with size \";\r\n",
        "  return nullptr;\r\n",
        "}\r\n",
        "\r\n",
        "float GetLoss(mindspore::session::TrainSession *train_session) {\r\n",
        "  auto outputsv = SearchOutputsForSize(train_session, 1);  // Search for Loss which is a single value tensor\r\n",
        "  if (outputsv == nullptr) {\r\n",
        "    return 10000;\r\n",
        "  }\r\n",
        "  auto loss = reinterpret_cast<float *>(outputsv->MutableData());\r\n",
        "  return loss[0];\r\n",
        "}\r\n",
        "mindspore::session::TrainSession *GetSession(const std::string &ms_file, bool train_mode) {\r\n",
        "  // create model file\r\n",
        "  mindspore::lite::Context context;\r\n",
        "  context.device_list_[0].device_info_.cpu_device_info_.cpu_bind_mode_ = mindspore::lite::NO_BIND;\r\n",
        "  context.thread_num_ = 1;\r\n",
        "  return mindspore::session::TrainSession::CreateSession(ms_file, &context, train_mode);\r\n",
        "}\r\n",
        "\r\n",
        "// net training function\r\n",
        "int fl_lenet_lite_Inference(const std::string &ms_file, int batch_num, int test_nums) {\r\n",
        "  auto session = GetSession(ms_file, false);\r\n",
        "  char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\r\n",
        "  float accuracy = 0.0;\r\n",
        "  session->Eval();\r\n",
        "  auto inputs = session->GetInputs();\r\n",
        "  if (inputs[1]->shape().size() != 2) {\r\n",
        "    return mindspore::lite::RET_ERROR;\r\n",
        "  }\r\n",
        "  auto batch_size = inputs[1]->shape()[0];\r\n",
        "  auto num_of_class = inputs[1]->shape()[1];\r\n",
        "  for (int j = 0; j < test_nums; ++j) {\r\n",
        "    auto labels = FillInputData(session, batch_num, true);\r\n",
        "    session->RunGraph();\r\n",
        "    auto outputsv = SearchOutputsForSize(session, batch_size * num_of_class);\r\n",
        "    auto scores = reinterpret_cast<float *>(outputsv->MutableData());\r\n",
        "    for (int b = 0; b < batch_size; b++) {\r\n",
        "      int max_idx = 0;\r\n",
        "      float max_score = scores[num_of_class * b];\r\n",
        "      for (int c = 0; c < num_of_class; c++) {\r\n",
        "        if (scores[num_of_class * b + c] > max_score) {\r\n",
        "          max_score = scores[num_of_class * b + c];\r\n",
        "          max_idx = c;\r\n",
        "        }\r\n",
        "      }\r\n",
        "      if (labels[b] == max_idx) accuracy += 1.0;\r\n",
        "    }\r\n",
        "  }\r\n",
        "  fl_lenet_I0 = origin_input[0];\r\n",
        "  fl_lenet_I1 = origin_input[1];\r\n",
        "  accuracy /= static_cast<float>(batch_size * test_nums);\r\n",
        "  MS_LOG(INFO) << \"accuracy  is \" << accuracy;\r\n",
        "  return mindspore::lite::RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "// net training function\r\n",
        "int fl_lenet_lite_Train(const std::string &ms_file, const int batch_num, const int iterations) {\r\n",
        "  auto session = GetSession(ms_file, true);\r\n",
        "  if (iterations <= 0) {\r\n",
        "    MS_LOG(ERROR) << \"error iterations or epoch!, epoch:\"\r\n",
        "                 << \", iterations\" << iterations;\r\n",
        "    return mindspore::lite::RET_ERROR;\r\n",
        "  }\r\n",
        "  MS_LOG(INFO) << \"total iterations :\" << iterations << \"batch_num:\" << batch_num;\r\n",
        "  char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\r\n",
        "  float min_loss = 1000.;\r\n",
        "  for (int j = 0; j < iterations; ++j) {\r\n",
        "    FillInputData(session, batch_num, false);\r\n",
        "    session->RunGraph(nullptr, nullptr);\r\n",
        "    float loss = GetLoss(session);\r\n",
        "    if (min_loss > loss) min_loss = loss;\r\n",
        "    if (j % 50 == 0) {\r\n",
        "      MS_LOG(INFO) << \"iteration:\" << j << \",Loss is\" << loss << \" [min=\" << min_loss << \"]\";\r\n",
        "    }\r\n",
        "  }\r\n",
        "  session->SaveToFile(ms_file);\r\n",
        "  fl_lenet_I0 = origin_input[0];\r\n",
        "  fl_lenet_I1 = origin_input[1];\r\n",
        "  return mindspore::lite::RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "int fl_lenet_lite_UpdateFeatures(const std::string &update_ms_file, TrainFeatureParam *new_features, int size) {\r\n",
        "  auto train_session = GetSession(update_ms_file, false);\r\n",
        "  auto status = train_session->UpdateFeatureMaps(update_ms_file, new_features, size);\r\n",
        "  if (status != mindspore::lite::RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"update model feature map failed\" << update_ms_file;\r\n",
        "  }\r\n",
        "  delete train_session;\r\n",
        "  return status;\r\n",
        "}\r\n",
        "\r\n",
        "int fl_lenet_lite_GetFeatures(const std::string &update_ms_file, mindspore::session::TrainFeatureParam ***feature,\r\n",
        "                              int *size) {\r\n",
        "  auto train_session = GetSession(update_ms_file, false);\r\n",
        "  std::vector<mindspore::session::TrainFeatureParam *> new_features;\r\n",
        "  auto status = train_session->GetFeatureMaps(&new_features);\r\n",
        "  if (status != mindspore::lite::RET_OK) {\r\n",
        "    MS_LOG(ERROR) << \"get model feature map failed\" << update_ms_file;\r\n",
        "    delete train_session;\r\n",
        "    return mindspore::lite::RET_ERROR;\r\n",
        "  }\r\n",
        "  *feature = new (std::nothrow) TrainFeatureParam *[new_features.size()];\r\n",
        "  if (*feature == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"create features failed\";\r\n",
        "    delete train_session;\r\n",
        "    return mindspore::lite::RET_ERROR;\r\n",
        "  }\r\n",
        "  for (int i = 0; i < new_features.size(); i++) {\r\n",
        "    (*feature)[i] = new_features[i];\r\n",
        "  }\r\n",
        "  *size = new_features.size();\r\n",
        "  delete train_session;\r\n",
        "  return mindspore::lite::RET_OK;\r\n",
        "}\r\n",
        "\r\n",
        "std::string RealPath(const char *path) {\r\n",
        "  if (path == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"path is nullptr\";\r\n",
        "    return \"\";\r\n",
        "  }\r\n",
        "  if ((strlen(path)) >= PATH_MAX) {\r\n",
        "    MS_LOG(ERROR) << \"path is too long\";\r\n",
        "    return \"\";\r\n",
        "  }\r\n",
        "  auto resolved_path = std::make_unique<char[]>(PATH_MAX);\r\n",
        "  if (resolved_path == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"new resolved_path failed\";\r\n",
        "    return \"\";\r\n",
        "  }\r\n",
        "#ifdef _WIN32\r\n",
        "  char *real_path = _fullpath(resolved_path.get(), path, 1024);\r\n",
        "#else\r\n",
        "  char *real_path = realpath(path, resolved_path.get());\r\n",
        "#endif\r\n",
        "  if (real_path == nullptr || strlen(real_path) == 0) {\r\n",
        "    MS_LOG(ERROR) << \"file path is not valid : \" << path;\r\n",
        "    return \"\";\r\n",
        "  }\r\n",
        "  std::string res = resolved_path.get();\r\n",
        "  return res;\r\n",
        "}\r\n",
        "\r\n",
        "char *ReadFile(const char *file, size_t *size) {\r\n",
        "  if (file == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"file is nullptr\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  //  MS_ASSERT(size != nullptr);\r\n",
        "  std::string real_path = RealPath(file);\r\n",
        "  std::ifstream ifs(real_path);\r\n",
        "  if (!ifs.good()) {\r\n",
        "    MS_LOG(ERROR) << \"file: \" << real_path << \" is not exist\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "\r\n",
        "  if (!ifs.is_open()) {\r\n",
        "    MS_LOG(ERROR) << \"file: \" << real_path << \" open failed\";\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "\r\n",
        "  ifs.seekg(0, std::ios::end);\r\n",
        "  *size = ifs.tellg();\r\n",
        "  std::unique_ptr<char[]> buf(new (std::nothrow) char[*size]);\r\n",
        "  if (buf == nullptr) {\r\n",
        "    MS_LOG(ERROR) << \"malloc buf failed, file: \" << real_path;\r\n",
        "    ifs.close();\r\n",
        "    return nullptr;\r\n",
        "  }\r\n",
        "  ifs.seekg(0, std::ios::beg);\r\n",
        "  ifs.read(buf.get(), *size);\r\n",
        "  ifs.close();\r\n",
        "\r\n",
        "  return buf.release();\r\n",
        "}\r\n",
        "\r\n",
        "// Set input tensors.\r\n",
        "int fl_lenet_lite_SetInputs(const std::string &files, int num) {\r\n",
        "  std::vector<std::string> res;\r\n",
        "  if (files.empty()) {\r\n",
        "    MS_LOG(ERROR) << \"files empty\";\r\n",
        "    return -1;\r\n",
        "  }\r\n",
        "  std::string pattern = \",\";\r\n",
        "  std::string strs = files + pattern;\r\n",
        "  size_t pos = strs.find(pattern);\r\n",
        "  while (pos != strs.npos) {\r\n",
        "    std::string temp = strs.substr(0, pos);\r\n",
        "    res.push_back(temp);\r\n",
        "    strs = strs.substr(pos + 1, strs.size());\r\n",
        "    pos = strs.find(pattern);\r\n",
        "  }\r\n",
        "  if (res.size() != 2) {\r\n",
        "    MS_LOG(ERROR) << \"res size not equal 2\";\r\n",
        "    return -1;\r\n",
        "  }\r\n",
        "  for (int i = 0; i < 2; i++) {\r\n",
        "    size_t size;\r\n",
        "    char *bin_buf = ReadFile(res[i].c_str(), &size);\r\n",
        "    if (bin_buf == nullptr) {\r\n",
        "      MS_LOG(ERROR) << \"ReadFile return nullptr\";\r\n",
        "      return mindspore::lite::RET_ERROR;\r\n",
        "    }\r\n",
        "    if (i == 0) {\r\n",
        "      fl_lenet_I0 = bin_buf;\r\n",
        "    }\r\n",
        "    if (i == 1) {\r\n",
        "      fl_lenet_I1 = bin_buf;\r\n",
        "    }\r\n",
        "  }\r\n",
        "\r\n",
        "  return 0;\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oVNAD7nBAHa"
      },
      "source": [
        "/**\r\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\r\n",
        " * <p>\r\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        " * you may not use this file except in compliance with the License.\r\n",
        " * You may obtain a copy of the License at\r\n",
        " * <p>\r\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\r\n",
        " * <p>\r\n",
        " * Unless required by applicable law or agreed to in writing, software\r\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        " * See the License for the specific language governing permissions and\r\n",
        " * limitations under the License.\r\n",
        " */\r\n",
        "\r\n",
        "package com.huawei.flclient;\r\n",
        "\r\n",
        "import com.google.flatbuffers.FlatBufferBuilder;\r\n",
        "import mindspore.schema.FeatureMap;\r\n",
        "import java.util.ArrayList;\r\n",
        "\r\n",
        "public  class LiteTrain {\r\n",
        "    static {\r\n",
        "        System.loadLibrary(\"fl\");\r\n",
        "    }\r\n",
        "\r\n",
        "    private static LiteTrain train;\r\n",
        "\r\n",
        "    private LiteTrain() {\r\n",
        "    }\r\n",
        "    public static synchronized LiteTrain getInstance() {\r\n",
        "        if (train == null) {\r\n",
        "            train = new LiteTrain();\r\n",
        "        }\r\n",
        "        return train;\r\n",
        "    }\r\n",
        "    /**\r\n",
        "     * set the Inference set or Train set\r\n",
        "     *\r\n",
        "     * @param fileSet   input binary file path which format is NHWC\r\n",
        "     * @param batch_num binary file batch num\r\n",
        "     * @return\r\n",
        "     */\r\n",
        "    native int setInput(String fileSet, int num);\r\n",
        "\r\n",
        "    /**\r\n",
        "     * inference\r\n",
        "     *\r\n",
        "     * @return status\r\n",
        "     */\r\n",
        "    public native int inference(String modelName,int batch_num,int test_nums);\r\n",
        "\r\n",
        "    /**\r\n",
        "     * train\r\n",
        "     *\r\n",
        "     * @return status\r\n",
        "     */\r\n",
        "    public native int train(String modelName, int batch_num,int iterations);\r\n",
        "\r\n",
        "    /**\r\n",
        "     * get the features map of training model\r\n",
        "     *\r\n",
        "     * @param builder FlatBufferBuilder\r\n",
        "     * @return features offset\r\n",
        "     */\r\n",
        "    native int[] getFeaturesMap(String modelName,FlatBufferBuilder builder);\r\n",
        "\r\n",
        "    /**\r\n",
        "     * update the features map of training model\r\n",
        "     *\r\n",
        "     * @param featureMaps\r\n",
        "     * @return status\r\n",
        "     */\r\n",
        "    native int updateFeatures(String modelName,ArrayList<FeatureMap> featureMaps);\r\n",
        "\r\n",
        "    /**\r\n",
        "     * free Inference or Train runtime memory resource\r\n",
        "     *\r\n",
        "     * @return status\r\n",
        "     */\r\n",
        "    native int free();\r\n",
        "}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}