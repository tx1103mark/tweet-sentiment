{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18a4343c030b4371b899e99d4f8c513c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97212f9b24d549d08e65ef631c788e5e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c9b0b798db64f1298760c85a57f097c",
              "IPY_MODEL_e3fe3c2345634b088bff27a09a10b640"
            ]
          }
        },
        "97212f9b24d549d08e65ef631c788e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c9b0b798db64f1298760c85a57f097c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33c8818e4b764cdcba3e4b6f52f1dbea",
            "_dom_classes": [],
            "description": "Training:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 171,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94e37f508ab34e898ec927961919de34"
          }
        },
        "e3fe3c2345634b088bff27a09a10b640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49f8aa1ae9f84e4b9a2c5177bc74ea4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/171 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c95bbed6e4ba46b18898146970ea9de6"
          }
        },
        "33c8818e4b764cdcba3e4b6f52f1dbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94e37f508ab34e898ec927961919de34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49f8aa1ae9f84e4b9a2c5177bc74ea4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c95bbed6e4ba46b18898146970ea9de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kheg6AR0jqim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include <vector>\n",
        "#include <memory>\n",
        "#include \"src/gllo/common/gllo_utils.h\"\n",
        "#include \"src/ir/primitive_t_value.h\"\n",
        "#include \"frontend/operator/ops.h\"\n",
        "\n",
        "using PrimitiveTValuePtr = std::shared_ptr<mindspore::lite::PrimitiveTValue>;\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "namespace{\n",
        "constexpr auto kAnfPrimitiveIndex = 0;\n",
        "bool CheckPrimitiveType(const AnfNodePtr &node, const PrimitivePtr &primitive_type) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  if (!node->isa<CNode>()) {\n",
        "    return false;\n",
        "  }\n",
        "  auto cnode = node->cast<CNodePtr>();\n",
        "  MS_EXCEPTION_IF_NULL(cnode);\n",
        "  return IsPrimitive(cnode->input(kAnfPrimitiveIndex), primitive_type);\n",
        "}\n",
        "\n",
        "bool IsRealKernel(const AnfNodePtr &node) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  // parameter and value node is not a real kernel too\n",
        "  if (!node->isa<CNode>()) {\n",
        "    return true;\n",
        "  }\n",
        "  auto cnode = node->cast<CNodePtr>();\n",
        "  MS_EXCEPTION_IF_NULL(cnode);\n",
        "  if (cnode->inputs().empty()) {\n",
        "    MS_LOG(EXCEPTION) << \"Illegal null input of cnode(%s)\" << node->DebugString();\n",
        "  }\n",
        "  auto input = cnode->inputs()[0];\n",
        "  bool is_virtual_node = IsPrimitive(input, prim::kPrimImageSummary) || IsPrimitive(input, prim::kPrimScalarSummary) ||\n",
        "      IsPrimitive(input, prim::kPrimTensorSummary) ||\n",
        "      IsPrimitive(input, prim::kPrimHistogramSummary) || IsPrimitive(input, prim::kPrimMakeTuple) ||\n",
        "      IsPrimitive(input, prim::kPrimStateSetItem) || IsPrimitive(input, prim::kPrimDepend) ||\n",
        "      IsPrimitive(input, prim::kPrimTupleGetItem) || IsPrimitive(input, prim::kPrimControlDepend) ||\n",
        "      IsPrimitive(input, prim::kPrimReturn) || IsPrimitive(input, prim::kPrimPartial);\n",
        "  return !is_virtual_node;\n",
        "}\n",
        "\n",
        "ValueNodePtr CreateValueNodeWithSexp(const BaseRef &sexp) {\n",
        "  if (utils::isa<int>(sexp)) {\n",
        "    return NewValueNode(utils::cast<int>(sexp));\n",
        "  }\n",
        "  if (utils::isa<float>(sexp)) {\n",
        "    return NewValueNode(utils::cast<float>(sexp));\n",
        "  }\n",
        "  if (utils::isa<bool>(sexp)) {\n",
        "    return NewValueNode(utils::cast<bool>(sexp));\n",
        "  }\n",
        "  if (utils::isa<ValuePtr>(sexp)) {\n",
        "    return NewValueNode(utils::cast<ValuePtr>(sexp));\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "CNodePtr CreateCNodeWithGraph(const std::vector<AnfNodePtr> &input_nodes, const BaseRef &graph) {\n",
        "  if (utils::isa<FuncGraphPtr>(graph)) {\n",
        "    return std::make_shared<CNode>(input_nodes, utils::cast<FuncGraphPtr>(graph));\n",
        "  }\n",
        "  if (utils::isa<VarPtr>(graph)) {\n",
        "    return std::make_shared<CNode>(input_nodes, utils::cast<VarPtr>(graph));\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "VarNodePtr CreateVarNodeWithSexp(const BaseRef &sexp, const BaseRef &graph) {\n",
        "  if (utils::isa<VarPtr>(graph)) {\n",
        "    MS_LOG(DEBUG) << \"make VarPtr \" + graph.ToString();\n",
        "    return std::make_shared<VarNode>(utils::cast<VarPtr>(sexp), nullptr);\n",
        "  }\n",
        "  if (utils::isa<FuncGraphPtr>(graph)) {\n",
        "    MS_LOG(DEBUG) << \"VarNode, should input a Var in graph. It's GraphPtr: \" + graph.ToString();\n",
        "    return std::make_shared<VarNode>(utils::cast<VarPtr>(sexp), utils::cast<FuncGraphPtr>(graph));\n",
        "  }\n",
        "  MS_LOG(ERROR) << \"VarNode, should input a Var in graph. It's \" + graph.ToString();\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "AnfNodePtr HandleSexpVector(const BaseRef &sexp, const BaseRef &graph, PrimitiveVarMap *primitive_vars,\n",
        "                            bool multigraph) {\n",
        "  MS_LOG(DEBUG) << \"HandleSexpVector sexp: \" + sexp.ToString() + \", graph \" + graph.ToString();\n",
        "  std::vector<AnfNodePtr> input_nodes;\n",
        "  const auto &tuple = utils::cast<VectorRef>(sexp);\n",
        "  if (multigraph && utils::isa<VarPtr>(graph)) {\n",
        "    for (auto &x : tuple) {\n",
        "      AnfNodePtr node = SexpToNode(x, std::make_shared<Var>(\"G\"), primitive_vars, true);\n",
        "      input_nodes.push_back(node);\n",
        "    }\n",
        "    VarPtr var_ptr = utils::cast<VarPtr>(graph);\n",
        "    return std::make_shared<CNode>(input_nodes, var_ptr);\n",
        "  }\n",
        "\n",
        "  for (auto &x : tuple) {\n",
        "    AnfNodePtr node = SexpToNode(x, graph, primitive_vars, multigraph);\n",
        "    input_nodes.push_back(node);\n",
        "  }\n",
        "  return CreateCNodeWithGraph(input_nodes, graph);\n",
        "}\n",
        "}  // namespace\n",
        "\n",
        "bool AnfEqual(const BaseRef &a, const BaseRef &b) {\n",
        "  if (utils::isa<AnfNodePtr>(a) && utils::isa<AnfNodePtr>(b)) {\n",
        "    auto a_node = utils::cast<AnfNodePtr>(a);\n",
        "    auto b_node = utils::cast<AnfNodePtr>(b);\n",
        "    MS_EXCEPTION_IF_NULL(a_node);\n",
        "    MS_EXCEPTION_IF_NULL(b_node);\n",
        "    if (IsValueNode<Primitive>(a_node) && IsValueNode<Primitive>(b_node)) {\n",
        "      auto a_value_node = a_node->cast<ValueNodePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(a_value_node);\n",
        "      auto a_value = a_value_node->value();\n",
        "      MS_EXCEPTION_IF_NULL(a_value);\n",
        "      auto a_prim = a_value->cast<PrimitivePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(a_prim);\n",
        "\n",
        "      auto b_value_node = b_node->cast<ValueNodePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(b_value_node);\n",
        "      auto b_value = b_value_node->value();\n",
        "      MS_EXCEPTION_IF_NULL(b_value);\n",
        "      auto b_prim = b_value->cast<PrimitivePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(b_prim);\n",
        "\n",
        "      return a_prim->name() == b_prim->name();\n",
        "    } else if (a_node->isa<ValueNode>() && b_node->isa<ValueNode>()) {\n",
        "      auto a_value_node_ptr = a_node->cast<ValueNodePtr>();\n",
        "      if (a_value_node_ptr == nullptr) {\n",
        "        MS_LOG(EXCEPTION) << \"cast value node ptr fail\";\n",
        "      }\n",
        "      auto a_value_ptr = a_value_node_ptr->value();\n",
        "      if (a_value_ptr == nullptr) {\n",
        "        MS_LOG(EXCEPTION) << \"value ptr is nullptr\";\n",
        "      }\n",
        "\n",
        "      auto b_value_node_ptr = b_node->cast<ValueNodePtr>();\n",
        "      if (b_value_node_ptr == nullptr) {\n",
        "        MS_LOG(EXCEPTION) << \"cast value node ptr fail\";\n",
        "      }\n",
        "      auto b_value_ptr = b_value_node_ptr->value();\n",
        "      if (b_value_ptr == nullptr) {\n",
        "        MS_LOG(EXCEPTION) << \"value ptr is nullptr\";\n",
        "      }\n",
        "\n",
        "      if (utils::isa<lite::PrimitiveTValue>(a_value_ptr) && utils::isa<lite::PrimitiveTValue>(b_value_ptr)) {\n",
        "        auto a_obj = (lite::PrimitiveTValue *)(a_value_ptr.get());\n",
        "        auto b_obj = (lite::PrimitiveTValue *)(b_value_ptr.get());\n",
        "        return (*a_obj) == (*b_obj);\n",
        "      } else {\n",
        "        return (*a_value_ptr) == (*b_value_ptr);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  if (a.m_ptr->isa<lite::PrimitiveTValue>() && b.m_ptr->isa<lite::PrimitiveTValue>()) {\n",
        "    auto a_value_node_ptr = a.m_ptr->cast<PrimitiveTValuePtr>();\n",
        "    auto b_value_node_ptr = b.m_ptr->cast<PrimitiveTValuePtr>();\n",
        "    return a_value_node_ptr->GetPrimitiveT()->value.type == b_value_node_ptr->GetPrimitiveT()->value.type;\n",
        "  }\n",
        "\n",
        "  return a == b;\n",
        "}\n",
        "\n",
        "bool CNodeTypeEqual(const BaseRef &a, const BaseRef &b) {\n",
        "  // To matchCNode and Kernel's type\n",
        "  if (utils::isa<CNode>(a) && utils::isa<CNode>(b)) {\n",
        "    return true;\n",
        "  }\n",
        "  return a.type() == b.type();\n",
        "}\n",
        "\n",
        "AnfNodePtr SexpToNode(const BaseRef &sexp, const BaseRef &graph, PrimitiveVarMap *primitive_vars, bool multigraph) {\n",
        "  MS_LOG(DEBUG) << \"SexpToNode sexp: \" + sexp.ToString() + \", graph \" + graph.ToString();\n",
        "  MS_EXCEPTION_IF_NULL(primitive_vars);\n",
        "  if (utils::isa<VectorRef>(sexp)) {\n",
        "    return HandleSexpVector(sexp, graph, primitive_vars, multigraph);\n",
        "  }\n",
        "  if (utils::isa<VarPtr>(sexp)) {\n",
        "    auto var_ptr = utils::cast<VarPtr>(sexp);\n",
        "    MS_EXCEPTION_IF_NULL(var_ptr);\n",
        "    if (var_ptr->primitive()) {\n",
        "      (*primitive_vars)[var_ptr->primitive()] = var_ptr;\n",
        "      return NewValueNode(var_ptr->primitive());\n",
        "    }\n",
        "    return CreateVarNodeWithSexp(sexp, graph);\n",
        "  }\n",
        "  if (utils::isa<AnfNodePtr>(sexp)) {\n",
        "    return utils::cast<AnfNodePtr>(sexp);\n",
        "  }\n",
        "  auto value_node = CreateValueNodeWithSexp(sexp);\n",
        "  if (value_node == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"sexp cannot converted. sexp: \" + sexp.ToString();\n",
        "  }\n",
        "  return value_node;\n",
        "}\n",
        "\n",
        "\n",
        "bool IsRealCNodeKernel(const AnfNodePtr &node) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  // parameter and value node is not a real cnode kernel\n",
        "  if (!node->isa<CNode>()) {\n",
        "    return false;\n",
        "  }\n",
        "  // return considered as a real node\n",
        "  if (CheckPrimitiveType(node, prim::kPrimReturn)) {\n",
        "    return true;\n",
        "  }\n",
        "  return IsRealKernel(node);\n",
        "}\n",
        "bool IsGraphKernel(const AnfNodePtr &node) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  // graph kernel should be a real cnode kernel.\n",
        "  if (!IsRealCNodeKernel(node)) {\n",
        "    return false;\n",
        "  }\n",
        "\n",
        "  auto cnode = node->cast<CNodePtr>();\n",
        "  MS_EXCEPTION_IF_NULL(cnode);\n",
        "  auto input = cnode->input(kAnfPrimitiveIndex);\n",
        "  // graph kernel should has func_graph as first input.\n",
        "  if (!IsValueNode<FuncGraph>(input)) {\n",
        "    return false;\n",
        "  }\n",
        "\n",
        "  auto func_graph = GetValueNode<FuncGraphPtr>(input);\n",
        "  MS_EXCEPTION_IF_NULL(func_graph);\n",
        "  return func_graph->has_attr(FUNC_GRAPH_ATTR_GRAPH_KERNEL);\n",
        "}\n",
        "\n",
        "\n",
        "void CheckIfFuncGraphIsNull(const FuncGraphPtr &graph) {\n",
        "  if (graph == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"The graph is null.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckIfAnfNodeIsNull(const AnfNodePtr &node) {\n",
        "  if (node == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"The AnfNode is null.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckIfCNodeIsNull(const CNodePtr &node) {\n",
        "  if (node == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"The CNode is null.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckIfVarIsNull(const VarPtr &var) {\n",
        "  if (var == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"The Var is null.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckIfNodeIsParam(const AnfNodePtr &node) {\n",
        "  if (node != nullptr && !utils::isa<ParameterPtr>(node)) {\n",
        "    MS_LOG(EXCEPTION) << \"The Node is not param.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckInputSize(const CNodePtr &node, const int size) {\n",
        "  if (node->inputs().size() != size) {\n",
        "    MS_LOG(EXCEPTION) << \"The input size of node must be \" << size << \", but it is\" << node->inputs().size();\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckLeastInputSize(const CNodePtr &node, const int size) {\n",
        "  if (node->inputs().size() < size) {\n",
        "    MS_LOG(EXCEPTION) << \"The input size of node must be \" << size << \", but it is\" << node->inputs().size();\n",
        "  }\n",
        "}\n",
        "\n",
        "AnfNodePtr AddNewBiasNode(float *bias_data, const FuncGraphPtr &func_graph, int kernel_num,\n",
        "                          const ParamValueLitePtr &weight_tensor) {\n",
        "  auto bias_parameter = func_graph->add_parameter();\n",
        "  MS_ASSERT(bias_parameter != nullptr);\n",
        "  std::vector<int> shape = {kernel_num};\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(TypeIdToType(weight_tensor->tensor_type()), shape);\n",
        "  bias_parameter->set_abstract(abstract_tensor);\n",
        "\n",
        "  ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\n",
        "  MS_ASSERT(param_value != nullptr);\n",
        "  param_value->set_tensor_addr(bias_data);\n",
        "  param_value->set_tensor_size(kernel_num * sizeof(float) / sizeof(uint8_t));\n",
        "  bias_parameter->set_default_param(param_value);\n",
        "  return bias_parameter;\n",
        "}\n",
        "\n",
        "schema::PrimitiveType GetCNodeType(const BaseRef &n) {\n",
        "  ValueNodePtr value_node;\n",
        "  if (utils::isa<CNodePtr>(n)) {\n",
        "    auto in = utils::cast<CNodePtr>(n);\n",
        "    value_node = in->input(0)->cast<ValueNodePtr>();\n",
        "  } else if (utils::isa<ValueNodePtr>(n)) {\n",
        "    value_node = utils::cast<ValueNodePtr>(n);\n",
        "  } else {\n",
        "    MS_LOG(EXCEPTION) << \"only value node or cnode has type\";\n",
        "    return schema::PrimitiveType_NONE;\n",
        "  }\n",
        "  MS_EXCEPTION_IF_NULL(value_node);\n",
        "  auto value = value_node->value();\n",
        "  MS_ASSERT(value != nullptr);\n",
        "  if (utils::isa<PrimitiveTValuePtr>(value)) {\n",
        "    auto primitive = value->cast<PrimitiveTValuePtr>();\n",
        "    MS_ASSERT(primitive != nullptr);\n",
        "    return primitive->GetPrimitiveT()->value.type;\n",
        "  }\n",
        "  return schema::PrimitiveType_NONE;\n",
        "}\n",
        "\n",
        "bool IsParamNode(const BaseRef &n) {\n",
        "  return utils::isa<ParameterPtr>(n);\n",
        "}\n",
        "\n",
        "bool IsConvNode(const BaseRef &n) {\n",
        "  if (utils::isa<CNodePtr>(n) || utils::isa<ValueNodePtr>(n)) {\n",
        "    auto type = opt::GetCNodeType(n);\n",
        "    return type == schema::PrimitiveType_Conv2D || type == schema::PrimitiveType_DepthwiseConv2D;\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuPwvpjujygJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include <vector>\n",
        "#include <memory>\n",
        "#include \"src/gllo/common/gllo_utils.h\"\n",
        "#include \"src/ir/primitive_t_value.h\"\n",
        "#include \"frontend/operator/ops.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "namespace {\n",
        "constexpr auto kAnfPrimitiveIndex = 0;\n",
        "bool CheckPrimitiveType(const AnfNodePtr &node, const PrimitivePtr &primitive_type) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  if (!node->isa<CNode>()) {\n",
        "    return false;\n",
        "  }\n",
        "  auto cnode = node->cast<CNodePtr>();\n",
        "  MS_EXCEPTION_IF_NULL(cnode);\n",
        "  return IsPrimitive(cnode->input(kAnfPrimitiveIndex), primitive_type);\n",
        "}\n",
        "\n",
        "bool IsRealKernel(const AnfNodePtr &node) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  // parameter and value node is not a real kernel too\n",
        "  if (!node->isa<CNode>()) {\n",
        "    return true;\n",
        "  }\n",
        "  auto cnode = node->cast<CNodePtr>();\n",
        "  MS_EXCEPTION_IF_NULL(cnode);\n",
        "  if (cnode->inputs().empty()) {\n",
        "    MS_LOG(EXCEPTION) << \"Illegal null input of cnode(%s)\" << node->DebugString();\n",
        "  }\n",
        "  auto input = cnode->inputs()[0];\n",
        "  bool is_virtual_node = IsPrimitive(input, prim::kPrimImageSummary) || IsPrimitive(input, prim::kPrimScalarSummary) ||\n",
        "      IsPrimitive(input, prim::kPrimTensorSummary) ||\n",
        "      IsPrimitive(input, prim::kPrimHistogramSummary) || IsPrimitive(input, prim::kPrimMakeTuple) ||\n",
        "      IsPrimitive(input, prim::kPrimStateSetItem) || IsPrimitive(input, prim::kPrimDepend) ||\n",
        "      IsPrimitive(input, prim::kPrimTupleGetItem) || IsPrimitive(input, prim::kPrimControlDepend) ||\n",
        "      IsPrimitive(input, prim::kPrimReturn) || IsPrimitive(input, prim::kPrimPartial);\n",
        "  return !is_virtual_node;\n",
        "}\n",
        "\n",
        "ValueNodePtr CreateValueNodeWithSexp(const BaseRef &sexp) {\n",
        "  if (utils::isa<int>(sexp)) {\n",
        "    return NewValueNode(utils::cast<int>(sexp));\n",
        "  }\n",
        "  if (utils::isa<float>(sexp)) {\n",
        "    return NewValueNode(utils::cast<float>(sexp));\n",
        "  }\n",
        "  if (utils::isa<bool>(sexp)) {\n",
        "    return NewValueNode(utils::cast<bool>(sexp));\n",
        "  }\n",
        "  if (utils::isa<ValuePtr>(sexp)) {\n",
        "    return NewValueNode(utils::cast<ValuePtr>(sexp));\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "CNodePtr CreateCNodeWithGraph(const std::vector<AnfNodePtr> &input_nodes, const BaseRef &graph) {\n",
        "  if (utils::isa<FuncGraphPtr>(graph)) {\n",
        "    return std::make_shared<CNode>(input_nodes, utils::cast<FuncGraphPtr>(graph));\n",
        "  }\n",
        "  if (utils::isa<VarPtr>(graph)) {\n",
        "    return std::make_shared<CNode>(input_nodes, utils::cast<VarPtr>(graph));\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "VarNodePtr CreateVarNodeWithSexp(const BaseRef &sexp, const BaseRef &graph) {\n",
        "  if (utils::isa<VarPtr>(graph)) {\n",
        "    MS_LOG(DEBUG) << \"make VarPtr \" + graph.ToString();\n",
        "    return std::make_shared<VarNode>(utils::cast<VarPtr>(sexp), nullptr);\n",
        "  }\n",
        "  if (utils::isa<FuncGraphPtr>(graph)) {\n",
        "    MS_LOG(DEBUG) << \"VarNode, should input a Var in graph. It's GraphPtr: \" + graph.ToString();\n",
        "    return std::make_shared<VarNode>(utils::cast<VarPtr>(sexp), utils::cast<FuncGraphPtr>(graph));\n",
        "  }\n",
        "  MS_LOG(ERROR) << \"VarNode, should input a Var in graph. It's \" + graph.ToString();\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "AnfNodePtr HandleSexpVector(const BaseRef &sexp, const BaseRef &graph, PrimitiveVarMap *primitive_vars,\n",
        "                            bool multigraph) {\n",
        "  MS_LOG(DEBUG) << \"HandleSexpVector sexp: \" + sexp.ToString() + \", graph \" + graph.ToString();\n",
        "  std::vector<AnfNodePtr> input_nodes;\n",
        "  const auto &tuple = utils::cast<VectorRef>(sexp);\n",
        "  if (multigraph && utils::isa<VarPtr>(graph)) {\n",
        "    for (auto &x : tuple) {\n",
        "      AnfNodePtr node = SexpToNode(x, std::make_shared<Var>(\"G\"), primitive_vars, true);\n",
        "      input_nodes.push_back(node);\n",
        "    }\n",
        "    VarPtr var_ptr = utils::cast<VarPtr>(graph);\n",
        "    return std::make_shared<CNode>(input_nodes, var_ptr);\n",
        "  }\n",
        "\n",
        "  for (auto &x : tuple) {\n",
        "    AnfNodePtr node = SexpToNode(x, graph, primitive_vars, multigraph);\n",
        "    input_nodes.push_back(node);\n",
        "  }\n",
        "  return CreateCNodeWithGraph(input_nodes, graph);\n",
        "}\n",
        "}  // namespace\n",
        "\n",
        "bool AnfEqual(const BaseRef &a, const BaseRef &b) {\n",
        "  if (utils::isa<AnfNodePtr>(a) && utils::isa<AnfNodePtr>(b)) {\n",
        "    auto a_node = utils::cast<AnfNodePtr>(a);\n",
        "    auto b_node = utils::cast<AnfNodePtr>(b);\n",
        "    MS_EXCEPTION_IF_NULL(a_node);\n",
        "    MS_EXCEPTION_IF_NULL(b_node);\n",
        "    if (IsValueNode<Primitive>(a_node) && IsValueNode<Primitive>(b_node)) {\n",
        "      auto a_value_node = a_node->cast<ValueNodePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(a_value_node);\n",
        "      auto a_value = a_value_node->value();\n",
        "      MS_EXCEPTION_IF_NULL(a_value);\n",
        "      auto a_prim = a_value->cast<PrimitivePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(a_prim);\n",
        "\n",
        "      auto b_value_node = b_node->cast<ValueNodePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(b_value_node);\n",
        "      auto b_value = b_value_node->value();\n",
        "      MS_EXCEPTION_IF_NULL(b_value);\n",
        "      auto b_prim = b_value->cast<PrimitivePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(b_prim);\n",
        "\n",
        "      return a_prim->name() == b_prim->name();\n",
        "    } else if (a_node->isa<ValueNode>() && b_node->isa<ValueNode>()) {\n",
        "      auto a_value_node_ptr = a_node->cast<ValueNodePtr>();\n",
        "      if (a_value_node_ptr == nullptr) {\n",
        "        MS_LOG(EXCEPTION) << \"cast value node ptr fail\";\n",
        "      }\n",
        "      auto a_value_ptr = a_value_node_ptr->value();\n",
        "      if (a_value_ptr == nullptr) {\n",
        "        MS_LOG(EXCEPTION) << \"value ptr is nullptr\";\n",
        "      }\n",
        "\n",
        "      auto b_value_node_ptr = b_node->cast<ValueNodePtr>();\n",
        "      if (b_value_node_ptr == nullptr) {\n",
        "        MS_LOG(EXCEPTION) << \"cast value node ptr fail\";\n",
        "      }\n",
        "      auto b_value_ptr = b_value_node_ptr->value();\n",
        "      if (b_value_ptr == nullptr) {\n",
        "        MS_LOG(EXCEPTION) << \"value ptr is nullptr\";\n",
        "      }\n",
        "\n",
        "      if (utils::isa<lite::PrimitiveTValue>(a_value_ptr) && utils::isa<lite::PrimitiveTValue>(b_value_ptr)) {\n",
        "        auto a_obj = (lite::PrimitiveTValue *) (a_value_ptr.get());\n",
        "        auto b_obj = (lite::PrimitiveTValue *) (b_value_ptr.get());\n",
        "        return (*a_obj) == (*b_obj);\n",
        "      } else {\n",
        "        return (*a_value_ptr) == (*b_value_ptr);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  if (a.m_ptr->isa<lite::PrimitiveTValue>() && b.m_ptr->isa<lite::PrimitiveTValue>()) {\n",
        "    auto a_value_node_ptr = a.m_ptr->cast<PrimitiveTValuePtr>();\n",
        "    auto b_value_node_ptr = b.m_ptr->cast<PrimitiveTValuePtr>();\n",
        "    return a_value_node_ptr->GetPrimitiveT()->value.type == b_value_node_ptr->GetPrimitiveT()->value.type;\n",
        "  }\n",
        "\n",
        "  return a == b;\n",
        "}\n",
        "\n",
        "bool CNodeTypeEqual(const BaseRef &a, const BaseRef &b) {\n",
        "  // To matchCNode and Kernel's type\n",
        "  if (utils::isa<CNode>(a) && utils::isa<CNode>(b)) {\n",
        "    return true;\n",
        "  }\n",
        "  return a.type() == b.type();\n",
        "}\n",
        "\n",
        "AnfNodePtr SexpToNode(const BaseRef &sexp, const BaseRef &graph, PrimitiveVarMap *primitive_vars, bool multigraph) {\n",
        "  MS_LOG(DEBUG) << \"SexpToNode sexp: \" + sexp.ToString() + \", graph \" + graph.ToString();\n",
        "  MS_EXCEPTION_IF_NULL(primitive_vars);\n",
        "  if (utils::isa<VectorRef>(sexp)) {\n",
        "    return HandleSexpVector(sexp, graph, primitive_vars, multigraph);\n",
        "  }\n",
        "  if (utils::isa<VarPtr>(sexp)) {\n",
        "    auto var_ptr = utils::cast<VarPtr>(sexp);\n",
        "    MS_EXCEPTION_IF_NULL(var_ptr);\n",
        "    if (var_ptr->primitive()) {\n",
        "      (*primitive_vars)[var_ptr->primitive()] = var_ptr;\n",
        "      return NewValueNode(var_ptr->primitive());\n",
        "    }\n",
        "    return CreateVarNodeWithSexp(sexp, graph);\n",
        "  }\n",
        "  if (utils::isa<AnfNodePtr>(sexp)) {\n",
        "    return utils::cast<AnfNodePtr>(sexp);\n",
        "  }\n",
        "  auto value_node = CreateValueNodeWithSexp(sexp);\n",
        "  if (value_node == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"sexp cannot converted. sexp: \" + sexp.ToString();\n",
        "  }\n",
        "  return value_node;\n",
        "}\n",
        "\n",
        "bool IsRealCNodeKernel(const AnfNodePtr &node) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  // parameter and value node is not a real cnode kernel\n",
        "  if (!node->isa<CNode>()) {\n",
        "    return false;\n",
        "  }\n",
        "  // return considered as a real node\n",
        "  if (CheckPrimitiveType(node, prim::kPrimReturn)) {\n",
        "    return true;\n",
        "  }\n",
        "  return IsRealKernel(node);\n",
        "}\n",
        "bool IsGraphKernel(const AnfNodePtr &node) {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  // graph kernel should be a real cnode kernel.\n",
        "  if (!IsRealCNodeKernel(node)) {\n",
        "    return false;\n",
        "  }\n",
        "\n",
        "  auto cnode = node->cast<CNodePtr>();\n",
        "  MS_EXCEPTION_IF_NULL(cnode);\n",
        "  auto input = cnode->input(kAnfPrimitiveIndex);\n",
        "  // graph kernel should has func_graph as first input.\n",
        "  if (!IsValueNode<FuncGraph>(input)) {\n",
        "    return false;\n",
        "  }\n",
        "\n",
        "  auto func_graph = GetValueNode<FuncGraphPtr>(input);\n",
        "  MS_EXCEPTION_IF_NULL(func_graph);\n",
        "  return func_graph->has_attr(FUNC_GRAPH_ATTR_GRAPH_KERNEL);\n",
        "}\n",
        "\n",
        "void CheckIfFuncGraphIsNull(const FuncGraphPtr &graph) {\n",
        "  if (graph == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"The graph is null.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckIfAnfNodeIsNull(const AnfNodePtr &node) {\n",
        "  if (node == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"The AnfNode is null.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckIfCNodeIsNull(const CNodePtr &node) {\n",
        "  if (node == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"The CNode is null.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckIfVarIsNull(const VarPtr &var) {\n",
        "  if (var == nullptr) {\n",
        "    MS_LOG(EXCEPTION) << \"The Var is null.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckIfNodeIsParam(const AnfNodePtr &node) {\n",
        "  if (node != nullptr && !utils::isa<ParameterPtr>(node)) {\n",
        "    MS_LOG(EXCEPTION) << \"The Node is not param.\";\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckInputSize(const CNodePtr &node, const int size) {\n",
        "  if (node->inputs().size() != size) {\n",
        "    MS_LOG(EXCEPTION) << \"The input size of node must be \" << size << \", but it is\" << node->inputs().size();\n",
        "  }\n",
        "}\n",
        "\n",
        "void CheckLeastInputSize(const CNodePtr &node, const int size) {\n",
        "  if (node->inputs().size() < size) {\n",
        "    MS_LOG(EXCEPTION) << \"The input size of node must be \" << size << \", but it is\" << node->inputs().size();\n",
        "  }\n",
        "}\n",
        "\n",
        "AnfNodePtr AddNewBiasNode(float *bias_data, const FuncGraphPtr &func_graph, int kernel_num,\n",
        "                          const ParamValueLitePtr &weight_tensor) {\n",
        "  auto bias_parameter = func_graph->add_parameter();\n",
        "  MS_ASSERT(bias_parameter != nullptr);\n",
        "  std::vector<int> shape = {kernel_num};\n",
        "  auto abstract_tensor = std::make_shared<abstract::AbstractTensor>(TypeIdToType(weight_tensor->tensor_type()), shape);\n",
        "  bias_parameter->set_abstract(abstract_tensor);\n",
        "\n",
        "  ParamValueLitePtr param_value = std::make_shared<ParamValueLite>();\n",
        "  MS_ASSERT(param_value != nullptr);\n",
        "  param_value->set_tensor_addr(bias_data);\n",
        "  param_value->set_tensor_size(kernel_num * sizeof(float) / sizeof(uint8_t));\n",
        "  bias_parameter->set_default_param(param_value);\n",
        "  return bias_parameter;\n",
        "}\n",
        "\n",
        "schema::PrimitiveType GetCNodeType(const BaseRef &n) {\n",
        "  ValueNodePtr value_node;\n",
        "  if (utils::isa<CNodePtr>(n)) {\n",
        "    auto in = utils::cast<CNodePtr>(n);\n",
        "    value_node = in->input(0)->cast<ValueNodePtr>();\n",
        "  } else if (utils::isa<ValueNodePtr>(n)) {\n",
        "    value_node = utils::cast<ValueNodePtr>(n);\n",
        "  } else {\n",
        "    MS_LOG(EXCEPTION) << \"only value node or cnode has type\";\n",
        "    return schema::PrimitiveType_NONE;\n",
        "  }\n",
        "  MS_EXCEPTION_IF_NULL(value_node);\n",
        "  auto value = value_node->value();\n",
        "  MS_ASSERT(value != nullptr);\n",
        "  if (utils::isa<PrimitiveTValuePtr>(value)) {\n",
        "    auto primitive = value->cast<PrimitiveTValuePtr>();\n",
        "    MS_ASSERT(primitive != nullptr);\n",
        "    return primitive->GetPrimitiveT()->value.type;\n",
        "  }\n",
        "  return schema::PrimitiveType_NONE;\n",
        "}\n",
        "\n",
        "bool IsParamNode(const BaseRef &n) {\n",
        "  return utils::isa<ParameterPtr>(n);\n",
        "}\n",
        "\n",
        "bool IsConvNode(const BaseRef &n) {\n",
        "  if (utils::isa<CNodePtr>(n) || utils::isa<ValueNodePtr>(n)) {\n",
        "    auto type = opt::GetCNodeType(n);\n",
        "    return type == schema::PrimitiveType_Conv2D || type == schema::PrimitiveType_DepthwiseConv2D;\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBumO_XUj09K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "\n",
        "#ifndef MINDSPORE_LITE_SRC_PASS_COMMON_UTILS_H_\n",
        "#define MINDSPORE_LITE_SRC_PASS_COMMON_UTILS_H_\n",
        "\n",
        "#include <mindspore/lite/src/ir/primitive_t_value.h>\n",
        "#include <memory>\n",
        "#include \"ir/anf.h\"\n",
        "#include \"ir/func_graph.h\"\n",
        "#include \"src/common/utils.h\"\n",
        "#include \"mindspore/ccsrc/backend/optimizer/common/pattern_engine.h\"\n",
        "#include \"schema/inner/model_generated.h\"\n",
        "#include \"src/param_value_lite.h\"\n",
        "\n",
        "using PrimitiveTValuePtr = std::shared_ptr<mindspore::lite::PrimitiveTValue>;\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "\n",
        "bool AnfEqual(const BaseRef &a, const BaseRef &b);\n",
        "\n",
        "bool CNodeTypeEqual(const BaseRef &a, const BaseRef &b);\n",
        "\n",
        "AnfNodePtr SexpToNode(const BaseRef &sexp, const BaseRef &graph, PrimitiveVarMap *primitive_vars,\n",
        "                      bool multigraph = false);\n",
        "\n",
        "bool IsGraphKernel(const AnfNodePtr &node);\n",
        "\n",
        "bool IsRealCNodeKernel(const AnfNodePtr &node);\n",
        "\n",
        "void CheckIfFuncGraphIsNull(const FuncGraphPtr &graph);\n",
        "\n",
        "void CheckIfAnfNodeIsNull(const AnfNodePtr &node);\n",
        "\n",
        "void CheckIfCNodeIsNull(const CNodePtr &node);\n",
        "\n",
        "void CheckIfVarIsNull(const VarPtr &var);\n",
        "\n",
        "void CheckInputSize(const CNodePtr &node, int size);\n",
        "\n",
        "void CheckIfNodeIsParam(const AnfNodePtr &node);\n",
        "\n",
        "void CheckLeastInputSize(const CNodePtr &node, int size);\n",
        "\n",
        "AnfNodePtr AddNewBiasNode(float *bias_data, const FuncGraphPtr &func_graph, int kernel_num,\n",
        "                          const ParamValueLitePtr &weight_tensor);\n",
        "\n",
        "schema::PrimitiveType GetCNodeType(const BaseRef &node);\n",
        "\n",
        "bool IsParamNode(const BaseRef &n);\n",
        "\n",
        "bool IsConvNode(const BaseRef &n);\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n",
        "#endif  // MINDSPORE_LITE_SRC_PASS_COMMON_UTILS_H_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1s4Aj0Mkmwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include \"mindspore/ccsrc/backend/optimizer/common/node_pass.h\"\n",
        "\n",
        "#include <unordered_set>\n",
        "#include <deque>\n",
        "#include <algorithm>\n",
        "\n",
        "#include \"ir/anf.h\"\n",
        "#include \"ir/func_graph.h\"\n",
        "#include \"ir/manager.h\"\n",
        "#include \"mindspore/lite/src/gllo/common/gllo_utils.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "bool NodePass::Run(const FuncGraphPtr &func_graph) {\n",
        "  MS_EXCEPTION_IF_NULL(func_graph);\n",
        "  FuncGraphManagerPtr manager = func_graph->manager();\n",
        "  MS_EXCEPTION_IF_NULL(manager);\n",
        "  manager->AddFuncGraph(func_graph);\n",
        "\n",
        "  std::unordered_set<AnfNodePtr> seen_node;\n",
        "  std::deque<AnfNodePtr> todo{func_graph->output()};\n",
        "  bool changes = false;\n",
        "  while (!todo.empty()) {\n",
        "    AnfNodePtr node = todo.front();\n",
        "    todo.pop_front();\n",
        "    if (seen_node.count(node) > 0 || !manager->all_nodes().contains(node)) {\n",
        "      continue;\n",
        "    }\n",
        "    (void)seen_node.insert(node);\n",
        "    AnfNodePtr new_node = Run(func_graph, node);\n",
        "    bool change = (new_node != nullptr);\n",
        "    if (new_node != nullptr && new_node != node) {\n",
        "      (void)manager->Replace(node, new_node);\n",
        "      (void)seen_node.erase(node);\n",
        "    } else if (new_node == nullptr) {\n",
        "      new_node = node;\n",
        "    }\n",
        "    if (new_node && IsValueNode<FuncGraph>(new_node)) {\n",
        "      auto const_func_graph = GetValueNode<FuncGraphPtr>(new_node);\n",
        "      MS_EXCEPTION_IF_NULL(const_func_graph);\n",
        "      todo.push_back(const_func_graph->output());\n",
        "    } else if (new_node && new_node->isa<CNode>()) {\n",
        "      if (IsGraphKernel(new_node)) {\n",
        "        todo.push_back(new_node);\n",
        "      }\n",
        "      auto cnode = new_node->cast<CNodePtr>();\n",
        "      MS_EXCEPTION_IF_NULL(cnode);\n",
        "      auto inputs = cnode->inputs();\n",
        "      (void)todo.insert(todo.end(), inputs.begin(), inputs.end());\n",
        "    }\n",
        "    changes = changes || change;\n",
        "  }\n",
        "  return changes;\n",
        "}\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ8_xO2LkrX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include \"src/gllo/common/optimizer.h\"\n",
        "\n",
        "#include <functional>\n",
        "#include <memory>\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <algorithm>\n",
        "#include <utility>\n",
        "#include <initializer_list>\n",
        "\n",
        "#include \"mindspore/ccsrc/backend/optimizer/common/pass_manager.h\"\n",
        "#include \"ir/manager.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "PatternProcessPass::PatternProcessPass(const std::string &name, bool multigraph)\n",
        "    : NodePass(name),\n",
        "      multigraph_(multigraph),\n",
        "      pattern_engine_(PatternEngine(std::make_shared<DefaultVisitor>(),\n",
        "                                    std::function<bool(const BaseRef &, const BaseRef &)>(AnfEqual),\n",
        "                                    std::function<bool(const BaseRef &, const BaseRef &)>(CNodeTypeEqual))),\n",
        "      primitive_vars_(std::make_shared<PrimitiveVarMap>()) {}\n",
        "\n",
        "const BaseRef PatternProcessPass::DefinePattern() const {\n",
        "  VarPtr X = std::make_shared<Var>();\n",
        "  return BaseRef({X});\n",
        "}\n",
        "\n",
        "void PatternProcessPass::Build() {\n",
        "  VarPtr fg = std::make_shared<Var>(\"RootG\");\n",
        "  BaseRef pattern = std::move(DefinePattern());\n",
        "  pattern_ = SexpToNode(pattern, fg, primitive_vars_.get(), multigraph_);\n",
        "}\n",
        "\n",
        "AnfNodePtr PatternProcessPass::Run(const FuncGraphPtr &func_graph, const AnfNodePtr &node) {\n",
        "  if (pattern_ == nullptr) {\n",
        "    Build();\n",
        "  }\n",
        "\n",
        "  auto empty_equiv = std::make_shared<Equiv>();\n",
        "  MS_EXCEPTION_IF_NULL(primitive_vars_);\n",
        "  EquivPtr equiv = pattern_engine_.Match(pattern_, node, *primitive_vars_, empty_equiv);\n",
        "  if (equiv != nullptr && !equiv->empty()) {\n",
        "    return Process(func_graph, node, equiv);\n",
        "  }\n",
        "  return nullptr;\n",
        "}\n",
        "\n",
        "bool MultipleOutputPatternProcessPass::MatchAnotherPattern(const AnfNodePtr &node, const EquivPtr &equiv) const {\n",
        "  MS_EXCEPTION_IF_NULL(node);\n",
        "  MS_EXCEPTION_IF_NULL(equiv);\n",
        "  VarPtr fg = std::make_shared<Var>(\"RootG\");\n",
        "  auto empty_equiv = std::make_shared<Equiv>();\n",
        "  MS_EXCEPTION_IF_NULL(child_primitive_vars_);\n",
        "  EquivPtr another_equiv =\n",
        "    child_pattern_engine_.Match(SexpToNode(DefineAnotherPattern(), fg, child_primitive_vars_.get(), true), node,\n",
        "                                *child_primitive_vars_, empty_equiv);\n",
        "  if (another_equiv != nullptr && !another_equiv->empty()) {\n",
        "    return IsShareNodes(equiv, another_equiv);\n",
        "  }\n",
        "  return false;\n",
        "}\n",
        "\n",
        "void GraphOptimizer::AddPassManager(const PassManagerPtr &pass_manager) {\n",
        "  if (pass_manager != nullptr) {\n",
        "    pass_managers_.push_back(pass_manager);\n",
        "  }\n",
        "}\n",
        "\n",
        "FuncGraphPtr GraphOptimizer::Optimize(const FuncGraphPtr &func_graph, bool run_only_once) {\n",
        "  MS_EXCEPTION_IF_NULL(func_graph);\n",
        "  run_only_once_ = (pass_managers_.size() == 1) ? true : run_only_once;\n",
        "  auto manager = func_graph->manager();\n",
        "  if (manager == nullptr) {\n",
        "    manager = Manage(func_graph, false);\n",
        "    func_graph->set_manager(manager);\n",
        "  }\n",
        "\n",
        "  bool changed = true;\n",
        "  while (changed) {\n",
        "    changed = false;\n",
        "    for (size_t i = 0; i < pass_managers_.size(); ++i) {\n",
        "      const PassManagerPtr &pm = pass_managers_[i];\n",
        "      if (pm != nullptr && pm->Run(func_graph)) {\n",
        "        changed = true;\n",
        "      }\n",
        "    }\n",
        "    if (run_only_once_) {\n",
        "      break;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  std::vector<FuncGraphPtr> func_graphs;\n",
        "  func_graphs.push_back(func_graph);\n",
        "  manager->KeepRoots(func_graphs);\n",
        "  (void)TopoSort(func_graph->get_return());\n",
        "  return func_graph;\n",
        "}\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ENze3D0ktx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#ifndef MINDSPORE_LITE_SRC_PASS_COMMON_OPTIMIZER_H_\n",
        "#define MINDSPORE_LITE_SRC_PASS_COMMON_OPTIMIZER_H_\n",
        "\n",
        "#include <memory>\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <unordered_map>\n",
        "\n",
        "#include \"ir/anf.h\"\n",
        "#include \"ir/func_graph.h\"\n",
        "#include \"ir/graph_utils.h\"\n",
        "#include \"src/common/utils.h\"\n",
        "\n",
        "#include \"mindspore/ccsrc/backend/optimizer/common/pass_manager.h\"\n",
        "#include \"mindspore/ccsrc/backend/optimizer/common/pattern_engine.h\"\n",
        "#include \"mindspore/lite/src/gllo/common/gllo_utils.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "using PatternListType = std::initializer_list<BaseRef>;\n",
        "\n",
        "class PatternProcessPass : public NodePass {\n",
        " public:\n",
        "  explicit PatternProcessPass(const std::string &name = \"\", bool multigraph = true);\n",
        "  ~PatternProcessPass() override = default;\n",
        "  virtual const AnfNodePtr Process(const FuncGraphPtr &, const AnfNodePtr &, const EquivPtr &) const = 0;\n",
        "  virtual const BaseRef DefinePattern() const;\n",
        "  AnfNodePtr Run(const FuncGraphPtr &func_graph, const AnfNodePtr &node) override;\n",
        "\n",
        " private:\n",
        "  void Build();\n",
        "\n",
        "  AnfNodePtr pattern_ = nullptr;\n",
        "  bool multigraph_ = true;\n",
        "  PatternEngine pattern_engine_;\n",
        "  PrimitiveVarMapPtr primitive_vars_;\n",
        "};\n",
        "\n",
        "class MultipleOutputPatternProcessPass : public PatternProcessPass {\n",
        " public:\n",
        "  explicit MultipleOutputPatternProcessPass(const std::string &name = \"\", bool multigraph = true)\n",
        "      : PatternProcessPass(name, multigraph),\n",
        "        child_pattern_engine_(PatternEngine(std::make_shared<DefaultVisitor>(),\n",
        "                                            std::function<bool(const BaseRef &, const BaseRef &)>(AnfEqual),\n",
        "                                            std::function<bool(const BaseRef &, const BaseRef &)>(CNodeTypeEqual))),\n",
        "        child_primitive_vars_(std::make_shared<PrimitiveVarMap>()) {}\n",
        "  ~MultipleOutputPatternProcessPass() override = default;\n",
        "  virtual BaseRef DefineAnotherPattern() const = 0;\n",
        "  // check two patterns whether share the same nodes or not\n",
        "  virtual bool IsShareNodes(const EquivPtr &equiv1, const EquivPtr &equiv2) const = 0;\n",
        "\n",
        " protected:\n",
        "  bool MatchAnotherPattern(const AnfNodePtr &node, const EquivPtr &equiv) const;\n",
        "  PatternEngine child_pattern_engine_;\n",
        "  PrimitiveVarMapPtr child_primitive_vars_;\n",
        "};\n",
        "\n",
        "class GraphOptimizer {\n",
        " public:\n",
        "  explicit GraphOptimizer(const std::string &name = \"graph_optimizer\") : name_(name) {}\n",
        "  virtual ~GraphOptimizer() = default;\n",
        "\n",
        "  void AddPassManager(const PassManagerPtr &pass_manager);\n",
        "  FuncGraphPtr Optimize(const FuncGraphPtr &func_graph, bool run_only_once = true);\n",
        "\n",
        " private:\n",
        "  const std::string name_ = \"graph_optimizer\";\n",
        "  std::vector<PassManagerPtr> pass_managers_{};\n",
        "  bool run_only_once_ = true;\n",
        "};\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n",
        "\n",
        "#endif  // MINDSPORE_LITE_SRC_PASS_COMMON_OPTIMIZER_H_\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_T_8aaLkwAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/**\n",
        " * Copyright 2020 Huawei Technologies Co., Ltd\n",
        " *\n",
        " * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        " * you may not use this file except in compliance with the License.\n",
        " * You may obtain a copy of the License at\n",
        " *\n",
        " * http://www.apache.org/licenses/LICENSE-2.0\n",
        " *\n",
        " * Unless required by applicable law or agreed to in writing, software\n",
        " * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " * See the License for the specific language governing permissions and\n",
        " * limitations under the License.\n",
        " */\n",
        "#include \"mindspore/ccsrc/backend/optimizer/common/pass_manager.h\"\n",
        "\n",
        "#include <sys/time.h>\n",
        "#include <unordered_set>\n",
        "#include <deque>\n",
        "#include <string>\n",
        "#include <algorithm>\n",
        "\n",
        "#include \"ir/anf.h\"\n",
        "#include \"ir/func_graph.h\"\n",
        "#include \"ir/manager.h\"\n",
        "#include \"utils/utils.h\"\n",
        "\n",
        "namespace mindspore {\n",
        "namespace opt {\n",
        "const std::vector<PassPtr> &PassManager::Passes() const { return passes_; }\n",
        "\n",
        "void PassManager::AddPass(const PassPtr &pass) {\n",
        "  if (pass != nullptr) {\n",
        "    passes_.push_back(pass);\n",
        "  }\n",
        "}\n",
        "\n",
        "bool PassManager::Run(const FuncGraphPtr &func_graph, const std::vector<PassPtr> &passes) const {\n",
        "  if (func_graph == nullptr) {\n",
        "    return false;\n",
        "  }\n",
        "  bool changed = false;\n",
        "  size_t num = 0;\n",
        "  for (const auto &pass : passes) {\n",
        "    if (pass != nullptr) {\n",
        "#if defined(_WIN32) || defined(_WIN64)\n",
        "      auto start_time = std::chrono::steady_clock::now();\n",
        "#else\n",
        "      struct timeval start_time {};\n",
        "      struct timeval end_time {};\n",
        "      (void)gettimeofday(&start_time, nullptr);\n",
        "#endif\n",
        "      if (pass->Run(func_graph)) {\n",
        "        MS_LOG(DEBUG) << \"Run pass and find change\";\n",
        "        changed = true;\n",
        "      }\n",
        "#if defined(_WIN32) || defined(_WIN64)\n",
        "      auto end_time = std::chrono::steady_clock::now();\n",
        "      std::chrono::duration<double, std::ratio<1, 1000000>> cost = end_time - start_time;\n",
        "      MS_LOG(INFO) << \"Run pass hwopt_\" + name() + \"_\" << num << \"_\" + pass->name() + \" in \" << cost.count() << \" us\";\n",
        "#else\n",
        "      (void)gettimeofday(&end_time, nullptr);\n",
        "      const uint64_t kUSecondInSecond = 1000000;\n",
        "      uint64_t cost = kUSecondInSecond * static_cast<uint64_t>(end_time.tv_sec - start_time.tv_sec);\n",
        "      cost += static_cast<uint64_t>(end_time.tv_usec - start_time.tv_usec);\n",
        "      MS_LOG(INFO) << \"Run pass hwopt_\" + name() + \"_\" << num << \"_\" + pass->name() + \" in \" << cost << \" us\";\n",
        "#endif\n",
        "      num++;\n",
        "    }\n",
        "  }\n",
        "  return changed;\n",
        "}\n",
        "\n",
        "bool PassManager::Run(const FuncGraphPtr &func_graph) const {\n",
        "  bool changed = false;\n",
        "  // run all passes\n",
        "  bool change = true;\n",
        "  while (change) {\n",
        "    change = Run(func_graph, passes_);\n",
        "    changed = change || changed;\n",
        "    if (run_only_once_) {\n",
        "      break;\n",
        "    }\n",
        "  }\n",
        "  return changed;\n",
        "}\n",
        "}  // namespace opt\n",
        "}  // namespace mindspore\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehNC95DRu3EL",
        "colab_type": "text"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqDrsrE2u1oI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run():\n",
        "    device = xm.xla_device()\n",
        "    model = MX.to(device)\n",
        "\n",
        "    train_dataset = TweetDataset(\n",
        "        tweet=df_train.text.values,\n",
        "        sentiment=df_train.sentiment.values,\n",
        "        selected_text=df_train.selected_text.values\n",
        "    )\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "      train_dataset,\n",
        "      num_replicas=xm.xrt_world_size(),\n",
        "      rank=xm.get_ordinal(),\n",
        "      shuffle=True\n",
        "    )\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.TRAIN_BATCH_SIZE,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    valid_dataset = TweetDataset(\n",
        "        tweet=df_valid.text.values,\n",
        "        sentiment=df_valid.sentiment.values,\n",
        "        selected_text=df_valid.selected_text.values\n",
        "    )\n",
        "\n",
        "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "      valid_dataset,\n",
        "      num_replicas=xm.xrt_world_size(),\n",
        "      rank=xm.get_ordinal(),\n",
        "      shuffle=False\n",
        "    )\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        sampler=valid_sampler,\n",
        "        drop_last=False,\n",
        "        num_workers=1\n",
        "    )\n",
        "\n",
        "    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\n",
        "        \"bias\",\n",
        "        \"LayerNorm.bias\",\n",
        "        \"LayerNorm.weight\"\n",
        "    ]\n",
        "    optimizer_parameters = [\n",
        "        {\n",
        "            'params': [\n",
        "                p for n, p in param_optimizer if not any(\n",
        "                    nd in n for nd in no_decay\n",
        "                )\n",
        "            ], \n",
        "         'weight_decay': 0.001\n",
        "        },\n",
        "        {\n",
        "            'params': [\n",
        "                p for n, p in param_optimizer if any(\n",
        "                    nd in n for nd in no_decay\n",
        "                )\n",
        "            ], \n",
        "            'weight_decay': 0.0\n",
        "        },\n",
        "    ]\n",
        "    num_train_steps = int(\n",
        "        len(df_train) / config.TRAIN_BATCH_SIZE / xm.xrt_world_size() * config.EPOCHS\n",
        "    )\n",
        "    optimizer = AdamW(\n",
        "        optimizer_parameters, \n",
        "        lr=config.LEARNING_RATE * xm.xrt_world_size()\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_jac = 0\n",
        "    es = EarlyStopping(patience=2, mode=\"max\")\n",
        "    num_batches = int(len(df_train) / (config.TRAIN_BATCH_SIZE * xm.xrt_world_size()))\n",
        "    \n",
        "    xm.master_print(\"Training is Starting....\")\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
        "        train_fn(\n",
        "            para_loader.per_device_loader(device), \n",
        "            model, \n",
        "            optimizer, \n",
        "            device,\n",
        "            num_batches,\n",
        "            scheduler\n",
        "        )\n",
        "\n",
        "        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
        "        jac = eval_fn(\n",
        "            para_loader.per_device_loader(device), \n",
        "            model, \n",
        "            device\n",
        "        )\n",
        "        jac = xm.mesh_reduce('jac_reduce', jac, reduce_fn)\n",
        "        xm.master_print(f'Epoch={epoch}, Jaccard={jac}')\n",
        "        if jac > best_jac:\n",
        "            xm.master_print(\"Model Improved!!! Saving Model\")\n",
        "            xm.save(model.state_dict(), f\"model_{config.FOLD}.bin\")\n",
        "            best_jac = jac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHlyHRTVvEwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _mp_fn(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    a = run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99O6yUgLvHgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "18a4343c030b4371b899e99d4f8c513c",
            "97212f9b24d549d08e65ef631c788e5e",
            "2c9b0b798db64f1298760c85a57f097c",
            "e3fe3c2345634b088bff27a09a10b640",
            "33c8818e4b764cdcba3e4b6f52f1dbea",
            "94e37f508ab34e898ec927961919de34",
            "49f8aa1ae9f84e4b9a2c5177bc74ea4b",
            "c95bbed6e4ba46b18898146970ea9de6"
          ]
        },
        "outputId": "30bc90da-0640-45d1-8873-5724f16c8935"
      },
      "source": [
        "FLAGS={}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training is Starting....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18a4343c030b4371b899e99d4f8c513c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Training', max=171.0, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}