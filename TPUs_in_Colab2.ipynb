{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEXiYVE2eqpL"
      },
      "source": [
        "From a3e00c43755bcd21fe29ab730b0c5e7d47d147c5 Mon Sep 17 00:00:00 2001\n",
        "From: guohongzilong <guohongzilong@huawei.com>\n",
        "Date: Sat, 3 Apr 2021 19:10:22 +0800\n",
        "Subject: [PATCH] modify code structure\n",
        "\n",
        "---\n",
        " .../main/java/com/huawei/flclient/LiteTrain.java   | 119 ++---\n",
        " .../main/java/com/huawei/flclient/NativeTrain.java |  46 ++\n",
        " .../lite/flclient/src/main/native/CMakeLists.txt   |  18 +-\n",
        " .../lite/flclient/src/main/native/bert_train.cpp   | 197 ++++++++\n",
        " .../lite/flclient/src/main/native/bert_train.h     |  26 ++\n",
        " .../lite/flclient/src/main/native/data_prepare.cpp | 517 ---------------------\n",
        " .../src/main/native/dataset/data_prepare.cpp       | 517 +++++++++++++++++++++\n",
        " .../lite/flclient/src/main/native/lenet_train.cpp  | 167 +++++++\n",
        " .../lite/flclient/src/main/native/lenet_train.h    |  27 ++\n",
        " .../lite/flclient/src/main/native/lite_train.cpp   | 287 ------------\n",
        " .../lite/flclient/src/main/native/lite_train.h     |  35 --\n",
        " .../flclient/src/main/native/lite_train_jni.cpp    | 131 ++++--\n",
        " mindspore/lite/flclient/src/main/native/util.cpp   | 100 ++++\n",
        " mindspore/lite/flclient/src/main/native/util.h     |  33 ++\n",
        " 14 files changed, 1257 insertions(+), 963 deletions(-)\n",
        " create mode 100644 mindspore/lite/flclient/src/main/java/com/huawei/flclient/NativeTrain.java\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/bert_train.cpp\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/bert_train.h\n",
        " delete mode 100644 mindspore/lite/flclient/src/main/native/data_prepare.cpp\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/dataset/data_prepare.cpp\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/lenet_train.cpp\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/lenet_train.h\n",
        " delete mode 100644 mindspore/lite/flclient/src/main/native/lite_train.cpp\n",
        " delete mode 100644 mindspore/lite/flclient/src/main/native/lite_train.h\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/util.cpp\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/util.h\n",
        "\n",
        "diff --git a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "index 5f9a8de..6c8cfd2 100644\n",
        "--- a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "+++ b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "@@ -1,21 +1,6 @@\n",
        "-/**\n",
        "- * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "- * <p>\n",
        "- * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "- * you may not use this file except in compliance with the License.\n",
        "- * You may obtain a copy of the License at\n",
        "- * <p>\n",
        "- * http://www.apache.org/licenses/LICENSE-2.0\n",
        "- * <p>\n",
        "- * Unless required by applicable law or agreed to in writing, software\n",
        "- * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "- * See the License for the specific language governing permissions and\n",
        "- * limitations under the License.\n",
        "- */\n",
        "-\n",
        " package com.huawei.flclient;\n",
        " \n",
        "+\n",
        " import com.google.flatbuffers.FlatBufferBuilder;\n",
        " import mindspore.schema.FeatureMap;\n",
        " import mindspore.schema.FeatureMapList;\n",
        "@@ -27,15 +12,13 @@ import java.util.Iterator;\n",
        " import java.util.Map;\n",
        " import java.util.TreeMap;\n",
        " \n",
        "-public  class LiteTrain {\n",
        "-    static {\n",
        "-        System.loadLibrary(\"fl\");\n",
        "-    }\n",
        "-    private static HashMap featureMaps;\n",
        "+public class LiteTrain {\n",
        "     private static LiteTrain train;\n",
        "+    private long sessionPtr;\n",
        " \n",
        "-    private LiteTrain() {\n",
        "+    private LenetTrain() {\n",
        "     }\n",
        "+\n",
        "     public static synchronized LiteTrain getInstance() {\n",
        "         if (train == null) {\n",
        "             train = new LiteTrain();\n",
        "@@ -43,9 +26,9 @@ public  class LiteTrain {\n",
        "         return train;\n",
        "     }\n",
        " \n",
        "-    public FlatBufferBuilder FeatureMapBuilder(String modelName){\n",
        "+    public FlatBufferBuilder FeatureMapBuilder(String modelName) {\n",
        "         FlatBufferBuilder builder = new FlatBufferBuilder();\n",
        "-        int[] fmOffsets = getSeralizeFeaturesMap(modelName,builder);\n",
        "+        int[] fmOffsets = getSeralizeFeaturesMap(builder);\n",
        "         int fmOffset = FeatureMapList.createFeatureMapVector(builder, fmOffsets);\n",
        "         RequestUpdateModel.startRequestUpdateModel(builder);\n",
        "         RequestUpdateModel.addFlName(builder, 0);\n",
        "@@ -86,60 +69,42 @@ public  class LiteTrain {\n",
        "         }\n",
        "         return map;\n",
        "     }\n",
        "+    // todo add msconfig\n",
        "+    public int init(String modelPath) {\n",
        "+         sessionPtr = NativeTrain.createSession(modelPath,0L);\n",
        "+         return 0;\n",
        "+    }\n",
        " \n",
        "+    public int setInput(String fileSet) {\n",
        "+        return NativeTrain.setInput(fileSet);\n",
        "+    }\n",
        "+\n",
        "+    public int train(int batch_size,int epoches, int earlyStopMod) {\n",
        "+        return NativeTrain.train(sessionPtr, epoches, earlyStopMod);\n",
        "+    }\n",
        "+\n",
        "+    public float infer() {\n",
        "+        return NativeTrain.infer(sessionPtr);\n",
        "+    }\n",
        " \n",
        "+    public int[] getInferLabels() {\n",
        "+        return NativeTrain.getInferLables(sessionPtr);\n",
        "+    }\n",
        "+\n",
        "+    public Map<String, float[]> getFeaturesMap() {\n",
        "+        return NativeTrain.getFeaturesMap(sessionPtr);\n",
        "+    }\n",
        "+\n",
        "+    public int[] getSeralizeFeaturesMap(FlatBufferBuilder builder) {\n",
        "+        return NativeTrain.getSeralizeFeaturesMap(sessionPtr, builder);\n",
        "+    }\n",
        "+\n",
        "+    public int updateFeatures(ArrayList<FeatureMap> featureMaps) {\n",
        "+        return NativeTrain.updateFeatures(sessionPtr, featureMaps);\n",
        "+    }\n",
        "+\n",
        "+    public int free() {\n",
        "+        return NativeTrain.free(sessionPtr);\n",
        "+    }\n",
        " \n",
        "-    /**\n",
        "-     * set the Inference set or Train set\n",
        "-     *\n",
        "-     * @param fileSet   input binary file path which format is NHWC\n",
        "-     * @param batch_num binary file batch num\n",
        "-     * @return\n",
        "-     */\n",
        "-    native int setInput(String fileSet, int batch_num);\n",
        "-\n",
        "-    /**\n",
        "-     * inference\n",
        "-     *\n",
        "-     * @return status\n",
        "-     */\n",
        "-    public native float inference(String modelName,int batch_num);\n",
        "-\n",
        "-    /**\n",
        "-     * train\n",
        "-     *\n",
        "-     * @return status\n",
        "-     */\n",
        "-    public native int train(String modelName, int batch_num,int iterations);\n",
        "-\n",
        "-    /**\n",
        "-     * get the features map of training model\n",
        "-     *\n",
        "-     * @param builder FlatBufferBuilder\n",
        "-     * @return features offset\n",
        "-     */\n",
        "-   native int[] getSeralizeFeaturesMap(String modelName, FlatBufferBuilder builder);\n",
        "-\n",
        "-         /**\n",
        "-             * get the features map of training model\n",
        "-             *\n",
        "-             * @param modelName model name\n",
        "-             * @return features map\n",
        "-             */\n",
        "-   native Map<String,float[]> getFeaturesMap(String modelName);\n",
        "-\n",
        "-    /**\n",
        "-     * update the features map of training model\n",
        "-     *\n",
        "-     * @param featureMaps\n",
        "-     * @return status\n",
        "-     */\n",
        "-    native int updateFeatures(String modelName,ArrayList<FeatureMap> featureMaps);\n",
        "-\n",
        "-    /**\n",
        "-     * free Inference or Train runtime memory resource\n",
        "-     *\n",
        "-     * @return status\n",
        "-     */\n",
        "-    native int free();\n",
        " }\n",
        "diff --git a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/NativeTrain.java b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/NativeTrain.java\n",
        "new file mode 100644\n",
        "index 0000000..b0dc4d0\n",
        "--- /dev/null\n",
        "+++ b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/NativeTrain.java\n",
        "@@ -0,0 +1,46 @@\n",
        "+/**\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "+ * <p>\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "+ * you may not use this file except in compliance with the License.\n",
        "+ * You may obtain a copy of the License at\n",
        "+ * <p>\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\n",
        "+ * <p>\n",
        "+ * Unless required by applicable law or agreed to in writing, software\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "+ * See the License for the specific language governing permissions and\n",
        "+ * limitations under the License.\n",
        "+ */\n",
        "+\n",
        "+package com.huawei.flclient;\n",
        "+\n",
        "+import com.google.flatbuffers.FlatBufferBuilder;\n",
        "+import mindspore.schema.FeatureMap;\n",
        "+import java.util.ArrayList;\n",
        "+import java.util.Map;\n",
        "+\n",
        "+public  class NativeTrain {\n",
        "+    static {\n",
        "+        System.loadLibrary(\"fl\");\n",
        "+    }\n",
        "+\n",
        "+    static native int setInput(String fileSet);\n",
        "+\n",
        "+    static native long createSession(String modelPath,long msConfigPtr);\n",
        "+\n",
        "+    static native float infer(long sessionPtr);\n",
        "+\n",
        "+    static native int[]  getInferLables(long sessionPtr);\n",
        "+\n",
        "+    static native int train(long sessionPtr,int batch_size,int epoches,int earlyStopMod);\n",
        "+\n",
        "+   static native int[] getSeralizeFeaturesMap(long sessionPtr, FlatBufferBuilder builder);\n",
        "+\n",
        "+   static native Map<String,float[]> getFeaturesMap(long sessionPtr);\n",
        "+\n",
        "+   static native int updateFeatures(long sessionPtr,ArrayList<FeatureMap> featureMaps);\n",
        "+\n",
        "+   static native int free(long sessionPtr);\n",
        "+}\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/CMakeLists.txt b/mindspore/lite/flclient/src/main/native/CMakeLists.txt\n",
        "index 5171696..89bc06f 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/CMakeLists.txt\n",
        "+++ b/mindspore/lite/flclient/src/main/native/CMakeLists.txt\n",
        "@@ -20,6 +20,7 @@ set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++17\")\n",
        " \n",
        " include_directories(${CMAKE_CURRENT_SOURCE_DIR})\n",
        " include_directories(${CMAKE_CURRENT_SOURCE_DIR}/linux)\n",
        "+include_directories(${CMAKE_CURRENT_SOURCE_DIR}/dataset)\n",
        " \n",
        " \n",
        " include_directories(${LITE_DIR}) ## lite include\n",
        "@@ -28,17 +29,18 @@ include_directories(${TOP_DIR}/mindspore/core/) ## core include\n",
        " include_directories(${LITE_DIR}/build) ## flatbuffers\n",
        " \n",
        " set(OP_SRC\n",
        "-        lite_train.cpp\n",
        "-        data_prepare.cpp\n",
        "-            )\n",
        "-\n",
        "-set(SRC_FILES\n",
        "         lite_train_jni.cpp\n",
        "-        )\n",
        "+        util.cpp\n",
        "+        bert_train.cpp\n",
        "+        lenet_train.cpp\n",
        "+        dataset/CustomizedTokenizer.cc\n",
        "+            )\n",
        " find_library(log-lib glog)\n",
        " \n",
        "-add_library(fl SHARED ${SRC_FILES} ${OP_SRC})\n",
        "-target_link_libraries(fl mindspore-lite  glog)\n",
        "+add_library(fl SHARED ${OP_SRC})\n",
        "+\n",
        " link_directories(${CMAKE_CURRENT_SOURCE_DIR}/lib/)\n",
        " \n",
        " install(TARGETS fl LIBRARY DESTINATION ${CMAKE_CURRENT_SOURCE_DIR}/lib)\n",
        "+add_executable(test test_train.cc ${OP_SRC} )\n",
        "+target_link_libraries(test mindspore-lite  glog)\n",
        "\\ No newline at end of file\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/bert_train.cpp b/mindspore/lite/flclient/src/main/native/bert_train.cpp\n",
        "new file mode 100644\n",
        "index 0000000..d5fca9a\n",
        "--- /dev/null\n",
        "+++ b/mindspore/lite/flclient/src/main/native/bert_train.cpp\n",
        "@@ -0,0 +1,197 @@\n",
        "+/**\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "+ *\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "+ * you may not use this file except in compliance with the License.\n",
        "+ * You may obtain a copy of the License at\n",
        "+ *\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\n",
        "+ *\n",
        "+ * Unless required by applicable law or agreed to in writing, software\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "+ * See the License for the specific language governing permissions and\n",
        "+ * limitations under the License.\n",
        "+ */\n",
        "+#include \"bert_train.h\"\n",
        "+#include \"util.h\"\n",
        "+#include <cstring>\n",
        "+#include <fstream>\n",
        "+#include <iostream>\n",
        "+#include \"include/context.h\"\n",
        "+#include \"include/errorcode.h\"\n",
        "+#include \"src/common/log_adapter.h\"\n",
        "+#include \"dataset/CustomizedTokenizer.h\"\n",
        "+#include <climits>\n",
        "+\n",
        "+static int *lable_ids = 0;\n",
        "+static int *input_ids = 0;\n",
        "+static int *input_mask = 0;\n",
        "+static int *token_type_ids = 0;\n",
        "+static int  batch_num = 0;\n",
        "+static int total_size = 0;\n",
        "+\n",
        "+#define MAX_SEQ_LENGTH 32\n",
        "+#define BATCH_SIZE 16\n",
        "+#define LABEL_CLASS 107\n",
        "+\n",
        "+std::vector<int> FillBertInputData(mindspore::session::TrainSession *train_session, int batch_idx) {\n",
        "+  auto inputs = train_session->GetInputs();\n",
        "+  int batch_size = inputs[0]->shape()[0];\n",
        "+\n",
        "+  auto model_input_mask = reinterpret_cast<int *>(inputs.at(0)->MutableData());\n",
        "+  auto model_input_ids = reinterpret_cast<int *>(inputs.at(1)->MutableData());\n",
        "+  auto model_token_id = reinterpret_cast<int *>(inputs.at(2)->MutableData());\n",
        "+  auto model_label_ids = reinterpret_cast<int *>(inputs.at(3)->MutableData());\n",
        "+  std::vector<int> labels_vec(batch_size);\n",
        "+  for (int i = 0; i < batch_size; i++) {\n",
        "+    std::memcpy(model_input_mask + i * MAX_SEQ_LENGTH,\n",
        "+                input_mask + +batch_idx * inputs[0]->ElementsNum() + i * MAX_SEQ_LENGTH, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+    std::memcpy(model_input_ids + i * MAX_SEQ_LENGTH,\n",
        "+                input_ids + +batch_idx * inputs[1]->ElementsNum() + i * MAX_SEQ_LENGTH, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+    std::memcpy(model_token_id + i * MAX_SEQ_LENGTH,\n",
        "+                token_type_ids + +batch_idx * inputs[2]->ElementsNum() + i * MAX_SEQ_LENGTH, MAX_SEQ_LENGTH * sizeof(int));\n",
        "+    model_label_ids[i] = lable_ids[batch_idx*batch_size+i];\n",
        "+    labels_vec[i] = lable_ids[batch_idx*batch_size+i];\n",
        "+\n",
        "+  }\n",
        "+//  std::ofstream  ofs(\"model_input_mask.bin\", std::ios::binary | std::ios::out);\n",
        "+//  ofs.write((const char*)model_input_mask, sizeof(int) * inputs[0]->ElementsNum());\n",
        "+//  ofs.close();\n",
        "+//\n",
        "+//  std::ofstream  ofs1(\"model_input_ids.bin\", std::ios::binary | std::ios::out);\n",
        "+//  ofs1.write((const char*)model_input_ids, sizeof(int) * inputs[1]->ElementsNum());\n",
        "+//  ofs1.close();\n",
        "+//\n",
        "+//  std::ofstream  ofs3(\"model_label_ids.bin\", std::ios::binary | std::ios::out);\n",
        "+//  ofs3.write((const char*)model_label_ids, sizeof(int) * inputs[3]->ElementsNum());\n",
        "+//  ofs3.close();\n",
        "+//\n",
        "+//  std::ofstream  ofs2(\"model_token_id.bin\", std::ios::binary | std::ios::out);\n",
        "+//  ofs2.write((const char*)model_token_id, sizeof(int) * inputs[2]->ElementsNum());\n",
        "+//  ofs2.close();\n",
        "+  return labels_vec;\n",
        "+}\n",
        "+\n",
        "+\n",
        "+\n",
        "+// net inference function\n",
        "+float InferBert(TrainSession *session) {\n",
        "+  auto labels = FillBertInputData(session, 0);\n",
        "+  auto infer_acc = CalculateAccuracy(session, labels,LABEL_CLASS);\n",
        "+  std::cout << \"inference acc is:\" << infer_acc << std::endl;\n",
        "+  return infer_acc;\n",
        "+}\n",
        "+\n",
        "+\n",
        "+// net training function\n",
        "+int TrainBert(TrainSession *session,const std::string &ms_file,int batch_size, int epoches) {\n",
        "+  if (epoches <= 0) {\n",
        "+    std::cout << \"error iterations or epoch!, epoch:\"\n",
        "+                  << \", iterations\" << epoches;\n",
        "+    return mindspore::lite::RET_ERROR;\n",
        "+  }\n",
        "+  batch_num = total_size/batch_size;\n",
        "+  std::cout << \"total epoches :\" << epoches << \",batch_num:\" << batch_num<<std::endl;\n",
        "+  for (int j = 0; j < epoches; ++j) {\n",
        "+    float sum_loss_per_epoch = 0.0f;\n",
        "+    float sum_acc_per_epoch = 0.0f;\n",
        "+    for (int k = 0; k < batch_num; ++k) {\n",
        "+      session->Train();\n",
        "+      auto lables = FillBertInputData(session, k);\n",
        "+      session->RunGraph(nullptr, nullptr);\n",
        "+      auto loss = GetLoss(session);\n",
        "+      sum_loss_per_epoch += loss;\n",
        "+      std::cout<< \"batch:\"<< k<<\",loss:\"<< loss <<std::endl;\n",
        "+      sum_acc_per_epoch += CalculateAccuracy(session, lables,LABEL_CLASS);\n",
        "+\n",
        "+    }\n",
        "+    std::cout << \"epoch \"\n",
        "+              << \"[\" << j << \"]\"\n",
        "+              << \",mean Loss \" << sum_loss_per_epoch / batch_num << \",train acc \" << sum_acc_per_epoch / batch_num\n",
        "+              << std::endl;\n",
        "+  }\n",
        "+  session->SaveToFile(ms_file);\n",
        "+  return mindspore::lite::RET_OK;\n",
        "+}\n",
        "+\n",
        "+void ReadTxt(const std::string &file, std::vector<std::string> *train_data) {\n",
        "+  std::fstream fin;\n",
        "+  fin.open(file, std::ios::in);\n",
        "+  if (fin.is_open()) {\n",
        "+    std::string train_sentense;\n",
        "+    while (!fin.eof()) {\n",
        "+      getline(fin, train_sentense, '\\n');\n",
        "+      size_t endpos = train_sentense.find_last_not_of(\"\\r\");\n",
        "+      if(endpos != std::string::npos) {\n",
        "+        train_sentense.substr(0,endpos+1).swap(train_sentense);\n",
        "+      }\n",
        "+      if (!train_sentense.empty()) {\n",
        "+        train_data->push_back(train_sentense);\n",
        "+      }\n",
        "+    }\n",
        "+    fin.close();\n",
        "+  }\n",
        "+}\n",
        "+\n",
        "+// Set input tensors.\n",
        "+int SetBertInputs(const std::string &train_file,const std::string &vocab_file,const std::string &labels_file) {\n",
        "+  if (train_file.empty()) {\n",
        "+    std::cout << \"files empty\";\n",
        "+    return -1;\n",
        "+  }\n",
        "+  std::vector<std::string> train_data;\n",
        "+  ReadTxt(train_file, &train_data);\n",
        "+  std::vector<std::string> labels;\n",
        "+  ReadTxt(labels_file, &labels);\n",
        "+  std::map<std::string,int> labels_map;\n",
        "+  for(int i=0;i<labels.size();i++) {\n",
        "+    labels_map[labels[i]] = i;\n",
        "+  }\n",
        "+  total_size = train_data.size();\n",
        "+  int total_batch_num = total_size / BATCH_SIZE;\n",
        "+  if(total_batch_num == 0) {\n",
        "+    std::cout << \"train data size less than one batch,not support now\";\n",
        "+    return -1;\n",
        "+  }\n",
        "+  int train_size = total_batch_num * BATCH_SIZE;\n",
        "+  input_ids = new (std::nothrow) int[train_size * MAX_SEQ_LENGTH];\n",
        "+  input_mask = new (std::nothrow) int[train_size * MAX_SEQ_LENGTH];\n",
        "+  token_type_ids = new (std::nothrow) int[train_size * MAX_SEQ_LENGTH];\n",
        "+  lable_ids = new (std::nothrow) int[train_size];\n",
        "+\n",
        "+  CustomizedTokenizer customized_tokenizer;\n",
        "+  bool do_lower_case = true;\n",
        "+  customized_tokenizer.init(vocab_file, do_lower_case);\n",
        "+\n",
        "+  int s_input_ids[MAX_SEQ_LENGTH];\n",
        "+  int s_attention_mask[MAX_SEQ_LENGTH];\n",
        "+  int s_token_type_ids[MAX_SEQ_LENGTH];\n",
        "+  int seq_length;\n",
        "+  // less than one batch would  drop\n",
        "+  for (int i = 0; i < train_size; i++) {\n",
        "+    std::vector<std::string> dataset_tuple(2);\n",
        "+    dataset_tuple.clear();\n",
        "+    char* token = strtok(reinterpret_cast<char *>(train_data[i].data()),\"\\t\");\n",
        "+    while (token != NULL) {\n",
        "+      dataset_tuple.push_back(token);\n",
        "+      token = strtok(NULL, \"\\t\");\n",
        "+    }\n",
        "+    if(dataset_tuple.size() != 2) {\n",
        "+      std::cout<< \"train data error,must 2 word\"<<std::endl;\n",
        "+    }\n",
        "+    customized_tokenizer.tokenize(dataset_tuple[1], s_input_ids, s_attention_mask, s_token_type_ids, seq_length);\n",
        "+    memcpy(input_ids + i * MAX_SEQ_LENGTH, s_input_ids, MAX_SEQ_LENGTH);\n",
        "+    memcpy(input_mask + i * MAX_SEQ_LENGTH, s_attention_mask, MAX_SEQ_LENGTH);\n",
        "+    memcpy(token_type_ids + i * MAX_SEQ_LENGTH, s_token_type_ids, MAX_SEQ_LENGTH);\n",
        "+    std::string key = dataset_tuple[0];\n",
        "+    lable_ids[i] = labels_map[key];\n",
        "+  }\n",
        "+  return train_size;\n",
        "+}\n",
        "+\n",
        "+void FreeBertInput() {\n",
        "+  delete input_ids;\n",
        "+  delete input_mask;\n",
        "+  delete token_type_ids;\n",
        "+}\n",
        "\\ No newline at end of file\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/bert_train.h b/mindspore/lite/flclient/src/main/native/bert_train.h\n",
        "new file mode 100644\n",
        "index 0000000..f222be2\n",
        "--- /dev/null\n",
        "+++ b/mindspore/lite/flclient/src/main/native/bert_train.h\n",
        "@@ -0,0 +1,26 @@\n",
        "+/**\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "+ *\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "+ * you may not use this file except in compliance with the License.\n",
        "+ * You may obtain a copy of the License at\n",
        "+ *\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\n",
        "+ *\n",
        "+ * Unless required by applicable law or agreed to in writing, software\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "+ * See the License for the specific language governing permissions and\n",
        "+ * limitations under the License.\n",
        "+ */\n",
        "+\n",
        "+#ifndef MSLITE_FL_BERT_TRAIN_H\n",
        "+#define MSLITE_FL_BERT_TRAIN_H\n",
        "+\n",
        "+#include \"include/train/train_session.h\"\n",
        "+#include <string>\n",
        "+int SetBertInputs(const std::string &train_file,const std::string &vocab_file,const std::string &labels_file);\n",
        "+void FreeBertInput();\n",
        "+int TrainBert(mindspore::session::TrainSession *session,const std::string &ms_file,int batch_size ,int epoches);\n",
        "+float InferBert(mindspore::session::TrainSession *session);\n",
        "+#endif  // MSLITE_FL_BERT_TRAIN_H\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/data_prepare.cpp b/mindspore/lite/flclient/src/main/native/data_prepare.cpp\n",
        "deleted file mode 100644\n",
        "index c8a1b5e..0000000\n",
        "--- a/mindspore/lite/flclient/src/main/native/data_prepare.cpp\n",
        "+++ /dev/null\n",
        "@@ -1,517 +0,0 @@\n",
        "-/**\n",
        "- * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "- *\n",
        "- * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "- * you may not use this file except in compliance with the License.\n",
        "- * You may obtain a copy of the License at\n",
        "- *\n",
        "- * http://www.apache.org/licenses/LICENSE-2.0\n",
        "- *\n",
        "- * Unless required by applicable law or agreed to in writing, software\n",
        "- * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "- * See the License for the specific language governing permissions and\n",
        "- * limitations under the License.\n",
        "- */\n",
        "-\n",
        "-\n",
        "-#include <fstream>\n",
        "-#include <iostream>\n",
        "-#include <cstdio>\n",
        "-#include <vector>\n",
        "-#include <map>\n",
        "-#include <ctime>\n",
        "-//#include <cstring>\n",
        "-//#include <algorithm>\n",
        "-//#include <cstdlib>\n",
        "-using namespace std;\n",
        "-#define MAX_SEQ_LENGTH 256\n",
        "-\n",
        "-class CustomizedTokenizer\n",
        "-{\n",
        "- public:\n",
        "-  CustomizedTokenizer();\n",
        "-  ~CustomizedTokenizer();\n",
        "-\n",
        "-  void init(const string &vocab_file, bool do_lower_case);\n",
        "-  void tokenize(const string &text, string output_tokens[MAX_SEQ_LENGTH], int &seq_length);\n",
        "-  void tokenize(const string &text, int input_ids[MAX_SEQ_LENGTH],\n",
        "-                int attention_mask[MAX_SEQ_LENGTH], int token_type_ids[MAX_SEQ_LENGTH], int &seq_length);\n",
        "-\n",
        "-//private:\n",
        "-  string _text;\n",
        "-  string _tokens[MAX_SEQ_LENGTH];\n",
        "-  int _tokens_length = 0;\n",
        "-  int _text_length = 0;\n",
        "-\n",
        "-  map<string, int> _vocab;\n",
        "-  bool _do_lower_case = true;\n",
        "-  int _max_input_chars_per_word = 100;\n",
        "-\n",
        "-  static void _lower_token(const string &token, string &new_token);\n",
        "-  void _split_text();\n",
        "-  void _clean_text();\n",
        "-  void _fixed_matching(int &pos, string &token);\n",
        "-  void _load_vocab(const string &vocab_file);\n",
        "-};\n",
        "-\n",
        "-CustomizedTokenizer::CustomizedTokenizer() = default;\n",
        "-\n",
        "-CustomizedTokenizer::~CustomizedTokenizer() {\n",
        "-  _vocab.clear();\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::init(const string &vocab_file, bool do_lower_case) {\n",
        "-  _do_lower_case = do_lower_case;\n",
        "-  _load_vocab(vocab_file);\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::tokenize(const string &text, string output_tokens[MAX_SEQ_LENGTH], int &seq_length) {\n",
        "-//  clock_t startTime;\n",
        "-//  double time_cost = 0.0;\n",
        "-  _text = text;\n",
        "-  _split_text();\n",
        "-\n",
        "-  int output_tokens_pos = 0;\n",
        "-\n",
        "-//  startTime = clock();\n",
        "-  for (int i = 0; i < _tokens_length; ++i) {\n",
        "-    int length = _tokens[i].length();\n",
        "-    if (length > _max_input_chars_per_word) {\n",
        "-      output_tokens[output_tokens_pos] = \"[UNK]\";\n",
        "-      output_tokens_pos++;\n",
        "-      if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "-        _tokens_length = 0;\n",
        "-        output_tokens[MAX_SEQ_LENGTH - 1] = \"[SEP]\";\n",
        "-        return;\n",
        "-      }\n",
        "-      continue;\n",
        "-    }\n",
        "-\n",
        "-    bool is_bad = false;\n",
        "-    int start = 0;\n",
        "-    vector<string> sub_tokens;\n",
        "-    while (start < length) {\n",
        "-      int end = length;\n",
        "-      string cur_substr;\n",
        "-      while (start < end) {\n",
        "-        string substr = _tokens[i].substr(start, end - start);\n",
        "-        if (start > 0) {\n",
        "-          substr.insert(0,\"##\");\n",
        "-        }\n",
        "-        if (_vocab.find(substr) != _vocab.end()) {\n",
        "-          cur_substr = substr;\n",
        "-          break;\n",
        "-        }\n",
        "-        end--;\n",
        "-      }\n",
        "-      if (cur_substr.empty()) {\n",
        "-        is_bad = true;\n",
        "-        break;\n",
        "-      }\n",
        "-      sub_tokens.emplace_back(cur_substr);\n",
        "-      start = end;\n",
        "-    }\n",
        "-    if (is_bad) {\n",
        "-      output_tokens[output_tokens_pos] = \"[UNK]\";\n",
        "-      output_tokens_pos++;\n",
        "-      if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "-        _tokens_length = 0;\n",
        "-        output_tokens[MAX_SEQ_LENGTH - 1] = \"[SEP]\";\n",
        "-        return;\n",
        "-      }\n",
        "-    } else {\n",
        "-      for (const string& sub_token: sub_tokens) {\n",
        "-        output_tokens[output_tokens_pos] = sub_token;\n",
        "-        output_tokens_pos++;\n",
        "-        if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "-          _tokens_length = 0;\n",
        "-          output_tokens[MAX_SEQ_LENGTH - 1] = \"[SEP]\";\n",
        "-          return;\n",
        "-        }\n",
        "-      }\n",
        "-    }\n",
        "-  }\n",
        "-\n",
        "-  output_tokens[output_tokens_pos] = \"[SEP]\";\n",
        "-  for (int i = output_tokens_pos + 1; i < MAX_SEQ_LENGTH; ++i) {\n",
        "-    output_tokens[i] = \"[PAD]\";\n",
        "-  }\n",
        "-//  time_cost += (double)(clock() - startTime) / CLOCKS_PER_SEC;\n",
        "-  _tokens_length = 0;\n",
        "-\n",
        "-//  cout << \"Local run time is: \" << time_cost << endl;\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::tokenize(const string &text, int input_ids[MAX_SEQ_LENGTH],\n",
        "-                                   int attention_mask[MAX_SEQ_LENGTH], int token_type_ids[MAX_SEQ_LENGTH],\n",
        "-                                   int &seq_length) {\n",
        "-//  clock_t startTime;\n",
        "-//  double time_cost = 0.0;\n",
        "-  _text = text;\n",
        "-  _split_text();\n",
        "-\n",
        "-  int output_tokens_pos = 0;\n",
        "-\n",
        "-//  startTime = clock();\n",
        "-  for (int i = 0; i < _tokens_length; ++i) {\n",
        "-    int length = _tokens[i].length();\n",
        "-    if (length > _max_input_chars_per_word) {\n",
        "-      input_ids[output_tokens_pos] = _vocab[\"[UNK]\"];\n",
        "-      attention_mask[output_tokens_pos] = 1;\n",
        "-      token_type_ids[output_tokens_pos] = 0;\n",
        "-      output_tokens_pos++;\n",
        "-      if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "-        _tokens_length = 0;\n",
        "-        input_ids[MAX_SEQ_LENGTH - 1] = _vocab[\"[SEP]\"];\n",
        "-        attention_mask[MAX_SEQ_LENGTH - 1] = 1;\n",
        "-        token_type_ids[MAX_SEQ_LENGTH - 1] = 0;\n",
        "-        return;\n",
        "-      }\n",
        "-      continue;\n",
        "-    }\n",
        "-\n",
        "-    bool is_bad = false;\n",
        "-    int start = 0;\n",
        "-    vector<string> sub_tokens;\n",
        "-    while (start < length) {\n",
        "-      int end = length;\n",
        "-      string cur_substr;\n",
        "-      while (start < end) {\n",
        "-        string substr = _tokens[i].substr(start, end - start);\n",
        "-        if (start > 0) {\n",
        "-          substr.insert(0,\"##\");\n",
        "-        }\n",
        "-        if (_vocab.find(substr) != _vocab.end()) {\n",
        "-          cur_substr = substr;\n",
        "-          break;\n",
        "-        }\n",
        "-        end--;\n",
        "-      }\n",
        "-      if (cur_substr.empty()) {\n",
        "-        is_bad = true;\n",
        "-        break;\n",
        "-      }\n",
        "-      sub_tokens.emplace_back(cur_substr);\n",
        "-      start = end;\n",
        "-    }\n",
        "-    if (is_bad) {\n",
        "-      input_ids[output_tokens_pos] = _vocab[\"[UNK]\"];\n",
        "-      attention_mask[output_tokens_pos] = 1;\n",
        "-      token_type_ids[output_tokens_pos] = 0;\n",
        "-      output_tokens_pos++;\n",
        "-      if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "-        _tokens_length = 0;\n",
        "-        input_ids[MAX_SEQ_LENGTH - 1] = _vocab[\"[SEP]\"];\n",
        "-        attention_mask[MAX_SEQ_LENGTH - 1] = 1;\n",
        "-        token_type_ids[MAX_SEQ_LENGTH - 1] = 0;\n",
        "-        return;\n",
        "-      }\n",
        "-    } else {\n",
        "-      for (const string& sub_token: sub_tokens) {\n",
        "-        input_ids[output_tokens_pos] = _vocab[sub_token];\n",
        "-        attention_mask[output_tokens_pos] = 1;\n",
        "-        token_type_ids[output_tokens_pos] = 0;\n",
        "-        output_tokens_pos++;\n",
        "-        if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "-          _tokens_length = 0;\n",
        "-          input_ids[MAX_SEQ_LENGTH - 1] = _vocab[\"[SEP]\"];\n",
        "-          attention_mask[MAX_SEQ_LENGTH - 1] = 1;\n",
        "-          token_type_ids[MAX_SEQ_LENGTH - 1] = 0;\n",
        "-          return;\n",
        "-        }\n",
        "-      }\n",
        "-    }\n",
        "-  }\n",
        "-//  time_cost += (double)(clock() - startTime) / CLOCKS_PER_SEC;\n",
        "-  input_ids[output_tokens_pos] = _vocab[\"[SEP]\"];\n",
        "-  attention_mask[output_tokens_pos] = 1;\n",
        "-  token_type_ids[output_tokens_pos] = 0;\n",
        "-  for (int i = output_tokens_pos + 1; i < MAX_SEQ_LENGTH; ++i) {\n",
        "-    input_ids[i] = 0;\n",
        "-    attention_mask[i] = 0;\n",
        "-    token_type_ids[i] = 0;\n",
        "-  }\n",
        "-  _tokens_length = 0;\n",
        "-\n",
        "-//  cout << \"Local run time is: \" << time_cost << endl;\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::_lower_token(const string &token, string &new_token) {\n",
        "-  int length = token.length();\n",
        "-  if (token[0] == '[') {\n",
        "-    if (length == 5) {\n",
        "-      if (token[4] == ']') {\n",
        "-        if (token[1] == 'U' && token[2] == 'N' && token[3] == 'K') {\n",
        "-          new_token = token;\n",
        "-          return;\n",
        "-        }\n",
        "-        if (token[1] == 'S' && token[2] == 'E' && token[3] == 'P') {\n",
        "-          new_token = token;\n",
        "-          return;\n",
        "-        }\n",
        "-        if (token[1] == 'P' && token[2] == 'A' && token[3] == 'D') {\n",
        "-          new_token = token;\n",
        "-          return;\n",
        "-        }\n",
        "-        if (token[1] == 'C' && token[2] == 'L' && token[3] == 'S') {\n",
        "-          new_token = token;\n",
        "-          return;\n",
        "-        }\n",
        "-      }\n",
        "-    }\n",
        "-    if (length == 6) {\n",
        "-      if (token[1] == 'M' && token[2] == 'A' && token[3] == 'S' && token[4] == 'K' && token[5] == ']') {\n",
        "-        new_token = token;\n",
        "-        return;\n",
        "-      }\n",
        "-    }\n",
        "-  }\n",
        "-\n",
        "-  for (char ch: token) {\n",
        "-    if (ch <= 90 && ch >= 65) {\n",
        "-      new_token += char(ch + 32);\n",
        "-    } else {\n",
        "-      new_token += ch;\n",
        "-    }\n",
        "-  }\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::_clean_text() {\n",
        "-  int pos;\n",
        "-  pos = _text.find(\"\\u00A0\");\n",
        "-  while (pos > 0) {\n",
        "-    _text = _text.replace(pos, 2, \" \");\n",
        "-    pos = _text.find(\"\\u00A0\");\n",
        "-  }\n",
        "-  pos = _text.find(\"\\u2800\");\n",
        "-  while (pos > 0) {\n",
        "-    _text = _text.replace(pos, 3, \" \");\n",
        "-    pos = _text.find(\"\\u2800\");\n",
        "-  }\n",
        "-  pos = _text.find(\"\\u3000\");\n",
        "-  while (pos > 0) {\n",
        "-    _text = _text.replace(pos, 3, \" \");\n",
        "-    pos = _text.find(\"\\u3000\");\n",
        "-  }\n",
        "-  pos = _text.find(\"\\ufeff\");\n",
        "-  while (pos > 0) {\n",
        "-    _text = _text.replace(pos, 3, \"\");\n",
        "-    pos = _text.find(\"\\ufeff\");\n",
        "-  }\n",
        "-  pos = _text.find(\"\\ue312\");\n",
        "-  while (pos > 0) {\n",
        "-    _text = _text.replace(pos, 3, \"\");\n",
        "-    pos = _text.find(\"\\ue312\");\n",
        "-  }\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::_load_vocab(const string &vocab_file) {\n",
        "-  int index = 0;\n",
        "-  fstream fin;\n",
        "-  fin.open(vocab_file, ios::in);\n",
        "-  if (fin.is_open()) {\n",
        "-    string basicString;\n",
        "-    while (!fin.eof()) {\n",
        "-      getline(fin, basicString, '\\n');\n",
        "-      if (!basicString.empty()) {\n",
        "-        _vocab[basicString] = index;\n",
        "-      }\n",
        "-      index++;\n",
        "-    }\n",
        "-    fin.close();\n",
        "-  }\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::_fixed_matching(int &pos, string &token) {\n",
        "-  token += _text[pos];\n",
        "-  int rest_length = _text_length - pos;\n",
        "-  if (rest_length < 2) {\n",
        "-    pos++;\n",
        "-    return;\n",
        "-  }\n",
        "-  if (_text[pos] == char(-16)) {\n",
        "-    if (rest_length < 4) {\n",
        "-      pos++;\n",
        "-      return;\n",
        "-    }\n",
        "-    if (_text[pos+1] < char(0) && _text[pos+2] < char(0) && _text[pos+3] < char(0)) {\n",
        "-      token += _text[pos+1];\n",
        "-      token += _text[pos+2];\n",
        "-      token += _text[pos+3];\n",
        "-      pos += 4;\n",
        "-      return;\n",
        "-    }\n",
        "-    pos++;\n",
        "-    return;\n",
        "-  }\n",
        "-  if (_text[pos] >= char(-62) && _text[pos] <= char(-37)) {\n",
        "-    if (_text[pos+1] < char(0)) {\n",
        "-      token += _text[pos+1];\n",
        "-      pos += 2;\n",
        "-      return;\n",
        "-    }\n",
        "-    pos++;\n",
        "-    return;\n",
        "-  }\n",
        "-  if (rest_length < 3) {\n",
        "-    pos++;\n",
        "-    return;\n",
        "-  }\n",
        "-  if (_text[pos+1] < char(0) && _text[pos+2] < char(0)) {\n",
        "-    token += _text[pos+1];\n",
        "-    token += _text[pos+2];\n",
        "-    pos += 3;\n",
        "-    return;\n",
        "-  }\n",
        "-  pos++;\n",
        "-}\n",
        "-\n",
        "-void CustomizedTokenizer::_split_text() {\n",
        "-  // Performs invalid character removal and whitespace cleanup on text.\n",
        "-  _clean_text();\n",
        "-  _text_length = _text.length();\n",
        "-  int pos = 0;\n",
        "-  string token;\n",
        "-  _tokens[_tokens_length++] = \"[CLS]\";\n",
        "-  while (pos < _text_length) {\n",
        "-    if (_tokens_length == MAX_SEQ_LENGTH) {\n",
        "-      break;\n",
        "-    }\n",
        "-    if (_text[pos] == ' ') {\n",
        "-      if (!token.empty()) {\n",
        "-        if (token[0] >= char(0) && _do_lower_case) {\n",
        "-          string new_token;\n",
        "-          _lower_token(token, new_token);\n",
        "-          _tokens[_tokens_length++] = new_token;\n",
        "-        } else {\n",
        "-          _tokens[_tokens_length++] = token;\n",
        "-        }\n",
        "-        token.clear();\n",
        "-      }\n",
        "-      pos++;\n",
        "-      continue;\n",
        "-    }\n",
        "-    // We treat all non-letter/number ASCII as punctuation.\n",
        "-    // Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
        "-    // Punctuation class but we treat them as punctuation anyways, for\n",
        "-    // consistency.\n",
        "-    if ((_text[pos] >= char(33) && _text[pos] <= char(47)) ||\n",
        "-      (_text[pos] >= char(58) && _text[pos] <= char(64)) ||\n",
        "-      (_text[pos] >= char(91) && _text[pos] <= char(96)) ||\n",
        "-      (_text[pos] >= char(123) && _text[pos] <= char(126))\n",
        "-      ) {\n",
        "-      if (!token.empty()) {\n",
        "-        if (token[0] >= char(0) && _do_lower_case) {\n",
        "-          string new_token;\n",
        "-          _lower_token(token, new_token);\n",
        "-          _tokens[_tokens_length++] = new_token;\n",
        "-        } else {\n",
        "-          _tokens[_tokens_length++] = token;\n",
        "-        }\n",
        "-        token.clear();\n",
        "-      }\n",
        "-      if (_text[pos] == char(91)) {\n",
        "-        if (pos < _text_length - 4) {\n",
        "-          if (_text[pos+1] == 'S' && _text[pos+2] == 'E' && _text[pos+3] == 'P' && _text[pos+4] == ']') {\n",
        "-            _tokens[_tokens_length++] = \"[SEP]\";\n",
        "-            pos += 5;\n",
        "-            continue;\n",
        "-          }\n",
        "-          if (_text[pos+1] == 'U' && _text[pos+2] == 'N' && _text[pos+3] == 'K' && _text[pos+4] == ']') {\n",
        "-            _tokens[_tokens_length++] = \"[UNK]\";\n",
        "-            pos += 5;\n",
        "-            continue;\n",
        "-          }\n",
        "-          if (_text[pos+1] == 'P' && _text[pos+2] == 'A' && _text[pos+3] == 'D' && _text[pos+4] == ']') {\n",
        "-            _tokens[_tokens_length++] = \"[PAD]\";\n",
        "-            pos += 5;\n",
        "-            continue;\n",
        "-          }\n",
        "-          if (_text[pos+1] == 'C' && _text[pos+2] == 'L' && _text[pos+3] == 'S' && _text[pos+4] == ']') {\n",
        "-            _tokens[_tokens_length++] = \"[CLS]\";\n",
        "-            pos += 5;\n",
        "-            continue;\n",
        "-          }\n",
        "-        }\n",
        "-        if (pos < _text_length - 5) {\n",
        "-          if (_text[pos+1] == 'M' && _text[pos+2] == 'A' && _text[pos+3] == 'S' && _text[pos+4] == 'K' &&\n",
        "-            _text[pos+5] == ']') {\n",
        "-            _tokens[_tokens_length++] = \"[MASK]\";\n",
        "-            pos += 6;\n",
        "-            continue;\n",
        "-          }\n",
        "-        }\n",
        "-      }\n",
        "-      string temp = {_text[pos]};\n",
        "-      _tokens[_tokens_length++] = temp;\n",
        "-      pos++;\n",
        "-      continue;\n",
        "-    }\n",
        "-    if (_text[pos] < char(0)) {\n",
        "-      if (!token.empty()) {\n",
        "-        if (token[0] >= char(0) && _do_lower_case) {\n",
        "-          string new_token;\n",
        "-          _lower_token(token, new_token);\n",
        "-          _tokens[_tokens_length++] = new_token;\n",
        "-        } else {\n",
        "-          _tokens[_tokens_length++] = token;\n",
        "-        }\n",
        "-        token.clear();\n",
        "-      }\n",
        "-      _fixed_matching(pos, token);\n",
        "-      _tokens[_tokens_length++] = token;\n",
        "-      token.clear();\n",
        "-    } else {\n",
        "-      token += _text[pos];\n",
        "-      pos++;\n",
        "-    }\n",
        "-  }\n",
        "-  if (!token.empty()) {\n",
        "-    if (token[0] >= char(0) && _do_lower_case) {\n",
        "-      string new_token;\n",
        "-      _lower_token(token, new_token);\n",
        "-      _tokens[_tokens_length++] = new_token;\n",
        "-    } else {\n",
        "-      _tokens[_tokens_length++] = token;\n",
        "-    }\n",
        "-  }\n",
        "-}\n",
        "-"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}