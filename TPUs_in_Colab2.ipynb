{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPUs in Colab",
      "provenance": [],
      "collapsed_sections": [
        "clSFHJkFNylD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tx1103mark/tweet-sentiment/blob/master/TPUs_in_Colab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFDeMgtjqW4"
      },
      "source": [
        "# TPUs in Colab&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>\n",
        "In this example, we'll work through training a model to classify images of\n",
        "flowers on Google's lightning-fast Cloud TPUs. Our model will take as input a photo of a flower and return whether it is a daisy, dandelion, rose, sunflower, or tulip.\n",
        "\n",
        "We use the Keras framework, new to TPUs in TF 2.1.0. Adapted from [this notebook](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_xception_fine_tuned_best.ipynb) by [Martin Gorner](https://twitter.com/martin_gorner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clSFHJkFNylD"
      },
      "source": [
        "#### License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "Copyright 2019-2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Enabling and testing the TPU\n",
        "\n",
        "First, you'll need to enable TPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select TPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll check that we can connect to the TPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIR6iAnttgJk"
      },
      "source": [
        "#Data process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xicq53SkeQ6_"
      },
      "source": [
        "From df8f267f67caf86040fccd1d80421173b6ba4f22 Mon Sep 17 00:00:00 2001\n",
        "From: guohongzilong <guohongzilong@huawei.com>\n",
        "Date: Fri, 26 Mar 2021 15:51:00 +0800\n",
        "Subject: [PATCH] code clean and remove micro code\n",
        "\n",
        "---\n",
        " .../main/java/com/huawei/flclient/LiteTrain.java   |  16 +-\n",
        " .../lite/flclient/src/main/native/CMakeLists.txt   |  54 +--\n",
        " .../src/main/native/com_huawei_flclient_Train.h    |  69 ---\n",
        " .../lite/flclient/src/main/native/data_prepare.cpp | 517 +++++++++++++++++++++\n",
        " .../flclient/src/main/native/lenet_train_jni.cpp   | 157 -------\n",
        " .../lite/flclient/src/main/native/lite_train.cpp   | 287 ++++++++++++\n",
        " .../lite/flclient/src/main/native/lite_train.h     |  35 ++\n",
        " .../flclient/src/main/native/lite_train_jni.cpp    | 219 +++++++++\n",
        " mindspore/lite/include/train/train_session.h       |  11 +\n",
        " mindspore/lite/nnacl/infer/arithmetic_grad_infer.c |   1 -\n",
        " mindspore/lite/nnacl/infer/maximum_grad_infer.c    |   1 +\n",
        " mindspore/lite/src/train/train_session.cc          |  57 ++-\n",
        " mindspore/lite/src/train/train_session.h           |   4 +\n",
        " 13 files changed, 1148 insertions(+), 280 deletions(-)\n",
        " delete mode 100644 mindspore/lite/flclient/src/main/native/com_huawei_flclient_Train.h\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/data_prepare.cpp\n",
        " delete mode 100644 mindspore/lite/flclient/src/main/native/lenet_train_jni.cpp\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/lite_train.cpp\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/lite_train.h\n",
        " create mode 100644 mindspore/lite/flclient/src/main/native/lite_train_jni.cpp\n",
        "\n",
        "diff --git a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "index 70ea94f..5f9a8de 100644\n",
        "--- a/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "+++ b/mindspore/lite/flclient/src/main/java/com/huawei/flclient/LiteTrain.java\n",
        "@@ -31,7 +31,7 @@ public  class LiteTrain {\n",
        "     static {\n",
        "         System.loadLibrary(\"fl\");\n",
        "     }\n",
        "-\n",
        "+    private static HashMap featureMaps;\n",
        "     private static LiteTrain train;\n",
        " \n",
        "     private LiteTrain() {\n",
        "@@ -45,7 +45,7 @@ public  class LiteTrain {\n",
        " \n",
        "     public FlatBufferBuilder FeatureMapBuilder(String modelName){\n",
        "         FlatBufferBuilder builder = new FlatBufferBuilder();\n",
        "-        int[] fmOffsets = getFeaturesMap(modelName,builder);\n",
        "+        int[] fmOffsets = getSeralizeFeaturesMap(modelName,builder);\n",
        "         int fmOffset = FeatureMapList.createFeatureMapVector(builder, fmOffsets);\n",
        "         RequestUpdateModel.startRequestUpdateModel(builder);\n",
        "         RequestUpdateModel.addFlName(builder, 0);\n",
        "@@ -103,7 +103,7 @@ public  class LiteTrain {\n",
        "      *\n",
        "      * @return status\n",
        "      */\n",
        "-    public native int inference(String modelName,int batch_num,int test_nums);\n",
        "+    public native float inference(String modelName,int batch_num);\n",
        " \n",
        "     /**\n",
        "      * train\n",
        "@@ -118,7 +118,15 @@ public  class LiteTrain {\n",
        "      * @param builder FlatBufferBuilder\n",
        "      * @return features offset\n",
        "      */\n",
        "-    native int[] getFeaturesMap(String modelName,FlatBufferBuilder builder);\n",
        "+   native int[] getSeralizeFeaturesMap(String modelName, FlatBufferBuilder builder);\n",
        "+\n",
        "+         /**\n",
        "+             * get the features map of training model\n",
        "+             *\n",
        "+             * @param modelName model name\n",
        "+             * @return features map\n",
        "+             */\n",
        "+   native Map<String,float[]> getFeaturesMap(String modelName);\n",
        " \n",
        "     /**\n",
        "      * update the features map of training model\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/CMakeLists.txt b/mindspore/lite/flclient/src/main/native/CMakeLists.txt\n",
        "index 1ee548e..81ea6d7 100644\n",
        "--- a/mindspore/lite/flclient/src/main/native/CMakeLists.txt\n",
        "+++ b/mindspore/lite/flclient/src/main/native/CMakeLists.txt\n",
        "@@ -20,63 +20,21 @@ set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++17\")\n",
        " \n",
        " include_directories(${CMAKE_CURRENT_SOURCE_DIR})\n",
        " include_directories(${CMAKE_CURRENT_SOURCE_DIR}/linux)\n",
        "-include_directories(${CMAKE_CURRENT_SOURCE_DIR}/include)\n",
        "-include_directories(${CMAKE_CURRENT_SOURCE_DIR}/src)\n",
        "-if(ENABLE_MICRO)\n",
        "-include_directories(${CMAKE_CURRENT_SOURCE_DIR}/src/runtime)\n",
        "-endif()\n",
        "+\n",
        "+\n",
        " include_directories(${LITE_DIR}) ## lite include\n",
        " include_directories(${TOP_DIR}) ## api include\n",
        " include_directories(${TOP_DIR}/mindspore/core/) ## core include\n",
        " include_directories(${LITE_DIR}/build) ## flatbuffers\n",
        " \n",
        "-if(ENABLE_MICRO)\n",
        " set(OP_SRC\n",
        "-    src/nnacl/arithmetic_common.c\n",
        "-    src/nnacl/common_func.c\n",
        "-    src/nnacl/fp32/activation.c\n",
        "-    src/nnacl/fp32/arithmetic.c\n",
        "-    src/nnacl/fp32/common_func.c\n",
        "-    src/nnacl/fp32/conv.c\n",
        "-    src/nnacl/fp32/matmul.c\n",
        "-    src/nnacl/fp32/softmax.c\n",
        "-    src/nnacl/fp32_grad/activation_grad.c\n",
        "-    src/nnacl/fp32_grad/gemm.c\n",
        "-    src/nnacl/fp32_grad/pack_ext.c\n",
        "-    src/nnacl/fp32_grad/pooling_grad.c\n",
        "-    src/nnacl/int8/conv_int8.c\n",
        "-    src/nnacl/int8/matmul_int8.c\n",
        "-    src/nnacl/minimal_filtering_generator.c\n",
        "-    src/nnacl/pack.c\n",
        "-    src/nnacl/quantization/fixed_point.c\n",
        "-    src/nnacl/reshape.c\n",
        "-    src/nnacl/winograd_transform.c\n",
        "-    src/nnacl/winograd_utils.c\n",
        "-    src/runtime/kernel/fp32/max_pooling.c\n",
        "-    src/runtime/kernel/fp32_grad/apply_momentum.c\n",
        "-    src/runtime/kernel/fp32_grad/biasadd_grad.c\n",
        "-    src/runtime/kernel/fp32_grad/compute_gradient.c\n",
        "-    src/runtime/kernel/fp32_grad/conv_filter_grad.c\n",
        "-    src/runtime/kernel/fp32_grad/conv_input_grad.c\n",
        "-    src/runtime/kernel/fp32_grad/init_matrix.c\n",
        "-    src/runtime/kernel/fp32_grad/sparse_softmax_cross_entropy_with_logist.c\n",
        "-    src/runtime/load_input.c\n",
        "-    src/fl_lenet.c\n",
        "-    src/weight_files/fl_lenet_weight_epoch_0.c\n",
        "-)\n",
        "-else()\n",
        "-    set(OP_SRC\n",
        "-            src/lenet_train.cpp\n",
        "+        lite_train.cpp\n",
        "+        data_prepare.cpp\n",
        "             )\n",
        "-    endif()\n",
        "-if(ENABLE_MICRO)\n",
        "-    set(SRC_FILES\n",
        "-            flearning.cpp)\n",
        "-    else()\n",
        "+\n",
        " set(SRC_FILES\n",
        "-        lenet_train_jni.cpp\n",
        "+        lite_train_jni.cpp\n",
        "         )\n",
        "-endif()\n",
        " find_library(log-lib glog)\n",
        " \n",
        " add_library(fl SHARED ${SRC_FILES} ${OP_SRC})\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/com_huawei_flclient_Train.h b/mindspore/lite/flclient/src/main/native/com_huawei_flclient_Train.h\n",
        "deleted file mode 100644\n",
        "index cd0345e..0000000\n",
        "--- a/mindspore/lite/flclient/src/main/native/com_huawei_flclient_Train.h\n",
        "+++ /dev/null\n",
        "@@ -1,69 +0,0 @@\n",
        "-/* DO NOT EDIT THIS FILE - it is machine generated */\n",
        "-#include <jni.h>\n",
        "-/* Header for class com_huawei_flclient_Train */\n",
        "-\n",
        "-#ifndef _Included_com_huawei_flclient_Train\n",
        "-#define _Included_com_huawei_flclient_Train\n",
        "-#ifdef __cplusplus\n",
        "-extern \"C\" {\n",
        "-#endif\n",
        "-/*\n",
        "- * Class:     com_huawei_flclient_Train\n",
        "- * Method:    setInput\n",
        "- * Signature: (Ljava/lang/String;I)I\n",
        "- */\n",
        "-JNIEXPORT jint JNICALL Java_com_huawei_flclient_Train_setInput\n",
        "-  (JNIEnv *, jobject, jstring, jint);\n",
        "-\n",
        "-/*\n",
        "- * Class:     com_huawei_flclient_Train\n",
        "- * Method:    prepare\n",
        "- * Signature: ()I\n",
        "- */\n",
        "-JNIEXPORT jint JNICALL Java_com_huawei_flclient_Train_prepare\n",
        "-  (JNIEnv *, jobject);\n",
        "-\n",
        "-/*\n",
        "- * Class:     com_huawei_flclient_Train\n",
        "- * Method:    Inference\n",
        "- * Signature: ()I\n",
        "- */\n",
        "-JNIEXPORT jint JNICALL Java_com_huawei_flclient_Train_inference\n",
        "-  (JNIEnv *, jobject);\n",
        "-\n",
        "-/*\n",
        "- * Class:     com_huawei_flclient_Train\n",
        "- * Method:    Train\n",
        "- * Signature: (II)I\n",
        "- */\n",
        "-JNIEXPORT jint JNICALL Java_com_huawei_flclient_Train_train\n",
        "-  (JNIEnv *, jobject, jint, jint);\n",
        "-\n",
        "-/*\n",
        "- * Class:     com_huawei_flclient_Train\n",
        "- * Method:    getFeaturesMap\n",
        "- * Signature: (Lcom/google/flatbuffers/FlatBufferBuilder;)[I\n",
        "- */\n",
        "-JNIEXPORT jintArray JNICALL Java_com_huawei_flclient_Train_getFeaturesMap\n",
        "-  (JNIEnv *, jobject, jobject);\n",
        "-\n",
        "-/*\n",
        "- * Class:     com_huawei_flclient_Train\n",
        "- * Method:    updateFeatures\n",
        "- * Signature: (Ljava/util/ArrayList;)I\n",
        "- */\n",
        "-JNIEXPORT jint JNICALL Java_com_huawei_flclient_Train_updateFeatures\n",
        "-  (JNIEnv *, jobject, jobject);\n",
        "-\n",
        "-/*\n",
        "- * Class:     com_huawei_flclient_Train\n",
        "- * Method:    free\n",
        "- * Signature: ()I\n",
        "- */\n",
        "-JNIEXPORT jint JNICALL Java_com_huawei_flclient_Train_free\n",
        "-  (JNIEnv *, jobject);\n",
        "-\n",
        "-#ifdef __cplusplus\n",
        "-}\n",
        "-#endif\n",
        "-#endif\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/data_prepare.cpp b/mindspore/lite/flclient/src/main/native/data_prepare.cpp\n",
        "new file mode 100644\n",
        "index 0000000..c8a1b5e\n",
        "--- /dev/null\n",
        "+++ b/mindspore/lite/flclient/src/main/native/data_prepare.cpp\n",
        "@@ -0,0 +1,517 @@\n",
        "+/**\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "+ *\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "+ * you may not use this file except in compliance with the License.\n",
        "+ * You may obtain a copy of the License at\n",
        "+ *\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\n",
        "+ *\n",
        "+ * Unless required by applicable law or agreed to in writing, software\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "+ * See the License for the specific language governing permissions and\n",
        "+ * limitations under the License.\n",
        "+ */\n",
        "+\n",
        "+\n",
        "+#include <fstream>\n",
        "+#include <iostream>\n",
        "+#include <cstdio>\n",
        "+#include <vector>\n",
        "+#include <map>\n",
        "+#include <ctime>\n",
        "+//#include <cstring>\n",
        "+//#include <algorithm>\n",
        "+//#include <cstdlib>\n",
        "+using namespace std;\n",
        "+#define MAX_SEQ_LENGTH 256\n",
        "+\n",
        "+class CustomizedTokenizer\n",
        "+{\n",
        "+ public:\n",
        "+  CustomizedTokenizer();\n",
        "+  ~CustomizedTokenizer();\n",
        "+\n",
        "+  void init(const string &vocab_file, bool do_lower_case);\n",
        "+  void tokenize(const string &text, string output_tokens[MAX_SEQ_LENGTH], int &seq_length);\n",
        "+  void tokenize(const string &text, int input_ids[MAX_SEQ_LENGTH],\n",
        "+                int attention_mask[MAX_SEQ_LENGTH], int token_type_ids[MAX_SEQ_LENGTH], int &seq_length);\n",
        "+\n",
        "+//private:\n",
        "+  string _text;\n",
        "+  string _tokens[MAX_SEQ_LENGTH];\n",
        "+  int _tokens_length = 0;\n",
        "+  int _text_length = 0;\n",
        "+\n",
        "+  map<string, int> _vocab;\n",
        "+  bool _do_lower_case = true;\n",
        "+  int _max_input_chars_per_word = 100;\n",
        "+\n",
        "+  static void _lower_token(const string &token, string &new_token);\n",
        "+  void _split_text();\n",
        "+  void _clean_text();\n",
        "+  void _fixed_matching(int &pos, string &token);\n",
        "+  void _load_vocab(const string &vocab_file);\n",
        "+};\n",
        "+\n",
        "+CustomizedTokenizer::CustomizedTokenizer() = default;\n",
        "+\n",
        "+CustomizedTokenizer::~CustomizedTokenizer() {\n",
        "+  _vocab.clear();\n",
        "+}\n",
        "+\n",
        "+void CustomizedTokenizer::init(const string &vocab_file, bool do_lower_case) {\n",
        "+  _do_lower_case = do_lower_case;\n",
        "+  _load_vocab(vocab_file);\n",
        "+}\n",
        "+\n",
        "+void CustomizedTokenizer::tokenize(const string &text, string output_tokens[MAX_SEQ_LENGTH], int &seq_length) {\n",
        "+//  clock_t startTime;\n",
        "+//  double time_cost = 0.0;\n",
        "+  _text = text;\n",
        "+  _split_text();\n",
        "+\n",
        "+  int output_tokens_pos = 0;\n",
        "+\n",
        "+//  startTime = clock();\n",
        "+  for (int i = 0; i < _tokens_length; ++i) {\n",
        "+    int length = _tokens[i].length();\n",
        "+    if (length > _max_input_chars_per_word) {\n",
        "+      output_tokens[output_tokens_pos] = \"[UNK]\";\n",
        "+      output_tokens_pos++;\n",
        "+      if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "+        _tokens_length = 0;\n",
        "+        output_tokens[MAX_SEQ_LENGTH - 1] = \"[SEP]\";\n",
        "+        return;\n",
        "+      }\n",
        "+      continue;\n",
        "+    }\n",
        "+\n",
        "+    bool is_bad = false;\n",
        "+    int start = 0;\n",
        "+    vector<string> sub_tokens;\n",
        "+    while (start < length) {\n",
        "+      int end = length;\n",
        "+      string cur_substr;\n",
        "+      while (start < end) {\n",
        "+        string substr = _tokens[i].substr(start, end - start);\n",
        "+        if (start > 0) {\n",
        "+          substr.insert(0,\"##\");\n",
        "+        }\n",
        "+        if (_vocab.find(substr) != _vocab.end()) {\n",
        "+          cur_substr = substr;\n",
        "+          break;\n",
        "+        }\n",
        "+        end--;\n",
        "+      }\n",
        "+      if (cur_substr.empty()) {\n",
        "+        is_bad = true;\n",
        "+        break;\n",
        "+      }\n",
        "+      sub_tokens.emplace_back(cur_substr);\n",
        "+      start = end;\n",
        "+    }\n",
        "+    if (is_bad) {\n",
        "+      output_tokens[output_tokens_pos] = \"[UNK]\";\n",
        "+      output_tokens_pos++;\n",
        "+      if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "+        _tokens_length = 0;\n",
        "+        output_tokens[MAX_SEQ_LENGTH - 1] = \"[SEP]\";\n",
        "+        return;\n",
        "+      }\n",
        "+    } else {\n",
        "+      for (const string& sub_token: sub_tokens) {\n",
        "+        output_tokens[output_tokens_pos] = sub_token;\n",
        "+        output_tokens_pos++;\n",
        "+        if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "+          _tokens_length = 0;\n",
        "+          output_tokens[MAX_SEQ_LENGTH - 1] = \"[SEP]\";\n",
        "+          return;\n",
        "+        }\n",
        "+      }\n",
        "+    }\n",
        "+  }\n",
        "+\n",
        "+  output_tokens[output_tokens_pos] = \"[SEP]\";\n",
        "+  for (int i = output_tokens_pos + 1; i < MAX_SEQ_LENGTH; ++i) {\n",
        "+    output_tokens[i] = \"[PAD]\";\n",
        "+  }\n",
        "+//  time_cost += (double)(clock() - startTime) / CLOCKS_PER_SEC;\n",
        "+  _tokens_length = 0;\n",
        "+\n",
        "+//  cout << \"Local run time is: \" << time_cost << endl;\n",
        "+}\n",
        "+\n",
        "+void CustomizedTokenizer::tokenize(const string &text, int input_ids[MAX_SEQ_LENGTH],\n",
        "+                                   int attention_mask[MAX_SEQ_LENGTH], int token_type_ids[MAX_SEQ_LENGTH],\n",
        "+                                   int &seq_length) {\n",
        "+//  clock_t startTime;\n",
        "+//  double time_cost = 0.0;\n",
        "+  _text = text;\n",
        "+  _split_text();\n",
        "+\n",
        "+  int output_tokens_pos = 0;\n",
        "+\n",
        "+//  startTime = clock();\n",
        "+  for (int i = 0; i < _tokens_length; ++i) {\n",
        "+    int length = _tokens[i].length();\n",
        "+    if (length > _max_input_chars_per_word) {\n",
        "+      input_ids[output_tokens_pos] = _vocab[\"[UNK]\"];\n",
        "+      attention_mask[output_tokens_pos] = 1;\n",
        "+      token_type_ids[output_tokens_pos] = 0;\n",
        "+      output_tokens_pos++;\n",
        "+      if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "+        _tokens_length = 0;\n",
        "+        input_ids[MAX_SEQ_LENGTH - 1] = _vocab[\"[SEP]\"];\n",
        "+        attention_mask[MAX_SEQ_LENGTH - 1] = 1;\n",
        "+        token_type_ids[MAX_SEQ_LENGTH - 1] = 0;\n",
        "+        return;\n",
        "+      }\n",
        "+      continue;\n",
        "+    }\n",
        "+\n",
        "+    bool is_bad = false;\n",
        "+    int start = 0;\n",
        "+    vector<string> sub_tokens;\n",
        "+    while (start < length) {\n",
        "+      int end = length;\n",
        "+      string cur_substr;\n",
        "+      while (start < end) {\n",
        "+        string substr = _tokens[i].substr(start, end - start);\n",
        "+        if (start > 0) {\n",
        "+          substr.insert(0,\"##\");\n",
        "+        }\n",
        "+        if (_vocab.find(substr) != _vocab.end()) {\n",
        "+          cur_substr = substr;\n",
        "+          break;\n",
        "+        }\n",
        "+        end--;\n",
        "+      }\n",
        "+      if (cur_substr.empty()) {\n",
        "+        is_bad = true;\n",
        "+        break;\n",
        "+      }\n",
        "+      sub_tokens.emplace_back(cur_substr);\n",
        "+      start = end;\n",
        "+    }\n",
        "+    if (is_bad) {\n",
        "+      input_ids[output_tokens_pos] = _vocab[\"[UNK]\"];\n",
        "+      attention_mask[output_tokens_pos] = 1;\n",
        "+      token_type_ids[output_tokens_pos] = 0;\n",
        "+      output_tokens_pos++;\n",
        "+      if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "+        _tokens_length = 0;\n",
        "+        input_ids[MAX_SEQ_LENGTH - 1] = _vocab[\"[SEP]\"];\n",
        "+        attention_mask[MAX_SEQ_LENGTH - 1] = 1;\n",
        "+        token_type_ids[MAX_SEQ_LENGTH - 1] = 0;\n",
        "+        return;\n",
        "+      }\n",
        "+    } else {\n",
        "+      for (const string& sub_token: sub_tokens) {\n",
        "+        input_ids[output_tokens_pos] = _vocab[sub_token];\n",
        "+        attention_mask[output_tokens_pos] = 1;\n",
        "+        token_type_ids[output_tokens_pos] = 0;\n",
        "+        output_tokens_pos++;\n",
        "+        if (MAX_SEQ_LENGTH <= output_tokens_pos) {\n",
        "+          _tokens_length = 0;\n",
        "+          input_ids[MAX_SEQ_LENGTH - 1] = _vocab[\"[SEP]\"];\n",
        "+          attention_mask[MAX_SEQ_LENGTH - 1] = 1;\n",
        "+          token_type_ids[MAX_SEQ_LENGTH - 1] = 0;\n",
        "+          return;\n",
        "+        }\n",
        "+      }\n",
        "+    }\n",
        "+  }\n",
        "+//  time_cost += (double)(clock() - startTime) / CLOCKS_PER_SEC;\n",
        "+  input_ids[output_tokens_pos] = _vocab[\"[SEP]\"];\n",
        "+  attention_mask[output_tokens_pos] = 1;\n",
        "+  token_type_ids[output_tokens_pos] = 0;\n",
        "+  for (int i = output_tokens_pos + 1; i < MAX_SEQ_LENGTH; ++i) {\n",
        "+    input_ids[i] = 0;\n",
        "+    attention_mask[i] = 0;\n",
        "+    token_type_ids[i] = 0;\n",
        "+  }\n",
        "+  _tokens_length = 0;\n",
        "+\n",
        "+//  cout << \"Local run time is: \" << time_cost << endl;\n",
        "+}\n",
        "+\n",
        "+void CustomizedTokenizer::_lower_token(const string &token, string &new_token) {\n",
        "+  int length = token.length();\n",
        "+  if (token[0] == '[') {\n",
        "+    if (length == 5) {\n",
        "+      if (token[4] == ']') {\n",
        "+        if (token[1] == 'U' && token[2] == 'N' && token[3] == 'K') {\n",
        "+          new_token = token;\n",
        "+          return;\n",
        "+        }\n",
        "+        if (token[1] == 'S' && token[2] == 'E' && token[3] == 'P') {\n",
        "+          new_token = token;\n",
        "+          return;\n",
        "+        }\n",
        "+        if (token[1] == 'P' && token[2] == 'A' && token[3] == 'D') {\n",
        "+          new_token = token;\n",
        "+          return;\n",
        "+        }\n",
        "+        if (token[1] == 'C' && token[2] == 'L' && token[3] == 'S') {\n",
        "+          new_token = token;\n",
        "+          return;\n",
        "+        }\n",
        "+      }\n",
        "+    }\n",
        "+    if (length == 6) {\n",
        "+      if (token[1] == 'M' && token[2] == 'A' && token[3] == 'S' && token[4] == 'K' && token[5] == ']') {\n",
        "+        new_token = token;\n",
        "+        return;\n",
        "+      }\n",
        "+    }\n",
        "+  }\n",
        "+\n",
        "+  for (char ch: token) {\n",
        "+    if (ch <= 90 && ch >= 65) {\n",
        "+      new_token += char(ch + 32);\n",
        "+    } else {\n",
        "+      new_token += ch;\n",
        "+    }\n",
        "+  }\n",
        "+}\n",
        "+\n",
        "+void CustomizedTokenizer::_clean_text() {\n",
        "+  int pos;\n",
        "+  pos = _text.find(\"\\u00A0\");\n",
        "+  while (pos > 0) {\n",
        "+    _text = _text.replace(pos, 2, \" \");\n",
        "+    pos = _text.find(\"\\u00A0\");\n",
        "+  }\n",
        "+  pos = _text.find(\"\\u2800\");\n",
        "+  while (pos > 0) {\n",
        "+    _text = _text.replace(pos, 3, \" \");\n",
        "+    pos = _text.find(\"\\u2800\");\n",
        "+  }\n",
        "+  pos = _text.find(\"\\u3000\");\n",
        "+  while (pos > 0) {\n",
        "+    _text = _text.replace(pos, 3, \" \");\n",
        "+    pos = _text.find(\"\\u3000\");\n",
        "+  }\n",
        "+  pos = _text.find(\"\\ufeff\");\n",
        "+  while (pos > 0) {\n",
        "+    _text = _text.replace(pos, 3, \"\");\n",
        "+    pos = _text.find(\"\\ufeff\");\n",
        "+  }\n",
        "+  pos = _text.find(\"\\ue312\");\n",
        "+  while (pos > 0) {\n",
        "+    _text = _text.replace(pos, 3, \"\");\n",
        "+    pos = _text.find(\"\\ue312\");\n",
        "+  }\n",
        "+}\n",
        "+\n",
        "+void CustomizedTokenizer::_load_vocab(const string &vocab_file) {\n",
        "+  int index = 0;\n",
        "+  fstream fin;\n",
        "+  fin.open(vocab_file, ios::in);\n",
        "+  if (fin.is_open()) {\n",
        "+    string basicString;\n",
        "+    while (!fin.eof()) {\n",
        "+      getline(fin, basicString, '\\n');\n",
        "+      if (!basicString.empty()) {\n",
        "+        _vocab[basicString] = index;\n",
        "+      }\n",
        "+      index++;\n",
        "+    }\n",
        "+    fin.close();\n",
        "+  }\n",
        "+}\n",
        "+\n",
        "+void CustomizedTokenizer::_fixed_matching(int &pos, string &token) {\n",
        "+  token += _text[pos];\n",
        "+  int rest_length = _text_length - pos;\n",
        "+  if (rest_length < 2) {\n",
        "+    pos++;\n",
        "+    return;\n",
        "+  }\n",
        "+  if (_text[pos] == char(-16)) {\n",
        "+    if (rest_length < 4) {\n",
        "+      pos++;\n",
        "+      return;\n",
        "+    }\n",
        "+    if (_text[pos+1] < char(0) && _text[pos+2] < char(0) && _text[pos+3] < char(0)) {\n",
        "+      token += _text[pos+1];\n",
        "+      token += _text[pos+2];\n",
        "+      token += _text[pos+3];\n",
        "+      pos += 4;\n",
        "+      return;\n",
        "+    }\n",
        "+    pos++;\n",
        "+    return;\n",
        "+  }\n",
        "+  if (_text[pos] >= char(-62) && _text[pos] <= char(-37)) {\n",
        "+    if (_text[pos+1] < char(0)) {\n",
        "+      token += _text[pos+1];\n",
        "+      pos += 2;\n",
        "+      return;\n",
        "+    }\n",
        "+    pos++;\n",
        "+    return;\n",
        "+  }\n",
        "+  if (rest_length < 3) {\n",
        "+    pos++;\n",
        "+    return;\n",
        "+  }\n",
        "+  if (_text[pos+1] < char(0) && _text[pos+2] < char(0)) {\n",
        "+    token += _text[pos+1];\n",
        "+    token += _text[pos+2];\n",
        "+    pos += 3;\n",
        "+    return;\n",
        "+  }\n",
        "+  pos++;\n",
        "+}\n",
        "+\n",
        "+void CustomizedTokenizer::_split_text() {\n",
        "+  // Performs invalid character removal and whitespace cleanup on text.\n",
        "+  _clean_text();\n",
        "+  _text_length = _text.length();\n",
        "+  int pos = 0;\n",
        "+  string token;\n",
        "+  _tokens[_tokens_length++] = \"[CLS]\";\n",
        "+  while (pos < _text_length) {\n",
        "+    if (_tokens_length == MAX_SEQ_LENGTH) {\n",
        "+      break;\n",
        "+    }\n",
        "+    if (_text[pos] == ' ') {\n",
        "+      if (!token.empty()) {\n",
        "+        if (token[0] >= char(0) && _do_lower_case) {\n",
        "+          string new_token;\n",
        "+          _lower_token(token, new_token);\n",
        "+          _tokens[_tokens_length++] = new_token;\n",
        "+        } else {\n",
        "+          _tokens[_tokens_length++] = token;\n",
        "+        }\n",
        "+        token.clear();\n",
        "+      }\n",
        "+      pos++;\n",
        "+      continue;\n",
        "+    }\n",
        "+    // We treat all non-letter/number ASCII as punctuation.\n",
        "+    // Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
        "+    // Punctuation class but we treat them as punctuation anyways, for\n",
        "+    // consistency.\n",
        "+    if ((_text[pos] >= char(33) && _text[pos] <= char(47)) ||\n",
        "+      (_text[pos] >= char(58) && _text[pos] <= char(64)) ||\n",
        "+      (_text[pos] >= char(91) && _text[pos] <= char(96)) ||\n",
        "+      (_text[pos] >= char(123) && _text[pos] <= char(126))\n",
        "+      ) {\n",
        "+      if (!token.empty()) {\n",
        "+        if (token[0] >= char(0) && _do_lower_case) {\n",
        "+          string new_token;\n",
        "+          _lower_token(token, new_token);\n",
        "+          _tokens[_tokens_length++] = new_token;\n",
        "+        } else {\n",
        "+          _tokens[_tokens_length++] = token;\n",
        "+        }\n",
        "+        token.clear();\n",
        "+      }\n",
        "+      if (_text[pos] == char(91)) {\n",
        "+        if (pos < _text_length - 4) {\n",
        "+          if (_text[pos+1] == 'S' && _text[pos+2] == 'E' && _text[pos+3] == 'P' && _text[pos+4] == ']') {\n",
        "+            _tokens[_tokens_length++] = \"[SEP]\";\n",
        "+            pos += 5;\n",
        "+            continue;\n",
        "+          }\n",
        "+          if (_text[pos+1] == 'U' && _text[pos+2] == 'N' && _text[pos+3] == 'K' && _text[pos+4] == ']') {\n",
        "+            _tokens[_tokens_length++] = \"[UNK]\";\n",
        "+            pos += 5;\n",
        "+            continue;\n",
        "+          }\n",
        "+          if (_text[pos+1] == 'P' && _text[pos+2] == 'A' && _text[pos+3] == 'D' && _text[pos+4] == ']') {\n",
        "+            _tokens[_tokens_length++] = \"[PAD]\";\n",
        "+            pos += 5;\n",
        "+            continue;\n",
        "+          }\n",
        "+          if (_text[pos+1] == 'C' && _text[pos+2] == 'L' && _text[pos+3] == 'S' && _text[pos+4] == ']') {\n",
        "+            _tokens[_tokens_length++] = \"[CLS]\";\n",
        "+            pos += 5;\n",
        "+            continue;\n",
        "+          }\n",
        "+        }\n",
        "+        if (pos < _text_length - 5) {\n",
        "+          if (_text[pos+1] == 'M' && _text[pos+2] == 'A' && _text[pos+3] == 'S' && _text[pos+4] == 'K' &&\n",
        "+            _text[pos+5] == ']') {\n",
        "+            _tokens[_tokens_length++] = \"[MASK]\";\n",
        "+            pos += 6;\n",
        "+            continue;\n",
        "+          }\n",
        "+        }\n",
        "+      }\n",
        "+      string temp = {_text[pos]};\n",
        "+      _tokens[_tokens_length++] = temp;\n",
        "+      pos++;\n",
        "+      continue;\n",
        "+    }\n",
        "+    if (_text[pos] < char(0)) {\n",
        "+      if (!token.empty()) {\n",
        "+        if (token[0] >= char(0) && _do_lower_case) {\n",
        "+          string new_token;\n",
        "+          _lower_token(token, new_token);\n",
        "+          _tokens[_tokens_length++] = new_token;\n",
        "+        } else {\n",
        "+          _tokens[_tokens_length++] = token;\n",
        "+        }\n",
        "+        token.clear();\n",
        "+      }\n",
        "+      _fixed_matching(pos, token);\n",
        "+      _tokens[_tokens_length++] = token;\n",
        "+      token.clear();\n",
        "+    } else {\n",
        "+      token += _text[pos];\n",
        "+      pos++;\n",
        "+    }\n",
        "+  }\n",
        "+  if (!token.empty()) {\n",
        "+    if (token[0] >= char(0) && _do_lower_case) {\n",
        "+      string new_token;\n",
        "+      _lower_token(token, new_token);\n",
        "+      _tokens[_tokens_length++] = new_token;\n",
        "+    } else {\n",
        "+      _tokens[_tokens_length++] = token;\n",
        "+    }\n",
        "+  }\n",
        "+}\n",
        "+\n",
        "+int main()\n",
        "+{\n",
        "+  cout << \"-----------\" << endl;\n",
        "+  string vocab_file = \"/home/lizheng/tcwu/model_save/nlp/albert_chinese_tiny/vocab.txt\";\n",
        "+  bool do_lower_case = true;\n",
        "+  CustomizedTokenizer customized_tokenizer;\n",
        "+  customized_tokenizer.init(vocab_file, do_lower_case);\n",
        "+  clock_t startTime = clock();\n",
        "+\n",
        "+  string text = \"\";\n",
        "+  string tokens[MAX_SEQ_LENGTH];\n",
        "+  int input_ids[MAX_SEQ_LENGTH];\n",
        "+  int attention_mask[MAX_SEQ_LENGTH];\n",
        "+  int token_type_ids[MAX_SEQ_LENGTH];\n",
        "+  int seq_length;\n",
        "+  for (int i = 0; i < 10000; ++i) {\n",
        "+    customized_tokenizer.tokenize(text, input_ids, attention_mask, token_type_ids, seq_length);\n",
        "+//    for (int input_id : input_ids) {\n",
        "+//      cout << input_id << ' ';\n",
        "+//    }\n",
        "+//    cout << endl;\n",
        "+//    for (int j : attention_mask) {\n",
        "+//      cout << j << ' ';\n",
        "+//    }\n",
        "+//    cout << endl;\n",
        "+//    for (int token_type_id : token_type_ids) {\n",
        "+//      cout << token_type_id << ' ';\n",
        "+//    }\n",
        "+//    cout << endl;\n",
        "+\n",
        "+    if (i == 1)\n",
        "+      break;\n",
        "+  }\n",
        "+  cout << \"The run time is: \" << (double)(clock() - startTime) / CLOCKS_PER_SEC << endl;\n",
        "+  cout << \"-----------\" << endl;\n",
        "+  return 0;\n",
        "+}\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/lenet_train_jni.cpp b/mindspore/lite/flclient/src/main/native/lenet_train_jni.cpp\n",
        "deleted file mode 100644\n",
        "index db070c0..0000000\n",
        "--- a/mindspore/lite/flclient/src/main/native/lenet_train_jni.cpp\n",
        "+++ /dev/null\n",
        "@@ -1,157 +0,0 @@\n",
        "-/**\n",
        "- * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "- *\n",
        "- * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "- * you may not use this file except in compliance with the License.\n",
        "- * You may obtain a copy of the License at\n",
        "- *\n",
        "- * http://www.apache.org/licenses/LICENSE-2.0\n",
        "- *\n",
        "- * Unless required by applicable law or agreed to in writing, software\n",
        "- * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "- * See the License for the specific language governing permissions and\n",
        "- * limitations under the License.\n",
        "- */\n",
        "-\n",
        "-#include <lenet_train_jni.h>\n",
        "-#include <jni.h>\n",
        "-#include <cstring>\n",
        "-#include \"include/errorcode.h\"\n",
        "-#include \"include/train_session.h\"\n",
        "-#include \"include/lenet_train.h\"\n",
        "-#include \"src/common/log_adapter.h\"\n",
        "-\n",
        "-static jobject fbb;\n",
        "-static jmethodID create_string_char;\n",
        "-\n",
        "-char *JstringToChar(JNIEnv *env, jstring jstr) {\n",
        "-  char *rtn = nullptr;\n",
        "-  jclass clsstring = env->FindClass(\"java/lang/String\");\n",
        "-  jstring strencode = env->NewStringUTF(\"GB2312\");\n",
        "-  jmethodID mid = env->GetMethodID(clsstring, \"getBytes\", \"(Ljava/lang/String;)[B\");\n",
        "-  jbyteArray barr = (jbyteArray)env->CallObjectMethod(jstr, mid, strencode);\n",
        "-  jsize alen = env->GetArrayLength(barr);\n",
        "-  jbyte *ba = env->GetByteArrayElements(barr, JNI_FALSE);\n",
        "-  if (alen > 0) {\n",
        "-    rtn = new char[alen + 1];\n",
        "-    memcpy(rtn, ba, alen);\n",
        "-    rtn[alen] = 0;\n",
        "-  }\n",
        "-  env->ReleaseByteArrayElements(barr, ba, 0);\n",
        "-  return rtn;\n",
        "-}\n",
        "-extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_train(JNIEnv *env, jobject thiz, jstring ms_file,\n",
        "-                                                                           jint batch_num, jint iterations) {\n",
        "-  return fl_lenet_lite_Train(JstringToChar(env, ms_file), batch_num, iterations);\n",
        "-}\n",
        "-\n",
        "-extern \"C\" jint CreateFeatureMap(JNIEnv *env, const char *name, float *data, size_t size) {\n",
        "-  jstring name1 = env->NewStringUTF(name);\n",
        "-  jint name_offset = env->CallIntMethod(fbb, create_string_char, name1);\n",
        "-  // 1. set data size\n",
        "-  jfloatArray ret = env->NewFloatArray(size);\n",
        "-  env->SetFloatArrayRegion(ret, 0, size, data);\n",
        "-  // 2. get methodid createDataVector\n",
        "-  jclass fm_cls = env->FindClass(\"mindspore/schema/FeatureMap\");\n",
        "-  jmethodID createDataVector =\n",
        "-    env->GetStaticMethodID(fm_cls, \"createDataVector\", \"(Lcom/google/flatbuffers/FlatBufferBuilder;[F)I\");\n",
        "-  // 3. calc data offset\n",
        "-  jint data_offset = env->CallStaticIntMethod(fm_cls, createDataVector, fbb, ret);\n",
        "-  jmethodID createFeatureMap =\n",
        "-    env->GetStaticMethodID(fm_cls, \"createFeatureMap\", \"(Lcom/google/flatbuffers/FlatBufferBuilder;II)I\");\n",
        "-  jint fm_offset = env->CallStaticIntMethod(fm_cls, createFeatureMap, fbb, name_offset, data_offset);\n",
        "-  return fm_offset;\n",
        "-}\n",
        "-\n",
        "-extern \"C\" JNIEXPORT jintArray JNICALL Java_com_huawei_flclient_LiteTrain_getFeaturesMap(JNIEnv *env, jobject thiz,\n",
        "-                                                                                         jstring ms_file,\n",
        "-                                                                                         jobject builder) {\n",
        "-  fbb = builder;\n",
        "-  jclass fb_clazz = env->GetObjectClass(builder);\n",
        "-  create_string_char = env->GetMethodID(fb_clazz, \"createString\", \"(Ljava/lang/CharSequence;)I\");\n",
        "-  TrainFeatureParam **train_features = nullptr;\n",
        "-  int feature_size = 0;\n",
        "-  auto status = fl_lenet_lite_GetFeatures(JstringToChar(env, ms_file), &train_features, &feature_size);\n",
        "-  if (status != mindspore::lite::RET_OK) {\n",
        "-    MS_LOG(ERROR) << \"get features failed:\" << ms_file;\n",
        "-    return env->NewIntArray(0);\n",
        "-  }\n",
        "-  jintArray ret = env->NewIntArray(feature_size);\n",
        "-  jint *data = env->GetIntArrayElements(ret, NULL);\n",
        "-\n",
        "-  for (int i = 0; i < feature_size; i++) {\n",
        "-    data[i] = CreateFeatureMap(env, train_features[i]->name, reinterpret_cast<float *>(train_features[i]->data),\n",
        "-                               train_features[i]->elenums);\n",
        "-    MS_LOG(INFO) << \"upload feature:\"\n",
        "-                 << \", name:\" << train_features[i]->name << \", elenums:\" << train_features[i]->elenums;\n",
        "-  }\n",
        "-  env->ReleaseIntArrayElements(ret, data, 0);\n",
        "-  for (int i = 0; i < feature_size; i++) {\n",
        "-    delete train_features[i];\n",
        "-  }\n",
        "-  return ret;\n",
        "-}\n",
        "-\n",
        "-extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_updateFeatures(JNIEnv *env, jobject,\n",
        "-                                                                                    jstring ms_file, jobject features) {\n",
        "-  jclass arr_cls = env->GetObjectClass(features);\n",
        "-  jmethodID size_method = env->GetMethodID(arr_cls, \"size\", \"()I\");\n",
        "-  jmethodID get_method = env->GetMethodID(arr_cls, \"get\", \"(I)Ljava/lang/Object;\");\n",
        "-\n",
        "-  jclass fm_cls = env->FindClass(\"mindspore/schema/FeatureMap\");\n",
        "-  jmethodID weight_name_method = env->GetMethodID(fm_cls, \"weightFullname\", \"()Ljava/lang/String;\");\n",
        "-  jmethodID data_length_method = env->GetMethodID(fm_cls, \"dataLength\", \"()I\");\n",
        "-  jmethodID data_method = env->GetMethodID(fm_cls, \"data\", \"(I)F\");\n",
        "-  jclass clsstring = env->FindClass(\"java/lang/String\");\n",
        "-  jmethodID mid = env->GetMethodID(clsstring, \"getBytes\", \"(Ljava/lang/String;)[B\");\n",
        "-  int size = env->CallIntMethod(features, size_method);\n",
        "-  // transform FeatureMap to TrainFeatureParm\n",
        "-  TrainFeatureParam *features_param = reinterpret_cast<TrainFeatureParam *>(malloc(size * sizeof(TrainFeatureParam)));\n",
        "-  for (int i = 0; i < size; ++i) {\n",
        "-    TrainFeatureParam *param = features_param + i;\n",
        "-    jobject feature = env->CallObjectMethod(features, get_method, i);\n",
        "-    // set feature_param name\n",
        "-    jstring weight_full_name = (jstring)env->CallObjectMethod(feature, weight_name_method);\n",
        "-    jstring strencode = env->NewStringUTF(\"GB2312\");\n",
        "-    jbyteArray barr = (jbyteArray)env->CallObjectMethod(weight_full_name, mid, strencode);\n",
        "-    char *name = nullptr;\n",
        "-    jsize alen = env->GetArrayLength(barr);\n",
        "-    jbyte *ba = env->GetByteArrayElements(barr, JNI_FALSE);\n",
        "-    if (alen > 0) {\n",
        "-      name = new char[alen + 1];\n",
        "-      if (ba == nullptr) {\n",
        "-        MS_LOG(ERROR) << \"name is nullptr\";\n",
        "-        return mindspore::lite::RET_ERROR;\n",
        "-      }\n",
        "-      memcpy(name, ba, alen);\n",
        "-      name[alen] = 0;\n",
        "-    }\n",
        "-    param->name = name;\n",
        "-    env->ReleaseByteArrayElements(barr, ba, 0);\n",
        "-    int data_length = env->CallIntMethod(feature, data_length_method);\n",
        "-    float *data = static_cast<float *>(malloc(data_length * sizeof(float)));\n",
        "-    memset(data, 0, data_length * sizeof(float));\n",
        "-    for (int j = 0; j < data_length; ++j) {\n",
        "-      float *addr = data + j;\n",
        "-      *addr = env->CallFloatMethod(feature, data_method, j);\n",
        "-    }\n",
        "-    param->data = data;\n",
        "-    param->elenums = data_length;\n",
        "-    param->type = mindspore::kNumberTypeFloat32;\n",
        "-    MS_LOG(INFO) << \"get feature:\" << param->name << \",elenums:\" << param->elenums;\n",
        "-  }\n",
        "-  return fl_lenet_lite_UpdateFeatures(JstringToChar(env, ms_file), features_param, size);\n",
        "-}\n",
        "-\n",
        "-extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_setInput(JNIEnv *env, jobject, jstring files,\n",
        "-                                                                              jint nums) {\n",
        "-  return fl_lenet_lite_SetInputs(JstringToChar(env, files), nums);\n",
        "-}\n",
        "-\n",
        "-extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_inference(JNIEnv *env, jobject, jstring ms_file,\n",
        "-                                                                               jint batch_num, jint test_nums) {\n",
        "-  return fl_lenet_lite_Inference(JstringToChar(env, ms_file), batch_num, test_nums);\n",
        "-}\n",
        "-\n",
        "-extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_free(JNIEnv *, jobject) { return 0; }\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/lite_train.cpp b/mindspore/lite/flclient/src/main/native/lite_train.cpp\n",
        "new file mode 100644\n",
        "index 0000000..5c940b6\n",
        "--- /dev/null\n",
        "+++ b/mindspore/lite/flclient/src/main/native/lite_train.cpp\n",
        "@@ -0,0 +1,287 @@\n",
        "+/**\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "+ *\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "+ * you may not use this file except in compliance with the License.\n",
        "+ * You may obtain a copy of the License at\n",
        "+ *\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\n",
        "+ *\n",
        "+ * Unless required by applicable law or agreed to in writing, software\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "+ * See the License for the specific language governing permissions and\n",
        "+ * limitations under the License.\n",
        "+ */\n",
        "+#include \"lite_train.h\"\n",
        "+#include <cstring>\n",
        "+#include <fstream>\n",
        "+#include <iostream>\n",
        "+#include \"include/context.h\"\n",
        "+#include \"include/errorcode.h\"\n",
        "+#include \"src/common/log_adapter.h\"\n",
        "+#include <climits>\n",
        "+\n",
        "+//#include \"include/lenet_train.h\"\n",
        "+//#include <cstring>\n",
        "+//#include <fstream>\n",
        "+//#include <iostream>\n",
        "+//#include \"include/api/lite_context.h\"\n",
        "+//#include \"include/context.h\"\n",
        "+//#include \"include/errorcode.h\"\n",
        "+//#include \"src/common/log_adapter.h\"\n",
        "+//#include \"limits.h\"\n",
        "+\n",
        "+\n",
        "+static char *fl_lenet_I0 = 0;\n",
        "+static char *fl_lenet_I1 = 0;\n",
        "+unsigned int seed_ = time(NULL);\n",
        "+\n",
        "+std::vector<int> FillInputData(mindspore::session::TrainSession *train_session, int batch_num, int batch_idx,bool serially) {\n",
        "+  std::vector<int> labels_vec;\n",
        "+  auto inputs = train_session->GetInputs();\n",
        "+  int batch_size = inputs[0]->shape()[0];\n",
        "+  int data_size = inputs[0]->ElementsNum() / batch_size;\n",
        "+  int num_classes = inputs[1]->shape()[1];\n",
        "+  float* input_data = reinterpret_cast<float *>(inputs.at(0)->MutableData());\n",
        "+  auto labels = reinterpret_cast<float *>(inputs.at(1)->MutableData());\n",
        "+  std::fill(labels, labels + inputs.at(1)->ElementsNum(), 0.f);\n",
        "+  int label_idx = 0;\n",
        "+  int idx = 0;\n",
        "+  for (int i = 0; i < batch_size; i++) {\n",
        "+    if (serially) {\n",
        "+      idx = i;\n",
        "+      std::memcpy(input_data + i * data_size, (float*)fl_lenet_I0 + +batch_idx*inputs[0]->ElementsNum()+idx * data_size, data_size*sizeof(float));\n",
        "+      label_idx = *(reinterpret_cast<int *>(fl_lenet_I1) + batch_idx*batch_size+idx);\n",
        "+    } else {\n",
        "+      idx = rand_r(&seed_) % (batch_num*batch_size);\n",
        "+      std::memcpy(input_data + i * data_size, (float*)fl_lenet_I0 + idx * data_size, data_size*sizeof(float));\n",
        "+      label_idx = *(reinterpret_cast<int *>(fl_lenet_I1) + idx);\n",
        "+    }\n",
        "+    labels[i * num_classes + label_idx] = 1.0;  // Model expects labels in onehot representation\n",
        "+    labels_vec.push_back(label_idx);\n",
        "+  }\n",
        "+  return labels_vec;\n",
        "+}\n",
        "+\n",
        "+mindspore::tensor::MSTensor *SearchOutputsForSize(mindspore::session::TrainSession *train_session, size_t size) {\n",
        "+  auto outputs = train_session->GetOutputs();\n",
        "+  for (auto it = outputs.begin(); it != outputs.end(); ++it) {\n",
        "+    if (it->second->ElementsNum() == size) return it->second;\n",
        "+  }\n",
        "+  MS_LOG(ERROR) << \"Model does not have an output tensor with size:\"<<size;\n",
        "+  return nullptr;\n",
        "+}\n",
        "+\n",
        "+float GetLoss(mindspore::session::TrainSession *train_session) {\n",
        "+  auto outputsv = SearchOutputsForSize(train_session, 1);  // Search for Loss which is a single value tensor\n",
        "+  if (outputsv == nullptr) {\n",
        "+    return 10000;\n",
        "+  }\n",
        "+  auto loss = reinterpret_cast<float *>(outputsv->MutableData());\n",
        "+  return loss[0];\n",
        "+}\n",
        "+mindspore::session::TrainSession *GetSession(const std::string &ms_file, bool train_mode) {\n",
        "+  // create model file\n",
        "+  mindspore::lite::Context context;\n",
        "+  context.device_list_[0].device_info_.cpu_device_info_.cpu_bind_mode_ = mindspore::lite::NO_BIND;\n",
        "+  context.thread_num_ = 1;\n",
        "+  return mindspore::session::TrainSession::CreateSession(ms_file, &context, train_mode);\n",
        "+}\n",
        "+\n",
        "+float CalculateAccuracy(mindspore::session::TrainSession *session,const std::vector<int> &labels) {\n",
        "+  session->Eval();\n",
        "+  session->RunGraph();\n",
        "+  auto inputs = session->GetInputs();\n",
        "+  auto batch_size = inputs[1]->shape()[0];\n",
        "+  auto num_of_class = inputs[1]->shape()[1];\n",
        "+  auto outputsv = SearchOutputsForSize(session, batch_size * num_of_class);\n",
        "+  auto scores = reinterpret_cast<float *>(outputsv->MutableData());\n",
        "+  float accuracy = 0.0;\n",
        "+  for (int b = 0; b < batch_size; b++) {\n",
        "+    int max_idx = 0;\n",
        "+    float max_score = scores[num_of_class * b];\n",
        "+    for (int c = 0; c < num_of_class; c++) {\n",
        "+      if (scores[num_of_class * b + c] > max_score) {\n",
        "+        max_score = scores[num_of_class * b + c];\n",
        "+        max_idx = c;\n",
        "+      }\n",
        "+    }\n",
        "+    if (labels[b] == max_idx) accuracy += 1.0;\n",
        "+  }\n",
        "+  return accuracy/batch_size;\n",
        "+}\n",
        "+\n",
        "+\n",
        "+// net inference function\n",
        "+float fl_lite_Inference(const std::string &ms_file, int batch_num) {\n",
        "+  auto session = GetSession(ms_file, false);\n",
        "+  char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\n",
        "+  auto labels = FillInputData(session, batch_num,0, true);;\n",
        "+    auto infer_acc = CalculateAccuracy(session,labels);\n",
        "+    std::cout << \"inference acc is:\" << infer_acc << std::endl;\n",
        "+  fl_lenet_I0 = origin_input[0];\n",
        "+  fl_lenet_I1 = origin_input[1];\n",
        "+  return infer_acc;\n",
        "+}\n",
        "+\n",
        "+\n",
        "+// net training function\n",
        "+int fl_lite_Train(const std::string &ms_file, const int batch_num, const int iterations) {\n",
        "+  auto session = GetSession(ms_file, true);\n",
        "+  if (iterations <= 0) {\n",
        "+    MS_LOG(ERROR) << \"error iterations or epoch!, epoch:\"\n",
        "+                  << \", iterations\" << iterations;\n",
        "+    return mindspore::lite::RET_ERROR;\n",
        "+  }\n",
        "+  MS_LOG(INFO) << \"total iterations :\" << iterations << \"batch_num:\" << batch_num;\n",
        "+  char *origin_input[] = {fl_lenet_I0, fl_lenet_I1};\n",
        "+  for (int j = 0; j < iterations/batch_num; ++j) {\n",
        "+    float sum_loss_per_epoch = 0.0f;\n",
        "+    float sum_acc_per_epoch = 0.0f;\n",
        "+    for(int k=0;k<batch_num;++k) {\n",
        "+      auto lables = FillInputData(session, batch_num,k, true);\n",
        "+      session->RunGraph(nullptr, nullptr);\n",
        "+      sum_loss_per_epoch+=GetLoss(session);\n",
        "+      sum_acc_per_epoch += CalculateAccuracy(session,lables);\n",
        "+      session->Train();\n",
        "+    }\n",
        "+    std::cout << \"epoch \" << \"[\" <<j<<\"]\" << \",mean Loss \" << sum_loss_per_epoch/batch_num <<\",train acc \"<<  sum_acc_per_epoch/batch_num<<std::endl;\n",
        "+\n",
        "+  }\n",
        "+  session->SaveToFile(ms_file);\n",
        "+  fl_lenet_I0 = origin_input[0];\n",
        "+  fl_lenet_I1 = origin_input[1];\n",
        "+  return mindspore::lite::RET_OK;\n",
        "+}\n",
        "+\n",
        "+int fl_lite_UpdateFeatures(const std::string &update_ms_file, TrainFeatureParam *new_features, int size) {\n",
        "+  auto train_session = GetSession(update_ms_file, false);\n",
        "+  auto status = train_session->UpdateFeatureMaps(update_ms_file, new_features, size);\n",
        "+  if (status != mindspore::lite::RET_OK) {\n",
        "+    MS_LOG(ERROR) << \"update model feature map failed\" << update_ms_file;\n",
        "+  }\n",
        "+  delete train_session;\n",
        "+  return status;\n",
        "+}\n",
        "+\n",
        "+int fl_lite_GetFeatures(const std::string &update_ms_file, mindspore::session::TrainFeatureParam ***feature,\n",
        "+                              int *size) {\n",
        "+  auto train_session = GetSession(update_ms_file, false);\n",
        "+  std::vector<mindspore::session::TrainFeatureParam *> new_features;\n",
        "+  auto status = train_session->GetFeatureMaps(&new_features);\n",
        "+  if (status != mindspore::lite::RET_OK) {\n",
        "+    MS_LOG(ERROR) << \"get model feature map failed\" << update_ms_file;\n",
        "+    delete train_session;\n",
        "+    return mindspore::lite::RET_ERROR;\n",
        "+  }\n",
        "+  *feature = new (std::nothrow) TrainFeatureParam *[new_features.size()];\n",
        "+  if (*feature == nullptr) {\n",
        "+    MS_LOG(ERROR) << \"create features failed\";\n",
        "+    delete train_session;\n",
        "+    return mindspore::lite::RET_ERROR;\n",
        "+  }\n",
        "+  for (int i = 0; i < new_features.size(); i++) {\n",
        "+    (*feature)[i] = new_features[i];\n",
        "+  }\n",
        "+  *size = new_features.size();\n",
        "+  delete train_session;\n",
        "+  return mindspore::lite::RET_OK;\n",
        "+}\n",
        "+\n",
        "+std::string RealPath(const char *path) {\n",
        "+  if (path == nullptr) {\n",
        "+    MS_LOG(ERROR) << \"path is nullptr\";\n",
        "+    return \"\";\n",
        "+  }\n",
        "+  if ((strlen(path)) >= PATH_MAX) {\n",
        "+    MS_LOG(ERROR) << \"path is too long\";\n",
        "+    return \"\";\n",
        "+  }\n",
        "+  auto resolved_path = std::make_unique<char[]>(PATH_MAX);\n",
        "+  if (resolved_path == nullptr) {\n",
        "+    MS_LOG(ERROR) << \"new resolved_path failed\";\n",
        "+    return \"\";\n",
        "+  }\n",
        "+#ifdef _WIN32\n",
        "+  char *real_path = _fullpath(resolved_path.get(), path, 1024);\n",
        "+#else\n",
        "+  char *real_path = realpath(path, resolved_path.get());\n",
        "+#endif\n",
        "+  if (real_path == nullptr || strlen(real_path) == 0) {\n",
        "+    MS_LOG(ERROR) << \"file path is not valid : \" << path;\n",
        "+    return \"\";\n",
        "+  }\n",
        "+  std::string res = resolved_path.get();\n",
        "+  return res;\n",
        "+}\n",
        "+\n",
        "+char *ReadFile(const char *file, size_t *size) {\n",
        "+  if (file == nullptr) {\n",
        "+    MS_LOG(ERROR) << \"file is nullptr\";\n",
        "+    return nullptr;\n",
        "+  }\n",
        "+  //  MS_ASSERT(size != nullptr);\n",
        "+  std::string real_path = RealPath(file);\n",
        "+  std::ifstream ifs(real_path);\n",
        "+  if (!ifs.good()) {\n",
        "+    MS_LOG(ERROR) << \"file: \" << real_path << \" is not exist\";\n",
        "+    return nullptr;\n",
        "+  }\n",
        "+\n",
        "+  if (!ifs.is_open()) {\n",
        "+    MS_LOG(ERROR) << \"file: \" << real_path << \" open failed\";\n",
        "+    return nullptr;\n",
        "+  }\n",
        "+\n",
        "+  ifs.seekg(0, std::ios::end);\n",
        "+  *size = ifs.tellg();\n",
        "+  std::unique_ptr<char[]> buf(new (std::nothrow) char[*size]);\n",
        "+  if (buf == nullptr) {\n",
        "+    MS_LOG(ERROR) << \"malloc buf failed, file: \" << real_path;\n",
        "+    ifs.close();\n",
        "+    return nullptr;\n",
        "+  }\n",
        "+  ifs.seekg(0, std::ios::beg);\n",
        "+  ifs.read(buf.get(), *size);\n",
        "+  ifs.close();\n",
        "+\n",
        "+  return buf.release();\n",
        "+}\n",
        "+\n",
        "+// Set input tensors.\n",
        "+int fl_lite_SetInputs(const std::string &files, int num) {\n",
        "+  std::vector<std::string> res;\n",
        "+  if (files.empty()) {\n",
        "+    MS_LOG(ERROR) << \"files empty\";\n",
        "+    return -1;\n",
        "+  }\n",
        "+  std::string pattern = \",\";\n",
        "+  std::string strs = files + pattern;\n",
        "+  size_t pos = strs.find(pattern);\n",
        "+  while (pos != strs.npos) {\n",
        "+    std::string temp = strs.substr(0, pos);\n",
        "+    res.push_back(temp);\n",
        "+    strs = strs.substr(pos + 1, strs.size());\n",
        "+    pos = strs.find(pattern);\n",
        "+  }\n",
        "+  if (res.size() != 2) {\n",
        "+    MS_LOG(ERROR) << \"res size not equal 2\";\n",
        "+    return -1;\n",
        "+  }\n",
        "+  for (int i = 0; i < 2; i++) {\n",
        "+    size_t size;\n",
        "+    char *bin_buf = ReadFile(res[i].c_str(), &size);\n",
        "+    if (bin_buf == nullptr) {\n",
        "+      MS_LOG(ERROR) << \"ReadFile return nullptr\";\n",
        "+      return mindspore::lite::RET_ERROR;\n",
        "+    }\n",
        "+    if (i == 0) {\n",
        "+      fl_lenet_I0 = bin_buf;\n",
        "+    }\n",
        "+    if (i == 1) {\n",
        "+      fl_lenet_I1 = bin_buf;\n",
        "+    }\n",
        "+  }\n",
        "+  return 0;\n",
        "+}\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/lite_train.h b/mindspore/lite/flclient/src/main/native/lite_train.h\n",
        "new file mode 100644\n",
        "index 0000000..6ac7199\n",
        "--- /dev/null\n",
        "+++ b/mindspore/lite/flclient/src/main/native/lite_train.h\n",
        "@@ -0,0 +1,35 @@\n",
        "+/**\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "+ *\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "+ * you may not use this file except in compliance with the License.\n",
        "+ * You may obtain a copy of the License at\n",
        "+ *\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\n",
        "+ *\n",
        "+ * Unless required by applicable law or agreed to in writing, software\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "+ * See the License for the specific language governing permissions and\n",
        "+ * limitations under the License.\n",
        "+ */\n",
        "+\n",
        "+#ifndef MSLITE_FL_LITE_H\n",
        "+#define MSLITE_FL_LITE_H\n",
        "+\n",
        "+#include <string>\n",
        "+#include \"include/train/train_session.h\"\n",
        "+\n",
        "+using mindspore::session::TrainFeatureParam;\n",
        "+\n",
        "+int fl_lite_Train(const std::string &ms_file, const int batch_num, const int iterations);\n",
        "+\n",
        "+float fl_lite_Inference(const std::string &ms_file, int batch_num);\n",
        "+\n",
        "+int fl_lite_GetFeatures(const std::string &update_ms_file, mindspore::session::TrainFeatureParam ***features,\n",
        "+                              int *size);\n",
        "+int fl_lite_UpdateFeatures(const std::string &update_ms_file, TrainFeatureParam *new_features, int size);\n",
        "+mindspore::session::TrainSession *GetSession(const std::string &ms_file, bool train_mode = false);\n",
        "+\n",
        "+int fl_lite_SetInputs(const std::string &files, int num);\n",
        "+#endif  // MSLITE_FL_LITE_H\n",
        "diff --git a/mindspore/lite/flclient/src/main/native/lite_train_jni.cpp b/mindspore/lite/flclient/src/main/native/lite_train_jni.cpp\n",
        "new file mode 100644\n",
        "index 0000000..8829afd\n",
        "--- /dev/null\n",
        "+++ b/mindspore/lite/flclient/src/main/native/lite_train_jni.cpp\n",
        "@@ -0,0 +1,219 @@\n",
        "+/**\n",
        "+ * Copyright 2020 Huawei Technologies Co., Ltd\n",
        "+ *\n",
        "+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "+ * you may not use this file except in compliance with the License.\n",
        "+ * You may obtain a copy of the License at\n",
        "+ *\n",
        "+ * http://www.apache.org/licenses/LICENSE-2.0\n",
        "+ *\n",
        "+ * Unless required by applicable law or agreed to in writing, software\n",
        "+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "+ * See the License for the specific language governing permissions and\n",
        "+ * limitations under the License.\n",
        "+ */\n",
        "+\n",
        "+#include <jni.h>\n",
        "+#include <cstring>\n",
        "+#include \"include/errorcode.h\"\n",
        "+#include \"include/train/train_session.h\"\n",
        "+#include \"lite_train.h\"\n",
        "+#include \"src/common/log_adapter.h\"\n",
        "+\n",
        "+static jobject fbb;\n",
        "+static jmethodID create_string_char;\n",
        "+static jobject jmap;\n",
        "+\n",
        "+char *JstringToChar(JNIEnv *env, jstring jstr) {\n",
        "+  char *rtn = nullptr;\n",
        "+  jclass clsstring = env->FindClass(\"java/lang/String\");\n",
        "+  jstring strencode = env->NewStringUTF(\"GB2312\");\n",
        "+  jmethodID mid = env->GetMethodID(clsstring, \"getBytes\", \"(Ljava/lang/String;)[B\");\n",
        "+  jbyteArray barr = (jbyteArray)env->CallObjectMethod(jstr, mid, strencode);\n",
        "+  jsize alen = env->GetArrayLength(barr);\n",
        "+  jbyte *ba = env->GetByteArrayElements(barr, JNI_FALSE);\n",
        "+  if (alen > 0) {\n",
        "+    rtn = new char[alen + 1];\n",
        "+    memcpy(rtn, ba, alen);\n",
        "+    rtn[alen] = 0;\n",
        "+  }\n",
        "+  env->ReleaseByteArrayElements(barr, ba, 0);\n",
        "+  return rtn;\n",
        "+}\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_train(JNIEnv *env, jobject thiz, jstring ms_file,\n",
        "+                                                                           jint batch_num, jint iterations) {\n",
        "+  return fl_lite_Train(JstringToChar(env, ms_file), batch_num, iterations);\n",
        "+}\n",
        "+\n",
        "+extern \"C\" jint CreateFeatureMap(JNIEnv *env, const char *name, float *data, size_t size) {\n",
        "+  jstring name1 = env->NewStringUTF(name);\n",
        "+  jint name_offset = env->CallIntMethod(fbb, create_string_char, name1);\n",
        "+  // 1. set data size\n",
        "+  jfloatArray ret = env->NewFloatArray(size);\n",
        "+  env->SetFloatArrayRegion(ret, 0, size, data);\n",
        "+  // 2. get methodid createDataVector\n",
        "+  jclass fm_cls = env->FindClass(\"mindspore/schema/FeatureMap\");\n",
        "+  jmethodID createDataVector =\n",
        "+    env->GetStaticMethodID(fm_cls, \"createDataVector\", \"(Lcom/google/flatbuffers/FlatBufferBuilder;[F)I\");\n",
        "+  // 3. calc data offset\n",
        "+  jint data_offset = env->CallStaticIntMethod(fm_cls, createDataVector, fbb, ret);\n",
        "+  jmethodID createFeatureMap =\n",
        "+    env->GetStaticMethodID(fm_cls, \"createFeatureMap\", \"(Lcom/google/flatbuffers/FlatBufferBuilder;II)I\");\n",
        "+  jint fm_offset = env->CallStaticIntMethod(fm_cls, createFeatureMap, fbb, name_offset, data_offset);\n",
        "+  return fm_offset;\n",
        "+}\n",
        "+\n",
        "+extern \"C\" JNIEXPORT jobject JNICALL Java_com_huawei_flclient_LiteTrain_getFeaturesMap(JNIEnv *env, jobject thiz, jstring ms_file) {\n",
        "+\n",
        "+\n",
        "+  jclass strClass = env->FindClass(\"java/lang/String\");\n",
        "+  jmethodID ctorID = env->GetMethodID(strClass, \"<init>\", \"([BLjava/lang/String;)V\");\n",
        "+  jstring encoding = env->NewStringUTF(\"GB2312\");\n",
        "+\n",
        "+  TrainFeatureParam **train_features = nullptr;\n",
        "+  int feature_size = 0;\n",
        "+  auto status = fl_lite_GetFeatures(JstringToChar(env, ms_file), &train_features, &feature_size);\n",
        "+  if (status != mindspore::lite::RET_OK) {\n",
        "+    MS_LOG(ERROR) << \"get features failed:\" << ms_file;\n",
        "+    return NULL;\n",
        "+  }\n",
        "+  jclass jmapClass = env->FindClass(\"java/util/HashMap\");\n",
        "+  if (jmapClass == NULL) {\n",
        "+    return NULL;\n",
        "+  }\n",
        "+  jmethodID mid = env->GetMethodID(jmapClass, \"<init>\", \"()V\");\n",
        "+  jmethodID putMethod = env->GetMethodID(jmapClass, \"put\", \"(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;\");\n",
        "+  jmethodID getMethod = env->GetMethodID(jmapClass, \"get\", \"(Ljava/lang/Object;)Ljava/lang/Object;\");\n",
        "+  bool map_exist = true;\n",
        "+  if(jmap == nullptr) {\n",
        "+   jmap = env->NewGlobalRef(env->NewObject(jmapClass, mid, feature_size));\n",
        "+   map_exist = false;\n",
        "+  }\n",
        "+  for (int i = 0; i < feature_size; i++) {\n",
        "+    jbyteArray bytes = env->NewByteArray(strlen(train_features[i]->name));\n",
        "+    env->SetByteArrayRegion(bytes, 0, strlen(train_features[i]->name), (jbyte *)train_features[i]->name);\n",
        "+    auto key =  (jstring)env->NewObject(strClass, ctorID, bytes, encoding);\n",
        "+    jfloatArray feature_data;\n",
        "+    if(map_exist) {\n",
        "+      feature_data = static_cast<jfloatArray>(env->CallObjectMethod(jmap, getMethod, key));\n",
        "+    } else {\n",
        "+     feature_data = env->NewFloatArray(train_features[i]->elenums);\n",
        "+    }\n",
        "+    if(feature_data == nullptr) {\n",
        "+      std::cout<< \"create null feature data\"<<std::endl;\n",
        "+    }\n",
        "+    jfloat* fd = env->GetFloatArrayElements( feature_data,NULL);\n",
        "+    for(int j=0;j<train_features[i]->elenums;j++) {\n",
        "+      fd[j] =  reinterpret_cast<float *>(train_features[i]->data)[j];\n",
        "+    }\n",
        "+    env->ReleaseFloatArrayElements(feature_data, fd, 0);\n",
        "+    env->CallObjectMethod(jmap, putMethod,key, feature_data);\n",
        "+    env->DeleteLocalRef(bytes);\n",
        "+    env->DeleteLocalRef(key);\n",
        "+  }\n",
        "+  env->DeleteLocalRef(encoding);\n",
        "+  for (int i = 0; i < feature_size; i++) {\n",
        "+    delete train_features[i]->name;\n",
        "+    free (train_features[i]->data);\n",
        "+    delete train_features[i];\n",
        "+  }\n",
        "+  return jmap;\n",
        "+}\n",
        "+\n",
        "+extern \"C\" JNIEXPORT jintArray JNICALL Java_com_huawei_flclient_LiteTrain_getSeralizeFeaturesMap(JNIEnv *env, jobject thiz,\n",
        "+                                                                                         jstring ms_file,\n",
        "+                                                                                         jobject builder) {\n",
        "+  fbb = builder;\n",
        "+  jclass fb_clazz = env->GetObjectClass(builder);\n",
        "+  create_string_char = env->GetMethodID(fb_clazz, \"createString\", \"(Ljava/lang/CharSequence;)I\");\n",
        "+  TrainFeatureParam **train_features = nullptr;\n",
        "+  int feature_size = 0;\n",
        "+  auto status = fl_lite_GetFeatures(JstringToChar(env, ms_file), &train_features, &feature_size);\n",
        "+  if (status != mindspore::lite::RET_OK) {\n",
        "+    MS_LOG(ERROR) << \"get features failed:\" << ms_file;\n",
        "+    return env->NewIntArray(0);\n",
        "+  }\n",
        "+  jintArray ret = env->NewIntArray(feature_size);\n",
        "+  jint *data = env->GetIntArrayElements(ret, NULL);\n",
        "+\n",
        "+  for (int i = 0; i < feature_size; i++) {\n",
        "+    data[i] = CreateFeatureMap(env, train_features[i]->name, reinterpret_cast<float *>(train_features[i]->data),\n",
        "+                               train_features[i]->elenums);\n",
        "+    MS_LOG(INFO) << \"upload feature:\"\n",
        "+                 << \", name:\" << train_features[i]->name << \", elenums:\" << train_features[i]->elenums;\n",
        "+  }\n",
        "+  env->ReleaseIntArrayElements(ret, data, 0);\n",
        "+  for (int i = 0; i < feature_size; i++) {\n",
        "+    delete train_features[i]->name;\n",
        "+    free (train_features[i]->data);\n",
        "+   delete train_features[i];\n",
        "+  }\n",
        "+  return ret;\n",
        "+}\n",
        "+\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_updateFeatures(JNIEnv *env, jobject,\n",
        "+                                                                                    jstring ms_file, jobject features) {\n",
        "+  jclass arr_cls = env->GetObjectClass(features);\n",
        "+  jmethodID size_method = env->GetMethodID(arr_cls, \"size\", \"()I\");\n",
        "+  jmethodID get_method = env->GetMethodID(arr_cls, \"get\", \"(I)Ljava/lang/Object;\");\n",
        "+\n",
        "+  jclass fm_cls = env->FindClass(\"mindspore/schema/FeatureMap\");\n",
        "+  jmethodID weight_name_method = env->GetMethodID(fm_cls, \"weightFullname\", \"()Ljava/lang/String;\");\n",
        "+  jmethodID data_length_method = env->GetMethodID(fm_cls, \"dataLength\", \"()I\");\n",
        "+  jmethodID data_method = env->GetMethodID(fm_cls, \"data\", \"(I)F\");\n",
        "+  jclass clsstring = env->FindClass(\"java/lang/String\");\n",
        "+  jmethodID mid = env->GetMethodID(clsstring, \"getBytes\", \"(Ljava/lang/String;)[B\");\n",
        "+  int size = env->CallIntMethod(features, size_method);\n",
        "+  // transform FeatureMap to TrainFeatureParm\n",
        "+  TrainFeatureParam *features_param = reinterpret_cast<TrainFeatureParam *>(malloc(size * sizeof(TrainFeatureParam)));\n",
        "+  for (int i = 0; i < size; ++i) {\n",
        "+    TrainFeatureParam *param = features_param + i;\n",
        "+    jobject feature = env->CallObjectMethod(features, get_method, i);\n",
        "+    // set feature_param name\n",
        "+    jstring weight_full_name = (jstring)env->CallObjectMethod(feature, weight_name_method);\n",
        "+    jstring strencode = env->NewStringUTF(\"GB2312\");\n",
        "+    jbyteArray barr = (jbyteArray)env->CallObjectMethod(weight_full_name, mid, strencode);\n",
        "+    char *name = nullptr;\n",
        "+    jsize alen = env->GetArrayLength(barr);\n",
        "+    jbyte *ba = env->GetByteArrayElements(barr, JNI_FALSE);\n",
        "+    if (alen > 0) {\n",
        "+      name = new char[alen + 1];\n",
        "+      if (ba == nullptr) {\n",
        "+        MS_LOG(ERROR) << \"name is nullptr\";\n",
        "+        return mindspore::lite::RET_ERROR;\n",
        "+      }\n",
        "+      memcpy(name, ba, alen);\n",
        "+      name[alen] = 0;\n",
        "+    }\n",
        "+    param->name = name;\n",
        "+    env->ReleaseByteArrayElements(barr, ba, 0);\n",
        "+    int data_length = env->CallIntMethod(feature, data_length_method);\n",
        "+    float *data = static_cast<float *>(malloc(data_length * sizeof(float)));\n",
        "+    memset(data, 0, data_length * sizeof(float));\n",
        "+    for (int j = 0; j < data_length; ++j) {\n",
        "+      float *addr = data + j;\n",
        "+      *addr = env->CallFloatMethod(feature, data_method, j);\n",
        "+    }\n",
        "+    param->data = data;\n",
        "+    param->elenums = data_length;\n",
        "+    param->type = mindspore::kNumberTypeFloat32;\n",
        "+    MS_LOG(INFO) << \"get feature:\" << param->name << \",elenums:\" << param->elenums;\n",
        "+  }\n",
        "+  return fl_lite_UpdateFeatures(JstringToChar(env, ms_file), features_param, size);\n",
        "+}\n",
        "+\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_setInput(JNIEnv *env, jobject, jstring files,\n",
        "+                                                                              jint nums) {\n",
        "+  return fl_lite_SetInputs(JstringToChar(env, files), nums);\n",
        "+}\n",
        "+\n",
        "+extern \"C\" JNIEXPORT jfloat JNICALL Java_com_huawei_flclient_LiteTrain_inference(JNIEnv *env, jobject, jstring ms_file,\n",
        "+                                                                               jint batch_num) {\n",
        "+  return fl_lite_Inference(JstringToChar(env, ms_file), batch_num);\n",
        "+}\n",
        "+\n",
        "+extern \"C\" JNIEXPORT jint JNICALL Java_com_huawei_flclient_LiteTrain_free(JNIEnv * env, jobject) {\n",
        "+  env->DeleteGlobalRef(jmap);\n",
        "+  jmap = NULL;\n",
        "+  return 0; }\n",
        "diff --git a/mindspore/lite/include/train/train_session.h b/mindspore/lite/include/train/train_session.h\n",
        "index 97a80b3..437e027 100644\n",
        "--- a/mindspore/lite/include/train/train_session.h\n",
        "+++ b/mindspore/lite/include/train/train_session.h\n",
        "@@ -24,6 +24,13 @@\n",
        " namespace mindspore {\n",
        " namespace session {\n",
        " \n",
        "+struct TrainFeatureParam{\n",
        "+  char* name;\n",
        "+  void *data;\n",
        "+  size_t elenums;\n",
        "+  enum TypeId type;\n",
        "+};\n",
        "+\n",
        " /// \\brief TrainSession Defines a class that allows training a MindSpore model\n",
        " class TrainSession : public session::LiteSession {\n",
        "  public:\n",
        "@@ -142,6 +149,10 @@ class TrainSession : public session::LiteSession {\n",
        "     return mindspore::lite::RET_OK;\n",
        "   }\n",
        " \n",
        "+  virtual int GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *>* feature_maps) =0;\n",
        "+\n",
        "+  virtual int UpdateFeatureMaps(const std::string &update_ms_file,\n",
        "+                                TrainFeatureParam* new_features,int size) =0;\n",
        "  protected:\n",
        "   bool train_mode_ = false;\n",
        "   std::string get_loss_name() const { return loss_name_; }\n",
        "diff --git a/mindspore/lite/nnacl/infer/arithmetic_grad_infer.c b/mindspore/lite/nnacl/infer/arithmetic_grad_infer.c\n",
        "index a6d85ca..ed00572 100644\n",
        "--- a/mindspore/lite/nnacl/infer/arithmetic_grad_infer.c\n",
        "+++ b/mindspore/lite/nnacl/infer/arithmetic_grad_infer.c\n",
        "@@ -103,4 +103,3 @@ int ArithmeticGradInferShape(const TensorC *const *inputs, size_t inputs_size, T\n",
        " \n",
        " REG_INFER(DivGrad, PrimType_DivGrad, ArithmeticGradInferShape)\n",
        " REG_INFER(MulGrad, PrimType_MulGrad, ArithmeticGradInferShape)\n",
        "-REG_INFER(MinimumGrad, PrimType_MinimumGrad, ArithmeticGradInferShape)\n",
        "diff --git a/mindspore/lite/nnacl/infer/maximum_grad_infer.c b/mindspore/lite/nnacl/infer/maximum_grad_infer.c\n",
        "index c06774e..a72de16 100644\n",
        "--- a/mindspore/lite/nnacl/infer/maximum_grad_infer.c\n",
        "+++ b/mindspore/lite/nnacl/infer/maximum_grad_infer.c\n",
        "@@ -61,3 +61,4 @@ int MaximumGradInferShape(const TensorC *const *inputs, size_t inputs_size, Tens\n",
        " }\n",
        " \n",
        " REG_INFER(MaximumGrad, PrimType_MaximumGrad, MaximumGradInferShape)\n",
        "+REG_INFER(MinimumGrad, PrimType_MinimumGrad, MaximumGradInferShape)\n",
        "diff --git a/mindspore/lite/src/train/train_session.cc b/mindspore/lite/src/train/train_session.cc\n",
        "index 34d5ef2..d468459 100644\n",
        "--- a/mindspore/lite/src/train/train_session.cc\n",
        "+++ b/mindspore/lite/src/train/train_session.cc\n",
        "@@ -22,6 +22,7 @@\n",
        " #include <iostream>\n",
        " #include <fstream>\n",
        " #include <memory>\n",
        "+#include <cstring>\n",
        " #include \"include/errorcode.h\"\n",
        " #include \"src/common/utils.h\"\n",
        " #include \"src/tensor.h\"\n",
        "@@ -228,7 +229,7 @@ int TrainSession::SaveToFile(const std::string &filename) const {\n",
        "   ofs.seekp(0, std::ios::beg);\n",
        "   ofs.write(buf, fb_size);\n",
        "   ofs.close();\n",
        "-  return chmod(filename.c_str(), S_IRUSR);\n",
        "+  return chmod(filename.c_str(), S_IRWXU);\n",
        " }\n",
        " \n",
        " int TrainSession::Train() {\n",
        "@@ -518,6 +519,60 @@ int TrainSession::SetLossName(std::string loss_name) {\n",
        "   }\n",
        "   return RET_OK;\n",
        " }\n",
        "+\n",
        "+int TrainSession::GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *> *feature_maps) {\n",
        "+  for (auto tensor : this->tensors_) {\n",
        "+    if (tensor->IsConst()) {\n",
        "+      auto param = new mindspore::session::TrainFeatureParam();\n",
        "+      int len = tensor->tensor_name().length();\n",
        "+      char* name = nullptr;\n",
        "+      if(len>0) {\n",
        "+        name = new char[len+1];\n",
        "+        memcpy(name, tensor->tensor_name().c_str(), len);\n",
        "+        name[len] = 0;\n",
        "+      }\n",
        "+      param->name =  name;\n",
        "+//      param->data = new float[tensor->ElementsNum()];\n",
        "+      param->data = malloc(tensor->ElementsNum() * sizeof(float));\n",
        "+      memcpy(param->data, tensor->data_c(), tensor->ElementsNum()*sizeof(float));\n",
        "+      param->elenums = tensor->ElementsNum();\n",
        "+      param->type = tensor->data_type();\n",
        "+      feature_maps->push_back(param);\n",
        "+    }\n",
        "+  }\n",
        "+  MS_LOG(INFO) << \"get feature map success\";\n",
        "+  return RET_OK;\n",
        "+}\n",
        "+int TrainSession::UpdateFeatureMaps(const std::string &update_ms_file,\n",
        "+                                    mindspore::session::TrainFeatureParam *new_features, int size) {\n",
        "+  bool find = false;\n",
        "+  for (int i = 0; i < size; ++i) {\n",
        "+    mindspore::session::TrainFeatureParam *new_feature = new_features + i;\n",
        "+    for (auto tensor : this->tensors_) {\n",
        "+      if (!tensor->IsConst()) {\n",
        "+        continue;\n",
        "+      }\n",
        "+\n",
        "+      if (strcmp(tensor->tensor_name().c_str(), new_feature->name) == 0) {\n",
        "+        if (tensor->ElementsNum() != static_cast<int>(new_feature->elenums)) {\n",
        "+          MS_LOG(ERROR) << \"feature name:\" << tensor->tensor_name() << \",len diff:\"\n",
        "+                        << \"old is:\" << new_feature->elenums << \"new is:\" << new_feature->elenums;\n",
        "+          return RET_ERROR;\n",
        "+        }\n",
        "+        find = true;\n",
        "+        memcpy(tensor->data_c(), new_feature->data, new_feature->elenums * sizeof(float));\n",
        "+        break;\n",
        "+      }\n",
        "+    }\n",
        "+    if (!find) {\n",
        "+      MS_LOG(ERROR) << \"cannot find feature:\" << new_feature->name << \",update failed\";\n",
        "+      return RET_ERROR;\n",
        "+    }\n",
        "+  }\n",
        "+  SaveToFile(update_ms_file);\n",
        "+  MS_LOG(INFO) << \"update model:\" << update_ms_file << \",feature map success\";\n",
        "+  return RET_OK;\n",
        "+}\n",
        " }  // namespace lite\n",
        " \n",
        " session::TrainSession *session::TrainSession::CreateSession(const char *model_buf, size_t size, lite::Context *context,\n",
        "diff --git a/mindspore/lite/src/train/train_session.h b/mindspore/lite/src/train/train_session.h\n",
        "index 69e73e8..24fae33 100644\n",
        "--- a/mindspore/lite/src/train/train_session.h\n",
        "+++ b/mindspore/lite/src/train/train_session.h\n",
        "@@ -92,6 +92,10 @@ class TrainSession : virtual public session::TrainSession, virtual public lite::\n",
        "     return outputs;\n",
        "   }\n",
        " \n",
        "+  int GetFeatureMaps(std::vector<mindspore::session::TrainFeatureParam *> *feature_maps) override;\n",
        "+  int UpdateFeatureMaps(const std::string &update_ms_file,\n",
        "+                        mindspore::session::TrainFeatureParam* new_features,int size) override;\n",
        "+\n",
        "  protected:\n",
        "   void AllocWorkSpace();\n",
        "   bool IsLossKernel(const kernel::LiteKernel *kernel) const;\n",
        "-- \n",
        "2.7.4\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}